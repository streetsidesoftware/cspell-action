import { builtinModules, createRequire } from "node:module";
import * as Path from "node:path";
import path, { isAbsolute, posix, relative, resolve, sep } from "node:path";
import * as nativeFs$1 from "fs";
import nativeFs, { existsSync, readFileSync } from "fs";
import * as os$3 from "os";
import os, { EOL } from "os";
import crypto from "node:crypto";
import fs, { constants, promises, readFileSync as readFileSync$1, realpathSync, statSync } from "node:fs";
import * as os$2 from "node:os";
import os$1, { homedir } from "node:os";
import fs$1, { access, appendFile, readFile, stat, writeFile } from "node:fs/promises";
import { exec } from "node:child_process";
import { format, formatWithOptions, inspect, promisify, stripVTControlCharacters } from "node:util";
import * as path$6 from "path";
import path$1, { basename, dirname, normalize, posix as posix$1, relative as relative$1, resolve as resolve$1, sep as sep$1 } from "path";
import { fileURLToPath, pathToFileURL } from "node:url";
import assert from "node:assert";
import process$1 from "node:process";
import v8 from "node:v8";
import { createRequire as createRequire$1 } from "module";
import { Buffer as Buffer$1 } from "node:buffer";
import { gunzipSync, gzip } from "node:zlib";
import * as Stream from "node:stream";
import { extname } from "node:path/posix";
import tty from "node:tty";
import streamConsumers from "node:stream/consumers";
import { fileURLToPath as fileURLToPath$1 } from "url";
import * as readline from "node:readline";

//#region rolldown:runtime
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __commonJSMin = (cb, mod) => () => (mod || cb((mod = { exports: {} }).exports, mod), mod.exports);
var __exportAll = (all, symbols) => {
	let target = {};
	for (var name in all) {
		__defProp(target, name, {
			get: all[name],
			enumerable: true
		});
	}
	if (symbols) {
		__defProp(target, Symbol.toStringTag, { value: "Module" });
	}
	return target;
};
var __copyProps = (to, from, except, desc) => {
	if (from && typeof from === "object" || typeof from === "function") {
		for (var keys = __getOwnPropNames(from), i = 0, n = keys.length, key; i < n; i++) {
			key = keys[i];
			if (!__hasOwnProp.call(to, key) && key !== except) {
				__defProp(to, key, {
					get: ((k) => from[k]).bind(null, key),
					enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
				});
			}
		}
	}
	return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", {
	value: mod,
	enumerable: true
}) : target, mod));
var __require$1 = /* @__PURE__ */ createRequire(import.meta.url);

//#endregion
//#region src/error.ts
var AppError = class extends Error {
	constructor(message) {
		super(message);
	}
};
/**
* Convert an unknown value to an error
* @param e - the unknown error
* @returns Error
*/
function toError$5(e) {
	if (e instanceof Error) return e;
	if (typeof e === "string") return new Error(e);
	return new Error("Unknown error", { cause: e });
}

//#endregion
//#region src/ActionParams.ts
const defaultActionParams = {
	files: "",
	incremental_files_only: "true",
	config: "",
	root: "",
	inline: "warning",
	treat_flagged_words_as_errors: "false",
	strict: "true",
	verbose: "false",
	check_dot_files: "explicit",
	use_cspell_files: "false",
	suggestions: "false",
	report: void 0,
	summary: "false"
};
function applyDefaults(params) {
	const results = {
		...defaultActionParams,
		...params
	};
	const alias = results;
	for (const [key, value] of Object.entries(defaultActionParams)) alias[key] = alias[key] || value;
	return results;
}
function validateConfig(params) {
	const config = params.config;
	return !(!config || existsSync(config)) ? `Configuration file "${config}" not found.` : void 0;
}
function validateRoot(params) {
	const root = params.root;
	return !(!root || existsSync(root)) ? `Root path does not exist: "${root}"` : void 0;
}
function validateTrueFalse(key) {
	return validateOptions(key, ["true", "false"]);
}
function validateOptions(key, options, optional) {
	return (params) => {
		const value = params[key];
		if (optional && !value) return;
		return !options.includes(value) ? `Invalid ${key} setting, must be one of (${options.join(", ")})` : void 0;
	};
}
function validateActionParams(params, logError) {
	if (![
		validateConfig,
		validateRoot,
		validateOptions("inline", [
			"error",
			"warning",
			"none"
		]),
		validateTrueFalse("treat_flagged_words_as_errors"),
		validateTrueFalse("strict"),
		validateTrueFalse("incremental_files_only"),
		validateTrueFalse("verbose"),
		validateTrueFalse("use_cspell_files"),
		validateTrueFalse("suggestions"),
		validateOptions("check_dot_files", [
			"true",
			"false",
			"explicit"
		]),
		validateOptions("report", [
			"all",
			"simple",
			"typos",
			"flagged"
		], true),
		validateTrueFalse("summary")
	].map((fn) => fn(params)).map((msg) => !msg || (logError(msg), false)).reduce((a, b) => a && b, true)) throw new AppError("Bad Configuration.");
}

//#endregion
//#region src/actions/core/utils.ts
/**
* Sanitizes an input into a string so it can be passed into issueCommand safely
* @param input input to sanitize into a string
*/
function toCommandValue(input) {
	if (input === null || input === void 0) return "";
	else if (typeof input === "string" || input instanceof String) return input;
	return JSON.stringify(input);
}
/**
*
* @param annotationProperties
* @returns The command properties to send with the actual annotation command
* See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646
*/
function toCommandProperties(annotationProperties) {
	if (!Object.keys(annotationProperties).length) return {};
	return {
		title: annotationProperties.title,
		file: annotationProperties.file,
		line: annotationProperties.startLine,
		endLine: annotationProperties.endLine,
		col: annotationProperties.startColumn,
		endColumn: annotationProperties.endColumn
	};
}

//#endregion
//#region src/actions/core/command.ts
/**
* Issues a command to the GitHub Actions runner
*
* @param command - The command name to issue
* @param properties - Additional properties for the command (key-value pairs)
* @param message - The message to include with the command
* @remarks
* This function outputs a specially formatted string to stdout that the Actions
* runner interprets as a command. These commands can control workflow behavior,
* set outputs, create annotations, mask values, and more.
*
* Command Format:
*   ::name key=value,key=value::message
*
* @example
* ```typescript
* // Issue a warning annotation
* issueCommand('warning', {}, 'This is a warning message');
* // Output: ::warning::This is a warning message
*
* // Set an environment variable
* issueCommand('set-env', { name: 'MY_VAR' }, 'some value');
* // Output: ::set-env name=MY_VAR::some value
*
* // Add a secret mask
* issueCommand('add-mask', {}, 'secretValue123');
* // Output: ::add-mask::secretValue123
* ```
*
* @internal
* This is an internal utility function that powers the public API functions
* such as setSecret, warning, error, and exportVariable.
*/
function issueCommand(command, properties, message) {
	const cmd = formatCommand(command, properties, message);
	process.stdout.write(cmd + os$3.EOL);
}
function formatCommand(command, properties, message) {
	return new Command(command, properties, message).toString();
}
const CMD_STRING = "::";
var Command = class {
	command;
	message;
	properties;
	constructor(command, properties, message) {
		if (!command) command = "missing.command";
		this.command = command;
		this.properties = properties;
		this.message = message;
	}
	toString() {
		let cmdStr = CMD_STRING + this.command;
		if (this.properties && Object.keys(this.properties).length > 0) {
			cmdStr += " ";
			let first = true;
			for (const [key, val] of Object.entries(this.properties)) if (val) {
				if (first) first = false;
				else cmdStr += ",";
				cmdStr += `${key}=${escapeProperty(val)}`;
			}
		}
		cmdStr += `${CMD_STRING}${escapeData(this.message)}`;
		return cmdStr;
	}
};
function escapeData(s) {
	return toCommandValue(s).replace(/%/g, "%25").replace(/\r/g, "%0D").replace(/\n/g, "%0A");
}
function escapeProperty(s) {
	return toCommandValue(s).replace(/%/g, "%25").replace(/\r/g, "%0D").replace(/\n/g, "%0A").replace(/:/g, "%3A").replace(/,/g, "%2C");
}

//#endregion
//#region src/actions/core/coreTypes.ts
/**
* The code to exit an action
*/
let ExitCode = /* @__PURE__ */ function(ExitCode) {
	/**
	* A code indicating that the action was successful
	*/
	ExitCode[ExitCode["Success"] = 0] = "Success";
	/**
	* A code indicating that the action was a failure
	*/
	ExitCode[ExitCode["Failure"] = 1] = "Failure";
	return ExitCode;
}({});

//#endregion
//#region src/actions/core/file-command.ts
function issueFileCommand(command, message) {
	const filePath = process.env[`GITHUB_${command}`];
	if (!filePath) throw new Error(`Unable to find environment variable for file command ${command}`);
	if (!fs.existsSync(filePath)) throw new Error(`Missing file at path: ${filePath}`);
	fs.appendFileSync(filePath, `${toCommandValue(message)}${os$1.EOL}`, { encoding: "utf8" });
}
function prepareKeyValueMessage(key, value) {
	const delimiter = `ghadelimiter_${crypto.randomUUID()}`;
	const convertedValue = toCommandValue(value);
	return `${key}<<${delimiter}${os$1.EOL}${convertedValue}${os$1.EOL}${delimiter}`;
}

//#endregion
//#region src/actions/core/core.ts
/**
* Gets the value of an input.
* Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.
* Returns an empty string if the value is not defined.
*
* @param     name     name of the input to get
* @param     options  optional. See InputOptions.
* @returns   string
*/
function getInput(name, options) {
	const val = process.env[`INPUT_${name.replace(/ /g, "_").toUpperCase()}`] || "";
	if (options?.required && !val) throw new Error(`Input required and not supplied: ${name}`);
	if (options?.trimWhitespace === false) return val;
	return val.trim();
}
/**
* Sets the value of an output.
*
* @param     name     name of the output to set
* @param     value    value to store. Non-string values will be converted to a string via JSON.stringify
*/
function setOutput(name, value) {
	if (process.env["GITHUB_OUTPUT"] || "") return issueFileCommand("OUTPUT", prepareKeyValueMessage(name, value));
	process.stdout.write(os$3.EOL);
	issueCommand("set-output", { name }, toCommandValue(value));
}
/**
* Sets the action status to failed.
* When the action exits it will be with an exit code of 1
* @param message add error issue message
*/
function setFailed(message) {
	process.exitCode = ExitCode.Failure;
	error(message);
}
/**
* Writes debug message to user log
* @param message debug message
*/
function debug$1(message) {
	issueCommand("debug", {}, message);
}
/**
* Adds an error issue
* @param message error issue message. Errors will be converted to string via toString()
* @param properties optional properties to add to the annotation.
*/
function error(message, properties = {}) {
	issueCommand("error", toCommandProperties(properties), message instanceof Error ? message.toString() : message);
}
/**
* Adds a warning issue
* @param message warning issue message. Errors will be converted to string via toString()
* @param properties optional properties to add to the annotation.
*/
function warning(message, properties = {}) {
	issueCommand("warning", toCommandProperties(properties), message instanceof Error ? message.toString() : message);
}
/**
* Writes info to log with console.log.
* @param message info message
*/
function info(message) {
	process.stdout.write(message + os$3.EOL);
}

//#endregion
//#region src/actions/core/summary.ts
const SUMMARY_ENV_VAR = "GITHUB_STEP_SUMMARY";
var Summary = class {
	_buffer;
	_filePath;
	constructor() {
		this._buffer = "";
	}
	/**
	* Finds the summary file path from the environment, rejects if env var is not found or file does not exist
	* Also checks r/w permissions.
	*
	* @returns step summary file path
	*/
	async filePath() {
		if (this._filePath) return this._filePath;
		const pathFromEnv = process.env[SUMMARY_ENV_VAR];
		if (!pathFromEnv) throw new Error(`Unable to find environment variable for $${SUMMARY_ENV_VAR}. Check if your runtime environment supports job summaries.`);
		try {
			await access(pathFromEnv, constants.R_OK | constants.W_OK);
		} catch {
			throw new Error(`Unable to access summary file: '${pathFromEnv}'. Check if the file has correct read/write permissions.`);
		}
		this._filePath = pathFromEnv;
		return this._filePath;
	}
	/**
	* Writes text in the buffer to the summary buffer file and empties buffer. Will append by default.
	*
	* @param (optional) options for write operation
	*
	* @returns summary instance
	*/
	async write(options) {
		const overwrite = !!options?.overwrite;
		const filePath = await this.filePath();
		await (overwrite ? writeFile : appendFile)(filePath, this._buffer, { encoding: "utf8" });
		return this.emptyBuffer();
	}
	/**
	* Resets the summary buffer without writing to summary file
	*
	* @returns summary instance
	*/
	emptyBuffer() {
		this._buffer = "";
		return this;
	}
	/**
	* Adds raw text to the summary buffer
	*
	* @param text content to add
	* @param (optional) append an EOL to the raw text (default: false)
	*
	* @returns summary instance
	*/
	addRaw(text) {
		this._buffer += text;
		return this;
	}
};
const summary$1 = new Summary();

//#endregion
//#region src/checkDotMap.ts
const checkDotMap = {
	true: true,
	false: false,
	explicit: void 0
};

//#endregion
//#region src/git.ts
const execP = promisify(exec);
async function gitListCommits(count = 100, _since) {
	return (await runGit([
		"rev-list",
		"HEAD",
		`-${count}`
	])).split("\n").map((a) => a.trim()).filter((a) => !!a);
}
async function gitDeepen(count) {
	await runGit(["fetch", `--deepen=${count}`]);
}
async function gitListFiles(sha1, sha2) {
	const SHAs = [sha1, sha2].map(cleanSha).filter((a) => !!a);
	if (!SHAs.length) return [];
	return (await runGit([
		"diff-tree",
		"--no-commit-id",
		"--name-only",
		"-r",
		...SHAs
	])).split("\n").map((a) => a.trim()).filter((a) => !!a);
}
async function gitRoot() {
	return (await runGit(["rev-parse", "--show-toplevel"])).trim();
}
function cleanSha(sha) {
	if (!sha) return "";
	if (["HEAD"].includes(sha)) return sha;
	return sha.trim().replace(/[^a-fA-F0-9]/g, "").replace(/^0+$/, "");
}
async function gitListFilesForPullRequest(pr) {
	const event = pr;
	const sha1 = pr?.pull_request?.base?.sha || event?.before;
	const sha2 = event?.after || pr?.pull_request?.head?.sha;
	if (!sha1 || !sha2 || !pr.pull_request) throw new GitError(`Invalid PR event base.sha: ${sha1}, head.sha: ${sha2}`);
	const commitCount = pr.pull_request.commits || 0;
	try {
		await deepenIfNecessary(commitCount + 1);
		return gitListFiles(sha1, sha2);
	} catch (e) {
		throw new GitError(`Error getting files for PR ${pr?.number} from git`, e);
	}
}
async function gitListFilesForPush(push) {
	try {
		await deepenIfNecessary((push.commits?.length || 0) + 1);
		return gitListFiles(push.before, push.after);
	} catch (e) {
		throw new GitError(`Error getting files for Push, (Commit: ${push?.after}) from git`, e);
	}
}
async function deepenIfNecessary(commitCount) {
	if ((await gitListCommits(commitCount)).length < commitCount) await gitDeepen(commitCount);
}
var GitError = class extends Error {
	constructor(message, cause) {
		super(message);
		this.cause = cause;
		this.name = "GitError";
	}
};
async function runGit(args) {
	const { stdout } = await execP(`git ${args.join(" ")}`);
	return stdout;
}

//#endregion
//#region src/logger.ts
const defaultLogger = createLogger();
function summary(message) {
	summary$1.addRaw(message);
	summary$1.write();
}
function createLogger(logger) {
	return {
		debug: debug$1,
		info,
		warning,
		error,
		issueCommand,
		summary,
		...logger
	};
}
function getDefaultLogger() {
	return defaultLogger;
}

//#endregion
//#region ../node_modules/.pnpm/vscode-uri@3.1.0/node_modules/vscode-uri/lib/esm/index.mjs
var LIB;
(() => {
	"use strict";
	var t = { 975: (t) => {
		function e(t) {
			if ("string" != typeof t) throw new TypeError("Path must be a string. Received " + JSON.stringify(t));
		}
		function r(t, e) {
			for (var r, n = "", i = 0, o = -1, s = 0, h = 0; h <= t.length; ++h) {
				if (h < t.length) r = t.charCodeAt(h);
				else {
					if (47 === r) break;
					r = 47;
				}
				if (47 === r) {
					if (o === h - 1 || 1 === s);
					else if (o !== h - 1 && 2 === s) {
						if (n.length < 2 || 2 !== i || 46 !== n.charCodeAt(n.length - 1) || 46 !== n.charCodeAt(n.length - 2)) {
							if (n.length > 2) {
								var a = n.lastIndexOf("/");
								if (a !== n.length - 1) {
									-1 === a ? (n = "", i = 0) : i = (n = n.slice(0, a)).length - 1 - n.lastIndexOf("/"), o = h, s = 0;
									continue;
								}
							} else if (2 === n.length || 1 === n.length) {
								n = "", i = 0, o = h, s = 0;
								continue;
							}
						}
						e && (n.length > 0 ? n += "/.." : n = "..", i = 2);
					} else n.length > 0 ? n += "/" + t.slice(o + 1, h) : n = t.slice(o + 1, h), i = h - o - 1;
					o = h, s = 0;
				} else 46 === r && -1 !== s ? ++s : s = -1;
			}
			return n;
		}
		var n = {
			resolve: function() {
				for (var t, n = "", i = !1, o = arguments.length - 1; o >= -1 && !i; o--) {
					var s;
					o >= 0 ? s = arguments[o] : (void 0 === t && (t = process.cwd()), s = t), e(s), 0 !== s.length && (n = s + "/" + n, i = 47 === s.charCodeAt(0));
				}
				return n = r(n, !i), i ? n.length > 0 ? "/" + n : "/" : n.length > 0 ? n : ".";
			},
			normalize: function(t) {
				if (e(t), 0 === t.length) return ".";
				var n = 47 === t.charCodeAt(0), i = 47 === t.charCodeAt(t.length - 1);
				return 0 !== (t = r(t, !n)).length || n || (t = "."), t.length > 0 && i && (t += "/"), n ? "/" + t : t;
			},
			isAbsolute: function(t) {
				return e(t), t.length > 0 && 47 === t.charCodeAt(0);
			},
			join: function() {
				if (0 === arguments.length) return ".";
				for (var t, r = 0; r < arguments.length; ++r) {
					var i = arguments[r];
					e(i), i.length > 0 && (void 0 === t ? t = i : t += "/" + i);
				}
				return void 0 === t ? "." : n.normalize(t);
			},
			relative: function(t, r) {
				if (e(t), e(r), t === r) return "";
				if ((t = n.resolve(t)) === (r = n.resolve(r))) return "";
				for (var i = 1; i < t.length && 47 === t.charCodeAt(i); ++i);
				for (var o = t.length, s = o - i, h = 1; h < r.length && 47 === r.charCodeAt(h); ++h);
				for (var a = r.length - h, c = s < a ? s : a, f = -1, u = 0; u <= c; ++u) {
					if (u === c) {
						if (a > c) {
							if (47 === r.charCodeAt(h + u)) return r.slice(h + u + 1);
							if (0 === u) return r.slice(h + u);
						} else s > c && (47 === t.charCodeAt(i + u) ? f = u : 0 === u && (f = 0));
						break;
					}
					var l = t.charCodeAt(i + u);
					if (l !== r.charCodeAt(h + u)) break;
					47 === l && (f = u);
				}
				var g = "";
				for (u = i + f + 1; u <= o; ++u) u !== o && 47 !== t.charCodeAt(u) || (0 === g.length ? g += ".." : g += "/..");
				return g.length > 0 ? g + r.slice(h + f) : (h += f, 47 === r.charCodeAt(h) && ++h, r.slice(h));
			},
			_makeLong: function(t) {
				return t;
			},
			dirname: function(t) {
				if (e(t), 0 === t.length) return ".";
				for (var r = t.charCodeAt(0), n = 47 === r, i = -1, o = !0, s = t.length - 1; s >= 1; --s) if (47 === (r = t.charCodeAt(s))) {
					if (!o) {
						i = s;
						break;
					}
				} else o = !1;
				return -1 === i ? n ? "/" : "." : n && 1 === i ? "//" : t.slice(0, i);
			},
			basename: function(t, r) {
				if (void 0 !== r && "string" != typeof r) throw new TypeError("\"ext\" argument must be a string");
				e(t);
				var n, i = 0, o = -1, s = !0;
				if (void 0 !== r && r.length > 0 && r.length <= t.length) {
					if (r.length === t.length && r === t) return "";
					var h = r.length - 1, a = -1;
					for (n = t.length - 1; n >= 0; --n) {
						var c = t.charCodeAt(n);
						if (47 === c) {
							if (!s) {
								i = n + 1;
								break;
							}
						} else -1 === a && (s = !1, a = n + 1), h >= 0 && (c === r.charCodeAt(h) ? -1 == --h && (o = n) : (h = -1, o = a));
					}
					return i === o ? o = a : -1 === o && (o = t.length), t.slice(i, o);
				}
				for (n = t.length - 1; n >= 0; --n) if (47 === t.charCodeAt(n)) {
					if (!s) {
						i = n + 1;
						break;
					}
				} else -1 === o && (s = !1, o = n + 1);
				return -1 === o ? "" : t.slice(i, o);
			},
			extname: function(t) {
				e(t);
				for (var r = -1, n = 0, i = -1, o = !0, s = 0, h = t.length - 1; h >= 0; --h) {
					var a = t.charCodeAt(h);
					if (47 !== a) -1 === i && (o = !1, i = h + 1), 46 === a ? -1 === r ? r = h : 1 !== s && (s = 1) : -1 !== r && (s = -1);
					else if (!o) {
						n = h + 1;
						break;
					}
				}
				return -1 === r || -1 === i || 0 === s || 1 === s && r === i - 1 && r === n + 1 ? "" : t.slice(r, i);
			},
			format: function(t) {
				if (null === t || "object" != typeof t) throw new TypeError("The \"pathObject\" argument must be of type Object. Received type " + typeof t);
				return function(t, e) {
					var r = e.dir || e.root, n = e.base || (e.name || "") + (e.ext || "");
					return r ? r === e.root ? r + n : r + "/" + n : n;
				}(0, t);
			},
			parse: function(t) {
				e(t);
				var r = {
					root: "",
					dir: "",
					base: "",
					ext: "",
					name: ""
				};
				if (0 === t.length) return r;
				var n, i = t.charCodeAt(0), o = 47 === i;
				o ? (r.root = "/", n = 1) : n = 0;
				for (var s = -1, h = 0, a = -1, c = !0, f = t.length - 1, u = 0; f >= n; --f) if (47 !== (i = t.charCodeAt(f))) -1 === a && (c = !1, a = f + 1), 46 === i ? -1 === s ? s = f : 1 !== u && (u = 1) : -1 !== s && (u = -1);
				else if (!c) {
					h = f + 1;
					break;
				}
				return -1 === s || -1 === a || 0 === u || 1 === u && s === a - 1 && s === h + 1 ? -1 !== a && (r.base = r.name = 0 === h && o ? t.slice(1, a) : t.slice(h, a)) : (0 === h && o ? (r.name = t.slice(1, s), r.base = t.slice(1, a)) : (r.name = t.slice(h, s), r.base = t.slice(h, a)), r.ext = t.slice(s, a)), h > 0 ? r.dir = t.slice(0, h - 1) : o && (r.dir = "/"), r;
			},
			sep: "/",
			delimiter: ":",
			win32: null,
			posix: null
		};
		n.posix = n, t.exports = n;
	} }, e = {};
	function r(n) {
		var i = e[n];
		if (void 0 !== i) return i.exports;
		var o = e[n] = { exports: {} };
		return t[n](o, o.exports, r), o.exports;
	}
	r.d = (t, e) => {
		for (var n in e) r.o(e, n) && !r.o(t, n) && Object.defineProperty(t, n, {
			enumerable: !0,
			get: e[n]
		});
	}, r.o = (t, e) => Object.prototype.hasOwnProperty.call(t, e), r.r = (t) => {
		"undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(t, Symbol.toStringTag, { value: "Module" }), Object.defineProperty(t, "__esModule", { value: !0 });
	};
	var n = {};
	let i;
	if (r.r(n), r.d(n, {
		URI: () => l,
		Utils: () => I
	}), "object" == typeof process) i = "win32" === process.platform;
	else if ("object" == typeof navigator) i = navigator.userAgent.indexOf("Windows") >= 0;
	const o = /^\w[\w\d+.-]*$/, s = /^\//, h = /^\/\//;
	function a(t, e) {
		if (!t.scheme && e) throw new Error(`[UriError]: Scheme is missing: {scheme: "", authority: "${t.authority}", path: "${t.path}", query: "${t.query}", fragment: "${t.fragment}"}`);
		if (t.scheme && !o.test(t.scheme)) throw new Error("[UriError]: Scheme contains illegal characters.");
		if (t.path) {
			if (t.authority) {
				if (!s.test(t.path)) throw new Error("[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character");
			} else if (h.test(t.path)) throw new Error("[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")");
		}
	}
	const c = "", f = "/", u = /^(([^:/?#]+?):)?(\/\/([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?/;
	class l {
		static isUri(t) {
			return t instanceof l || !!t && "string" == typeof t.authority && "string" == typeof t.fragment && "string" == typeof t.path && "string" == typeof t.query && "string" == typeof t.scheme && "string" == typeof t.fsPath && "function" == typeof t.with && "function" == typeof t.toString;
		}
		scheme;
		authority;
		path;
		query;
		fragment;
		constructor(t, e, r, n, i, o = !1) {
			"object" == typeof t ? (this.scheme = t.scheme || c, this.authority = t.authority || c, this.path = t.path || c, this.query = t.query || c, this.fragment = t.fragment || c) : (this.scheme = function(t, e) {
				return t || e ? t : "file";
			}(t, o), this.authority = e || c, this.path = function(t, e) {
				switch (t) {
					case "https":
					case "http":
					case "file": e ? e[0] !== f && (e = f + e) : e = f;
				}
				return e;
			}(this.scheme, r || c), this.query = n || c, this.fragment = i || c, a(this, o));
		}
		get fsPath() {
			return v(this, !1);
		}
		with(t) {
			if (!t) return this;
			let { scheme: e, authority: r, path: n, query: i, fragment: o } = t;
			return void 0 === e ? e = this.scheme : null === e && (e = c), void 0 === r ? r = this.authority : null === r && (r = c), void 0 === n ? n = this.path : null === n && (n = c), void 0 === i ? i = this.query : null === i && (i = c), void 0 === o ? o = this.fragment : null === o && (o = c), e === this.scheme && r === this.authority && n === this.path && i === this.query && o === this.fragment ? this : new d(e, r, n, i, o);
		}
		static parse(t, e = !1) {
			const r = u.exec(t);
			return r ? new d(r[2] || c, w(r[4] || c), w(r[5] || c), w(r[7] || c), w(r[9] || c), e) : new d(c, c, c, c, c);
		}
		static file(t) {
			let e = c;
			if (i && (t = t.replace(/\\/g, f)), t[0] === f && t[1] === f) {
				const r = t.indexOf(f, 2);
				-1 === r ? (e = t.substring(2), t = f) : (e = t.substring(2, r), t = t.substring(r) || f);
			}
			return new d("file", e, t, c, c);
		}
		static from(t) {
			const e = new d(t.scheme, t.authority, t.path, t.query, t.fragment);
			return a(e, !0), e;
		}
		toString(t = !1) {
			return b(this, t);
		}
		toJSON() {
			return this;
		}
		static revive(t) {
			if (t) {
				if (t instanceof l) return t;
				{
					const e = new d(t);
					return e._formatted = t.external, e._fsPath = t._sep === g ? t.fsPath : null, e;
				}
			}
			return t;
		}
	}
	const g = i ? 1 : void 0;
	class d extends l {
		_formatted = null;
		_fsPath = null;
		get fsPath() {
			return this._fsPath || (this._fsPath = v(this, !1)), this._fsPath;
		}
		toString(t = !1) {
			return t ? b(this, !0) : (this._formatted || (this._formatted = b(this, !1)), this._formatted);
		}
		toJSON() {
			const t = { $mid: 1 };
			return this._fsPath && (t.fsPath = this._fsPath, t._sep = g), this._formatted && (t.external = this._formatted), this.path && (t.path = this.path), this.scheme && (t.scheme = this.scheme), this.authority && (t.authority = this.authority), this.query && (t.query = this.query), this.fragment && (t.fragment = this.fragment), t;
		}
	}
	const p = {
		58: "%3A",
		47: "%2F",
		63: "%3F",
		35: "%23",
		91: "%5B",
		93: "%5D",
		64: "%40",
		33: "%21",
		36: "%24",
		38: "%26",
		39: "%27",
		40: "%28",
		41: "%29",
		42: "%2A",
		43: "%2B",
		44: "%2C",
		59: "%3B",
		61: "%3D",
		32: "%20"
	};
	function m(t, e, r) {
		let n, i = -1;
		for (let o = 0; o < t.length; o++) {
			const s = t.charCodeAt(o);
			if (s >= 97 && s <= 122 || s >= 65 && s <= 90 || s >= 48 && s <= 57 || 45 === s || 46 === s || 95 === s || 126 === s || e && 47 === s || r && 91 === s || r && 93 === s || r && 58 === s) -1 !== i && (n += encodeURIComponent(t.substring(i, o)), i = -1), void 0 !== n && (n += t.charAt(o));
			else {
				void 0 === n && (n = t.substr(0, o));
				const e = p[s];
				void 0 !== e ? (-1 !== i && (n += encodeURIComponent(t.substring(i, o)), i = -1), n += e) : -1 === i && (i = o);
			}
		}
		return -1 !== i && (n += encodeURIComponent(t.substring(i))), void 0 !== n ? n : t;
	}
	function y(t) {
		let e;
		for (let r = 0; r < t.length; r++) {
			const n = t.charCodeAt(r);
			35 === n || 63 === n ? (void 0 === e && (e = t.substr(0, r)), e += p[n]) : void 0 !== e && (e += t[r]);
		}
		return void 0 !== e ? e : t;
	}
	function v(t, e) {
		let r;
		return r = t.authority && t.path.length > 1 && "file" === t.scheme ? `//${t.authority}${t.path}` : 47 === t.path.charCodeAt(0) && (t.path.charCodeAt(1) >= 65 && t.path.charCodeAt(1) <= 90 || t.path.charCodeAt(1) >= 97 && t.path.charCodeAt(1) <= 122) && 58 === t.path.charCodeAt(2) ? e ? t.path.substr(1) : t.path[1].toLowerCase() + t.path.substr(2) : t.path, i && (r = r.replace(/\//g, "\\")), r;
	}
	function b(t, e) {
		const r = e ? y : m;
		let n = "", { scheme: i, authority: o, path: s, query: h, fragment: a } = t;
		if (i && (n += i, n += ":"), (o || "file" === i) && (n += f, n += f), o) {
			let t = o.indexOf("@");
			if (-1 !== t) {
				const e = o.substr(0, t);
				o = o.substr(t + 1), t = e.lastIndexOf(":"), -1 === t ? n += r(e, !1, !1) : (n += r(e.substr(0, t), !1, !1), n += ":", n += r(e.substr(t + 1), !1, !0)), n += "@";
			}
			o = o.toLowerCase(), t = o.lastIndexOf(":"), -1 === t ? n += r(o, !1, !0) : (n += r(o.substr(0, t), !1, !0), n += o.substr(t));
		}
		if (s) {
			if (s.length >= 3 && 47 === s.charCodeAt(0) && 58 === s.charCodeAt(2)) {
				const t = s.charCodeAt(1);
				t >= 65 && t <= 90 && (s = `/${String.fromCharCode(t + 32)}:${s.substr(3)}`);
			} else if (s.length >= 2 && 58 === s.charCodeAt(1)) {
				const t = s.charCodeAt(0);
				t >= 65 && t <= 90 && (s = `${String.fromCharCode(t + 32)}:${s.substr(2)}`);
			}
			n += r(s, !0, !1);
		}
		return h && (n += "?", n += r(h, !1, !1)), a && (n += "#", n += e ? a : m(a, !1, !1)), n;
	}
	function C(t) {
		try {
			return decodeURIComponent(t);
		} catch {
			return t.length > 3 ? t.substr(0, 3) + C(t.substr(3)) : t;
		}
	}
	const A = /(%[0-9A-Za-z][0-9A-Za-z])+/g;
	function w(t) {
		return t.match(A) ? t.replace(A, ((t) => C(t))) : t;
	}
	var x = r(975);
	const P = x.posix || x, _ = "/";
	var I;
	(function(t) {
		t.joinPath = function(t, ...e) {
			return t.with({ path: P.join(t.path, ...e) });
		}, t.resolvePath = function(t, ...e) {
			let r = t.path, n = !1;
			r[0] !== _ && (r = _ + r, n = !0);
			let i = P.resolve(r, ...e);
			return n && i[0] === _ && !t.authority && (i = i.substring(1)), t.with({ path: i });
		}, t.dirname = function(t) {
			if (0 === t.path.length || t.path === _) return t;
			let e = P.dirname(t.path);
			return 1 === e.length && 46 === e.charCodeAt(0) && (e = ""), t.with({ path: e });
		}, t.basename = function(t) {
			return P.basename(t.path);
		}, t.extname = function(t) {
			return P.extname(t.path);
		};
	})(I || (I = {})), LIB = n;
})();
const { URI, Utils } = LIB;

//#endregion
//#region src/reporter.ts
function nullEmitter$1(_msg) {}
var CSpellReporterForGithubAction = class {
	issues = [];
	issueCounts = /* @__PURE__ */ new Map();
	result = {
		files: -1,
		filesWithIssues: /* @__PURE__ */ new Set(),
		issues: -1,
		errors: -1,
		cachedFiles: 0,
		skippedFiles: 0
	};
	finished = false;
	verbose;
	onIssue;
	constructor(reportIssueCommand, options, logger = getDefaultLogger()) {
		this.reportIssueCommand = reportIssueCommand;
		this.options = options;
		this.logger = logger;
		this.verbose = options.verbose;
	}
	_issue(issue, _options) {
		const { issues, issueCounts } = this;
		const uri = issue.uri;
		if (uri) issueCounts.set(uri, (issueCounts.get(uri) || 0) + 1);
		issues.push(issue);
		if (this.onIssue) this.onIssue(issue, _options);
	}
	_info(message, _msgType) {
		this._debug(message);
	}
	_debug(message) {
		nullEmitter$1(message);
	}
	_progress(progress) {
		if (!this.verbose || !isProgressFileComplete(progress)) return;
		const { issueCounts, logger } = this;
		const issueCount = issueCounts.get(progress.filename) || 0;
		const { fileNum, fileCount, filename, elapsedTimeMs } = progress;
		const issues = issueCount ? ` issues: ${issueCount}` : "";
		const timeMsg = elapsedTimeMs ? `(${elapsedTimeMs.toFixed(2)}ms)` : "-";
		logger.info(`${fileNum}/${fileCount} ${filename}${issues} ${timeMsg}`);
	}
	_error(message, error) {
		const { logger } = this;
		logger.error(`${message}
        name: ${error.name}
        msg: ${error.message}
        stack:
${error.stack}
        `);
	}
	_result(result) {
		Object.assign(this.result, result);
		this.finished = true;
		const command = this.reportIssueCommand;
		const errorCommand = this.options.treatFlaggedWordsAsErrors ? "error" : command;
		const cwd = process.cwd();
		this.issues.forEach((item) => {
			const isError = item.isFlagged || false;
			const hasPreferred = item.suggestionsEx?.some((s) => s.isPreferred) || false;
			const msgPrefix = isError ? "Forbidden word" : hasPreferred ? "Misspelled word" : "Unknown word";
			const suggestions = item.suggestionsEx?.map((s) => s.word + (s.isPreferred ? "*" : "")).join(", ") || "";
			const sugMsg = suggestions ? ` Suggestions: (${suggestions})` : "";
			const message = `${msgPrefix} (${item.text})${sugMsg}`;
			const cmd = isError ? errorCommand : command;
			if (!["error", "warning"].includes(cmd)) return;
			this.logger.issueCommand(cmd, {
				file: relative$2(cwd, item.uri || ""),
				line: item.row,
				col: item.col
			}, message);
			console.warn("%s", `${relative$2(cwd, item.uri || "")}:${item.row}:${item.col} ${message}`);
		});
		if (this.options.summary) this.logger.summary(genSummary(this.result));
	}
	reporter = {
		debug: (...args) => this._debug(...args),
		error: (...args) => this._error(...args),
		info: (...args) => this._info(...args),
		issue: (...args) => this._issue(...args),
		progress: (...args) => this._progress(...args),
		result: (...args) => this._result(...args),
		features: { unknownWords: false }
	};
};
function isProgressFileComplete(p) {
	return p.type === "ProgressFileComplete";
}
function relative$2(cwd, fileUri) {
	const fsPath = URI.parse(fileUri).fsPath;
	return path$6.relative(cwd, fsPath);
}
function genSummary(result) {
	const items = [
		`- **Files checked:** ${result.files - (result.skippedFiles || 0)}`,
		`- **Issues found:** ${result.issues}`,
		`- **Files with issues:** ${result.filesWithIssues.size}`
	];
	if (result.errors) items.push(`- **Errors encountered:** ${result.errors}`);
	if (result.skippedFiles) items.push(`- **Files skipped:** ${result.skippedFiles}`);
	if (result.cachedFiles) items.push(`- **Files using cache:** ${result.cachedFiles}`);
	return `\
## CSpell Summary

${items.join("\n")}
`;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/helpers/iteratorToIterable.js
function* iteratorToIterable$1(iterator) {
	try {
		let n;
		while (!(n = iterator.next()).done) yield n.value;
	} catch (e) {
		if (iterator.throw) return iterator.throw(e);
		throw e;
	} finally {
		iterator.return?.();
	}
}
async function* asyncIteratorToAsyncIterable(iterator) {
	try {
		let n;
		while (!(n = await iterator.next()).done) yield n.value;
	} catch (e) {
		if (iterator.throw) return iterator.throw(e);
		throw e;
	} finally {
		iterator.return?.();
	}
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/helpers/util.js
function toPipeFn(syncFn, asyncFn) {
	function _(i) {
		return isAsyncIterable$1(i) ? asyncFn(i) : syncFn(i);
	}
	return _;
}
function isAsyncIterable$1(i) {
	return typeof i[Symbol.asyncIterator] === "function";
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/helpers/toArray.js
function toArray(i) {
	return isAsyncIterable$1(i) ? toArrayAsync(i) : toArraySync(i);
}
function toArraySync(iter) {
	return [...iter];
}
async function toArrayAsync(iter) {
	const collection = [];
	for await (const i of iter) collection.push(i);
	return collection;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/helpers/toAsyncIterable.js
/**
* Merge multiple iterables into an AsyncIterable
* @param iter - initial iterable.
* @param rest - iterables to merge.
*/
async function* mergeAsyncIterables(iter, ...rest) {
	for await (const i of [iter, ...rest]) yield* i;
}
/**
* Convert one or more iterables to an AsyncIterable
*/
const toAsyncIterable = mergeAsyncIterables;

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/append.js
/**
* Append values onto the end of an iterable.
* @param iterablesToAppend - the iterables in the order to be appended.
* @returns
*/
function opAppendAsync(...iterablesToAppend) {
	async function* fnAppend(iter) {
		yield* iter;
		for (const i of iterablesToAppend) yield* i;
	}
	return fnAppend;
}
/**
* Append values onto the end of an iterable.
* @param iterablesToAppend - the iterables in the order to be appended.
* @returns
*/
function opAppendSync$1(...iterablesToAppend) {
	function* fnAppend(iter) {
		yield* iter;
		for (const i of iterablesToAppend) yield* i;
	}
	return fnAppend;
}
function opAppend(...iterablesToAppend) {
	function _(i) {
		return isAsyncIterable$1(i) ? opAppendAsync(...iterablesToAppend)(i) : opAppendSync$1(...iterablesToAppend)(i);
	}
	return _;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/await.js
async function* _asyncAwait(iter) {
	for await (const v of iter) yield v;
}
function opAwaitAsync() {
	return _asyncAwait;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/buffer.js
/**
* Buffer the input iterable into arrays of the given size.
* @param size - The size of the buffer.
* @returns A function that takes an async iterable and returns an async iterable of arrays of the given size.
*/
function opBufferAsync(size) {
	async function* fnBuffer(iter) {
		let buffer = [];
		for await (const v of iter) {
			buffer.push(v);
			if (buffer.length >= size) {
				yield buffer;
				buffer = [];
			}
		}
		if (buffer.length > 0) yield buffer;
	}
	return fnBuffer;
}
/**
* @param size - The size of the buffer.
* @returns A function that takes an iterable and returns an iterable of arrays of the given size.
*/
function opBufferSync(size) {
	function* fnBuffer(iter) {
		let buffer = [];
		for (const v of iter) {
			buffer.push(v);
			if (buffer.length >= size) {
				yield buffer;
				buffer = [];
			}
		}
		if (buffer.length > 0) yield buffer;
	}
	return fnBuffer;
}
function opBuffer(size) {
	const asyncFn = opBufferAsync(size);
	const syncFn = opBufferSync(size);
	function _(i) {
		return isAsyncIterable$1(i) ? asyncFn(i) : syncFn(i);
	}
	return _;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/combine.js
function opCombineAsync(...fns) {
	function combine(iter) {
		for (const fn of fns) iter = fn(iter);
		return iter;
	}
	return combine;
}
function opCombineSync$1(...fns) {
	function combine(iter) {
		for (const fn of fns) iter = fn(iter);
		return iter;
	}
	return combine;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/concatMap.js
function opConcatMapAsync(mapFn) {
	async function* fn(iter) {
		for await (const v of iter) yield* mapFn(v);
	}
	return fn;
}
function opConcatMapSync$1(mapFn) {
	function fnConcatMapSync(iterable) {
		function opConcatMapIterator() {
			const iter = iterable[Symbol.iterator]();
			let resultsIter = void 0;
			function nextConcatMap() {
				while (true) {
					if (resultsIter) {
						const { done, value } = resultsIter.next();
						if (!done) return { value };
						resultsIter = void 0;
					}
					const { done, value } = iter.next();
					if (done) return {
						done,
						value: void 0
					};
					resultsIter = mapFn(value)[Symbol.iterator]();
				}
			}
			return { next: nextConcatMap };
		}
		return { [Symbol.iterator]: opConcatMapIterator };
	}
	return fnConcatMapSync;
}
const opConcatMap = (fn) => toPipeFn(opConcatMapSync$1(fn), opConcatMapAsync(fn));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/filter.js
function opFilterAsync$1(filterFn) {
	async function* genFilter(iter) {
		for await (const v of iter) if (await filterFn(v)) yield v;
	}
	return genFilter;
}
function opFilterSync$1(filterFn) {
	function opFilterIterable(iterable) {
		function opFilterIterator() {
			const iter = iterable[Symbol.iterator]();
			function nextOpFilter() {
				while (true) {
					const { done, value } = iter.next();
					if (done) return {
						done,
						value: void 0
					};
					if (filterFn(value)) return { value };
				}
			}
			return { next: nextOpFilter };
		}
		return { [Symbol.iterator]: opFilterIterator };
	}
	return opFilterIterable;
}
function opFilter(fn) {
	const asyncFn = opFilterAsync$1(fn);
	const syncFn = opFilterSync$1(fn);
	function _(i) {
		return isAsyncIterable$1(i) ? asyncFn(i) : syncFn(i);
	}
	return _;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/first.js
function opFirstAsync(firstFn) {
	async function* fn(iter) {
		for await (const v of iter) if (await firstFn(v)) {
			yield v;
			break;
		}
	}
	return fn;
}
function opFirstSync(firstFn) {
	function* fn(iter) {
		for (const v of iter) if (firstFn(v)) {
			yield v;
			break;
		}
	}
	return fn;
}
function opFirst(fn) {
	const asyncFn = opFirstAsync(fn);
	const syncFn = opFirstSync(fn);
	function _(i) {
		return isAsyncIterable$1(i) ? asyncFn(i) : syncFn(i);
	}
	return _;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/flatten.js
function opFlattenAsync() {
	async function* fn(iter) {
		for await (const v of iter) yield* v;
	}
	return fn;
}
function opFlattenSync$1() {
	function* fn(iter) {
		for (const v of iter) yield* v;
	}
	return fn;
}
const opFlatten = () => toPipeFn(opFlattenSync$1(), opFlattenAsync());

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/joinStrings.js
function opJoinStringsAsync(joinCharacter = ",") {
	async function* fn(iter) {
		for await (const v of iter) yield (await toArray(v)).join(joinCharacter);
	}
	return fn;
}
function opJoinStringsSync(joinCharacter = ",") {
	function* fn(iter) {
		for (const v of iter) yield toArray(v).join(joinCharacter);
	}
	return fn;
}
const opJoinStrings = (joinCharacter) => toPipeFn(opJoinStringsSync(joinCharacter), opJoinStringsAsync(joinCharacter));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/last.js
const symNotFound = Symbol("LastNotFound");
function opLastAsync(lastFn) {
	async function* fn(iter) {
		let last = symNotFound;
		for await (const v of iter) if (await lastFn(v)) last = v;
		if (last !== symNotFound) yield last;
	}
	return fn;
}
function opLastSync(lastFn) {
	function* fn(iter) {
		let last = symNotFound;
		for (const v of iter) if (lastFn(v)) last = v;
		if (last !== symNotFound) yield last;
	}
	return fn;
}
function opLast(fn) {
	const asyncFn = opLastAsync(fn);
	const syncFn = opLastSync(fn);
	function _(i) {
		return isAsyncIterable$1(i) ? asyncFn(i) : syncFn(i);
	}
	return _;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/map.js
function opMapAsync(mapFn) {
	async function* genMap(iter) {
		for await (const v of iter) yield mapFn(v);
	}
	return genMap;
}
function opMapSync$1(mapFn) {
	function opMapIterable(iterable) {
		function opMapIterator() {
			const iter = iterable[Symbol.iterator]();
			function nextOpMap() {
				const { done, value } = iter.next();
				if (done) return {
					done,
					value: void 0
				};
				return { value: mapFn(value) };
			}
			return { next: nextOpMap };
		}
		return { [Symbol.iterator]: opMapIterator };
	}
	return opMapIterable;
}
const opMap = (fn) => toPipeFn(opMapSync$1(fn), opMapAsync(fn));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/reduce.js
function opReduceAsync(reduceFn, initialValue) {
	async function* reduce(head, tail) {
		for await (const v of tail) head = reduceFn(head, v);
		yield head;
	}
	async function* fn(iter) {
		const ht = initialValue === void 0 ? await headTailAsync(iter) : {
			head: await initialValue,
			tail: iter
		};
		if (!ht) return;
		yield* reduce(ht.head, ht.tail);
	}
	return fn;
}
function opReduceSync$1(reduceFn, initialValue) {
	function* reduce(head, tail) {
		for (const v of tail) head = reduceFn(head, v);
		yield head;
	}
	function* fn(iter) {
		const ht = initialValue === void 0 ? headTail$1(iter) : {
			head: initialValue,
			tail: iter
		};
		if (!ht) return;
		yield* reduce(ht.head, ht.tail);
	}
	return fn;
}
function headTail$1(iter) {
	const iterator = iter[Symbol.iterator]();
	const first = iterator.next();
	if (first.done) return void 0;
	return {
		head: first.value,
		tail: iteratorToIterable$1(iterator)
	};
}
async function headTailAsync(iter) {
	const iterator = isIterable$2(iter) ? iter[Symbol.iterator]() : iter[Symbol.asyncIterator]();
	const first = await iterator.next();
	if (first.done) return void 0;
	return {
		head: first.value,
		tail: asyncIteratorToAsyncIterable(iterator)
	};
}
function isIterable$2(i) {
	return typeof i[Symbol.iterator] === "function";
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/skip.js
function opSkipAsync(count) {
	async function* fn(iter) {
		for await (const v of iter) {
			if (count > 0) {
				--count;
				continue;
			}
			yield v;
		}
	}
	return fn;
}
function opSkipSync(count) {
	function* fn(iter) {
		for (const v of iter) {
			if (count > 0) {
				--count;
				continue;
			}
			yield v;
		}
	}
	return fn;
}
const opSkip = (count) => toPipeFn(opSkipSync(count), opSkipAsync(count));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/take.js
function opTakeAsync(count) {
	async function* fn(iter) {
		if (count <= 0) return;
		for await (const v of iter) {
			yield v;
			if (--count <= 0) return;
		}
	}
	return fn;
}
function opTakeSync(count) {
	function* fn(iter) {
		if (count <= 0) return;
		for (const v of iter) {
			yield v;
			if (--count <= 0) return;
		}
	}
	return fn;
}
/**
* Consume only the first `count` number from the iterable.
* @param count - number to take
*/
const opTake = (count) => toPipeFn(opTakeSync(count), opTakeAsync(count));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/tap.js
/**
* Tap allows you to listen on values, without modifying them.
*
* @param fn - function to call for each value.
*/
function opTapAsync(tapFn) {
	async function* fn(iter) {
		for await (const v of iter) {
			tapFn(v);
			yield v;
		}
	}
	return fn;
}
/**
* Tap allows you to listen on values, without modifying them.
*
* @param fn - function to call for each value.
*/
function opTapSync(tapFn) {
	function* fn(iter) {
		for (const v of iter) {
			tapFn(v);
			yield v;
		}
	}
	return fn;
}
/**
* Tap allows you to listen on values, without modifying them.
*
* @param fn - function to call for each value.
*/
const opTap = (fn) => toPipeFn(opTapSync(fn), opTapAsync(fn));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/unique.js
function opUniqueAsync(k) {
	function fnK(k) {
		async function* fn(iter) {
			const s = /* @__PURE__ */ new Set();
			for await (const v of iter) {
				const kk = k(v);
				if (s.has(kk)) continue;
				s.add(kk);
				yield v;
			}
		}
		return fn;
	}
	async function* fn(iter) {
		const s = /* @__PURE__ */ new Set();
		for await (const v of iter) {
			if (s.has(v)) continue;
			s.add(v);
			yield v;
		}
	}
	return k ? fnK(k) : fn;
}
function opUniqueSync$1(k) {
	function fnK(key) {
		function* fn(iter) {
			const s = /* @__PURE__ */ new Set();
			for (const v of iter) {
				const kk = key(v);
				if (s.has(kk)) continue;
				s.add(kk);
				yield v;
			}
		}
		return fn;
	}
	function* fn(iter) {
		const s = /* @__PURE__ */ new Set();
		for (const v of iter) {
			if (s.has(v)) continue;
			s.add(v);
			yield v;
		}
	}
	return k ? fnK(k) : fn;
}
const opUnique = (getKey) => toPipeFn(opUniqueSync$1(getKey), opUniqueAsync(getKey));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/operators/index.js
var operators_exports = /* @__PURE__ */ __exportAll({
	opAppend: () => opAppend,
	opAppendAsync: () => opAppendAsync,
	opAppendSync: () => opAppendSync$1,
	opAwaitAsync: () => opAwaitAsync,
	opBuffer: () => opBuffer,
	opBufferAsync: () => opBufferAsync,
	opBufferSync: () => opBufferSync,
	opCombineAsync: () => opCombineAsync,
	opCombineSync: () => opCombineSync$1,
	opConcatMap: () => opConcatMap,
	opConcatMapAsync: () => opConcatMapAsync,
	opConcatMapSync: () => opConcatMapSync$1,
	opFilter: () => opFilter,
	opFilterAsync: () => opFilterAsync$1,
	opFilterSync: () => opFilterSync$1,
	opFirst: () => opFirst,
	opFirstAsync: () => opFirstAsync,
	opFirstSync: () => opFirstSync,
	opFlatten: () => opFlatten,
	opFlattenAsync: () => opFlattenAsync,
	opFlattenSync: () => opFlattenSync$1,
	opJoinStrings: () => opJoinStrings,
	opJoinStringsAsync: () => opJoinStringsAsync,
	opJoinStringsSync: () => opJoinStringsSync,
	opLast: () => opLast,
	opLastAsync: () => opLastAsync,
	opLastSync: () => opLastSync,
	opMap: () => opMap,
	opMapAsync: () => opMapAsync,
	opMapSync: () => opMapSync$1,
	opReduceAsync: () => opReduceAsync,
	opReduceSync: () => opReduceSync$1,
	opSkip: () => opSkip,
	opSkipAsync: () => opSkipAsync,
	opSkipSync: () => opSkipSync,
	opTake: () => opTake,
	opTakeAsync: () => opTakeAsync,
	opTakeSync: () => opTakeSync,
	opTap: () => opTap,
	opTapAsync: () => opTapAsync,
	opTapSync: () => opTapSync,
	opUnique: () => opUnique,
	opUniqueAsync: () => opUniqueAsync,
	opUniqueSync: () => opUniqueSync$1
});

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/pipe.js
function pipeAsync(i, ...fns) {
	const iter = toAsyncIterable(i);
	return opCombineAsync(...fns)(iter);
}
function pipeSync$1(i, ...fns) {
	return opCombineSync$1(...fns)(i);
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-pipe@9.6.4/node_modules/@cspell/cspell-pipe/dist/index.js
const operators = operators_exports;

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/errors.js
const allowStringOrUndefined = {
	string: true,
	undefined: true
};
function isError$4(e) {
	if (e instanceof Error) return true;
	if (!e || typeof e !== "object") return false;
	const ex = e;
	return typeof ex.name === "string" && typeof ex.message === "string" && typeof ex.stack in allowStringOrUndefined;
}
function toError$4(e, errorFactory = UnknownError) {
	if (isError$4(e)) return e;
	return new errorFactory(e);
}
var UnknownError = class extends Error {
	cause;
	constructor(cause) {
		super(format(cause));
		this.cause = cause;
	}
};
function catchPromiseError(p, handler) {
	if (p === void 0) return void 0;
	return _catchPromiseError(p, handler);
}
async function _catchPromiseError(p, handler) {
	try {
		return await p;
	} catch (e) {
		return handler(e);
	}
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/events/events.js
var EventEmitter = class {
	name;
	#listeners = /* @__PURE__ */ new Set();
	constructor(name) {
		this.name = name;
	}
	/**
	* The event listeners can subscribe to.
	*/
	on = (listener) => {
		this.#listeners.add(listener);
		return { dispose: () => {
			this.#listeners.delete(listener);
		} };
	};
	/**
	* Notify all subscribers of the {@link EventEmitter.on event}. Failure
	* of one or more listener will not fail this function call.
	*
	* @param data The event object.
	*/
	fire(event) {
		let errors;
		for (const listener of this.#listeners) try {
			listener(event);
		} catch (e) {
			errors = errors ?? [];
			errors.push(toError$4(e));
		}
		return errors;
	}
	/**
	* Dispose this object and free resources.
	*/
	dispose = () => {
		this.#listeners.clear();
	};
};
/**
* Event indicating that the cache should be cleared.
*/
var ClearCacheEvent = class ClearCacheEvent extends EventEmitter {
	constructor() {
		super(ClearCacheEvent.eventName);
	}
	static eventName = "clear-cache";
};
const clearCacheEvent = new ClearCacheEvent();
function onClearCache(listener) {
	return clearCacheEvent.on(listener);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/AutoCache.js
const CACHE_SIZE = 100;
var Cache01 = class {
	maxSize;
	hits = 0;
	misses = 0;
	swaps = 0;
	constructor(maxSize) {
		this.maxSize = maxSize;
	}
};
var Cache01Map = class extends Cache01 {
	count = 0;
	cache0 = /* @__PURE__ */ new Map();
	cache1 = /* @__PURE__ */ new Map();
	constructor(maxSize) {
		super(maxSize);
	}
	get(key) {
		const cache0 = this.cache0;
		const cache1 = this.cache1;
		let found = cache0.get(key);
		if (found !== void 0) {
			++this.hits;
			return found;
		}
		found = cache1.get(key);
		if (found !== void 0) {
			++this.hits;
			++this.count;
			cache0.set(key, found);
			return found;
		}
		++this.misses;
	}
	set(key, value) {
		if (this.count >= this.maxSize) {
			const c = this.cache1;
			this.cache1 = this.cache0;
			this.cache0 = c;
			c.clear();
			this.swaps++;
			this.count = 0;
		}
		++this.count;
		this.cache0.set(key, value);
		return this;
	}
};
function createCache01(size) {
	return new Cache01Map(size);
}
function autoCache(fn, size = CACHE_SIZE) {
	const cache = createCache01(size);
	const ac = get;
	ac.hits = 0;
	ac.misses = 0;
	ac.swaps = 0;
	function get(k) {
		const f = cache.get(k);
		if (f !== void 0) {
			++ac.hits;
			return f;
		}
		const r = fn(k);
		cache.set(k, r);
		ac.swaps = cache.swaps;
		++ac.misses;
		return r;
	}
	return ac;
}
function extractStats(ac) {
	const { hits, misses, swaps } = ac;
	return {
		hits,
		misses,
		swaps
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-trie-lib@9.6.4_@cspell+cspell-types@9.6.4/node_modules/cspell-trie-lib/dist/index.js
function* iteratorToIterable(iterator) {
	try {
		let n;
		while (!(n = iterator.next()).done) yield n.value;
	} catch (e) {
		if (iterator.throw) return iterator.throw(e);
		throw e;
	} finally {
		iterator.return?.();
	}
}
/**
* Append values onto the end of an iterable.
* @param iterablesToAppend - the iterables in the order to be appended.
* @returns
*/
function opAppendSync(...iterablesToAppend) {
	function* fnAppend(iter) {
		yield* iter;
		for (const i of iterablesToAppend) yield* i;
	}
	return fnAppend;
}
function opCombineSync(...fns) {
	function combine(iter) {
		for (const fn of fns) iter = fn(iter);
		return iter;
	}
	return combine;
}
function opConcatMapSync(mapFn) {
	function fnConcatMapSync(iterable) {
		function opConcatMapIterator() {
			const iter = iterable[Symbol.iterator]();
			let resultsIter = void 0;
			function nextConcatMap() {
				while (true) {
					if (resultsIter) {
						const { done, value } = resultsIter.next();
						if (!done) return { value };
						resultsIter = void 0;
					}
					const { done, value } = iter.next();
					if (done) return {
						done,
						value: void 0
					};
					resultsIter = mapFn(value)[Symbol.iterator]();
				}
			}
			return { next: nextConcatMap };
		}
		return { [Symbol.iterator]: opConcatMapIterator };
	}
	return fnConcatMapSync;
}
function opFilterSync(filterFn) {
	function opFilterIterable(iterable) {
		function opFilterIterator() {
			const iter = iterable[Symbol.iterator]();
			function nextOpFilter() {
				while (true) {
					const { done, value } = iter.next();
					if (done) return {
						done,
						value: void 0
					};
					if (filterFn(value)) return { value };
				}
			}
			return { next: nextOpFilter };
		}
		return { [Symbol.iterator]: opFilterIterator };
	}
	return opFilterIterable;
}
function opFlattenSync() {
	function* fn(iter) {
		for (const v of iter) yield* v;
	}
	return fn;
}
function opMapSync(mapFn) {
	function opMapIterable(iterable) {
		function opMapIterator() {
			const iter = iterable[Symbol.iterator]();
			function nextOpMap() {
				const { done, value } = iter.next();
				if (done) return {
					done,
					value: void 0
				};
				return { value: mapFn(value) };
			}
			return { next: nextOpMap };
		}
		return { [Symbol.iterator]: opMapIterator };
	}
	return opMapIterable;
}
function opReduceSync(reduceFn, initialValue) {
	function* reduce(head, tail) {
		for (const v of tail) head = reduceFn(head, v);
		yield head;
	}
	function* fn(iter) {
		const ht = initialValue === void 0 ? headTail(iter) : {
			head: initialValue,
			tail: iter
		};
		if (!ht) return;
		yield* reduce(ht.head, ht.tail);
	}
	return fn;
}
function headTail(iter) {
	const iterator = iter[Symbol.iterator]();
	const first = iterator.next();
	if (first.done) return void 0;
	return {
		head: first.value,
		tail: iteratorToIterable(iterator)
	};
}
function opUniqueSync(k) {
	function fnK(key) {
		function* fn(iter) {
			const s = /* @__PURE__ */ new Set();
			for (const v of iter) {
				const kk = key(v);
				if (s.has(kk)) continue;
				s.add(kk);
				yield v;
			}
		}
		return fn;
	}
	function* fn(iter) {
		const s = /* @__PURE__ */ new Set();
		for (const v of iter) {
			if (s.has(v)) continue;
			s.add(v);
			yield v;
		}
	}
	return k ? fnK(k) : fn;
}
function pipeSync(i, ...fns) {
	return opCombineSync(...fns)(i);
}
function reduceSync(iter, reduceFn, initialValue) {
	return [...initialValue === void 0 ? pipeSync(iter, opReduceSync(reduceFn)) : pipeSync(iter, opReduceSync(reduceFn, initialValue))][0];
}
const SymEmpty = Symbol("memorizeLastCall");
function memorizeLastCall(fn) {
	let lastP = void 0;
	let lastR = SymEmpty;
	function calc(p) {
		if (lastP === p && lastR !== SymEmpty) return lastR;
		lastP = p;
		lastR = fn(p);
		return lastR;
	}
	return calc;
}
const defaultLegacyMinCompoundLength$2 = 3;
const _defaultFindOptions$1 = {
	matchCase: false,
	compoundMode: "compound",
	legacyMinCompoundLength: defaultLegacyMinCompoundLength$2
};
Object.freeze(_defaultFindOptions$1);
const knownCompoundModes$1 = new Map([
	"none",
	"compound",
	"legacy"
].map((a) => [a, a]));
const notFound = {
	found: false,
	compoundUsed: false,
	caseMatched: false,
	forbidden: void 0
};
Object.freeze(notFound);
/**
*
* @param root Trie root node. root.c contains the compound root and forbidden root.
* @param word A pre normalized word use `normalizeWord` or `normalizeWordToLowercase`
* @param options
*/
function findWordNode$1(root, word, options) {
	return _findWordNode$1(root, word, options);
}
/**
*
* @param root Trie root node. root.c contains the compound root and forbidden root.
* @param word A pre normalized word use `normalizeWord` or `normalizeWordToLowercase`
* @param options
*/
function findWord$1(root, word, options) {
	if (root.find && !options?.compoundSeparator) {
		const found = root.find(word, options?.matchCase || false);
		if (found) {
			if (options?.checkForbidden && found.forbidden === void 0) found.forbidden = isForbiddenWord$1(root, word, root.forbidPrefix);
			return found;
		}
		if (!root.hasCompoundWords) return notFound;
	}
	const { found, compoundUsed, caseMatched, forbidden } = _findWordNode$1(root, word, options);
	const result = {
		found,
		compoundUsed,
		caseMatched,
		forbidden
	};
	if (options?.checkForbidden && forbidden === void 0) result.forbidden = isForbiddenWord$1(root, word, root.forbidPrefix);
	return result;
}
/**
*
* @param root Trie root node. root.c contains the compound root and forbidden root.
* @param word A pre normalized word use `normalizeWord` or `normalizeWordToLowercase`
* @param options
*/
function _findWordNode$1(root, word, options) {
	const trieInfo = root.info;
	const matchCase = options?.matchCase || false;
	const compoundMode = knownCompoundModes$1.get(options?.compoundMode) || _defaultFindOptions$1.compoundMode;
	const compoundPrefix = compoundMode === "compound" ? trieInfo.compoundCharacter ?? root.compoundFix : "";
	const ignoreCasePrefix = matchCase ? "" : trieInfo.stripCaseAndAccentsPrefix ?? root.caseInsensitivePrefix;
	const mustCheckForbidden = options?.checkForbidden === true;
	const checkForbidden = options?.checkForbidden ?? true;
	const compoundSeparator = options?.compoundSeparator || "";
	function __findCompound() {
		const f = findCompoundWord$1(root, word, compoundPrefix, ignoreCasePrefix, compoundSeparator);
		if (f.found !== false && (mustCheckForbidden || f.compoundUsed && checkForbidden)) f.forbidden = isForbiddenWord$1(!f.caseMatched ? walk$2(root, root.caseInsensitivePrefix) : root, word, root.forbidPrefix);
		return f;
	}
	function __findExact() {
		const n = root.getNode ? root.getNode(word) : walk$2(root, word);
		return {
			found: isEndOfWordNode$1(n) && word,
			compoundUsed: false,
			forbidden: checkForbidden ? isForbiddenWord$1(root, word, root.forbidPrefix) : void 0,
			node: n,
			caseMatched: true
		};
	}
	switch (compoundMode) {
		case "none": return matchCase ? __findExact() : __findCompound();
		case "compound": return __findCompound();
		case "legacy": return findLegacyCompound$1(root, word, options);
	}
}
function findLegacyCompound$1(root, word, options) {
	const roots = [root];
	if (!options?.matchCase) roots.push(walk$2(root, root.caseInsensitivePrefix));
	return findLegacyCompoundNode$1(roots, word, options?.legacyMinCompoundLength || defaultLegacyMinCompoundLength$2, options?.compoundSeparator ?? "+");
}
function findCompoundNode$1(root, word, compoundCharacter, ignoreCasePrefix, compoundSeparator) {
	const stack = [{
		n: root,
		compoundPrefix: ignoreCasePrefix,
		cr: void 0,
		caseMatched: true,
		s: ""
	}];
	const compoundPrefix = compoundCharacter || ignoreCasePrefix;
	const possibleCompoundPrefix = ignoreCasePrefix && compoundCharacter ? ignoreCasePrefix + compoundCharacter : "";
	const nw = word.normalize();
	const w = [...nw];
	function determineRoot(s) {
		const prefix = s.compoundPrefix;
		let r = root;
		let i;
		for (i = 0; i < prefix.length && r; ++i) r = r.get(prefix[i]);
		const caseMatched = s.caseMatched && prefix[0] !== ignoreCasePrefix;
		return {
			n: s.n,
			compoundPrefix: prefix === compoundPrefix ? possibleCompoundPrefix : "",
			cr: r,
			caseMatched,
			s: prefix.endsWith(compoundCharacter) ? compoundSeparator : ""
		};
	}
	let compoundUsed = false;
	let caseMatched = true;
	let i = 0;
	let node;
	while (true) {
		const s = stack[i];
		const h = w[i++];
		const n = s.cr || s.n;
		const c = h && n?.get(h) || void 0;
		if (c && i < word.length) {
			caseMatched = s.caseMatched;
			stack[i] = {
				n: c,
				compoundPrefix,
				cr: void 0,
				caseMatched,
				s: ""
			};
		} else if (!c || !c.eow) {
			node = node || c;
			while (--i > 0) {
				const s = stack[i];
				if (!s.compoundPrefix || !s.n?.hasChildren()) continue;
				if (s.n.get(compoundCharacter)) break;
			}
			if (i >= 0 && stack[i].compoundPrefix) {
				compoundUsed = i > 0;
				const r = determineRoot(stack[i]);
				stack[i] = r;
				if (!r.cr) break;
				if (!i && !r.caseMatched && nw !== nw.toLowerCase()) break;
			} else break;
		} else {
			node = c;
			caseMatched = s.caseMatched;
			break;
		}
	}
	function joinCompoundWord() {
		return stack.map((s) => s.s).map((c, i) => c + w[i]).join("");
	}
	const f = i === word.length && word || false;
	return {
		found: f && (compoundSeparator ? joinCompoundWord() : f),
		compoundUsed,
		node,
		forbidden: void 0,
		caseMatched
	};
}
function findCompoundWord$1(root, word, compoundCharacter, ignoreCasePrefix, compoundSeparator) {
	const { found, compoundUsed, node, caseMatched } = findCompoundNode$1(root, word, compoundCharacter, ignoreCasePrefix, compoundSeparator);
	if (!node || !node.eow) return {
		found: false,
		compoundUsed,
		node,
		forbidden: void 0,
		caseMatched
	};
	return {
		found,
		compoundUsed,
		node,
		forbidden: void 0,
		caseMatched
	};
}
function findWordExact$1(root, word) {
	const r = root;
	if (r?.findExact) return r.findExact(word);
	return isEndOfWordNode$1(walk$2(root, word));
}
function isEndOfWordNode$1(n) {
	return !!n?.eow;
}
function walk$2(root, word) {
	const w = [...word];
	let n = root;
	let i = 0;
	while (n && i < w.length) {
		const h = w[i++];
		n = n.get(h);
	}
	return n;
}
function findLegacyCompoundNode$1(roots, word, minCompoundLength, compoundSeparator) {
	const root = roots[0];
	const numRoots = roots.length;
	const stack = [{
		n: root,
		usedRoots: 1,
		subLength: 0,
		isCompound: false,
		cr: void 0,
		caseMatched: true
	}];
	const w = word;
	const wLen = w.length;
	let compoundUsed = false;
	let caseMatched = true;
	let i = 0;
	let node;
	while (true) {
		const s = stack[i];
		const h = w[i++];
		const c = (s.cr || s.n)?.get(h);
		if (c && i < wLen) stack[i] = {
			n: c,
			usedRoots: 0,
			subLength: s.subLength + 1,
			isCompound: s.isCompound,
			cr: void 0,
			caseMatched: s.caseMatched
		};
		else if (!c || !c.eow || c.eow && s.subLength < minCompoundLength - 1) {
			while (--i > 0) {
				const s = stack[i];
				if (s.usedRoots < numRoots && s.n?.eow && (s.subLength >= minCompoundLength || !s.subLength) && wLen - i >= minCompoundLength) break;
			}
			if (i > 0 || stack[i].usedRoots < numRoots) {
				compoundUsed = i > 0;
				const s = stack[i];
				s.cr = roots[s.usedRoots++];
				s.subLength = 0;
				s.isCompound = compoundUsed;
				s.caseMatched = s.caseMatched && s.usedRoots <= 1;
			} else break;
		} else {
			node = c;
			caseMatched = s.caseMatched;
			break;
		}
	}
	function extractWord() {
		if (!word || i < word.length) return false;
		const letters = [];
		let subLen = 0;
		for (let j = 0; j < i; ++j) {
			const { subLength } = stack[j];
			if (subLength < subLen) letters.push(compoundSeparator);
			letters.push(word[j]);
			subLen = subLength;
		}
		return letters.join("");
	}
	return {
		found: extractWord(),
		compoundUsed,
		node,
		forbidden: void 0,
		caseMatched
	};
}
function isForbiddenWord$1(root, word, forbiddenPrefix) {
	const r = root;
	if (r?.isForbidden) return r.isForbidden(word);
	return findWordExact$1(root?.get(forbiddenPrefix), word);
}
const createFindOptions$1 = memorizeLastCall(_createFindOptions$1);
function _createFindOptions$1(options) {
	if (!options) return _defaultFindOptions$1;
	const d = _defaultFindOptions$1;
	return {
		matchCase: options.matchCase ?? d.matchCase,
		compoundMode: options.compoundMode ?? d.compoundMode,
		legacyMinCompoundLength: options.legacyMinCompoundLength ?? d.legacyMinCompoundLength,
		checkForbidden: options.checkForbidden ?? d.checkForbidden,
		compoundSeparator: options.compoundSeparator ?? d.compoundSeparator
	};
}
const JOIN_SEPARATOR = "+";
const WORD_SEPARATOR = " ";
const CompoundWordsMethod = {
	NONE: 0,
	SEPARATE_WORDS: 1,
	JOIN_WORDS: 2,
	0: "NONE",
	1: "SEPARATE_WORDS",
	2: "JOIN_WORDS"
};
/**
* Walks the Trie and yields a value at each node.
* next(goDeeper: boolean):
*/
function* compoundWalker$1(root, compoundingMethod) {
	const empty = Object.freeze([]);
	const roots = {
		[CompoundWordsMethod.NONE]: empty,
		[CompoundWordsMethod.JOIN_WORDS]: [[JOIN_SEPARATOR, root]],
		[CompoundWordsMethod.SEPARATE_WORDS]: [[WORD_SEPARATOR, root]]
	};
	const rc = roots[compoundingMethod].length ? roots[compoundingMethod] : void 0;
	function children(n) {
		if (n.hasChildren()) {
			const entries = n.entries();
			const c = Array.isArray(entries) ? entries : [...entries];
			return n.eow && rc ? [...c, ...rc] : c;
		}
		if (n.eow) return roots[compoundingMethod];
		return empty;
	}
	let depth = 0;
	const stack = [];
	stack[depth] = {
		t: "",
		c: children(root),
		ci: 0
	};
	while (depth >= 0) {
		let s = stack[depth];
		let baseText = s.t;
		while (s.ci < s.c.length) {
			const [char, node] = s.c[s.ci++];
			const text = baseText + char;
			if ((yield {
				text,
				node,
				depth
			}) ?? true) {
				depth++;
				baseText = text;
				stack[depth] = {
					t: text,
					c: children(node),
					ci: 0
				};
			}
			s = stack[depth];
		}
		depth -= 1;
	}
}
/**
* Walks the Trie and yields a value at each node.
* next(goDeeper: boolean):
*/
function* nodeWalker$1(root) {
	let depth = 0;
	const stack = [];
	const entries = root.entries();
	stack[depth] = {
		t: "",
		n: root,
		c: Array.isArray(entries) ? entries : [...entries],
		ci: 0
	};
	while (depth >= 0) {
		let s = stack[depth];
		let baseText = s.t;
		while (s.ci < s.c.length && s.n) {
			const idx = s.ci++;
			const [char, node] = s.c[idx];
			const text = baseText + char;
			if ((yield {
				text,
				node,
				depth
			}) !== false) {
				depth++;
				baseText = text;
				const s = stack[depth];
				const entries = node.entries();
				const c = Array.isArray(entries) ? entries : [...entries];
				if (s) {
					s.t = text;
					s.n = node;
					s.c = c;
					s.ci = 0;
				} else stack[depth] = {
					t: text,
					n: node,
					c,
					ci: 0
				};
			}
			s = stack[depth];
		}
		depth -= 1;
	}
}
function walker$1(root, compoundingMethod = CompoundWordsMethod.NONE) {
	return compoundingMethod === CompoundWordsMethod.NONE ? nodeWalker$1(root) : compoundWalker$1(root, compoundingMethod);
}
function walkerWords$1(root) {
	return walkerWordsITrie(root);
}
/**
* Walks the Trie and yields each word.
*/
function* walkerWordsITrie(root) {
	let depth = 0;
	const stack = [];
	const entries = root.entries();
	stack[depth] = {
		t: "",
		n: root,
		c: Array.isArray(entries) ? entries : [...entries],
		ci: 0
	};
	while (depth >= 0) {
		let s = stack[depth];
		let baseText = s.t;
		while (s.ci < s.c.length && s.n) {
			const [char, node] = s.c[s.ci++];
			if (!node) continue;
			const text = baseText + char;
			if (node.eow) yield text;
			depth++;
			baseText = text;
			const entries = node.entries();
			const c = Array.isArray(entries) ? entries : [...entries];
			if (stack[depth]) {
				s = stack[depth];
				s.t = text;
				s.n = node;
				s.c = c;
				s.ci = 0;
			} else stack[depth] = {
				t: text,
				n: node,
				c,
				ci: 0
			};
			s = stack[depth];
		}
		depth -= 1;
	}
}
/**
* Generate a Iterator that can walk a Trie and yield the words.
*/
function iteratorTrieWords$1(node) {
	return walkerWords$1(node);
}
function findNode$1(node, word) {
	for (let i = 0; i < word.length; ++i) {
		const n = node.get(word[i]);
		if (!n) return void 0;
		node = n;
	}
	return node;
}
function countWords$1(root) {
	const visited = /* @__PURE__ */ new Map();
	function walk(n) {
		const nestedCount = visited.get(n.id);
		if (nestedCount !== void 0) return nestedCount;
		let cnt = n.eow ? 1 : 0;
		visited.set(n, cnt);
		for (const c of n.values()) cnt += walk(c);
		visited.set(n, cnt);
		return cnt;
	}
	return walk(root);
}
let debuggerIsAttached = false;
function isDebuggerAttached() {
	return debuggerIsAttached;
}
function trieRootToITrieRoot(root) {
	return ImplITrieRoot.toITrieNode(root);
}
const EmptyKeys = Object.freeze([]);
const EmptyValues = Object.freeze([]);
const EmptyEntries = Object.freeze([]);
var ImplITrieNode = class ImplITrieNode {
	id;
	_keys;
	node;
	constructor(node) {
		this.node = node;
		this.id = node;
	}
	/** flag End of Word */
	get eow() {
		return !!this.node.f;
	}
	/** number of children */
	get size() {
		if (!this.node.c) return 0;
		return this.keys().length;
	}
	/** get keys to children */
	keys() {
		if (this._keys) return this._keys;
		const keys = this.node.c ? Object.keys(this.node.c) : EmptyKeys;
		this._keys = keys;
		return keys;
	}
	/** get the child nodes */
	values() {
		return !this.node.c ? EmptyValues : Object.values(this.node.c).map((n) => ImplITrieNode.toITrieNode(n));
	}
	entries() {
		return !this.node.c ? EmptyEntries : Object.entries(this.node.c).map(([k, n]) => [k, ImplITrieNode.toITrieNode(n)]);
	}
	/** get child ITrieNode */
	get(char) {
		const n = this.node.c?.[char];
		if (!n) return void 0;
		return ImplITrieNode.toITrieNode(n);
	}
	getNode(chars) {
		return this.findNode(chars);
	}
	has(char) {
		const c = this.node.c;
		return c && char in c || false;
	}
	child(keyIdx) {
		const char = this.keys()[keyIdx];
		const n = char && this.get(char);
		if (!n) throw new Error("Index out of range.");
		return n;
	}
	hasChildren() {
		return !!this.node.c;
	}
	#findTrieNode(word) {
		let node = this.node;
		for (const char of word) {
			if (!node) return void 0;
			node = node.c?.[char];
		}
		return node;
	}
	findNode(word) {
		const node = this.#findTrieNode(word);
		return node && ImplITrieNode.toITrieNode(node);
	}
	findExact(word) {
		const node = this.#findTrieNode(word);
		return !!node && !!node.f;
	}
	static toITrieNode(node) {
		return new this(node);
	}
};
var ImplITrieRoot = class extends ImplITrieNode {
	info;
	hasForbiddenWords;
	hasCompoundWords;
	hasNonStrictWords;
	root;
	constructor(root) {
		super(root);
		this.root = root;
		const { stripCaseAndAccentsPrefix, compoundCharacter, forbiddenWordPrefix, suggestionPrefix } = root;
		this.info = {
			stripCaseAndAccentsPrefix,
			compoundCharacter,
			forbiddenWordPrefix,
			suggestionPrefix
		};
		this.hasForbiddenWords = !!root.c[forbiddenWordPrefix];
		this.hasCompoundWords = !!root.c[compoundCharacter];
		this.hasNonStrictWords = !!root.c[stripCaseAndAccentsPrefix];
	}
	get eow() {
		return false;
	}
	resolveId(id) {
		return new ImplITrieNode(id);
	}
	get forbidPrefix() {
		return this.root.forbiddenWordPrefix;
	}
	get compoundFix() {
		return this.root.compoundCharacter;
	}
	get caseInsensitivePrefix() {
		return this.root.stripCaseAndAccentsPrefix;
	}
	get suggestionPrefix() {
		return this.root.suggestionPrefix;
	}
	static toITrieNode(node) {
		return new this(node);
	}
};
const defaultSuggestionOptions = {
	compoundMethod: CompoundWordsMethod.NONE,
	ignoreCase: true,
	changeLimit: 5,
	numSuggestions: 8,
	includeTies: true,
	get timeout() {
		return isDebuggerAttached() ? 1e6 : 1e3;
	}
};
const keyMapOfSuggestionOptionsStrict = {
	changeLimit: "changeLimit",
	compoundMethod: "compoundMethod",
	ignoreCase: "ignoreCase",
	compoundSeparator: "compoundSeparator",
	filter: "filter",
	includeTies: "includeTies",
	numSuggestions: "numSuggestions",
	timeout: "timeout",
	weightMap: "weightMap"
};
/**
* Create suggestion options using composition.
* @param opts - partial options.
* @returns Options - with defaults.
*/
function createSuggestionOptions(...opts) {
	const options = { ...defaultSuggestionOptions };
	const keys = Object.keys(keyMapOfSuggestionOptionsStrict);
	for (const opt of opts) for (const key of keys) assign(options, opt, key);
	return options;
}
function assign(dest, src, k) {
	dest[k] = src[k] ?? dest[k];
}
var PairingHeap$1 = class {
	_heap;
	_size = 0;
	compare;
	constructor(compare) {
		this.compare = compare;
	}
	/** Add an item to the heap. */
	add(v) {
		this._heap = insert$1(this.compare, this._heap, v);
		++this._size;
		return this;
	}
	/** take an item from the heap. */
	dequeue() {
		const n = this.next();
		if (n.done) return void 0;
		return n.value;
	}
	/** Add items to the heap */
	append(i) {
		for (const v of i) this.add(v);
		return this;
	}
	/** get the next value */
	next() {
		if (!this._heap) return {
			value: void 0,
			done: true
		};
		const value = this._heap.v;
		--this._size;
		this._heap = removeHead$1(this.compare, this._heap);
		return { value };
	}
	/** peek at the next value without removing it. */
	peek() {
		return this._heap?.v;
	}
	[Symbol.iterator]() {
		return this;
	}
	/** alias of `size` */
	get length() {
		return this._size;
	}
	/** number of entries in the heap. */
	get size() {
		return this._size;
	}
};
function removeHead$1(compare, heap) {
	if (!heap || !heap.c) return void 0;
	return mergeSiblings$1(compare, heap.c);
}
function insert$1(compare, heap, v) {
	const n = {
		v,
		s: void 0,
		c: void 0
	};
	if (!heap || compare(v, heap.v) <= 0) {
		n.c = heap;
		return n;
	}
	n.s = heap.c;
	heap.c = n;
	return heap;
}
function merge$3(compare, a, b) {
	if (compare(a.v, b.v) <= 0) {
		a.s = void 0;
		b.s = a.c;
		a.c = b;
		return a;
	}
	b.s = void 0;
	a.s = b.c;
	b.c = a;
	return b;
}
function mergeSiblings$1(compare, n) {
	if (!n.s) return n;
	const s = n.s;
	const ss = s.s;
	const m = merge$3(compare, n, s);
	return ss ? merge$3(compare, m, mergeSiblings$1(compare, ss)) : m;
}
const DEFAULT_COMPOUNDED_WORD_SEPARATOR = "";
const opCosts = {
	baseCost: 100,
	swapCost: 75,
	duplicateLetterCost: 80,
	compound: 1,
	visuallySimilar: 1,
	firstLetterBias: 5,
	wordBreak: 99,
	wordLengthCostFactor: .5
};
new Intl.Collator("en", { sensitivity: "base" }).compare;
/**
* This a set of letters that look like each other.
* There can be a maximum of 30 groups.
* It is possible for a letter to appear in more than 1 group, but not encouraged.
*/
const visualLetterGroups = [
	forms("Aa") + "",
	forms("Bb"),
	forms("cC"),
	forms("Dd"),
	forms("eE"),
	forms("fF"),
	forms("Gg"),
	forms("Hh"),
	forms("Ii"),
	forms("jJ"),
	forms("Kk"),
	forms("Ll"),
	forms("Mm"),
	forms("nN"),
	forms("Oo"),
	forms("Pp"),
	forms("Qq"),
	forms("Rr"),
	forms("sS"),
	forms("tT"),
	forms("uU"),
	forms("Vv"),
	forms("wW"),
	forms("xX"),
	forms("Yy"),
	forms("Zz")
];
function forms(letters) {
	const n = letters.normalize("NFC").replaceAll(/\p{M}/gu, "");
	const na = n.normalize("NFD").replaceAll(/\p{M}/gu, "");
	return [...new Set(n + n.toLowerCase() + n.toUpperCase() + na + na.toLowerCase() + na.toUpperCase())].join("");
}
/**
* This is a map of letters to groups mask values.
* If two letters are part of the same group then `visualLetterMaskMap[a] & visualLetterMaskMap[b] !== 0`
*/
const visualLetterMaskMap = calcVisualLetterMasks(visualLetterGroups);
/**
*
* @param groups
* @returns
*/
function calcVisualLetterMasks(groups) {
	const map = Object.create(null);
	for (let i = 0; i < groups.length; ++i) {
		const m = 1 << i;
		const g = groups[i];
		for (const c of g) map[c] = (map[c] || 0) | m;
	}
	return map;
}
function assert$3(condition, message = "Assert Failed") {
	if (condition) return;
	throw new Error(message);
}
const matchPossibleWordSeparators = /[+]/g;
function createWeightMap(...defs) {
	const map = _createWeightMap();
	addDefsToWeightMap(map, defs);
	return map;
}
function addDefToWeightMap(map, ...defs) {
	return addDefsToWeightMap(map, defs);
}
function addAdjustment(map, ...adjustments) {
	for (const adj of adjustments) map.adjustments.set(adj.id, adj);
	return map;
}
function addDefsToWeightMap(map, defs) {
	function addSet(set, def) {
		addSetToTrieCost(map.insDel, set, def.insDel, def.penalty);
		addSetToTrieTrieCost(map.replace, set, def.replace, def.penalty);
		addSetToTrieTrieCost(map.swap, set, def.swap, def.penalty);
	}
	for (const _def of defs) {
		const def = normalizeDef(_def);
		splitMap$1(def).forEach((s) => addSet(s, def));
	}
	return map;
}
function _createWeightMap() {
	return {
		insDel: {},
		replace: {},
		swap: {},
		adjustments: /* @__PURE__ */ new Map()
	};
}
function lowest(a, b) {
	if (a === void 0) return b;
	if (b === void 0) return a;
	return a <= b ? a : b;
}
function highest(a, b) {
	if (a === void 0) return b;
	if (b === void 0) return a;
	return a >= b ? a : b;
}
function normalize$2(s) {
	const f = new Set([s]);
	f.add(s.normalize("NFC"));
	f.add(s.normalize("NFD"));
	return f;
}
function* splitMapSubstringsIterable(map) {
	let seq = "";
	let mode = 0;
	for (const char of map) {
		if (mode && char === ")") {
			yield* normalize$2(seq);
			mode = 0;
			continue;
		}
		if (mode) {
			seq += char;
			continue;
		}
		if (char === "(") {
			mode = 1;
			seq = "";
			continue;
		}
		yield* normalize$2(char);
	}
}
function splitMapSubstrings(map) {
	return [...splitMapSubstringsIterable(map)];
}
/**
* Splits a WeightedMapDef.map
* @param map
*/
function splitMap$1(def) {
	const { map } = def;
	return map.split("|").map(splitMapSubstrings).filter((s) => s.length > 0);
}
function addToTrieCost(trie, str, cost, penalties) {
	if (!str) return;
	let t = trie;
	for (const c of str) {
		const n = t.n = t.n || Object.create(null);
		t = n[c] = n[c] || Object.create(null);
	}
	t.c = lowest(t.c, cost);
	t.p = highest(t.p, penalties);
}
function addToTrieTrieCost(trie, left, right, cost, penalties) {
	let t = trie;
	for (const c of left) {
		const n = t.n = t.n || Object.create(null);
		t = n[c] = n[c] || Object.create(null);
	}
	addToTrieCost(t.t = t.t || Object.create(null), right, cost, penalties);
}
function addSetToTrieCost(trie, set, cost, penalties) {
	if (cost === void 0) return;
	for (const str of set) addToTrieCost(trie, str, cost, penalties);
}
function addSetToTrieTrieCost(trie, set, cost, penalties) {
	if (cost === void 0) return;
	for (const left of set) for (const right of set) {
		if (left === right) continue;
		addToTrieTrieCost(trie, left, right, cost, penalties);
	}
}
function* searchTrieNodes(trie, str, i) {
	const len = str.length;
	for (let n = trie.n; i < len && n;) {
		const t = n[str[i]];
		if (!t) return;
		++i;
		yield {
			i,
			t
		};
		n = t.n;
	}
}
function* findTrieCostPrefixes(trie, str, i) {
	for (const n of searchTrieNodes(trie, str, i)) {
		const { c, p } = n.t;
		if (c !== void 0) yield {
			i: n.i,
			c,
			p: p || 0
		};
	}
}
function* findTrieTrieCostPrefixes(trie, str, i) {
	for (const n of searchTrieNodes(trie, str, i)) {
		const t = n.t.t;
		if (t !== void 0) yield {
			i: n.i,
			t
		};
	}
}
function createWeightCostCalculator(weightMap) {
	return new _WeightCostCalculator(weightMap);
}
var _WeightCostCalculator = class {
	weightMap;
	constructor(weightMap) {
		this.weightMap = weightMap;
	}
	*calcInsDelCosts(pos) {
		const { a, ai, b, bi, c, p } = pos;
		for (const del of findTrieCostPrefixes(this.weightMap.insDel, a, ai)) yield {
			a,
			b,
			ai: del.i,
			bi,
			c: c + del.c,
			p: p + del.p
		};
		for (const ins of findTrieCostPrefixes(this.weightMap.insDel, b, bi)) yield {
			a,
			b,
			ai,
			bi: ins.i,
			c: c + ins.c,
			p: p + ins.p
		};
	}
	*calcReplaceCosts(pos) {
		const { a, ai, b, bi, c, p } = pos;
		for (const del of findTrieTrieCostPrefixes(this.weightMap.replace, a, ai)) for (const ins of findTrieCostPrefixes(del.t, b, bi)) yield {
			a,
			b,
			ai: del.i,
			bi: ins.i,
			c: c + ins.c,
			p: p + ins.p
		};
	}
	*calcSwapCosts(pos) {
		const { a, ai, b, bi, c, p } = pos;
		const swap = this.weightMap.swap;
		for (const left of findTrieTrieCostPrefixes(swap, a, ai)) for (const right of findTrieCostPrefixes(left.t, a, left.i)) {
			const sw = a.slice(left.i, right.i) + a.slice(ai, left.i);
			if (b.slice(bi).startsWith(sw)) {
				const len = sw.length;
				yield {
					a,
					b,
					ai: ai + len,
					bi: bi + len,
					c: c + right.c,
					p: p + right.p
				};
			}
		}
	}
	calcAdjustment(word) {
		let penalty = 0;
		for (const adj of this.weightMap.adjustments.values()) if (adj.regexp.global) for (const _m of word.matchAll(adj.regexp)) penalty += adj.penalty;
		else if (adj.regexp.test(word)) penalty += adj.penalty;
		return penalty;
	}
};
function normalizeDef(def) {
	const { map, ...rest } = def;
	return {
		...rest,
		map: normalizeMap(map)
	};
}
function normalizeMap(map) {
	return map.replaceAll(matchPossibleWordSeparators, DEFAULT_COMPOUNDED_WORD_SEPARATOR);
}
/**
* Calculate the edit distance between two words using an A* algorithm.
*
* Using basic weights, this algorithm has the same results as the Damerau-Levenshtein algorithm.
*/
function distanceAStarWeighted(wordA, wordB, map, cost = 100) {
	const calc = createWeightCostCalculator(map);
	const best = _distanceAStarWeightedEx(wordA, wordB, calc, cost);
	const penalty = calc.calcAdjustment(wordB);
	return best.c + best.p + penalty;
}
function _distanceAStarWeightedEx(wordA, wordB, map, cost = 100) {
	const a = "^" + wordA + "$";
	const b = "^" + wordB + "$";
	const aN = a.length;
	const bN = b.length;
	const candidates = new CandidatePool(aN, bN);
	candidates.add({
		ai: 0,
		bi: 0,
		c: 0,
		p: 0,
		f: void 0
	});
	/** Substitute / Replace */
	function opSub(n) {
		const { ai, bi, c, p } = n;
		if (ai < aN && bi < bN) {
			const cc = a[ai] === b[bi] ? c : c + cost;
			candidates.add({
				ai: ai + 1,
				bi: bi + 1,
				c: cc,
				p,
				f: n
			});
		}
	}
	/** Insert */
	function opIns(n) {
		const { ai, bi, c, p } = n;
		if (bi < bN) candidates.add({
			ai,
			bi: bi + 1,
			c: c + cost,
			p,
			f: n
		});
	}
	/** Delete */
	function opDel(n) {
		const { ai, bi, c, p } = n;
		if (ai < aN) candidates.add({
			ai: ai + 1,
			bi,
			c: c + cost,
			p,
			f: n
		});
	}
	/** Swap adjacent letters */
	function opSwap(n) {
		const { ai, bi, c, p } = n;
		if (a[ai] === b[bi + 1] && a[ai + 1] === b[bi]) candidates.add({
			ai: ai + 2,
			bi: bi + 2,
			c: c + cost,
			p,
			f: n
		});
	}
	function opMap(n) {
		const { ai, bi, c, p } = n;
		const pos = {
			a,
			b,
			ai,
			bi,
			c,
			p
		};
		[
			map.calcInsDelCosts(pos),
			map.calcSwapCosts(pos),
			map.calcReplaceCosts(pos)
		].forEach((iter) => {
			for (const nn of iter) candidates.add({
				...nn,
				f: n
			});
		});
	}
	let best;
	while (best = candidates.next()) {
		if (best.ai === aN && best.bi === bN) break;
		opSwap(best);
		opIns(best);
		opDel(best);
		opMap(best);
		opSub(best);
	}
	assert$3(best);
	return best;
}
var CandidatePool = class {
	pool = new PairingHeap$1(compare$1);
	grid = [];
	aN;
	bN;
	constructor(aN, bN) {
		this.aN = aN;
		this.bN = bN;
	}
	next() {
		let n;
		while (n = this.pool.dequeue()) if (!n.d) return n;
	}
	add(n) {
		const i = idx(n.ai, n.bi, this.bN);
		const g = this.grid[i];
		if (!g) {
			this.grid[i] = n;
			this.pool.add(n);
			return;
		}
		if (g.c <= n.c) return;
		g.d = true;
		this.grid[i] = n;
		this.pool.add(n);
	}
};
function idx(r, c, cols) {
	return r * cols + c;
}
function compare$1(a, b) {
	return a.c - b.c || b.ai + b.bi - a.ai - a.bi;
}
const initialRow = [...".".repeat(50)].map((_, i) => i);
Object.freeze(initialRow);
const defaultCost = 100;
/**
* Calculate the weighted edit distance between any two words.
* @param wordA
* @param wordB
* @param weights - the weights to use
* @param editCost - the cost of each edit (defaults to 100)
* @returns the edit distance
*/
function editDistanceWeighted(wordA, wordB, weights, editCost = defaultCost) {
	return distanceAStarWeighted(wordA, wordB, weights, editCost);
}
function startTimer() {
	const start = performance.now();
	return () => performance.now() - start;
}
function isDefined$1$1(a) {
	return a !== void 0;
}
/**
* Remove any fields with an `undefined` value.
* @param t - object to clean
* @returns t
*/
function cleanCopy(t) {
	return clean$1$1({ ...t });
}
/**
* Remove any fields with an `undefined` value.
* **MODIFIES THE OBJECT**
* @param t - object to clean
* @returns t
*/
function clean$1$1(t) {
	for (const prop in t) if (t[prop] === void 0) delete t[prop];
	return t;
}
function unique(a) {
	return [...new Set(a)];
}
/**
*
* @param text verbatim text to be inserted into a regexp
* @returns text that can be used in a regexp.
*/
function regexQuote(text) {
	return text.replaceAll(/([[\]\-+(){},|*.\\])/g, "\\$1");
}
/**
* Factory to create a function that will replace all occurrences of `match` with `withText`
* @param match - string to match
* @param replaceWithText - the text to substitute.
*/
function replaceAllFactory(match, replaceWithText) {
	const r = RegExp(regexQuote(match), "g");
	return (text) => text.replace(r, replaceWithText);
}
const defaultMaxNumberSuggestions = 10;
const BASE_COST = 100;
const MAX_NUM_CHANGES = 5;
const MAX_ALLOWED_COST_SCALE = 1.03 * .5;
const collator = new Intl.Collator();
const regexSeparator = new RegExp(`[${regexQuote(WORD_SEPARATOR)}]`, "g");
const wordLengthCost = [
	0,
	50,
	25,
	5,
	0
];
const EXTRA_WORD_COST = 5;
/** time in ms */
const DEFAULT_COLLECTOR_TIMEOUT = 1e3;
const symStopProcessing = Symbol("Collector Stop Processing");
function compSuggestionResults(a, b) {
	return (a.isPreferred && -1 || 0) - (b.isPreferred && -1 || 0) || a.cost - b.cost || a.word.length - b.word.length || collator.compare(a.word, b.word);
}
const defaultSuggestionCollectorOptions = Object.freeze({
	numSuggestions: defaultMaxNumberSuggestions,
	filter: () => true,
	changeLimit: MAX_NUM_CHANGES,
	includeTies: false,
	ignoreCase: true,
	timeout: DEFAULT_COLLECTOR_TIMEOUT,
	weightMap: void 0,
	compoundSeparator: "",
	compoundMethod: void 0
});
function suggestionCollector(wordToMatch, options) {
	const { filter = () => true, changeLimit = MAX_NUM_CHANGES, includeTies = false, ignoreCase = true, timeout = DEFAULT_COLLECTOR_TIMEOUT, weightMap, compoundSeparator = defaultSuggestionCollectorOptions.compoundSeparator } = options;
	const numSuggestions = Math.max(options.numSuggestions, 0) || 0;
	const numSugToHold = weightMap ? numSuggestions * 2 : numSuggestions;
	const sugs = /* @__PURE__ */ new Map();
	let maxCost = BASE_COST * Math.min(wordToMatch.length * MAX_ALLOWED_COST_SCALE, changeLimit);
	const useSeparator = compoundSeparator || (weightMap ? DEFAULT_COMPOUNDED_WORD_SEPARATOR : defaultSuggestionCollectorOptions.compoundSeparator);
	const fnCleanWord = !useSeparator || useSeparator === compoundSeparator ? (w) => w : replaceAllFactory(useSeparator, "");
	if (useSeparator && weightMap) addDefToWeightMap(weightMap, {
		map: useSeparator,
		insDel: 50
	});
	const genSuggestionOptions = clean$1$1({
		changeLimit,
		ignoreCase,
		compoundMethod: options.compoundMethod,
		compoundSeparator: useSeparator
	});
	let timeRemaining = timeout;
	function dropMax() {
		if (sugs.size < 2 || !numSuggestions) {
			sugs.clear();
			return;
		}
		const sorted = [...sugs.values()].sort(compSuggestionResults);
		let i = numSugToHold - 1;
		maxCost = sorted[i].cost;
		for (; i < sorted.length && sorted[i].cost <= maxCost; ++i);
		for (; i < sorted.length; ++i) sugs.delete(sorted[i].word);
	}
	function adjustCost(sug) {
		if (sug.isPreferred) return sug;
		const words = sug.word.split(regexSeparator);
		const extraCost = words.map((w) => wordLengthCost[w.length] || 0).reduce((a, b) => a + b, 0) + (words.length - 1) * EXTRA_WORD_COST;
		return {
			word: sug.word,
			cost: sug.cost + extraCost
		};
	}
	function collectSuggestion(suggestion) {
		const { word, cost, isPreferred } = adjustCost(suggestion);
		if (cost <= maxCost && filter(suggestion.word, cost)) {
			const known = sugs.get(word);
			if (known) {
				known.cost = Math.min(known.cost, cost);
				known.isPreferred = known.isPreferred || isPreferred;
			} else {
				sugs.set(word, {
					word,
					cost,
					isPreferred
				});
				if (cost < maxCost && sugs.size > numSugToHold) dropMax();
			}
		}
		return maxCost;
	}
	/**
	* Collection suggestions from a SuggestionIterator
	* @param src - the SuggestionIterator used to generate suggestions.
	* @param timeout - the amount of time in milliseconds to allow for suggestions.
	*/
	function collect(src, timeout, filter) {
		let stop = false;
		timeout = timeout ?? timeRemaining;
		timeout = Math.min(timeout, timeRemaining);
		if (timeout < 0) return;
		const timer = startTimer();
		let ir;
		while (!(ir = src.next(stop || maxCost)).done) {
			if (timer() > timeout) stop = symStopProcessing;
			const { value } = ir;
			if (!value) continue;
			if (isSuggestionResult(value)) {
				if (!filter || filter(value.word, value.cost)) collectSuggestion(value);
				continue;
			}
		}
		timeRemaining -= timer();
	}
	function cleanCompoundResult(sr) {
		const { word, cost } = sr;
		const cWord = fnCleanWord(word);
		if (cWord !== word) return {
			word: cWord,
			cost,
			compoundWord: word,
			isPreferred: void 0
		};
		return { ...sr };
	}
	function suggestions() {
		if (numSuggestions < 1 || !sugs.size) return [];
		const NF = "NFD";
		const nWordToMatch = wordToMatch.normalize(NF);
		const rawValues = [...sugs.values()];
		const sorted = (weightMap ? rawValues.map(({ word, cost, isPreferred }) => ({
			word,
			cost: isPreferred ? cost : editDistanceWeighted(nWordToMatch, word.normalize(NF), weightMap, 110),
			isPreferred
		})) : rawValues).sort(compSuggestionResults).map(cleanCompoundResult);
		let i = Math.min(sorted.length, numSuggestions) - 1;
		const limit = includeTies ? sorted.length : Math.min(sorted.length, numSuggestions);
		const iCost = sorted[i].cost;
		const maxCost = Math.min(iCost, weightMap ? changeLimit * BASE_COST - 1 : iCost);
		for (i = 1; i < limit && sorted[i].cost <= maxCost; ++i);
		sorted.length = i;
		return sorted;
	}
	return {
		collect,
		add: function(suggestion) {
			collectSuggestion(suggestion);
			return this;
		},
		get suggestions() {
			return suggestions();
		},
		get maxCost() {
			return maxCost;
		},
		get word() {
			return wordToMatch;
		},
		get maxNumSuggestions() {
			return numSuggestions;
		},
		get changeLimit() {
			return changeLimit;
		},
		includesTies: includeTies,
		ignoreCase,
		symbolStopProcessing: symStopProcessing,
		genSuggestionOptions
	};
}
/**
* Impersonating a Collector, allows searching for multiple variants on the same word.
* The collection is still in the original collector.
* @param collector - collector to impersonate
* @param word - word to present instead of `collector.word`.
* @returns a SuggestionCollector
*/
function impersonateCollector(collector, word) {
	const r = Object.create(collector);
	Object.defineProperty(r, "word", {
		value: word,
		writable: false
	});
	return r;
}
function isSuggestionResult(s) {
	const r = s;
	return !!r && typeof r === "object" && r?.cost !== void 0 && r.word !== void 0;
}
/**
* Compare Path Nodes.
* Balance the calculation between depth vs cost
*/
function comparePath(a, b) {
	return a.c / (a.i + 1) - b.c / (b.i + 1) + (b.i - a.i);
}
function suggestAStar(trie, word, options = {}) {
	const opts = createSuggestionOptions(options);
	const collector = suggestionCollector(word, opts);
	collector.collect(getSuggestionsAStar(trie, word, opts));
	return collector.suggestions;
}
function* getSuggestionsAStar(trie, srcWord, options = {}) {
	const { compoundMethod, changeLimit, ignoreCase, weightMap } = createSuggestionOptions(options);
	const visMap = visualLetterMaskMap;
	const root = trie.getRoot();
	const rootIgnoreCase = ignoreCase && root.get(root.info.stripCaseAndAccentsPrefix) || void 0;
	const pathHeap = new PairingHeap$1(comparePath);
	const resultHeap = new PairingHeap$1(compareSuggestion);
	const rootPNode = {
		n: root,
		i: 0,
		c: 0,
		s: "",
		p: void 0,
		t: createCostTrie()
	};
	const BC = opCosts.baseCost;
	const VC = opCosts.visuallySimilar;
	const DL = opCosts.duplicateLetterCost;
	const wordSeparator = compoundMethod === CompoundWordsMethod.JOIN_WORDS ? JOIN_SEPARATOR : WORD_SEPARATOR;
	const sc = specialChars(trie.info);
	const comp = trie.info.compoundCharacter;
	const compRoot = root.get(comp);
	const compRootIgnoreCase = rootIgnoreCase && rootIgnoreCase.get(comp);
	const emitted = Object.create(null);
	const debug = isDebuggerAttached();
	const srcLetters = [...srcWord];
	/** Initial limit is based upon the length of the word. */
	let limit = BC * Math.min(srcLetters.length * opCosts.wordLengthCostFactor, changeLimit);
	pathHeap.add(rootPNode);
	if (rootIgnoreCase) pathHeap.add({
		n: rootIgnoreCase,
		i: 0,
		c: 0,
		s: "",
		p: void 0,
		t: createCostTrie()
	});
	let best = pathHeap.dequeue();
	let maxSize = pathHeap.size;
	let suggestionsGenerated = 0;
	let nodesProcessed = 0;
	let nodesProcessedLimit = 1e3;
	let minGen = 1;
	while (best) {
		if (++nodesProcessed > nodesProcessedLimit) {
			nodesProcessedLimit += 1e3;
			if (suggestionsGenerated < minGen) break;
			minGen += suggestionsGenerated;
		}
		if (best.c > limit) {
			best = pathHeap.dequeue();
			maxSize = Math.max(maxSize, pathHeap.size);
			continue;
		}
		processPath(best);
		for (const sug of resultHeap) {
			++suggestionsGenerated;
			if (sug.cost > limit) continue;
			if (sug.word in emitted && emitted[sug.word] <= sug.cost) continue;
			const action = yield sug;
			emitted[sug.word] = sug.cost;
			if (typeof action === "number") limit = Math.min(action, limit);
			if (typeof action === "symbol") return;
		}
		best = pathHeap.dequeue();
		maxSize = Math.max(maxSize, pathHeap.size);
	}
	return;
	function compareSuggestion(a, b) {
		const pa = a.isPreferred && 1 || 0;
		return (b.isPreferred && 1 || 0) - pa || a.cost - b.cost || Math.abs(a.word.charCodeAt(0) - srcWord.charCodeAt(0)) - Math.abs(b.word.charCodeAt(0) - srcWord.charCodeAt(0));
	}
	function processPath(p) {
		const len = srcLetters.length;
		if (p.n.eow && p.i === len) {
			const result = {
				word: pNodeToWord(p),
				cost: p.c
			};
			if (debug) console.log("add possible suggestion: %o", {
				...result,
				nodes: pNodeToDbgInfo(p).map(({ id, s, c, a }) => `${a}{${s || ""}} $${c}-> ${id} `).join("")
			});
			resultHeap.add(result);
		}
		calcEdges(p);
	}
	function calcEdges(p) {
		const { n, i, t } = p;
		const s = srcLetters[i];
		const sg = visMap[s] || 0;
		const cost0 = p.c;
		const cost = cost0 + BC + (i ? 0 : opCosts.firstLetterBias);
		const costVis = cost0 + VC;
		const costLegacyCompound = cost0 + opCosts.wordBreak;
		const costCompound = cost0 + opCosts.compound;
		if (s) {
			const m = n.get(s);
			if (m) storePath(t, m, i + 1, cost0, s, p, "=", s);
			if (weightMap) processWeightMapEdges(p, weightMap);
			const ns = srcLetters[i + 1];
			if (s === ns && m) storePath(t, m, i + 2, cost0 + DL, s, p, "dd", s);
			storePath(t, n, i + 1, cost, "", p, "d", "");
			for (const [ss, node] of n.entries()) {
				if (ss === s || ss in sc) continue;
				const c = sg & (visMap[ss] || 0) ? costVis : cost;
				storePath(t, node, i + 1, c, ss, p, "r", ss);
			}
			if (n.eow && i && compoundMethod) storePath(t, root, i, costLegacyCompound, wordSeparator, p, "L", wordSeparator);
			if (ns) {
				const n2 = n.get(ns)?.get(s);
				if (n2) {
					const ss = ns + s;
					storePath(t, n2, i + 2, cost0 + opCosts.swapCost, ss, p, "s", ss);
				}
			}
		}
		if (compRoot && costCompound <= limit && n.get(comp)) {
			if (compRootIgnoreCase) storePath(t, compRootIgnoreCase, i, costCompound, "", p, "~+", "~+");
			storePath(t, compRoot, i, costCompound, "", p, "+", "+");
		}
		if (cost <= limit) for (const [char, node] of n.entries()) {
			if (char in sc) continue;
			storePath(t, node, i, cost, char, p, "i", char);
		}
	}
	function processWeightMapEdges(p, weightMap) {
		delLetters(p, weightMap, srcLetters, storePath);
		insLetters(p, weightMap, srcLetters, storePath);
		repLetters(p, weightMap, srcLetters, storePath);
	}
	/**
	* Apply a cost to the current step.
	* @param t - trie node
	* @param s - letter to apply, empty string means to apply to the current node
	* @param i - index
	* @param c - cost
	* @returns PNode if it was applied, otherwise undefined
	*/
	function storePath(t, n, i, c, s, p, a, ss) {
		const tt = getCostTrie(t, ss);
		if (tt.c[i] <= c || c > limit) return void 0;
		tt.c[i] = c;
		pathHeap.add({
			n,
			i,
			c,
			s,
			p,
			t: tt,
			a
		});
	}
}
function delLetters(pNode, weightMap, letters, storePath) {
	const { t, n } = pNode;
	const trie = weightMap.insDel;
	let ii = pNode.i;
	const cost0 = pNode.c - pNode.i;
	const len = letters.length;
	for (let nn = trie.n; ii < len && nn;) {
		const tt = nn[letters[ii]];
		if (!tt) return;
		++ii;
		if (tt.c !== void 0) storePath(t, n, ii, cost0 + tt.c, "", pNode, "d", "");
		nn = tt.n;
	}
}
function insLetters(p, weightMap, _letters, storePath) {
	const { t, i, c, n } = p;
	const cost0 = c;
	searchTrieCostNodesMatchingTrie2(weightMap.insDel, n, (s, tc, n) => {
		if (tc.c !== void 0) storePath(t, n, i, cost0 + tc.c, s, p, "i", s);
	});
}
function repLetters(pNode, weightMap, letters, storePath) {
	const node = pNode.n;
	const pt = pNode.t;
	const cost0 = pNode.c;
	const len = letters.length;
	const trie = weightMap.replace;
	let i = pNode.i;
	for (let n = trie.n; i < len && n;) {
		const t = n[letters[i]];
		if (!t) return;
		++i;
		const tInsert = t.t;
		if (tInsert) searchTrieCostNodesMatchingTrie2(tInsert, node, (s, tt, n) => {
			const c = tt.c;
			if (c === void 0) return;
			storePath(pt, n, i, cost0 + c + (tt.p || 0), s, pNode, "r", s);
		});
		n = t.n;
	}
}
function createCostTrie() {
	return {
		c: [],
		t: Object.create(null)
	};
}
function getCostTrie(t, s) {
	if (s.length === 1) return t.t[s] ??= createCostTrie();
	if (!s) return t;
	let tt = t;
	for (const c of s) tt = tt.t[c] ??= createCostTrie();
	return tt;
}
function pNodeToDbgInfo(p) {
	const parts = [];
	let n = p;
	while (n) {
		const id = formatNodeId(n.n.id);
		parts.push({
			id,
			s: n.s,
			c: n.c,
			a: n.a || ""
		});
		n = n.p;
	}
	parts.reverse();
	return parts;
}
function formatNodeId(id) {
	const s = id.toString(16).padStart(16, "0");
	const upper = s.slice(0, 8).replace(/^0+/, "").padStart(4, "0");
	const lower = s.slice(8).replace(/^0+/, "");
	return `${upper}${lower ? "." + lower : ""}`;
}
function pNodeToWord(p) {
	const parts = [];
	let n = p;
	while (n) {
		parts.push(n.s);
		n = n.p;
	}
	parts.reverse();
	return parts.join("");
}
function specialChars(options) {
	const charSet = Object.create(null);
	for (const c of Object.values(options)) if (typeof c === "string") charSet[c] = true;
	return charSet;
}
function searchTrieCostNodesMatchingTrie2(trie, node, emit, s = "") {
	const n = trie.n;
	if (!n) return;
	for (const [key, c] of node.entries()) {
		const t = n[key];
		if (!t) continue;
		const pfx = s + key;
		emit(pfx, t, c);
		if (t.n) searchTrieCostNodesMatchingTrie2(t, c, emit, pfx);
	}
}
const defaultTrieInfoSettings = {
	forbiddenWordPrefix: "!",
	stripCaseAndAccentsPrefix: "~",
	compoundCharacter: "+",
	suggestionPrefix: ":"
};
const revMapDefaultTrieInfoSettings = {
	"!": "forbiddenWordPrefix",
	"~": "stripCaseAndAccentsPrefix",
	"+": "compoundCharacter",
	":": "suggestionPrefix"
};
const defaultTrieCharacteristics = {
	hasForbiddenWords: "!",
	hasNonStrictWords: "~",
	hasCompoundWords: "+",
	hasPreferredSuggestions: ":"
};
const mapInfoToCharacteristics = {
	compoundCharacter: "hasCompoundWords",
	stripCaseAndAccentsPrefix: "hasNonStrictWords",
	forbiddenWordPrefix: "hasForbiddenWords",
	suggestionPrefix: "hasPreferredSuggestions"
};
const mapCharacteristicToInfo = {
	hasCompoundWords: "compoundCharacter",
	hasNonStrictWords: "stripCaseAndAccentsPrefix",
	hasForbiddenWords: "forbiddenWordPrefix",
	hasPreferredSuggestions: "suggestionPrefix"
};
const keysTrieCharacteristics = Object.keys(defaultTrieCharacteristics);
const keysTrieInfo = Object.keys(defaultTrieInfoSettings);
const revMapDefaultTrieCharacteristics = {
	"!": "hasForbiddenWords",
	"+": "hasCompoundWords",
	"~": "hasNonStrictWords",
	":": "hasPreferredSuggestions"
};
function parseTrieInfoFlags(info) {
	const trieInfo = {};
	for (let i = 0; i < info.length; i += 2) {
		const k = info[i];
		const c = info[i + 1];
		if (!charInRevMapDefaultTrieInfoSettings(k) || !c) continue;
		const key = revMapDefaultTrieInfoSettings[k];
		trieInfo[key] = c;
	}
	return trieInfo;
}
function normalizeTrieInfo(info, defaultInfo = defaultTrieInfoSettings) {
	return {
		compoundCharacter: info?.compoundCharacter || defaultInfo.compoundCharacter,
		stripCaseAndAccentsPrefix: info?.stripCaseAndAccentsPrefix || defaultInfo.stripCaseAndAccentsPrefix,
		forbiddenWordPrefix: info?.forbiddenWordPrefix || defaultInfo.forbiddenWordPrefix,
		suggestionPrefix: info?.suggestionPrefix || defaultInfo.suggestionPrefix
	};
}
/**
* Extract the TrieInfo a source PartialTrieInfo
* @param info - The source PartialTrieInfo
* @returns a new object with only the defined TrieInfo properties.
*/
function extractTrieInfo(info) {
	return partialInfoToInfo(info);
}
function cvtTrieInfoToFlags(info) {
	let flags = "";
	for (const k of keysTrieInfo) {
		const c = info[k];
		if (!c) continue;
		assert$3(c.length === 1, `Expected single character for trie info ${k}, got '${c}'`);
		const flagChar = defaultTrieInfoSettings[k];
		flags += flagChar + c;
	}
	return flags;
}
function charInRevMapDefaultTrieInfoSettings(c) {
	return c in revMapDefaultTrieInfoSettings;
}
function parseTrieCharacteristics(chars) {
	const characteristics = {};
	for (const c of chars) {
		if (!charInRevMapDefaultTrieCharacteristics(c)) continue;
		const key = revMapDefaultTrieCharacteristics[c];
		characteristics[key] = true;
	}
	return characteristics;
}
function mapTrieCharacteristics(characteristics, info) {
	let chars = "";
	for (const k of keysTrieCharacteristics) if (characteristics[k] === true) {
		const c = info[mapCharacteristicToInfo[k]] || "";
		chars += c;
	}
	return chars;
}
function cvtTrieCharacteristicsToFlags(characteristics) {
	return mapTrieCharacteristics(characteristics, defaultTrieInfoSettings);
}
function charInRevMapDefaultTrieCharacteristics(c) {
	return c in revMapDefaultTrieCharacteristics;
}
function mapTrieCharacteristicToInfoValues(char, info) {
	return keysTrieCharacteristics.map((k) => [k, char[k]]).filter((kvp) => kvp[1] === true).map(([k]) => mapCharacteristicToInfo[k]).map((k) => info[k]);
}
var TrieInfoBuilder = class {
	#givenInfo;
	#givenCharacteristics;
	#srcInfo;
	#knownChars;
	#foundChars;
	constructor(info, characteristics) {
		this.#givenInfo = info;
		this.#srcInfo = normalizeTrieInfo(info);
		this.#knownChars = revTrieInfo(this.#srcInfo);
		this.#givenCharacteristics = characteristics || {};
		this.#foundChars = new Set(mapTrieCharacteristicToInfoValues(this.#givenCharacteristics, this.#srcInfo));
	}
	setInfo(info) {
		this.#givenInfo = info;
		this.#srcInfo = normalizeTrieInfo(info);
		this.#knownChars = revTrieInfo(this.#srcInfo);
		this.#foundChars = new Set(mapTrieCharacteristicToInfoValues(this.#givenCharacteristics, this.#srcInfo));
	}
	getActiveInfo() {
		return this.#srcInfo;
	}
	addWord(word) {
		if (word[0] in this.#knownChars) this.#foundChars.add(word[0]);
	}
	#getCharacteristics() {
		const characteristics = {};
		for (const char of this.#foundChars) {
			const key = this.#knownChars[char];
			if (!key) continue;
			const charToCharacteristic = mapInfoToCharacteristics[key];
			if (!charToCharacteristic) continue;
			characteristics[charToCharacteristic] = true;
		}
		return characteristics;
	}
	#getInfo() {
		const info = partialInfoToInfo(this.#givenInfo);
		for (const char of this.#foundChars) {
			const key = this.#knownChars[char];
			if (!key) continue;
			info[key] = this.#srcInfo[key];
		}
		return info;
	}
	build() {
		return {
			info: this.#getInfo(),
			characteristics: this.#getCharacteristics()
		};
	}
};
function partialInfoToInfo(info) {
	if (!info) return {};
	return Object.fromEntries(keysTrieInfo.map((k) => [k, info[k]]).filter(([_k, v]) => !!v));
}
function revTrieInfo(info) {
	const rev = {};
	for (const k of keysTrieInfo) {
		const v = info[k];
		if (typeof v !== "string") continue;
		rev[v] = k;
	}
	return rev;
}
function endianness() {
	const uint32s = new Uint32Array([168496141]);
	return new Uint8Array(uint32s.buffer)[0] === 10 ? "BE" : "LE";
}
const isLittleEndian = endianness() === "LE";
const BytesSize = {
	uint8: 1,
	uint16: 2,
	uint32: 4,
	uint64: 8,
	string: 1
};
/**
* BinaryFormatBuilder is used to define the structure and layout of binary data.
* It provides methods to add various data types (uint8, uint16, uint32, strings, arrays)
* and pointers to the format definition. Each element is automatically aligned and positioned
* based on its type and size. Once all elements are added, call build() to create an
* immutable BinaryFormat that can be used with BinaryDataBuilder and BinaryDataReader.
*/
var BinaryFormatBuilder = class {
	#elements = [];
	#elementsByName = /* @__PURE__ */ new Map();
	#offset = 0;
	#textEncoder = new TextEncoder();
	addUint8(name, description, value) {
		const uValue = value === void 0 || typeof value === "number" ? new Uint8Array([value || 0]) : new Uint8Array(value);
		return this.addData(name, description, "value", uValue);
	}
	addUint16(name, description, value) {
		const uValue = value !== void 0 ? rawNumberToUint16Array(value) : rawNumberToUint16Array(0);
		return this.addData(name, description, "value", uValue);
	}
	addUint32(name, description, value) {
		const uValue = value !== void 0 ? rawNumberToUint32Array(value) : rawNumberToUint32Array(0);
		return this.addData(name, description, "value", uValue);
	}
	/**
	* A pointer to a uint32 array, it has two parts, the offset and the length.
	* @param name - name of pointer
	* @param description - the description of the field
	* @param overload - optional name of element to overload
	* @returns this
	*/
	addUint32ArrayPtr(name, description, overload) {
		return this.addPointer(BytesSize.uint32, name, description, overload);
	}
	/**
	* A pointer to a uint16 array, it has two parts, the offset and the length.
	* @param name - name of pointer
	* @param description - the description of the field
	* @param overload - optional name of element to overload
	* @returns this
	*/
	addUint16ArrayPtr(name, description, overload) {
		return this.addPointer(BytesSize.uint16, name, description, overload);
	}
	/**
	* A pointer to a uint8 array, it has two parts, the offset and the length.
	* @param name - name of pointer
	* @param description - the description of the field
	* @param overload - optional name of element to overload
	* @returns this
	*/
	addUint8ArrayPtr(name, description, overload) {
		return this.addPointer(BytesSize.uint8, name, description, overload);
	}
	/**
	* A pointer to a string of UTF-8 bytes, it has two parts, the offset and the length.
	* @param name - name of pointer
	* @param description - the description of the field
	* @param overload - optional name of element to overload
	* @returns this
	*/
	addStringPtr(name, description, overload) {
		return this.addPointer(BytesSize.string, name, description, overload);
	}
	/**
	* Add a pointer element.
	* @param byteSize - size of each element pointed to
	* @param name - name of the pointer
	* @param description - description of the pointer
	* @param overload - optional name of element to overload
	* @returns this
	*/
	addPointer(byteSize, name, description, overload) {
		const alignment = 4;
		let offset = byteAlign(this.#offset, alignment);
		if (overload) {
			const existing = this.#elementsByName.get(overload);
			assert$3(existing, `Overload target not found: ${overload}`);
			offset = byteAlign(existing.offset, alignment);
			assert$3(existing.offset === offset, `Overload target offset mismatch: ${overload}`);
		}
		const element = {
			name,
			description,
			type: "ptr+size",
			alignment,
			offset,
			size: 8,
			value: void 0,
			byteSize,
			overload
		};
		this.#addElement(element);
		return this;
	}
	addString(name, description, length) {
		const value = typeof length === "string" ? this.#textEncoder.encode(length) : new Uint8Array(length);
		this.addData(name, description, "value", value);
		return this;
	}
	addUint8Array(name, description, length) {
		const value = new Uint8Array(length);
		this.addData(name, description, "value", value);
		return this;
	}
	addData(name, description, formatType, data) {
		const byteSize = data.byteLength / data.length;
		assert$3(isByteAlignment(byteSize), `Invalid byte size: ${byteSize} for field: ${name}`);
		const alignment = byteSize;
		const offset = byteAlign(this.#offset, byteSize);
		const value = new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
		const size = value.byteLength;
		this.#addElement({
			name,
			description,
			type: formatType,
			alignment,
			offset,
			size,
			value,
			byteSize
		});
		return this;
	}
	#addElement(element) {
		assert$3(!this.#elementsByName.has(element.name), `Duplicate element name: ${element.name}`);
		const expectedOffset = byteAlign(element.offset, element.alignment);
		assert$3(element.offset === expectedOffset, `Element alignment mismatch for ${element.name} with alignment ${element.alignment}. Expected: ${expectedOffset}, Found: ${element.offset}`);
		this.#elementsByName.set(element.name, element);
		this.#elements.push(element);
		if (!element.overload) this.#offset = element.offset + element.size;
	}
	build() {
		return new BinaryFormat([...this.#elements]);
	}
};
/**
* BinaryFormat represents the structure and layout of binary data.
* It contains a collection of format elements that describe the fields,
* their types, offsets, sizes, and byte alignment within the binary data.
*
* This class is typically created using BinaryFormatBuilder and is used
* by BinaryDataBuilder and BinaryDataReader to write and read binary data
* according to the defined format.
*/
var BinaryFormat = class {
	elements;
	#fieldsByName = /* @__PURE__ */ new Map();
	#offset;
	constructor(elements) {
		this.elements = elements;
		this.#fieldsByName = new Map(elements.map((el) => [el.name, el]));
		this.#offset = Math.max(...elements.map((el) => el.offset + el.size), 0);
	}
	get size() {
		return this.#offset;
	}
	getField(name) {
		return this.#fieldsByName.get(name);
	}
	toJSON() {
		return this.elements.map(formatElementToJSON);
	}
	toString() {
		const nameWidth = Math.max(4, ...this.elements.map((el) => el.name.length), 4);
		const offsetWidth = 8;
		const sizeWidth = 6;
		const typeWidth = Math.max(4, ...this.elements.map((el) => el.type.length), 4);
		const lines = [];
		addHeaderLines();
		this.elements.forEach(addElement);
		return lines.join("\n");
		function addHeaderLines() {
			const line = formatLine([
				"name",
				"offset",
				"size",
				"type",
				"mask",
				"description",
				"value"
			]);
			lines.push("Binary Format:");
			lines.push(line);
			lines.push("-".repeat(line.length));
		}
		function addElement(e) {
			lines.push(formatLine([
				e.name,
				e.offset.toString(),
				e.size.toString(),
				e.type,
				e.byteSize.toString(2).padStart(4, "0"),
				e.description,
				e.value ? `${e.value}` : ""
			]));
		}
		function formatLine([name, offset, size, type, mask, description, value]) {
			name = name.padEnd(nameWidth, " ");
			offset = offset.padStart(offsetWidth, " ");
			size = size.padStart(sizeWidth, " ");
			type = type.padEnd(typeWidth, " ");
			value = value ? `(${value})` : "";
			return `${name} ${offset} ${size} ${type} ${mask} ${description} ${value}`.trim();
		}
	}
};
var BinaryDataBuilder = class {
	#dataElementMap = /* @__PURE__ */ new Map();
	#offset = 0;
	#endian;
	#useLE;
	#encoder = new TextEncoder();
	#dataByOffset = /* @__PURE__ */ new Map();
	format;
	constructor(format, endian = endianness()) {
		this.format = format;
		this.#offset = format.size;
		this.#endian = endian;
		this.#useLE = endian === "LE";
		this.#dataElementMap = /* @__PURE__ */ new Map();
		this.#populateDataElementMap();
	}
	#populateDataElementMap() {
		for (const ref of this.format.elements) {
			const { name, offset, size } = ref;
			let data = this.#dataByOffset.get(offset);
			if (!data || data.byteLength < size) {
				data = new Uint8Array(size);
				this.#dataByOffset.set(offset, data);
			}
			if (ref.value) data.set(ref.value);
			const de = {
				name,
				offset,
				size,
				data,
				ref
			};
			this.#dataElementMap.set(de.name, de);
			this.#offset = Math.max(this.#offset, offset + size);
		}
	}
	setString(name, value) {
		const element = this.getDataElement(name);
		assert$3(element, `Field not found: ${name}`);
		const formatElement = element.ref;
		assert$3(formatElement, `Field Format not found: ${name}`);
		assert$3(formatElement.byteSize === BytesSize.string, `Field is not a string: ${name}`);
		assert$3(this.#encoder.encodeInto(value, element.data).read === value.length, `String too long for field ${name}: ${value}`);
		return this;
	}
	setUint32(name, value) {
		const element = this.getDataElement(name);
		assert$3(element, `Field not found: ${name}`);
		const formatElement = element.ref;
		assert$3(formatElement, `Field Format not found: ${name}`);
		assert$3(formatElement.byteSize === BytesSize.uint32, `Field is not a uint32: ${name}`);
		const view = new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength);
		const useLittle = this.#endian === "LE";
		view.setUint32(0, value, useLittle);
		return this;
	}
	setUint16(name, value) {
		const element = this.getDataElement(name);
		assert$3(element, `Field not found: ${name}`);
		const formatElement = element.ref;
		assert$3(formatElement, `Field Format not found: ${name}`);
		assert$3(formatElement.byteSize === BytesSize.uint16, `Field is not a uint16: ${name}`);
		const view = new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength);
		const useLittle = this.#endian === "LE";
		view.setUint16(0, value, useLittle);
		return this;
	}
	setUint8(name, value) {
		const element = this.getDataElement(name);
		assert$3(element, `Field not found: ${name}`);
		const formatElement = element.ref;
		assert$3(formatElement, `Field Format not found: ${name}`);
		assert$3(formatElement.byteSize === BytesSize.uint8, `Field is not a uint8: ${name}`);
		element.data[0] = value;
		return this;
	}
	/**
	* Adjust the offset so it lands on the alignment boundary.
	* 1 = byte align
	* 2 = 16bit align
	* 4 = 32bit align
	* 8 = 64bit align
	* @param alignment - the byte alignment
	*/
	alignTo(alignment) {
		const aMask = alignment - 1;
		this.#offset = this.#offset + aMask & ~aMask;
	}
	/**
	* Append a data element to the binary data.
	* @param data - the data to add
	* @returns the DataElement added
	*/
	addDataElement(data, alignment) {
		this.alignTo(alignment);
		const offset = this.#offset;
		const name = `data_${offset}`;
		const size = data.byteLength;
		const de = {
			name,
			offset,
			size,
			data
		};
		this.#dataElementMap.set(de.name, de);
		this.#offset = offset + size;
		return de;
	}
	/**
	* Append the data and set the pointer to it.
	* The Uint32Array  will be converted to the proper endianness if necessary.
	* @param name - name of the pointer field
	* @param data - the data to add
	* @param alignment - the alignment for the data, default 4
	* @returns this
	*/
	setPtrUint32Array(name, data, alignment = 4) {
		return this.#setPtrData(name, convertUint32ArrayToUint8Array(data, this.#useLE), alignment);
	}
	/**
	* Append the data and set the pointer to it.
	* The Uint16Array  will be converted to the proper endianness if necessary.
	* @param name - name of the pointer field
	* @param data - the data to add
	* @param alignment - the alignment for the data, default 2
	* @returns this
	*/
	setPtrUint16Array(name, data, alignment = 2) {
		return this.#setPtrData(name, convertUint16ArrayToUint8Array(data, this.#useLE), alignment);
	}
	/**
	* Append the data and set the pointer to it.
	* @param name - name of the pointer field
	* @param data - the data to add
	* @param alignment - the alignment for the data, default 1
	* @returns this
	*/
	setPtrUint8Array(name, data, alignment = 1) {
		return this.#setPtrData(name, data, alignment);
	}
	/**
	* Append the string and set the pointer to it. It will be encoded as UTF-8.
	* Note: the alignment is 1. Use alignTo() if you need a different alignment.
	* @param name - name of the pointer field
	* @param str - the data to add
	* @returns this
	*/
	setPtrString(name, str) {
		return this.#setPtrData(name, this.#encoder.encode(str), 1);
	}
	#setPtrData(name, dataView, alignment) {
		const element = this.getDataElement(name);
		assert$3(element, `Field not found: ${name}`);
		const formatElement = element.ref;
		assert$3(formatElement, `Field Format not found: ${name}`);
		assert$3(formatElement.type === "ptr+size", `Field is not a pointer: ${name}`);
		assert$3(formatElement.byteSize === alignment, `Pointer byte size mismatch: ${name}`);
		const data = new Uint8Array(dataView.buffer, dataView.byteOffset, dataView.byteLength);
		const de = this.addDataElement(data, alignment);
		this.#setPtr(element, de.offset, de.size);
		return this;
	}
	#setPtr(element, dataOffset, dataLength) {
		assert$3(element.data.byteLength >= 8, `Pointer data too small: ${element.name}`);
		const view = new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength);
		view.setUint32(0, dataOffset, this.#useLE);
		view.setUint32(4, dataLength, this.#useLE);
	}
	get offset() {
		return this.#offset;
	}
	get endian() {
		return this.#endian;
	}
	getDataElement(name) {
		return this.#dataElementMap.get(name);
	}
	build() {
		const buffer = new Uint8Array(this.#offset);
		for (const element of this.#dataElementMap.values()) buffer.set(element.data, element.offset);
		return buffer;
	}
};
function convertUint32ArrayEndiannessInPlace(data) {
	const view = new DataView(data.buffer, data.byteOffset, data.byteLength);
	const byteLength = data.length * 4;
	for (let i = 0; i < byteLength; i += 4) {
		const v = view.getUint32(i, true);
		view.setUint32(i, v, false);
	}
	return data;
}
function convertUint16ArrayEndiannessInPlace(data) {
	const view = new DataView(data.buffer, data.byteOffset, data.byteLength);
	const byteLength = data.length * 2;
	for (let i = 0; i < byteLength; i += 2) {
		const v = view.getUint16(i, true);
		view.setUint16(i, v, false);
	}
	return data;
}
function convertUint32ArrayToUint8Array(data, useLittle, isLE = isLittleEndian) {
	if (isLE === useLittle) return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
	const target = new Uint32Array(data.length);
	target.set(data);
	convertUint32ArrayEndiannessInPlace(target);
	return new Uint8Array(target.buffer, target.byteOffset, target.byteLength);
}
function convertUint16ArrayToUint8Array(data, useLittle, isLE = isLittleEndian) {
	if (isLE === useLittle) return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
	const target = new Uint16Array(data.length);
	target.set(data);
	convertUint16ArrayEndiannessInPlace(target);
	return new Uint8Array(target.buffer, target.byteOffset, target.byteLength);
}
function rawNumberToUint32Array(value) {
	return new Uint32Array([value]);
}
function rawNumberToUint16Array(value) {
	return new Uint16Array([value]);
}
var BinaryDataReader = class {
	data;
	format;
	#decoder = new TextDecoder();
	#useLE;
	/**
	* Binary Data Reader
	* @param data - the raw binary data
	* @param format - the expected format
	* @param endian - the endian of the data (can be changed later)
	*/
	constructor(data, format, endian = endianness()) {
		this.data = new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
		this.format = format;
		this.#useLE = endian === "LE";
	}
	/**
	* Get a string from the data.
	* It will decode the string as UTF-8 from the following field types: 'string', 'ptrString', 'ptrUint8Array'.
	* @param name - name of the string field
	* @returns string value
	*/
	getString(name) {
		const element = this.getDataElement(name);
		const formatElement = element.ref;
		assert$3(formatElement.byteSize === BytesSize.string, `Field is not a string: ${name}`);
		if (formatElement.type === "value") return this.#decoder.decode(element.data);
		assert$3(formatElement.type === "ptr+size", `Field is not a string: ${name}`);
		const strData = this.#getPtrData(element);
		return this.#decoder.decode(strData);
	}
	/**
	* Get a Uint32 from the data.
	* @param name - name of the Uint32 field
	* @returns number value
	*/
	getUint32(name) {
		const element = this.getDataElement(name);
		const formatElement = element.ref;
		assert$3(formatElement.type === "value" && formatElement.byteSize === BytesSize.uint32, `Field is not a uint32: ${name}`);
		return new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength).getUint32(0, this.#useLE);
	}
	/**
	* Get a Uint16 from the data.
	* @param name - name of the Uint16 field
	* @returns number value
	*/
	getUint16(name) {
		const element = this.getDataElement(name);
		const formatElement = element.ref;
		assert$3(formatElement.type === "value" && formatElement.byteSize === BytesSize.uint16, `Field is not a uint16: ${name}`);
		return new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength).getUint16(0, this.#useLE);
	}
	/**
	* Read a field as Uint16 starting at the given byte offset.
	* @param name - name of field
	* @param byteOffset - offset of in bytes from the beginning of the field
	* @returns the value read.
	*/
	getAsUint16(name, byteOffset = 0) {
		const element = this.getDataElement(name);
		return new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength).getUint16(byteOffset, this.#useLE);
	}
	/**
	* Get a Uint8 from the data.
	* @param name - name of the Uint8 field
	* @returns number value
	*/
	getUint8(name) {
		const element = this.getDataElement(name);
		const formatElement = element.ref;
		assert$3(formatElement.type === "value" && formatElement.byteSize === BytesSize.uint8, `Field is not a uint8: ${name}`);
		return element.data[0];
	}
	/**
	* Gets Uint32Array data from a pointer field.
	* Note: The returned Uint32Array may be a view of the underlying data.
	* If the endianness does not match, a copy will be made.
	* @param name - name of the field
	* @returns Uint32Array value
	*/
	getPtrUint32Array(name) {
		const element = this.getDataElement(name);
		const ref = element.ref;
		assert$3(ref.type === "ptr+size" && ref.byteSize === BytesSize.uint32, `Field is not a ptrUint32Array: ${name}`);
		const arrData = this.#getPtrData(element);
		const rawData32 = new Uint32Array(arrData.buffer, arrData.byteOffset, arrData.byteLength / ref.byteSize);
		if (isLittleEndian === this.#useLE) return rawData32;
		return convertUint32ArrayEndiannessInPlace(new Uint32Array(rawData32));
	}
	/**
	* Gets Uint16Array data from a pointer field.
	* Note: The returned Uint16Array may be a view of the underlying data.
	* If the endianness does not match, a copy will be made.
	* @param name - name of the field
	* @returns Uint16Array value
	*/
	getPtrUint16Array(name) {
		const element = this.getDataElement(name);
		const ref = element.ref;
		assert$3(ref.type === "ptr+size" && ref.byteSize === BytesSize.uint16, `Field is not a ptrUint16Array: ${name}`);
		const arrData = this.#getPtrData(element);
		const rawData16 = new Uint16Array(arrData.buffer, arrData.byteOffset, arrData.byteLength / ref.byteSize);
		if (isLittleEndian === this.#useLE) return rawData16;
		return convertUint16ArrayEndiannessInPlace(new Uint16Array(rawData16));
	}
	/**
	* Gets Uint8Array data from a pointer field.
	* Note: The returned Uint8Array is a view of the underlying data.
	* @param name - name of the field
	* @returns Uint8Array value
	*/
	getPtrUint8Array(name) {
		const element = this.getDataElement(name);
		assert$3(element.ref.type === "ptr+size", `Field is not a ptr+size: ${name}`);
		return this.#getPtrData(element);
	}
	/**
	* Gets string data from a pointer field.
	* @param name - name of the field
	* @returns string value
	*/
	getPtrString(name) {
		const element = this.getDataElement(name);
		assert$3(element.ref.type === "ptr+size", `Field is not a ptr+size: ${name}`);
		const strData = this.#getPtrData(element);
		return this.#decoder.decode(strData);
	}
	#getPtrData(element) {
		const formatElement = element.ref;
		assert$3(formatElement.type === "ptr+size", `Field is not a ptr+size: ${element.name} (${formatElement.type})`);
		const view = new DataView(element.data.buffer, element.data.byteOffset, element.data.byteLength);
		const offset = view.getUint32(0, this.#useLE);
		const length = view.getUint32(4, this.#useLE);
		return this.data.subarray(offset, offset + length);
	}
	/**
	* Get the Element information by name
	* @param name - name of the field
	* @returns DataElementWithRef
	*/
	getDataElement(name) {
		const element = this.format.getField(name);
		assert$3(element, `Field not found: ${name}`);
		const data = this.data.subarray(element.offset, element.offset + element.size);
		return {
			name: element.name,
			offset: element.offset,
			size: element.size,
			data,
			ref: element
		};
	}
	set endian(endian) {
		this.#useLE = endian === "LE";
	}
	get endian() {
		return this.#useLE ? "LE" : "BE";
	}
	reverseEndian() {
		this.#useLE = !this.#useLE;
	}
	/**
	* Get the raw bytes for a field.
	* @param name - name of the field
	* @returns the bytes or undefined
	*/
	getUint8Array(name) {
		const element = this.getDataElement(name);
		if (!element) return void 0;
		return element.data;
	}
	/**
	* Get the FormatElement for a field.
	* @param name - name of the field
	* @returns the element or undefined
	*/
	getField(name) {
		return this.format.getField(name);
	}
};
function formatElementToJSON(fe) {
	const { value } = fe;
	const v = value ? [...value] : void 0;
	return {
		...fe,
		value: v
	};
}
function byteAlign(offset, alignment) {
	const aMask = alignment - 1;
	return offset + aMask & ~aMask;
}
function isByteAlignment(value) {
	return value === 1 || value === 2 || value === 4 || value === 8;
}
var GTrieNode = class {
	children;
	value;
	constructor(value, children) {
		this.value = value;
		this.children = children;
	}
};
/**
* ### Generic Tries
*
* This is a Trie class that can contain any data. It is used in optimizing the dictionary and storing lookup data.
* The performance is "good enough" for most uses, but may need to be optimized for large data sets.
*
* K - Key type
* V - Value type
*/
var GTrie = class GTrie {
	root;
	constructor() {
		this.root = new GTrieNode();
	}
	/**
	*
	* @param keys - the path to the child node
	* @param value - the value to set / insert
	* @return the previous value if one existed
	*/
	insert(keys, value) {
		const node = this.insertNode(keys);
		const prev = node.value;
		node.value = value;
		return prev;
	}
	/**
	* Insert nodes for the given keys into the trie.
	* Existing nodes are reused.
	* @param keys
	* @returns the final node inserted or found
	*/
	insertNode(keys) {
		let currentNode = this.root;
		for (const key of keys) {
			let children = currentNode.children;
			if (!children) {
				children = /* @__PURE__ */ new Map();
				currentNode.children = children;
			}
			let child = children.get(key);
			if (!child) {
				child = new GTrieNode();
				children.set(key, child);
			}
			currentNode = child;
		}
		return currentNode;
	}
	findNode(keys) {
		let currentNode = this.root;
		for (const key of keys) {
			const children = currentNode.children;
			if (!children) return;
			const child = children.get(key);
			if (!child) return;
			currentNode = child;
		}
		return currentNode;
	}
	has(keys) {
		return this.findNode(keys)?.value !== void 0;
	}
	hasNode(keys) {
		return this.findNode(keys) !== void 0;
	}
	get(keys) {
		const node = this.findNode(keys);
		return node ? node.value : void 0;
	}
	static fromEntries(entries) {
		const trie = new GTrie();
		for (const [keys, value] of entries) trie.insert(keys, value);
		return trie;
	}
};
const symbolCSpell$1 = Symbol.for("cspell");
const globalThisCSpell$1 = globalThis;
function _measurePerfStart$1(name, enabled) {
	if (!enabled) return;
	performance.mark(name + "-start");
}
function _measurePerfEnd$1(name, enabled) {
	if (!enabled) return;
	performance.mark(name + "-end");
	performance.measure(name, name + "-start", name + "-end");
}
/**
* Creates performance marks and measures the time taken between them.
* @param name - name of the performance entry
* @returns a function to stop the timer.
*/
function measurePerf$1(name) {
	const enabled = isEnabledPerformanceMeasurements$1();
	_measurePerfStart$1(name, enabled);
	return makeDisposableFunction$1(() => {
		_measurePerfEnd$1(name, enabled);
	});
}
function makeDisposableFunction$1(fn) {
	const disposableFn = fn;
	disposableFn[Symbol.dispose] = fn;
	disposableFn[Symbol.asyncDispose] = () => (fn(), Promise.resolve());
	return disposableFn;
}
function isEnabledPerformanceMeasurements$1() {
	return !!globalThisCSpell$1[symbolCSpell$1]?.enablePerformanceMeasurements;
}
/**
* This is a set of strings stored in a compact form.
*
* Strings are stored as UTF-8 encoded bytes in a single contiguous buffer.
* Each string is referenced by its starting index and length within the buffer.
*
* This design minimizes memory overhead by avoiding individual string objects,
* allowing efficient storage and retrieval of a large number of strings.
*
* Strings are retrieved based on their index.
*
* The internal index table contains the offset and length of each string in the buffer.
*
*/
var StringTable = class {
	#index;
	#data;
	#strLenBits;
	#strLenMask;
	#decoder = new TextDecoder();
	/**
	*
	* @param index - the lookup index format: `offset|len` where the low bits are the length
	* @param utf8ByteData - the UTF-8 encoded byte data for all the strings
	* @param strLenBits - number of bits used to store the length of the string in the index entry
	*/
	constructor(index, utf8ByteData, strLenBits) {
		this.#index = index;
		this.#data = utf8ByteData;
		this.#strLenBits = strLenBits;
		this.#strLenMask = (1 << strLenBits) - 1;
	}
	get index() {
		return this.#index;
	}
	get charData() {
		return this.#data;
	}
	get strLenBits() {
		return this.#strLenBits;
	}
	get length() {
		return this.#index.length;
	}
	getStringBytes(idx) {
		if (idx < 0 || idx >= this.#index.length) return void 0;
		return this.#getBytesByIndexValue(this.#index[idx]);
	}
	getString(idx) {
		const bytes = this.getStringBytes(idx);
		if (!bytes) return void 0;
		return this.#decoder.decode(bytes);
	}
	#getBytesByIndexValue(value) {
		const offset = value >>> this.#strLenBits;
		const length = value & this.#strLenMask;
		return this.#data.subarray(offset, offset + length);
	}
	dataByteLength() {
		return this.#data.byteLength;
	}
	bitInfo() {
		const strLenBits = this.strLenBits;
		const offsetBits = Math.ceil(Math.log2(this.charData.length + 1));
		return {
			strLenBits,
			offsetBits,
			minIndexBits: strLenBits + offsetBits
		};
	}
	values() {
		return [...this.#index].map((v) => this.#getBytesByIndexValue(v));
	}
	toString() {
		return [...this.#index].map((_, i) => this.getString(i) || "").join(", ");
	}
	toJSON() {
		return {
			index: [...this.#index],
			data: [...this.#data],
			strLenBits: this.#strLenBits
		};
	}
};
var StringTableBuilder = class StringTableBuilder {
	#data = [];
	#encoder = new TextEncoder();
	#lookupTrie = new GTrie();
	#locked = false;
	#maxStrLen = 0;
	addStringBytes(bytes) {
		assert$3(!this.#locked, "StringTableBuilder is locked and cannot be modified.");
		const found = this.#lookupTrie.get(bytes);
		if (found !== void 0) return found;
		const idx = this.#data.push(bytes) - 1;
		this.#lookupTrie.insert(bytes, idx);
		this.#maxStrLen = Math.max(this.#maxStrLen, bytes.length);
		return idx;
	}
	addString(str) {
		const bytes = this.#encoder.encode(str);
		return this.addStringBytes(bytes);
	}
	getEntry(idx) {
		return this.#data[idx];
	}
	get length() {
		return this.#data.length;
	}
	build() {
		const endPerf = measurePerf$1("StringTableBuilder.build");
		const table = this.#build();
		endPerf();
		return table;
	}
	#build() {
		this.#locked = true;
		if (!this.#data.length) return new StringTable([], new Uint8Array(0), 8);
		const sortedBySize = this.#data.map((b, i) => ({
			b,
			i
		})).sort((a, b) => b.b.length - a.b.length);
		const byteValues = [];
		const strLenBits = Math.ceil(Math.log2(this.#maxStrLen + 1));
		const strLenMask = (1 << strLenBits) - 1;
		const index = new Array(this.#data.length);
		for (const { b, i } of sortedBySize) {
			let offset = findValues(b);
			if (offset < 0) offset = appendValues(b);
			const length = b.length;
			assert$3(length <= strLenMask, `String length ${length} exceeds maximum of ${strLenMask}`);
			index[i] = offset << strLenBits | length;
		}
		return new StringTable(index, new Uint8Array(byteValues), strLenBits);
		function findValues(buf) {
			const bufLen = buf.length;
			const maxOffset = byteValues.length - bufLen;
			for (let i = 0; i <= maxOffset; i++) {
				let match = true;
				for (let j = 0; j < bufLen; j++) if (byteValues[i + j] !== buf[j]) {
					match = false;
					break;
				}
				if (match) return i;
			}
			return -1;
		}
		function appendValues(buf) {
			const offset = byteValues.length;
			byteValues.push(...buf);
			return offset;
		}
	}
	static fromStringTable(table) {
		const builder = new StringTableBuilder();
		const values = table.values();
		const len = values.length;
		for (let i = 0; i < len; ++i) builder.addStringBytes(values[i]);
		return builder;
	}
};
/**
* The endian code used to identify endianness in the binary format.
* We use the 16-bit value 0x5453 (corresponding to the characters 'S' (0x53) and 'T' (0x54)).
* In little-endian representation, 0x5453 is stored as bytes 0x53 0x54 ('S', 'T').
* In big-endian representation, 0x5453 is stored as bytes 0x54 0x53 ('T', 'S').
*
* The value stored should match the value retrieved, otherwise the endianness is incorrect.
*/
const bomCode = 21587;
function getStringTableBinaryFormat() {
	return new BinaryFormatBuilder().addUint8("indexBits", "The number of bits needed for each index entry", 32).addUint8("strLenBits", "The number of bits needed to store the max length of a string in the table.", 8).addUint16("bom", "The Byte Order Mark.", bomCode).addString("reserved", "Reserved for future use", 4).addUint32ArrayPtr("index32", "String index array of 32 bit entries").addUint16ArrayPtr("index16", "String index array of 16 bit entries", "index32").addUint8ArrayPtr("index", "String index array of 8 bit entries", "index32").addUint8ArrayPtr("data", "String byte data").build();
}
/**
* Encodes a StringTable into binary data so that it can be stored or transmitted.
* @param table - the string table to encode
* @param endian - the resulting endianness of the data.
* @returns The encoded string table binary data.
*/
function encodeStringTableToBinary(table, endian) {
	const strLenBits = table.strLenBits;
	const minIndexBits = strLenBits + Math.ceil(Math.log2(table.charData.length + 1));
	const indexBits = minIndexBits <= 16 ? 16 : 32;
	assert$3(minIndexBits <= indexBits, `Index bits ${indexBits} is too small for required bits ${minIndexBits}`);
	const builder = new BinaryDataBuilder(getStringTableBinaryFormat(), endian);
	builder.setUint8("indexBits", indexBits);
	builder.setUint8("strLenBits", strLenBits);
	builder.setUint16("bom", bomCode);
	if (indexBits === 16) builder.setPtrUint16Array("index16", toU16Array(table.index));
	else builder.setPtrUint32Array("index32", toU32Array(table.index));
	builder.setPtrUint8Array("data", table.charData);
	return builder.build();
}
/**
* Decodes binary data into a StringTable.
* @param data - the byte data of the string table.
* @param endian - the endianness of the encoded data.
* @returns The decoded StringTable.
*/
function decodeStringTableFromBinary(data, endian) {
	if (!data?.length) return new StringTable([], new Uint8Array(0), 8);
	const reader = new BinaryDataReader(data, getStringTableBinaryFormat(), endian);
	const indexBits = reader.getUint8("indexBits");
	const strLenBits = reader.getUint8("strLenBits");
	const bomStored = reader.getUint16("bom");
	assert$3(!bomStored || bomStored === bomCode, "Endian mismatch");
	return new StringTable(indexBits === 16 ? reader.getPtrUint16Array("index16") : reader.getPtrUint32Array("index32"), reader.getPtrUint8Array("data"), strLenBits);
}
function toU16Array(data) {
	if (data instanceof Uint16Array) return data;
	return new Uint16Array(data);
}
function toU32Array(data) {
	if (data instanceof Uint32Array) return data;
	return new Uint32Array(data);
}
/**
* Expand a line into a set of characters.
*
* Example:
* - `a-c` -> `<a,b,c>`
* - `ac-` -> `<a,c,->`
* - `-abz` -> `<-,a,b,z>`
* - `\u0300-\u0308` -> `<accents>`
*
* @param line - set of characters
* @param rangeChar - the character to indicate ranges, set to empty to not have ranges.
*/
function expandCharacterSet(line, rangeChar = "-") {
	const charSet = /* @__PURE__ */ new Set();
	let mode = 0;
	let prev = "";
	for (const char of line) {
		if (mode) {
			expandRange(prev, char).forEach((a) => charSet.add(a));
			mode = 0;
		}
		if (char === rangeChar && prev) {
			mode = 1;
			continue;
		}
		charSet.add(char);
		prev = char;
	}
	if (mode) charSet.add(rangeChar);
	return charSet;
}
/**
* Expands a range between two characters.
* - `a <= b` -- `[a, b]`
* - `a > b` -- `[]`
* @param a - staring character
* @param b - ending character
* @returns array of unicode characters.
*/
function expandRange(a, b) {
	const values = [];
	const end = b.codePointAt(0);
	const begin = a.codePointAt(0);
	if (!(begin && end)) return values;
	for (let i = begin; i <= end; ++i) values.push(String.fromCodePoint(i));
	return values;
}
/**
* Tries to find the different cases for a letter.
* It can generate multiple forms:
* - `` => `['', 'SS', 'ss']`
* - `a` => `['a', 'A']`
* - `A` => `['A', 'z']`
* - `` => `['A', 'z']`
* @param letter - the letter to generate upper and lower cases.
* @param locale - the locale to use for changing case.
* @returns the set of found cases.
*/
function caseForms(letter, locale) {
	const forms = new Set([letter]);
	function tryCases(s) {
		forms.add(s.toLocaleLowerCase(locale));
		forms.add(s.toLocaleUpperCase(locale));
	}
	tryCases(letter);
	[...forms].forEach(tryCases);
	return [...forms].filter((a) => !!a);
}
/**
* Generate the different normalized forms of the letters.
* @param letter - letter to normalize.
* @returns combined set of possible forms.
*/
function accentForms(letter) {
	return new Set([
		letter,
		letter.normalize("NFC"),
		letter.normalize("NFD")
	]);
}
/**
* Remove all accents.
* @param characters - unicode characters
* @returns characters with accents removed (if it was possible)
*/
function stripAccents(characters) {
	return characters.normalize("NFD").replaceAll(/\p{M}/gu, "");
}
/**
* Remove all non accent characters from a string.
* @param characters - characters with accents.
* @returns - only the accents.
*/
function stripNonAccents(characters) {
	return characters.normalize("NFD").replaceAll(/[^\p{M}]/gu, "");
}
function isValidUtf16Character(char) {
	const len = char.length;
	const code = char.charCodeAt(0) & 64512;
	return len === 1 && (code & 63488) !== 55296 || len === 2 && (code & 64512) === 55296 && (char.charCodeAt(1) & 64512) === 56320;
}
function assertValidUtf16Character(char) {
	if (!isValidUtf16Character(char)) {
		const len = char.length;
		const codes = toCharCodes(char.slice(0, 2)).map((c) => "0x" + ("0000" + c.toString(16)).slice(-4));
		let message;
		if (len === 1) message = `Invalid utf16 character, lone surrogate: ${codes[0]}`;
		else if (len === 2) message = `Invalid utf16 character, not a valid surrogate pair: [${codes.join(", ")}]`;
		else message = `Invalid utf16 character, must be a single character, found: ${len}`;
		throw new Error(message);
	}
}
function toCharCodes(s) {
	const values = [];
	for (let i = 0; i < s.length; ++i) values.push(s.charCodeAt(i));
	return values;
}
/**
* Encode a CodePoint into a Big Endian utf8 value, up to 4 bytes.
* These numbers sort into the correct order for utf8.
*
*            hightest byte           lowest byte   Code Point Range
* - 1 byte:  00000000 00000000 00000000 0xxxxxxx - 0x0000_0000 - 0x0000_007f
* - 2 bytes: 00000000 00000000 110xxxxx 10xxxxxx - 0x0000_0080 - 0x0000_07ff
* - 3 bytes: 00000000 1110xxxx 10xxxxxx 10xxxxxx - 0x0000_0800 - 0x0000_ffff
* - 4 bytes: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx - 0x0001_0000 - 0x001f_ffff
*
* @param code - the code point to encode
* @returns number containing the utf8 value.
*/
function encodeToUtf8_32(code) {
	if (code < 128) return code;
	if (code < 2048) return 49280 | (code & 1984) << 2 | code & 63;
	if (code < 65536) return 14712960 | (code & 61440) << 4 | (code & 4032) << 2 | code & 63;
	return 4034953344 + ((code & 1835008) << 6 | (code & 258048) << 4 | (code & 4032) << 2 | code & 63);
}
/**
* Encode a CodePoint into a Little Endian utf8 value, up to 4 bytes.
*
* These numbers DO NOT sort into the correct order for utf8.
*
*            hightest byte           lowest byte   Code Point Range
* - 1 byte:  00000000 00000000 00000000 0xxxxxxx - 0x0000_0000 - 0x0000_007f
* - 2 bytes: 00000000 00000000 10xxxxxx 110xxxxx - 0x0000_0080 - 0x0000_07ff
* - 3 bytes: 00000000 10xxxxxx 10xxxxxx 1110xxxx - 0x0000_0800 - 0x0000_ffff
* - 4 bytes: 10xxxxxx 10xxxxxx 10xxxxxx 11110xxx - 0x0001_0000 - 0x001f_ffff
*
* @param code - the code point to encode
* @returns number containing the utf8 value.
*/
function encodeToUtf8_32Rev(code) {
	if (code < 128) return code;
	if (code < 2048) return 32960 | (code & 1984) >> 6 | (code & 63) << 8;
	if (code < 65536) return 8421600 | (code & 61440) >>> 12 | (code & 4032) << 2 | (code & 63) << 16;
	return 2155905264 + ((code & 1835008) >>> 18 | (code & 258048) >>> 4 | (code & 4032) << 10 | (code & 63) << 24);
}
/**
* Incrementally decodes a stream of UTF8 bytes into Unicode code points.
*
* This class keeps a small amount of state (`remaining` and `value`) so that callers can
* feed it one byte at a time via {@link Utf8Accumulator.decode}, and receive a complete
* code point whenever enough continuation bytes have been seen. If a full code point has
* not yet been assembled, `decode` returns `undefined`. On invalid byte sequences, the
* accumulator is reset to a known-good state.
*
* The design is similar in spirit to {@link TextDecoderStream} (it copes with multi-byte
* sequences and boundaries that may fall between input chunks), but it is implemented as a
* lightweight, allocation-free helper object that can be cheaply cloned and reset. This
* makes it suitable for performancesensitive code and for environments where
* `TextDecoderStream` is not available or where creating full stream instances would be
* unnecessarily expensive.
*/
var Utf8Accumulator = class Utf8Accumulator {
	/**
	* Number of remaining continuation bytes expected for the current code point being decoded.
	*/
	remaining = 0;
	/**
	* Partially decoded code point value being accumulated.
	*/
	value = 0;
	/**
	* Decode a single utf8 byte
	* @param byte
	* @returns a CodePoint if a full code point has been decoded, undefined if more bytes are needed, or 0xfffd on error.
	*/
	decode(byte) {
		let remaining = this.remaining;
		if (byte & -256) return this.reset();
		if ((byte & 128) === 0) {
			if (remaining) return this.reset();
			return byte;
		}
		if (remaining) {
			if ((byte & 192) !== 128) return this.reset();
			let value = this.value;
			value = value << 6 | byte & 63;
			this.value = value;
			remaining -= 1;
			this.remaining = remaining;
			return remaining ? void 0 : value;
		}
		if ((byte & 224) === 192) {
			this.value = byte & 31;
			this.remaining = 1;
			return;
		}
		if ((byte & 240) === 224) {
			this.value = byte & 15;
			this.remaining = 2;
			return;
		}
		if ((byte & 248) === 240) {
			this.value = byte & 7;
			this.remaining = 3;
			return;
		}
		return this.reset();
	}
	get codePoint() {
		return this.remaining ? void 0 : this.value;
	}
	decodeBytesToString(bytes) {
		let value = "";
		const len = bytes.length;
		for (let i = 0; i < len; ++i) {
			const code = this.decode(bytes[i]);
			if (code) value += String.fromCodePoint(code);
		}
		return value;
	}
	reset() {
		this.remaining = 0;
		this.value = 0;
		return 65533;
	}
	clone(into = new Utf8Accumulator()) {
		into.remaining = this.remaining;
		into.value = this.value;
		return into;
	}
	static isMultiByte(v) {
		return (v & 128) !== 0;
	}
	static isSingleByte(v) {
		return (v & 128) === 0;
	}
	static create() {
		return new this();
	}
};
function encodeTextToUtf8_32Rev(offset) {
	const text = offset.text;
	let code = text.charCodeAt(offset.i) & 65535;
	code = (code & 63488) === 55296 ? text.codePointAt(offset.i++) || 0 : code;
	offset.i++;
	if (code < 128) return code;
	if (code < 2048) return 32960 | (code & 1984) >> 6 | (code & 63) << 8;
	if (code < 65536) return 8421600 | (code & 61440) >>> 12 | (code & 4032) << 2 | (code & 63) << 16;
	return 2155905264 + ((code & 1835008) >>> 18 | (code & 258048) >>> 4 | (code & 4032) << 10 | (code & 63) << 24);
}
function encodeTextToUtf8Into(text, into, offset = 0) {
	const t = {
		text,
		i: 0
	};
	let i = offset;
	for (; t.i < text.length;) {
		const code = encodeTextToUtf8_32Rev(t);
		for (let utf8_32Rev = code; utf8_32Rev !== 0; utf8_32Rev >>>= 8) into[i++] = utf8_32Rev & 255;
	}
	return i - offset;
}
function encodeTextToUtf8(text) {
	const into = new Array(text.length);
	encodeTextToUtf8Into(text, into);
	return into;
}
Object.freeze([0]);
var CharIndex = class CharIndex {
	#charToUtf8SeqMap;
	#lastWord = "";
	#lastWordSeq = [];
	#multiByteChars;
	charIndex;
	constructor(charIndex = /* @__PURE__ */ new Set()) {
		this.charIndex = charIndex;
		this.#charToUtf8SeqMap = buildCharIndexSequenceMap(charIndex);
		this.#multiByteChars = [...this.#charToUtf8SeqMap.values()].some((c) => c.length > 1);
	}
	getCharUtf8Seq(c) {
		const found = this.#charToUtf8SeqMap.get(c);
		if (found) return found;
		const s = encodeTextToUtf8(c);
		this.#charToUtf8SeqMap.set(c, s);
		return s;
	}
	wordToUtf8Seq(word) {
		if (this.#lastWord === word) return this.#lastWordSeq;
		const seq = encodeTextToUtf8(word);
		this.#lastWord = word;
		this.#lastWordSeq = seq;
		return seq;
	}
	indexContainsMultiByteChars() {
		return this.#multiByteChars;
	}
	get size() {
		return this.charIndex.size;
	}
	toJSON() {
		return { charIndex: [...this.charIndex].join("") };
	}
	static fromJSON(json) {
		return new CharIndex(new Set(json.charIndex));
	}
	static fromIterable(charIndex) {
		const charSet = /* @__PURE__ */ new Set();
		for (const s of charIndex) for (const c of s) charSet.add(c);
		return new CharIndex(charSet);
	}
};
function buildCharIndexSequenceMap(charIndex) {
	const map = /* @__PURE__ */ new Map();
	for (const key of charIndex) map.set(key, encodeTextToUtf8(key));
	return map;
}
var CharIndexBuilder = class {
	charIndex = /* @__PURE__ */ new Set();
	charIndexMap = /* @__PURE__ */ new Map();
	charIndexSeqMap = /* @__PURE__ */ new Map();
	#mapIdxToSeq = /* @__PURE__ */ new Map();
	constructor() {
		this.getUtf8Value("");
	}
	getUtf8Value(c) {
		const found = this.charIndexMap.get(c);
		if (found !== void 0) return found;
		const nc = c.normalize("NFC");
		this.charIndex.add(nc);
		const utf8 = encodeToUtf8_32(nc.codePointAt(0) || 0);
		this.charIndexMap.set(c, utf8);
		this.charIndexMap.set(nc, utf8);
		this.charIndexMap.set(c.normalize("NFD"), utf8);
		return utf8;
	}
	utf8ValueToUtf8Seq(idx) {
		const found = this.#mapIdxToSeq.get(idx);
		if (found !== void 0) return found;
		const seq = splitUtf8(idx);
		this.#mapIdxToSeq.set(idx, seq);
		return seq;
	}
	charToUtf8Seq(c) {
		const idx = this.getUtf8Value(c);
		return this.utf8ValueToUtf8Seq(idx);
	}
	wordToUtf8Seq(word) {
		const seq = new Array(word.length);
		let i = 0;
		for (const c of word) {
			const idx = this.getUtf8Value(c);
			const cSep = this.utf8ValueToUtf8Seq(idx);
			if (typeof cSep === "number") {
				seq[i++] = cSep;
				continue;
			}
			for (const cIdx of cSep) seq[i++] = cIdx;
		}
		if (seq.length !== i) seq.length = i;
		return seq;
	}
	get size() {
		return this.charIndex.size;
	}
	build() {
		return new CharIndex(this.charIndex);
	}
};
function splitUtf8(utf8) {
	utf8 = utf8 < 0 ? 4294967296 + utf8 : utf8;
	if (utf8 <= 255) return [utf8];
	if (utf8 <= 65535) return [utf8 >> 8 & 255, utf8 & 255];
	if (utf8 <= 16777215) return [
		utf8 >> 16 & 255,
		utf8 >> 8 & 255,
		utf8 & 255
	];
	return [
		utf8 >> 24 & 255,
		utf8 >> 16 & 255,
		utf8 >> 8 & 255,
		utf8 & 255
	].filter((v) => v);
}
const NodeHeaderNumChildrenShift = 0;
const NodeHeaderEOWMask = 256;
const NodeHeaderPrefixMask = 1073741312;
const NodeHeaderPrefixShift = 9;
const NodeHeaderNumChildrenMask = 255;
const NodeMaskCharByte = 255;
const NodeChildIndexRefShift = 8;
const MAX_AUTO_ADD_TO_STRING_TABLE = 4;
/**
* Convert from a Trie to a DAWG by merging identical nodes.
* @param nodes - the nodes to optimize. This array and the contents WILL BE CHANGED and used as a scratch space.
* @returns the optimized nodes.
*/
function optimizeNodes(nodes) {
	const endPerf = measurePerf$1("TrieBlob.optimizeNodes");
	/** the has map to look up locked nodes. */
	const nodeHashMap = /* @__PURE__ */ new Map();
	const lockedNodes = /* @__PURE__ */ new WeakMap();
	const eowNode = nodes[1];
	getHashList(eowNode).push(eowNode);
	lockNode(eowNode, 1);
	walk(0);
	const n = compactNodes(nodes);
	endPerf();
	return n;
	function getHashList(node) {
		const hash = xorNode(node);
		let list = nodeHashMap.get(hash);
		if (list) return list;
		list = [];
		nodeHashMap.set(hash, list);
		return list;
	}
	function lockNode(node, index) {
		lockedNodes.set(node, index);
		return index;
	}
	function findMatchingLockedNode(hash, node) {
		const candidates = nodeHashMap.get(hash);
		if (!candidates) return void 0;
		return findMatchingNode(node, candidates);
	}
	function registerNode(nodeIdx, node) {
		if (!nodeIdx) return nodeIdx;
		const match = findMatchingLockedNode(xorNode(node), node);
		if (!match) {
			getHashList(node).push(node);
			return lockNode(node, nodeIdx);
		}
		return lockNode(node, lockedNodes.get(match) || 0);
	}
	function walk(nodeIdx) {
		const node = nodes[nodeIdx];
		if (lockedNodes.has(node)) return nodeIdx;
		const count = node.length - 1;
		for (let i = 1; i <= count; ++i) {
			const entry = node[i];
			const childIdx = entry >> 8;
			const newChildIdx = walk(childIdx);
			if (newChildIdx !== childIdx) node[i] = entry & 255 | newChildIdx << 8;
		}
		return registerNode(nodeIdx, node);
	}
}
function xorNode(a) {
	let xor = 0;
	for (let i = 0; i < a.length; ++i) xor ^= a[i];
	return xor;
}
function findMatchingNode(node, candidates) {
	for (let i = candidates.length - 1; i >= 0; --i) {
		const candidate = candidates[i];
		if (compareNodes(node, candidate)) return candidate;
	}
}
function compareNodes(a, b) {
	if (a.length !== b.length) return false;
	let diff = 0;
	for (let i = 0; i < a.length && diff === 0; ++i) diff = a[i] - b[i];
	return !diff;
}
/**
* Walk the trie and remove any nodes that are not reachable.
* @param nodes - the nodes to compact they will get modified.
* @returns the compacted nodes.
*/
function compactNodes(nodes) {
	const nodeMap = /* @__PURE__ */ new Map();
	const compacted = [];
	nodeMap.set(0, 0);
	nodeMap.set(1, 1);
	compacted.push(nodes[0], nodes[1]);
	walk(0);
	return compacted;
	function walk(nodeIdx) {
		const found = nodeMap.get(nodeIdx);
		if (found) return found;
		const node = nodes[nodeIdx];
		const count = node.length - 1;
		for (let i = 1; i <= count; ++i) {
			const entry = node[i];
			const newChildIdx = walk(entry >> 8);
			node[i] = entry & 255 | newChildIdx << 8;
		}
		if (!nodeIdx) return nodeIdx;
		const newIndex = compacted.push(node) - 1;
		nodeMap.set(nodeIdx, newIndex);
		return newIndex;
	}
}
function calculateByteSize(nodes) {
	let count = 0;
	for (let i = nodes.length - 1; i >= 0; --i) count += nodes[i].length;
	return count * 4;
}
function copyNodes(nodes) {
	const size = calculateByteSize(nodes);
	const dst = Array(nodes.length);
	const buffer = new ArrayBuffer(size);
	for (let i = 0, offset = 0; i < nodes.length; ++i) {
		const node = nodes[i];
		const nodeCopy = new Uint32Array(buffer, offset, node.length);
		nodeCopy.set(node);
		dst[i] = nodeCopy;
		offset += nodeCopy.byteLength;
	}
	return dst;
}
function copyNodesAndStringTable(src) {
	return {
		nodes: copyNodes(src.nodes),
		stringTableBuilder: StringTableBuilder.fromStringTable(src.stringTable)
	};
}
function optimizeNodesWithStringTable(src) {
	const endPerf = measurePerf$1("TrieBlob.optimizeNodesWithStringTable");
	const { nodes, stringTableBuilder: builder } = copyNodesAndStringTable(src);
	const multipleNodeRefs = calcHasMultipleReferences(nodes);
	const multiStringRefs = new Set([0]);
	if (!builder.length) builder.addString("");
	walkNodes(nodes, 0, { after: processNode });
	const r = {
		nodes: optimizeNodes(nodes),
		stringTable: builder.build()
	};
	endPerf();
	return r;
	/**
	* If possible, replace the current node with a prefix node.
	* @param nodeIdx - node to process
	*/
	function processNode(nodeIdx) {
		const node = nodes[nodeIdx];
		if (node.length !== 2) return;
		const header = node[0];
		if ((header & NodeHeaderEOWMask) !== 0) return;
		if (header & NodeHeaderPrefixMask) return;
		const childEntry = node[1];
		const charByte = childEntry & NodeMaskCharByte;
		const childIdx = childEntry >>> 8;
		if (multipleNodeRefs.has(childIdx)) return;
		const childNode = nodes[childIdx];
		const childHeader = childNode[0];
		const childPrefixIdx = (childHeader & NodeHeaderPrefixMask) >>> NodeHeaderPrefixShift;
		const childBytes = builder.getEntry(childPrefixIdx) || [];
		if (!multiStringRefs.has(childPrefixIdx)) {
			multiStringRefs.add(childPrefixIdx);
			if (childBytes.length >= MAX_AUTO_ADD_TO_STRING_TABLE) return;
		}
		const prefixBytes = [charByte, ...childBytes];
		const prefixIdx = builder.addStringBytes(prefixBytes);
		const newNode = Uint32Array.from(childNode);
		newNode[0] = prefixIdx << NodeHeaderPrefixShift | childHeader & ~NodeHeaderPrefixMask;
		nodes[nodeIdx] = newNode;
	}
}
function calcHasMultipleReferences(nodes) {
	const seen = /* @__PURE__ */ new Set();
	const multiple = /* @__PURE__ */ new Set();
	walkNodes(nodes, 0, { before: (nodeIdx) => {
		if (seen.has(nodeIdx)) {
			multiple.add(nodeIdx);
			return true;
		}
		seen.add(nodeIdx);
		return false;
	} });
	return multiple;
}
function walkNodes(nodes, nodeIdx, options) {
	const after = options.after || (() => void 0);
	const before = options.before || (() => void 0);
	function walk(nodeIdx) {
		if (before(nodeIdx)) return;
		const node = nodes[nodeIdx];
		const count = node.length - 1;
		for (let i = 1; i <= count; ++i) walk(node[i] >> 8);
		after(nodeIdx);
	}
	walk(nodeIdx);
}
function resolveMap(map, key, resolve) {
	const r = map.get(key);
	if (r !== void 0) return r;
	const v = resolve(key);
	map.set(key, v);
	return v;
}
const COMPOUND_FIX = "+";
const OPTIONAL_COMPOUND_FIX = "*";
const CASE_INSENSITIVE_PREFIX = "~";
const FORBID_PREFIX = "!";
const LINE_COMMENT = "#";
const IDENTITY_PREFIX = "=";
const SUGGESTION_PREFIX = ":";
const SUGGESTIONS_DISABLED = " ";
const defaultTrieInfo = Object.freeze({
	compoundCharacter: COMPOUND_FIX,
	forbiddenWordPrefix: FORBID_PREFIX,
	stripCaseAndAccentsPrefix: CASE_INSENSITIVE_PREFIX,
	suggestionPrefix: SUGGESTION_PREFIX
});
/**
* Creates a new object of type T based upon the field values from `value`.
* n[k] = value[k] ?? default[k] where k must be a field in default.
* Note: it will remove fields not in defaultValue!
* @param value
* @param defaultValue
*/
function mergeDefaults(value, defaultValue) {
	const result = { ...defaultValue };
	if (value) {
		for (const [k, v] of Object.entries(value)) if (k in result) result[k] = v ?? result[k];
	}
	return result;
}
function mergeOptionalWithDefaults(...options) {
	return options.reduce((acc, opt) => mergeDefaults(opt, acc), defaultTrieInfo);
}
function matchEntirePrefix(text, prefix) {
	while (!prefix.done) {
		const byte = prefix.cur();
		const charVal = text.cur();
		if (text.done || byte !== charVal) return false;
		prefix.next();
		text.next();
	}
	return true;
}
function toUint8Array$1(data) {
	return data instanceof Uint8Array ? data : new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
}
const headerSig = "TrieBlob";
const version$1 = "00.01.00";
const endianSig = 67305985;
function getBinaryFormat() {
	return new BinaryFormatBuilder().addString("sig", "Signature \"TrieBlob\"", headerSig).addUint32("endian", "Endianness signature", endianSig).addString("version", "Version string", version$1).addUint32ArrayPtr("nodes", "Pointer to nodes array").addString("reserved0", "Old Pointer to TrieInfo JSON string", 8).addString("trieInfo", "Pointer to TrieInfo JSON string", 16).addString("characteristics", "Available characteristic values", 8).addUint8ArrayPtr("stringTable", "Pointer to String Table data").addString("reserved", "Reserved space", 64).build();
}
function encodeTrieBlobToBTrie(blob) {
	const builder = new BinaryDataBuilder(getBinaryFormat());
	builder.setPtrUint32Array("nodes", blob.nodes);
	builder.setString("trieInfo", cvtTrieInfoToFlags(blob.info));
	builder.setString("characteristics", cvtTrieCharacteristicsToFlags(blob.characteristics));
	if (blob.stringTable.length) {
		const stringTableData = encodeStringTableToBinary(blob.stringTable, builder.endian);
		builder.setPtrUint8Array("stringTable", stringTableData);
	}
	return builder.build();
}
function decodeTrieBlobToBTrie(blob) {
	const reader = new BinaryDataReader(blob, getBinaryFormat());
	if (reader.getString("sig") !== headerSig) throw new ErrorDecodeTrieBlob("Invalid TrieBlob Header");
	if (reader.getUint32("endian") !== endianSig) {
		reader.reverseEndian();
		assert$3(reader.getUint32("endian") === endianSig, "Invalid TrieBlob Header after endian conversion");
	}
	const fileVersion = reader.getString("version");
	if (fileVersion !== version$1) {
		console.warn(`Warning: TrieBlob version mismatch. Expected: ${version$1}, Found: ${fileVersion}`);
		assert$3(fileVersion.startsWith(version$1.slice(0, 6)), "Unsupported TrieBlob version");
	}
	const nodes = reader.getPtrUint32Array("nodes");
	const info = parseTrieInfoFlags(reader.getString("trieInfo"));
	const characteristics = parseTrieCharacteristics(reader.getString("characteristics"));
	return {
		nodes,
		stringTable: decodeStringTableFromBinary(reader.getPtrUint8Array("stringTable"), reader.endian),
		info,
		characteristics
	};
}
var ErrorDecodeTrieBlob = class extends Error {
	constructor(message) {
		super(message);
	}
};
function isBTrieData(data) {
	const buf = toUint8Array$1(data);
	if (buf.length < 8) return false;
	for (let i = 0; i < 8; i++) if (buf[i] !== headerSig.codePointAt(i)) return false;
	return true;
}
function trieBlobNodeRefToITrieNodeId(ref) {
	return (BigInt(ref.nodeIdx) << 32n) + BigInt(ref.pfx);
}
function iTrieNodeIdToTrieBlobNodeRefParts(id) {
	assert$3(typeof id === "bigint", "iTrieNodeIdToTrieBlobNodeRefParts: id must be a bigint");
	return {
		nodeIdx: Number(id >> 32n) & 2147483647,
		pfx: Number(id & 4294967295n)
	};
}
const EMPTY_KEYS = Object.freeze([]);
const EMPTY_NODES = Object.freeze([]);
const EMPTY_ENTRIES = Object.freeze([]);
var TrieBlobINode = class TrieBlobINode {
	id;
	node;
	eow;
	_keys;
	_hasChildren;
	_size;
	_nodesEntries;
	_entries;
	_values;
	charToIdx;
	trie;
	constructor(trie, node) {
		this.trie = trie;
		this.node = node;
		this.eow = trie.isEow(node);
		this.id = trieBlobNodeRefToITrieNodeId(node);
	}
	/** get keys to children */
	keys() {
		if (this._keys) return this._keys;
		if (!this.hasChildren) return EMPTY_KEYS;
		this._keys = this.getNodesEntries().map(([key]) => key);
		return this._keys;
	}
	values() {
		if (!this.hasChildren) return EMPTY_NODES;
		if (this._values) return this._values;
		this._values = this.entries().map(([, value]) => value);
		return this._values;
	}
	valueAt(keyIdx) {
		if (this._values) return this._values[keyIdx];
		return this.entryAt(keyIdx)[1];
	}
	entries() {
		if (this._entries) return this._entries;
		if (!this.hasChildren) return EMPTY_ENTRIES;
		this._entries = this.getNodesEntries().map(([key, value]) => [key, new TrieBlobINode(this.trie, value)]);
		return this._entries;
	}
	entryAt(keyIdx) {
		if (this._entries) return this._entries[keyIdx];
		return this.entries()[keyIdx];
	}
	/** get child ITrieNode */
	get(char) {
		return this.#getChildNode(char);
	}
	has(char) {
		return this.trie.nodeGetChild(this.node, char) !== void 0;
	}
	hasChildren() {
		return this._hasChildren ??= this.trie.hasChildren(this.node);
	}
	child(keyIdx) {
		return this.valueAt(keyIdx);
	}
	#getChildNodeRef(char) {
		return this.trie.nodeGetChild(this.node, char);
	}
	#getChildNode(char) {
		if (this.charToIdx) {
			const keyIdx = this.charToIdx[char];
			if (keyIdx === void 0) return void 0;
			return this.child(keyIdx);
		}
		const idx = this.#getChildNodeRef(char);
		if (idx === void 0) return void 0;
		return new TrieBlobINode(this.trie, idx);
	}
	getNode(word) {
		const n = this.trie.nodeFindNode(this.node, word);
		return n === void 0 ? void 0 : new TrieBlobINode(this.trie, n);
	}
	findExact(word) {
		return this.trie.nodeFindExact(this.node, word);
	}
	getNodesEntries() {
		return this._nodesEntries ??= this.trie.getChildEntries(this.node);
	}
	get size() {
		return this._size ??= this.getNodesEntries().length;
	}
};
var TrieBlobIRoot = class extends TrieBlobINode {
	find;
	isForbidden;
	hasForbiddenWords;
	hasCompoundWords;
	hasNonStrictWords;
	info;
	constructor(trie, nodeIdx) {
		super(trie, nodeIdx);
		this.info = trie.info;
		this.find = trie.find;
		this.isForbidden = trie.isForbidden;
		this.hasForbiddenWords = trie.hasForbiddenWords;
		this.hasCompoundWords = trie.hasCompoundWords;
		this.hasNonStrictWords = trie.hasNonStrictWords;
	}
	resolveId(id) {
		return new TrieBlobINode(this.trie, this.trie.fromITrieNodeId(id));
	}
	get forbidPrefix() {
		return this.info.forbiddenWordPrefix;
	}
	get compoundFix() {
		return this.info.compoundCharacter;
	}
	get caseInsensitivePrefix() {
		return this.info.stripCaseAndAccentsPrefix;
	}
	get suggestionPrefix() {
		return this.info.suggestionPrefix;
	}
};
var TypedArrayCursor = class {
	array;
	i;
	done;
	length;
	constructor(array, i = 0, done) {
		this.array = array;
		this.i = i;
		this.length = array.length;
		this.done = (done ?? (i >= this.length ? true : void 0)) || void 0;
	}
	cur() {
		return this.done ? void 0 : this.array[this.i];
	}
	next() {
		if (this.done) return void 0;
		const i = ++this.i;
		if (i >= this.array.length) {
			this.done = true;
			return;
		}
		return this.array[i];
	}
};
function createUint8ArrayCursor(array, i = 0) {
	return new TypedArrayCursor(array, i);
}
var Utf8CursorImpl = class {
	text;
	i;
	code;
	done;
	constructor(text, i = 0) {
		this.text = text;
		this.i = i < 0 ? i = text.length : i;
		this.code = 0;
		this.done = i < 0 || i >= text.length ? true : void 0;
		this.cur();
	}
	cur() {
		if (this.done) return 0;
		this.code ||= encodeTextToUtf8_32Rev(this);
		return this.code & 255;
	}
	next() {
		if (this.done) return 0;
		this.code >>>= 8;
		this.code ||= encodeTextToUtf8_32Rev(this);
		this.done = !this.code && this.i >= this.text.length;
		return this.code & 255;
	}
};
function createTextToUtf8Cursor(text, offset = 0) {
	return new Utf8CursorImpl(text, offset);
}
var TrieBlob = class TrieBlob {
	info;
	#forbidIdx;
	#compoundIdx;
	#nonStrictIdx;
	#suggestIdx;
	#size;
	#iTrieRoot;
	/** the nodes data in 8 bits */
	#nodes8;
	#stringTable;
	#beAdj = endianness() === "BE" ? 3 : 0;
	#rootRef;
	wordToCharacters = (word) => [...word];
	hasForbiddenWords;
	hasCompoundWords;
	hasNonStrictWords;
	nodes;
	NodeMaskNumChildren;
	NodeChildRefShift;
	hasPreferredSuggestions;
	constructor(nodes, stringTable, info) {
		this.nodes = nodes;
		this.#stringTable = stringTable;
		trieBlobSort(nodes);
		this.info = mergeOptionalWithDefaults(info);
		this.#rootRef = this.toRef(0);
		this.#nodes8 = new Uint8Array(nodes.buffer, nodes.byteOffset + this.#beAdj);
		this.#forbidIdx = this.#findNode(this.#rootRef, this.info.forbiddenWordPrefix);
		this.#compoundIdx = this.#findNode(this.#rootRef, this.info.compoundCharacter);
		this.#nonStrictIdx = this.#findNode(this.#rootRef, this.info.stripCaseAndAccentsPrefix);
		this.#suggestIdx = this.#findNode(this.#rootRef, this.info.suggestionPrefix);
		this.hasForbiddenWords = !!this.#forbidIdx;
		this.hasCompoundWords = !!this.#compoundIdx;
		this.hasNonStrictWords = !!this.#nonStrictIdx;
		this.NodeMaskNumChildren = NodeHeaderNumChildrenMask;
		this.NodeChildRefShift = NodeChildIndexRefShift;
		this.hasPreferredSuggestions = !!this.#suggestIdx;
	}
	has(word) {
		return this.#hasWord(this.rootRef, word);
	}
	isForbiddenWord(word) {
		return !!this.#forbidIdx && this.#hasWord(this.#forbidIdx, word);
	}
	/**
	* Try to find the word in the trie. The word must be normalized.
	* If `strict` is `true` the case and accents must match.
	* Compound words are supported assuming that the compound character is in the trie.
	*
	* @param word - the word to find (normalized)
	* @param strict - if `true` the case and accents must match.
	*/
	find(word, strict) {
		const found = this.#hasWord(this.rootRef, word);
		if (found || !this.hasCompoundWords) {
			if (found) return {
				found: word,
				compoundUsed: false,
				caseMatched: true,
				forbidden: void 0
			};
			if (strict || !this.#nonStrictIdx) return {
				found: false,
				compoundUsed: false,
				caseMatched: false,
				forbidden: void 0
			};
			return {
				found: this.#hasWord(this.#nonStrictIdx, word) && word,
				compoundUsed: false,
				caseMatched: false,
				forbidden: void 0
			};
		}
	}
	getRoot() {
		return this.#iTrieRoot ??= this._getRoot();
	}
	_getRoot() {
		return new TrieBlobIRoot({
			info: this.info,
			nodes: this.nodes,
			nodeFindExact: this.#hasWord.bind(this),
			nodeGetChild: this.#findNode.bind(this),
			nodeFindNode: this.#findNode.bind(this),
			isEow: this.isRefEOW.bind(this),
			getChildEntries: this.#getChildrenFromRef.bind(this),
			hasChildren: this.hasChildren.bind(this),
			isForbidden: this.isForbiddenWord.bind(this),
			findExact: this.has.bind(this),
			find: this.find.bind(this),
			nodeToITrieNodeId: trieBlobNodeRefToITrieNodeId,
			fromITrieNodeId: iTrieNodeIdToTrieBlobNodeRefParts,
			hasCompoundWords: this.hasCompoundWords,
			hasForbiddenWords: this.hasForbiddenWords,
			hasNonStrictWords: this.hasNonStrictWords,
			hasPreferredSuggestions: this.hasPreferredSuggestions
		}, this.rootRef);
	}
	getNode(prefix) {
		return findNode$1(this.getRoot(), prefix);
	}
	get stringTable() {
		return this.#stringTable;
	}
	/**
	* Check if the word is in the trie starting at the given node index.
	*/
	#hasWord(nodeRef, word) {
		const nodeIdxFound = this.#findNode(nodeRef, word);
		if (!nodeIdxFound) return false;
		return this.isRefEOW(nodeIdxFound);
	}
	/**
	* Find the node index for the given Utf8 character sequence.
	* @param nodeIdx - node index to start the search
	* @param seq - the byte sequence of the character to look for
	* @returns
	*/
	#findNode(nodeRef, text) {
		if (!nodeRef) return void 0;
		const _nodes = this.nodes;
		const _nodes8 = this.#nodes8;
		const pfxShift = NodeHeaderPrefixShift;
		let { nodeIdx, pfx, prefix } = nodeRef;
		const t = createTextToUtf8Cursor(text);
		for (; !t.done; t.next()) {
			const nodes = _nodes;
			const nodes8 = _nodes8;
			const node = nodes[nodeIdx];
			const prefixIdx = node >>> pfxShift;
			prefix ||= prefixIdx ? this.#stringTable.getStringBytes(prefixIdx) : void 0;
			const pfxCursor = prefix && createUint8ArrayCursor(prefix, pfx);
			if (pfxCursor && !matchEntirePrefix(t, pfxCursor)) return t.done ? {
				nodeIdx,
				pfx: pfxCursor.i,
				prefix
			} : void 0;
			prefix = void 0;
			pfx = 0;
			const charVal = t.cur() & 255;
			const count = node & 255;
			const idx4 = nodeIdx << 2;
			if (count > 15) {
				const pEnd = idx4 + (count << 2);
				let i = idx4 + 4;
				let j = pEnd;
				while (j - i >= 4) {
					const m = i + j >> 1 & -4;
					if (nodes8[m] < charVal) i = m + 4;
					else j = m;
				}
				if (i > pEnd || nodes8[i] !== charVal) return void 0;
				nodeIdx = nodes[i >> 2] >>> 8;
			} else {
				let i = idx4 + count * 4;
				for (; i > idx4; i -= 4) if (nodes8[i] === charVal) break;
				if (i <= idx4) return void 0;
				nodeIdx = nodes[i >> 2] >>> 8;
			}
		}
		return {
			nodeIdx,
			pfx,
			prefix
		};
	}
	/**
	* get an iterable for all the words in the dictionary.
	* @param prefix - optional prefix to filter the words returned. The words will be prefixed with this value.
	*/
	*words(prefix) {
		if (!prefix) {
			yield* this.#walkWords(this.rootRef);
			return;
		}
		const nodeIdx = this.#findNode(this.rootRef, prefix);
		if (!nodeIdx) return;
		for (const suffix of this.#walkWords(nodeIdx)) yield prefix + suffix;
	}
	*#walkWords(rootRef) {
		const NodeMaskNumChildren = NodeHeaderNumChildrenMask;
		const NodeMaskEOW = NodeHeaderEOWMask;
		const NodeMaskChildCharIndex = NodeMaskCharByte;
		const NodeChildRefShift = NodeChildIndexRefShift;
		const nodeHeaderPrefixShift = NodeHeaderPrefixShift;
		const nodes = this.nodes;
		const st = this.#stringTable;
		const stack = [{
			nodeIdx: rootRef.nodeIdx,
			pfx: rootRef.pfx,
			pos: 0,
			word: "",
			acc: Utf8Accumulator.create()
		}];
		let depth = 0;
		while (depth >= 0) {
			const s = stack[depth];
			if (!s.pos) applyPrefixString(s);
			const { nodeIdx, pos, word, acc } = s;
			const node = nodes[nodeIdx];
			if (!pos && node & NodeMaskEOW) yield word;
			if (pos >= (node & NodeMaskNumChildren)) {
				--depth;
				continue;
			}
			const entry = nodes[nodeIdx + ++stack[depth].pos];
			const nAcc = acc.clone();
			const codePoint = nAcc.decode(entry & NodeMaskChildCharIndex);
			const letter = codePoint && String.fromCodePoint(codePoint) || "";
			++depth;
			stack[depth] = {
				nodeIdx: entry >>> NodeChildRefShift,
				pos: 0,
				pfx: 0,
				word: word + letter,
				acc: nAcc
			};
		}
		function applyPrefixString(s) {
			const prefixIdx = nodes[s.nodeIdx] >>> nodeHeaderPrefixShift;
			const fullPrefix = prefixIdx ? st.getStringBytes(prefixIdx) : void 0;
			if (!fullPrefix || s.pfx >= fullPrefix.length) return;
			let prefix = fullPrefix;
			if (s.pfx) prefix = prefix.subarray(s.pfx);
			s.word += s.acc.decodeBytesToString(prefix);
			s.pfx = fullPrefix.length;
		}
	}
	get size() {
		if (this.#size) return this.#size;
		const NodeMaskNumChildren = NodeHeaderNumChildrenMask;
		const nodes = this.nodes;
		let p = 0;
		let count = 0;
		while (p < nodes.length) {
			++count;
			p += (nodes[p] & NodeMaskNumChildren) + 1;
		}
		this.#size = count;
		return count;
	}
	toJSON() {
		return {
			options: this.info,
			nodes: nodesToJson(this.nodes)
		};
	}
	encodeToBTrie() {
		return this.encodeBin();
	}
	encodeBin() {
		return encodeTrieBlobToBTrie({
			nodes: this.nodes,
			stringTable: this.stringTable,
			info: this.info,
			characteristics: this
		});
	}
	static decodeBin(blob) {
		const info = decodeTrieBlobToBTrie(blob);
		return new TrieBlob(info.nodes, info.stringTable, info.info);
	}
	/**
	* Walk the trie starting at the given reference at position 0 (or depth).
	* @param stack - the stack used while walking - updated
	* @param depth - that starting depth in the stack
	* @yields the depth in the stack. The stack will contain the current Reference.
	*/
	*#walk(stack, depth = 0) {
		const MaskNumChildren = NodeHeaderNumChildrenMask;
		const NodeRefShift = NodeChildIndexRefShift;
		const CharMask = NodeMaskCharByte;
		const PrefixMask = NodeHeaderPrefixMask;
		const PrefixShift = NodeHeaderPrefixShift;
		const nodes = this.nodes;
		stack[0] ||= {
			nodeIdx: 0,
			pfx: 0,
			pos: 0,
			prefix: void 0,
			bChar: 0
		};
		while (depth >= 0) {
			let s = stack[depth];
			const { nodeIdx, pos, pfx, prefix } = s;
			if (!pos) {
				if (!(yield depth)) {
					--depth;
					continue;
				}
			}
			if (prefix) {
				if (pos) {
					--depth;
					continue;
				}
				s.pos = 1;
				++depth;
				stack[depth] ||= {
					nodeIdx: 0,
					pfx: 0,
					pos: 0,
					prefix: void 0,
					bChar: 0
				};
				s = stack[depth];
				s.nodeIdx = nodeIdx;
				s.pfx = pfx + 1;
				s.pos = 0;
				s.prefix = s.pfx < prefix.length ? prefix : void 0;
				s.bChar = prefix[pfx];
				continue;
			}
			if (pos >= (nodes[nodeIdx] & MaskNumChildren)) {
				--depth;
				continue;
			}
			const entry = nodes[nodeIdx + ++s.pos];
			const eNodeIdx = entry >>> NodeRefShift;
			++depth;
			stack[depth] ||= {
				nodeIdx: 0,
				pfx: 0,
				pos: 0,
				prefix: void 0,
				bChar: 0
			};
			s = stack[depth];
			s.nodeIdx = eNodeIdx;
			s.pfx = 0;
			s.pos = 0;
			const pfxV = nodes[eNodeIdx] & PrefixMask;
			s.prefix = pfxV ? this.#stringTable.getStringBytes(pfxV >>> PrefixShift) : void 0;
			s.bChar = entry & CharMask;
		}
	}
	getChildrenFromRef(ref) {
		return this.#getChildrenFromRef(this.#cvtToRefPfx(ref));
	}
	hasChildren(ref) {
		const node = this.nodes[ref.nodeIdx];
		const pfxV = node & NodeHeaderPrefixMask;
		const has = (node & NodeHeaderNumChildrenMask) !== 0;
		if (!pfxV) return has;
		if (isRefPfx(ref)) return ref.prefix ? true : has;
		ref = this.#cvtToRefPfx(ref);
		return ref.prefix ? true : has;
	}
	#getChildrenFromRef(ref) {
		const accStack = [Utf8Accumulator.create()];
		const stack = [{
			...ref,
			pos: 0,
			bChar: 0
		}];
		const results = [];
		const iterable = this.#walk(stack);
		let deeper = false;
		for (let next = iterable.next(true); !next.done; next = iterable.next(deeper)) {
			const depth = next.value;
			if (depth <= 0) {
				if (!depth) {
					deeper = true;
					continue;
				}
				break;
			}
			const s = stack[depth];
			accStack[depth] = accStack[depth - 1].clone(accStack[depth]);
			const char = accStack[depth].decode(s.bChar);
			if (char) {
				deeper = false;
				results.push([String.fromCodePoint(char), {
					nodeIdx: s.nodeIdx,
					pfx: s.pfx,
					prefix: s.prefix
				}]);
				continue;
			}
			deeper = true;
		}
		return results;
	}
	/**
	* Checks if a location is at an end-of-word node.
	* @param ref
	* @returns
	*/
	isRefEOW(ref) {
		if (ref.prefix && ref.pfx < ref.prefix.length) return false;
		return !!(this.nodes[ref.nodeIdx] & NodeHeaderEOWMask);
	}
	#getNodePrefix(nodeIdx, pfx) {
		const pfxV = this.nodes[nodeIdx] & NodeHeaderPrefixMask;
		const prefix = pfxV ? this.#stringTable.getStringBytes(pfxV >>> NodeHeaderPrefixShift) : void 0;
		if (!prefix) return void 0;
		if (pfx >= prefix.length) return void 0;
		return prefix;
	}
	#cvtToRefPfx(ref) {
		if (isRefPfx(ref)) return ref;
		const refPfx = ref;
		refPfx.prefix = this.#getNodePrefix(ref.nodeIdx, ref.pfx);
		return refPfx;
	}
	toRef(nodeIdx, pfx = 0) {
		return this.#cvtToRefPfx({
			nodeIdx,
			pfx
		});
	}
	get rootRef() {
		return this.#rootRef;
	}
	getNodeDebugInfo(ref) {
		const node = this.nodes[ref.nodeIdx];
		const isEOW = !!(node & NodeHeaderEOWMask);
		const count = node & NodeHeaderNumChildrenMask;
		const children = /* @__PURE__ */ new Map();
		for (let i = 1; i <= count; ++i) {
			const entry = this.nodes[ref.nodeIdx + i];
			const c = entry & NodeMaskCharByte;
			const idx = entry >>> NodeChildIndexRefShift;
			children.set(charToHex(c), numberToHex(idx) + " " + idx);
		}
		return {
			...ref,
			prefix: ref.prefix ? [...ref.prefix].map(charToHex).join(", ") : "",
			isEOW,
			count,
			children
		};
	}
	static copyNodes(trie) {
		return new Uint32Array(trie.nodes);
	}
};
function nodesToJson(nodes) {
	function nodeElement(offset) {
		const node = nodes[offset];
		const numChildren = node & NodeHeaderNumChildrenMask;
		const eow = !!(node & NodeHeaderEOWMask);
		const children = [];
		for (let i = 1; i <= numChildren; ++i) children.push({
			c: ("00" + (nodes[offset + i] & NodeMaskCharByte).toString(16)).slice(-2),
			o: nodes[offset + i] >>> NodeChildIndexRefShift
		});
		return {
			id: offset,
			eow,
			n: offset + numChildren + 1,
			c: children
		};
	}
	const elements = [];
	let offset = 0;
	while (offset < nodes.length) {
		const e = nodeElement(offset);
		elements.push(e);
		offset = e.n;
	}
	return elements;
}
/**
* Sorts the child nodes in the trie to ensure binary lookup works.
* @param data
*/
function trieBlobSort(data) {
	const MaskNumChildren = NodeHeaderNumChildrenMask;
	const MaskChildCharIndex = NodeMaskCharByte;
	const limit = data.length;
	let idx = 0;
	let node = data[0];
	let nc = node & MaskNumChildren;
	for (; idx < limit; idx += nc + 1, node = data[idx], nc = node & MaskNumChildren) {
		if (!nc) continue;
		const start = idx + 1;
		const end = start + nc;
		let last = 0;
		let i = start;
		for (; i < end; ++i) {
			const cIdx = data[i] & MaskChildCharIndex;
			if (last >= cIdx) break;
			last = cIdx;
		}
		if (i === end) continue;
		data.slice(start, end).sort((a, b) => (a & MaskChildCharIndex) - (b & MaskChildCharIndex)).forEach((v, i) => data[start + i] = v);
	}
}
function numberToHex(n) {
	const digits = n.toString(16).padStart(8, "0");
	return "0x" + digits.slice(0, 4) + "_" + digits.slice(4);
}
function charToHex(c) {
	return c.toString(16).padStart(2, "0") + " " + (c >= 32 && c <= 126 ? String.fromCodePoint(c) : ".");
}
function isRefPfx(ref) {
	return "prefix" in ref;
}
/**
* Sorts the nodes in place if possible.
* @param nodes
* @param mask
* @returns
*/
function sortNodes(nodes, mask) {
	const endPerf = measurePerf$1("TrieBlobBuilder.sortNodes");
	for (let i = 0; i < nodes.length; ++i) {
		const node = nodes[i];
		if (node.length <= 2 || isSorted(node, mask, 1)) continue;
		sortSubArray(node, mask, 1);
	}
	endPerf();
	return nodes;
}
function sortSubArray(node, mask, startAt) {
	const compare = (a, b) => !a ? -1 : !b ? 1 : (a & mask) - (b & mask);
	if (node.subarray === void 0) {
		const header = node[0];
		node[0] = Number.MIN_SAFE_INTEGER;
		node.sort(compare);
		node[0] = header;
		return;
	}
	node.subarray(startAt).sort(compare);
}
function isSorted(node, mask, start, end) {
	if (node.length > 2) {
		const limit = end ?? node.length;
		let last = -1;
		for (let j = start; j < limit; ++j) {
			const n = node[j] & mask;
			if (n < last) return false;
			last = n;
		}
	}
	return true;
}
function toTrieBlob(nodes, stringTable, info) {
	const endPerf = measurePerf$1("TrieBlob.toTrieBlob");
	const nodeMaskChildCharIndex = NodeMaskCharByte;
	const nodeChildRefShift = NodeChildIndexRefShift;
	function calcNodeToIndex(nodes) {
		let offset = 0;
		const idx = Array(nodes.length + 1);
		for (let i = 0; i < nodes.length; ++i) {
			idx[i] = offset;
			offset += nodes[i].length;
		}
		idx[nodes.length] = offset;
		return idx;
	}
	const nodeToIndex = calcNodeToIndex(nodes);
	const nodeElementCount = nodeToIndex[nodeToIndex.length - 1];
	const binNodes = new Uint32Array(nodeElementCount);
	const lenShift = NodeHeaderNumChildrenShift;
	const refShift = NodeChildIndexRefShift;
	const NodeHeaderMask = ~NodeHeaderNumChildrenMask;
	let offset = 0;
	for (let i = 0; i < nodes.length; ++i) {
		const node = nodes[i];
		binNodes[offset++] = node.length - 1 << lenShift | node[0] & NodeHeaderMask;
		for (let j = 1; j < node.length; ++j) {
			const v = node[j];
			const nodeRef = v >>> nodeChildRefShift;
			const charIndex = v & nodeMaskChildCharIndex;
			binNodes[offset++] = nodeToIndex[nodeRef] << refShift | charIndex;
		}
	}
	const t = new TrieBlob(binNodes, stringTable, info);
	endPerf();
	return t;
}
const AUTO_OPTIMIZE_NODE_COUNT = 0;
var TrieBlobBuilder = class TrieBlobBuilder {
	charIndex = new CharIndexBuilder();
	nodes;
	_readonly = false;
	IdxEOW;
	_cursor;
	_cursorId = 0;
	wordToCharacters = (word) => [...word];
	#infoBuilder;
	constructor(options, characteristics) {
		this.nodes = [[0], Object.freeze([NodeHeaderEOWMask])];
		this.IdxEOW = 1;
		this.#infoBuilder = new TrieInfoBuilder(options, characteristics);
	}
	setOptions(options) {
		this.#infoBuilder.setInfo(options);
		return this.#infoBuilder.getActiveInfo();
	}
	get options() {
		return this.#infoBuilder.getActiveInfo();
	}
	wordToUtf8Seq(word) {
		return this.charIndex.wordToUtf8Seq(word);
	}
	letterToUtf8Seq(letter) {
		return this.charIndex.charToUtf8Seq(letter);
	}
	insert(word) {
		this.#assertNotReadonly();
		if (typeof word === "string") return this.#insertWord(word);
		return this.insertWords(word);
	}
	getCursor() {
		this.#assertNotReadonly();
		this._cursor ??= this.createCursor(++this._cursorId);
		return this._cursor;
	}
	createCursor(id) {
		const endPerf = measurePerf$1("TrieBlobBuilder.cursor");
		const nodeChildRefShift = NodeChildIndexRefShift;
		const NodeMaskEOW = NodeHeaderEOWMask;
		const LetterMask = NodeMaskCharByte;
		const refNodes = [0, 1];
		const lookupCharCode = createCharUtf8_32RevLookup();
		let disposed = false;
		const dispose = () => {
			if (disposed) return;
			endPerf();
			disposed = true;
			if (this._cursorId === id) this._cursor = void 0;
		};
		function childPos(node, letterIdx) {
			for (let i = 1; i < node.length; ++i) if ((node[i] & LetterMask) === letterIdx) return i;
			return 0;
		}
		assert$3(this.nodes.length === 2);
		const eowNodeIndex = 1;
		const eowShifted = eowNodeIndex << nodeChildRefShift;
		const nodes = this.nodes;
		const stack = [{
			nodeIdx: 0,
			pos: 0,
			pDepth: -1
		}];
		let nodeIdx = 0;
		let depth = 0;
		/**
		* Asserts that the cursor has not been disposed and is still valid.
		* There can be only one valid cursor per builder at a time.
		*/
		const assertNotDisposed = () => {
			assert$3(!disposed, "Cursor has been disposed");
			assert$3(id === this._cursorId, "Cursor is no longer valid");
		};
		/**
		* A single character can result in multiple nodes being created
		* because it takes multiple bytes to represent a character.
		* @param char - character to insert.
		*/
		function insertChar(char) {
			assertNotDisposed();
			if (!nodes[nodeIdx]) refNodes.push(nodeIdx);
			const pDepth = depth;
			for (let encoded = lookupCharCode(char); encoded; encoded >>>= 8) insertCharByteCode(encoded & 255, pDepth);
		}
		/**
		* A single character can result in multiple nodes being created
		* because it takes multiple bytes to represent a character.
		* @param byte - partial character index.
		*/
		function insertCharByteCode(byte, pDepth) {
			if (nodes[nodeIdx] && Object.isFrozen(nodes[nodeIdx])) {
				nodeIdx = nodes.push([...nodes[nodeIdx]]) - 1;
				const { pos, nodeIdx: pNodeIdx } = stack[depth];
				const pNode = nodes[pNodeIdx];
				pNode[pos] = pNode[pos] & LetterMask | nodeIdx << nodeChildRefShift;
			}
			const node = nodes[nodeIdx] || [0];
			nodes[nodeIdx] = node;
			const hasIdx = childPos(node, byte);
			const childIdx = hasIdx ? node[hasIdx] >>> nodeChildRefShift : nodes.length;
			const pos = hasIdx || node.push(childIdx << nodeChildRefShift | byte) - 1;
			++depth;
			const s = stack[depth];
			if (s) {
				s.nodeIdx = nodeIdx;
				s.pos = pos;
				s.pDepth = pDepth;
			} else stack[depth] = {
				nodeIdx,
				pos,
				pDepth
			};
			nodeIdx = childIdx;
		}
		function markEOW() {
			assertNotDisposed();
			if (nodeIdx === eowNodeIndex) return;
			const node = nodes[nodeIdx];
			if (!node) {
				const { pos, nodeIdx: pNodeIdx } = stack[depth];
				const pNode = nodes[pNodeIdx];
				pNode[pos] = pNode[pos] & LetterMask | eowShifted;
			} else {
				nodes[nodeIdx] = node;
				node[0] |= NodeMaskEOW;
			}
			nodeIdx = eowNodeIndex;
		}
		function reference(refId) {
			assertNotDisposed();
			const refNodeIdx = refNodes[refId];
			assert$3(refNodeIdx !== void 0);
			assert$3(nodes[nodeIdx] === void 0);
			assert$3(nodes[refNodeIdx]);
			Object.freeze(nodes[refNodeIdx]);
			const s = stack[depth];
			nodeIdx = s.nodeIdx;
			const pos = s.pos;
			const node = nodes[nodeIdx];
			node[pos] = refNodeIdx << nodeChildRefShift | node[pos] & LetterMask;
		}
		function backStep(num) {
			assertNotDisposed();
			if (!num) return;
			assert$3(num <= depth && num > 0);
			for (let n = num; n > 0; --n) depth = stack[depth].pDepth;
			nodeIdx = stack[depth + 1].nodeIdx;
		}
		return {
			insertChar,
			markEOW,
			reference,
			backStep,
			dispose,
			[Symbol.dispose]: dispose
		};
	}
	/**
	* Insert multiple words. Performance is (~10%) better if the words are sorted.
	* @param words - words to insert
	* @returns this
	*/
	insertWords(words) {
		for (const word of words) this.#insertWord(word);
		return this;
	}
	#insertWord(word) {
		word = word.trim();
		if (!word) return this;
		this.#infoBuilder.addWord(word);
		const NodeMaskChildCharIndex = NodeMaskCharByte;
		const nodeChildRefShift = NodeChildIndexRefShift;
		const NodeMaskEOW = NodeHeaderEOWMask;
		const IdxEOW = this.IdxEOW;
		const nodes = this.nodes;
		let nodeIdx = 0;
		const wLen = word.length;
		const bytes = [];
		for (const t = {
			text: word,
			i: 0
		}; t.i < wLen;) {
			const isLastChar = t.i >= wLen - 1;
			for (let utf8Code = encodeTextToUtf8_32Rev(t); utf8Code; utf8Code >>>= 8) {
				const seq = utf8Code & 255;
				bytes.push(seq);
				const node = nodes[nodeIdx];
				let i = node.length - 1;
				for (; i > 0; --i) if ((node[i] & NodeMaskChildCharIndex) === seq) break;
				const isEow = isLastChar && utf8Code <= 255;
				if (i > 0) {
					nodeIdx = node[i] >>> nodeChildRefShift;
					if (nodeIdx === 1 && !isEow) {
						nodeIdx = this.nodes.push([NodeMaskEOW]) - 1;
						node[i] = nodeIdx << nodeChildRefShift | seq;
					}
					continue;
				}
				nodeIdx = isEow ? IdxEOW : this.nodes.push([0]) - 1;
				node.push(nodeIdx << nodeChildRefShift | seq);
			}
		}
		if (nodeIdx > 1) {
			const node = nodes[nodeIdx];
			node[0] |= NodeMaskEOW;
		}
		return this;
	}
	has(word) {
		const NodeMaskChildCharIndex = NodeMaskCharByte;
		const nodeChildRefShift = NodeChildIndexRefShift;
		const NodeMaskEOW = NodeHeaderEOWMask;
		const nodes = this.nodes;
		const charIndexes = this.wordToUtf8Seq(word);
		const len = charIndexes.length;
		let nodeIdx = 0;
		let node = nodes[nodeIdx];
		for (let p = 0; p < len; ++p, node = nodes[nodeIdx]) {
			const letterIdx = charIndexes[p];
			let i = node.length - 1;
			for (; i > 0; --i) if ((node[i] & NodeMaskChildCharIndex) === letterIdx) break;
			if (i < 1) return false;
			nodeIdx = node[i] >>> nodeChildRefShift;
		}
		return !!(node[0] & NodeMaskEOW);
	}
	isReadonly() {
		return this._readonly;
	}
	freeze() {
		this._readonly = true;
		return this;
	}
	copyNodes() {
		return this.nodes.map((n) => [...n]);
	}
	build(buildOptions) {
		this._cursor?.dispose?.();
		this._readonly = true;
		this.freeze();
		const endPerf = measurePerf$1("TrieBlobBuilder.build");
		const { optimize, useStringTable } = buildOptions || {};
		const info = this.#infoBuilder.build();
		const bNodes = this.nodes;
		let sortedNodes = sortNodes(bNodes, NodeMaskCharByte);
		if (optimize ?? sortNodes.length < AUTO_OPTIMIZE_NODE_COUNT) sortedNodes = optimizeNodes(sortedNodes);
		const stringTable = new StringTableBuilder().build();
		const r = useStringTable ? optimizeNodesWithStringTable({
			nodes: sortedNodes,
			stringTable
		}) : {
			nodes: sortedNodes,
			stringTable
		};
		const data = toTrieBlob(r.nodes, r.stringTable, normalizeTrieInfo(info.info));
		endPerf();
		return data;
	}
	toJSON() {
		return {
			options: this.options,
			nodes: this.nodes
		};
	}
	#assertNotReadonly() {
		assert$3(!this.isReadonly(), "FastTrieBlobBuilder is readonly");
	}
	static fromWordList(words, options, buildOptions) {
		return new TrieBlobBuilder(options).insert(words).build(buildOptions);
	}
	/**
	* Create a TrieBlob from a TrieRoot.
	*
	* This is equivalent to, but slightly faster because it avoids creating an ITrieNodes
	* ```ts
	* static fromTrieRoot(root: TrieRoot, optimize?: boolean): TrieBlob {
	*   return this.fromITrieRoot(trieRootToITrieRoot(root), optimize);
	* }
	* ```
	*
	* @param root - TrieRoot
	* @param buildOptions - optional build options
	* @returns TrieBlob
	*/
	static fromTrieRoot(root, buildOptions) {
		const endPerf = measurePerf$1("TrieBlobBuilder.fromTrieRoot");
		const NodeCharIndexMask = NodeMaskCharByte;
		const nodeChildRefShift = NodeChildIndexRefShift;
		const NodeMaskEOW = NodeHeaderEOWMask;
		const tf = new TrieBlobBuilder(void 0, root);
		const IdxEOW = tf.IdxEOW;
		const known = new Map([[root, 0]]);
		function resolveNode(n) {
			if (n.f && !n.c) return IdxEOW;
			const node = [n.f ? NodeMaskEOW : 0];
			return tf.nodes.push(node) - 1;
		}
		function walk(n) {
			const found = known.get(n);
			if (found) return found;
			const nodeIdx = resolveMap(known, n, resolveNode);
			const node = tf.nodes[nodeIdx];
			if (!n.c) return nodeIdx;
			const children = Object.entries(n.c);
			for (let p = 0; p < children.length; ++p) {
				const [char, childNode] = children[p];
				addCharToNode(node, char, childNode);
			}
			return nodeIdx;
		}
		function resolveChild(node, charIndex) {
			let i = 1;
			for (i = 1; i < node.length && (node[i] & NodeCharIndexMask) !== charIndex; ++i);
			return i;
		}
		function addCharToNode(node, char, n) {
			const indexSeq = tf.letterToUtf8Seq(char);
			assertValidUtf16Character(char);
			for (const idx of indexSeq.slice(0, -1)) {
				const pos = resolveChild(node, idx);
				if (pos < node.length) node = tf.nodes[node[pos] >>> nodeChildRefShift];
				else {
					const next = [0];
					const nodeIdx = tf.nodes.push(next) - 1;
					node[pos] = nodeIdx << nodeChildRefShift | idx;
					node = next;
				}
			}
			const letterIdx = indexSeq[indexSeq.length - 1];
			const i = node.push(letterIdx) - 1;
			node[i] = walk(n) << nodeChildRefShift | letterIdx;
		}
		walk(root);
		const result = tf.build(buildOptions);
		endPerf();
		return result;
	}
	/**
	* Create a TrieBlob from a TrieRoot.
	*
	* @param root - root node
	* @param buildOptions - optional build options
	* @returns TrieBlob
	*/
	static fromITrieRoot(root, buildOptions) {
		const endPerf = measurePerf$1("TrieBlobBuilder.fromITrieRoot");
		const NodeCharIndexMask = NodeMaskCharByte;
		const nodeChildRefShift = NodeChildIndexRefShift;
		const NodeMaskEOW = NodeHeaderEOWMask;
		const tf = new TrieBlobBuilder(void 0, root);
		const IdxEOW = tf.IdxEOW;
		const known = new Map([[root.id, 0]]);
		function resolveNode(n) {
			if (n.eow && !n.hasChildren()) return IdxEOW;
			const node = [n.eow ? NodeMaskEOW : 0];
			return tf.nodes.push(node) - 1;
		}
		function walk(n) {
			const found = known.get(n.id);
			if (found) return found;
			const nodeIdx = resolveMap(known, n.id, () => resolveNode(n));
			const node = tf.nodes[nodeIdx];
			if (!n.hasChildren()) return nodeIdx;
			const children = n.entries();
			for (const [char, childNode] of children) addCharToNode(node, char, childNode);
			return nodeIdx;
		}
		function resolveChild(node, charIndex) {
			let i = 1;
			for (i = 1; i < node.length && (node[i] & NodeCharIndexMask) !== charIndex; ++i);
			return i;
		}
		function addCharToNode(node, char, n) {
			const indexSeq = tf.letterToUtf8Seq(char);
			assertValidUtf16Character(char);
			for (const idx of indexSeq.slice(0, -1)) {
				const pos = resolveChild(node, idx);
				if (pos < node.length) node = tf.nodes[node[pos] >>> nodeChildRefShift];
				else {
					const next = [0];
					const nodeIdx = tf.nodes.push(next) - 1;
					node[pos] = nodeIdx << nodeChildRefShift | idx;
					node = next;
				}
			}
			const letterIdx = indexSeq[indexSeq.length - 1];
			const i = node.push(letterIdx) - 1;
			node[i] = walk(n) << nodeChildRefShift | letterIdx;
		}
		walk(root);
		const result = tf.build(buildOptions);
		endPerf();
		return result;
	}
};
function createCharUtf8_32RevLookup(maxSize = 256) {
	let size = 0;
	let map = Object.create(null);
	return (char) => {
		let code = map[char];
		if (!code) {
			size++;
			if (size >= maxSize) {
				size = 1;
				map = Object.create(null);
			}
			code = encodeToUtf8_32Rev(char.codePointAt(0) || 0);
			map[char] = code;
		}
		return code;
	};
}
function clean$3(t) {
	const copy = { ...t };
	for (const key of Object.keys(copy)) if (copy[key] === void 0) delete copy[key];
	return copy;
}
const defaultLegacyMinCompoundLength$1 = 3;
const cvtFindWordOptions = memorizeLastCall(_cvtFindWordOptions);
function _cvtFindWordOptions(options) {
	return createFindOptions$1({
		matchCase: options?.caseSensitive,
		checkForbidden: options?.checkForbidden,
		compoundSeparator: options?.compoundSeparator
	});
}
var ITrieImpl = class ITrieImpl {
	_info;
	root;
	count;
	weightMap;
	#optionsCompound = this.createFindOptions({ compoundMode: "compound" });
	#findOptionsT = {
		caseSensitive: true,
		checkForbidden: true
	};
	#findOptionsF = {
		caseSensitive: false,
		checkForbidden: true
	};
	hasForbiddenWords;
	hasCompoundWords;
	hasNonStrictWords;
	data;
	constructor(data) {
		this.data = data;
		this.root = data.getRoot();
		this._info = mergeOptionalWithDefaults(data.info);
		this.hasForbiddenWords = data.hasForbiddenWords;
		this.hasCompoundWords = data.hasCompoundWords;
		this.hasNonStrictWords = data.hasNonStrictWords;
	}
	/**
	* Number of words in the Trie, the first call to this method might be expensive.
	* Use `size` to get the number of nodes.
	*/
	numWords() {
		this.count ??= countWords$1(this.root);
		return this.count;
	}
	isNumWordsKnown() {
		return this.count !== void 0;
	}
	get size() {
		return this.data.size;
	}
	get info() {
		return this._info;
	}
	/**
	* @param text - text to find in the Trie
	*/
	find(text) {
		return findWordNode$1(this.data.getRoot(), text, this.#optionsCompound).node;
	}
	/**
	* A case sensitive search for the word.
	* @param word - the word to search for.
	* @param minLegacyCompoundLength - minimum length of legacy compounds to consider.
	* @returns true if the word is found and not forbidden.
	*/
	has(word, minLegacyCompoundLength) {
		if (minLegacyCompoundLength !== void 0) return this.#hasLegacy(word, minLegacyCompoundLength);
		return this.hasWord(word, true);
	}
	#hasLegacy(word, minLegacyCompoundLength) {
		if (this.hasWord(word, false)) return true;
		if (minLegacyCompoundLength) {
			const f = this.findWord(word, {
				useLegacyWordCompounds: minLegacyCompoundLength,
				caseSensitive: false,
				checkForbidden: true
			});
			return !!f.found && !f.forbidden;
		}
		return false;
	}
	/**
	* Determine if a word is in the dictionary.
	* @param word - the exact word to search for - must be normalized.
	* @param caseSensitive - false means also searching a dictionary where the words were normalized to lower case and accents removed.
	* @returns true if the word was found and is not forbidden.
	*/
	hasWord(word, caseSensitive) {
		const options = caseSensitive ? this.#findOptionsT : this.#findOptionsF;
		const r = this.findWord(word, options);
		return !r.forbidden && !!r.found;
	}
	findWord(word, options) {
		if (options?.useLegacyWordCompounds) {
			const len = options.useLegacyWordCompounds !== true ? options.useLegacyWordCompounds : defaultLegacyMinCompoundLength$1;
			const findOptions = this.createFindOptions({
				legacyMinCompoundLength: len,
				matchCase: options.caseSensitive || false,
				compoundSeparator: void 0
			});
			return findLegacyCompound$1(this.root, word, findOptions);
		}
		return findWord$1(this.root, word, cvtFindWordOptions(options));
	}
	/**
	* Determine if a word is in the forbidden word list.
	* @param word the word to lookup.
	*/
	isForbiddenWord(word) {
		return this.hasForbiddenWords && isForbiddenWord$1(this.root, word, this.info.forbiddenWordPrefix);
	}
	/**
	* Provides an ordered sequence of words with the prefix of text.
	*/
	completeWord(text) {
		const n = this.find(text);
		const compoundChar = this.info.compoundCharacter;
		const subNodes = pipeSync(n ? iteratorTrieWords$1(n) : [], opFilterSync((w) => w[w.length - 1] !== compoundChar), opMapSync((suffix) => text + suffix));
		return pipeSync(n && n.eow ? [text] : [], opAppendSync(subNodes));
	}
	/**
	* Checks to see if there are preferred suggestions for the given text.
	* @param text
	*/
	wordHasPreferredSuggestions(text) {
		return this.has(this.info.suggestionPrefix + text);
	}
	/**
	* Get preferred suggestions for the given text.
	* @param text - the exact word to search for.
	*/
	getPreferredSuggestions(text) {
		const prefix = text + this.info.suggestionPrefix;
		return pipeSync(this.getAllPreferredSuggestions(prefix), opMapSync((s) => s.slice(prefix.length)));
	}
	/**
	* Get a list of all preferred suggestions in the trie.
	* They are returned in order and in the following format:
	* ```
	* <word1>:<suggestion1>
	* <word1>:<suggestion2>
	* <word2>:<suggestion1>
	* ```
	*
	* If `startingWith` is provided, only words that start with the prefix are returned.
	*
	* @param startingWith - optional prefix to filter the words returned.
	*/
	getAllPreferredSuggestions(startingWith = "") {
		const regexpSugIndex = /:[0-9a-f]{1,2}:/;
		const sugPrefix = this.info.suggestionPrefix;
		return pipeSync(this.data.words(sugPrefix + startingWith), opMapSync((result) => result.slice(1).replace(regexpSugIndex, ":")), opFilterSync((w) => w.includes(":")));
	}
	/**
	* Checks to see if the trie contains preferred suggestions for any words.
	*/
	get hasPreferredSuggestions() {
		return this.data.hasPreferredSuggestions;
	}
	/**
	* Suggest spellings for `text`.  The results are sorted by edit distance with changes near the beginning of a word having a greater impact.
	* @param text - the text to search for
	* @param maxNumSuggestions - the maximum number of suggestions to return.
	* @param compoundMethod - Use to control splitting words.
	* @param numChanges - the maximum number of changes allowed to text. This is an approximate value, since some changes cost less than others.
	*                      the lower the value, the faster results are returned. Values less than 4 are best.
	*/
	suggest(text, options) {
		return this.suggestWithCost(text, options).map((a) => a.word);
	}
	/**
	* Suggest spellings for `text`.  The results are sorted by edit distance with changes near the beginning of a word having a greater impact.
	* The results include the word and adjusted edit cost.  This is useful for merging results from multiple tries.
	*/
	suggestWithCost(text, options) {
		const sep = options.compoundSeparator;
		const weightMap = options.weightMap || this.weightMap;
		const adjWord = sep ? replaceAllFactory(sep, "") : (a) => a;
		const optFilter = options.filter;
		const filter = optFilter ? (word, cost) => {
			const w = adjWord(word);
			return !this.isForbiddenWord(w) && optFilter(w, cost);
		} : (word) => !this.isForbiddenWord(adjWord(word));
		const opts = {
			...options,
			filter,
			weightMap
		};
		return suggestAStar(this.data, text, opts);
	}
	/**
	* genSuggestions will generate suggestions and send them to `collector`. `collector` is responsible for returning the max acceptable cost.
	* Costs are measured in weighted changes. A cost of 100 is the same as 1 edit. Some edits are considered cheaper.
	* Returning a MaxCost < 0 will effectively cause the search for suggestions to stop.
	*/
	genSuggestions(collector, compoundMethod) {
		const filter = (word) => !this.isForbiddenWord(word);
		const options = createSuggestionOptions(clean$3({
			compoundMethod,
			...collector.genSuggestionOptions
		}));
		const suggestions = getSuggestionsAStar(this.data, collector.word, options);
		collector.collect(suggestions, void 0, filter);
	}
	/**
	* Returns an iterator that can be used to get all words in the trie. For some dictionaries, this can result in millions of words.
	* Note: this will not compound words automatically.
	* @param prefix - optional prefix to filter the words returned. The words will be prefixed with this value.
	*/
	words(prefix) {
		return this.data.words(prefix);
	}
	/**
	* Allows iteration over the entire tree.
	* On the returned Iterator, calling .next(goDeeper: boolean), allows for controlling the depth.
	*/
	iterate() {
		return walker$1(this.root);
	}
	static create(words, info) {
		const builder = new TrieBlobBuilder(info);
		builder.insert(words);
		return new ITrieImpl(builder.build());
	}
	createFindOptions(options) {
		return createFindOptions$1(options);
	}
};
function buildITrieFromWords(words, info = {}, buildOptions) {
	const endPerf = measurePerf$1("buildITrieFromWords");
	try {
		const builder = new TrieBlobBuilder(info);
		builder.insert(words);
		return new ITrieImpl(builder.build(buildOptions));
	} finally {
		endPerf();
	}
}
const FLAG_WORD = 1;
function insert$2(word, root = {}) {
	const text = [...word];
	let node = root;
	for (let i = 0; i < text.length; ++i) {
		const head = text[i];
		const c = node.c || Object.create(null);
		node.c = c;
		node = c[head] || {};
		c[head] = node;
	}
	node.f = (node.f || 0) | FLAG_WORD;
	return root;
}
function createTrieRoot(options) {
	return new CTrieRoot(options);
}
function createTrieRootFromList(words, options) {
	const root = createTrieRoot(options);
	for (const word of words) if (word.length) insert$2(word, root);
	return root;
}
function countNodes(root) {
	const seen = /* @__PURE__ */ new Set();
	function walk(n) {
		if (seen.has(n)) return;
		seen.add(n);
		if (n.c) Object.values(n.c).forEach((n) => walk(n));
	}
	walk(root);
	return seen.size;
}
function checkCircular(root) {
	const seen = /* @__PURE__ */ new Set();
	const inStack = /* @__PURE__ */ new Set();
	function walk(n) {
		if (seen.has(n)) return {
			isCircular: false,
			allSeen: true
		};
		if (inStack.has(n)) {
			const stack = [...inStack, n];
			return {
				isCircular: true,
				allSeen: false,
				ref: {
					stack,
					word: trieStackToWord(stack),
					pos: stack.indexOf(n)
				}
			};
		}
		inStack.add(n);
		let r = {
			isCircular: false,
			allSeen: true
		};
		if (n.c) r = Object.values(n.c).reduce((acc, n) => {
			if (acc.isCircular) return acc;
			const r = walk(n);
			r.allSeen = r.allSeen && acc.allSeen;
			return r;
		}, r);
		if (r.allSeen) seen.add(n);
		inStack.delete(n);
		return r;
	}
	return walk(root);
}
function reverseMapTrieNode(node) {
	return node.c && new Map(Object.entries(node.c).map(([c, n]) => [n, c]));
}
function trieStackToWord(stack) {
	let word = "";
	let lastMap = reverseMapTrieNode(stack[0]);
	for (let i = 1; i < stack.length; ++i) {
		const n = stack[i];
		const char = lastMap?.get(n);
		if (char) word += char;
		lastMap = reverseMapTrieNode(n);
	}
	return word;
}
function isCircular(root) {
	return checkCircular(root).isCircular;
}
function trieNodeToRoot(node, options) {
	return CTrieRoot.createFrom(node, options);
}
var CTrieRoot = class CTrieRoot {
	c;
	compoundCharacter;
	stripCaseAndAccentsPrefix;
	forbiddenWordPrefix;
	suggestionPrefix;
	constructor(options) {
		const newOptions = mergeOptionalWithDefaults(options);
		this.c = Object.create(null);
		this.compoundCharacter = newOptions.compoundCharacter;
		this.stripCaseAndAccentsPrefix = newOptions.stripCaseAndAccentsPrefix;
		this.forbiddenWordPrefix = newOptions.forbiddenWordPrefix;
		this.suggestionPrefix = newOptions.suggestionPrefix;
	}
	get hasForbiddenWords() {
		return !!this.c[this.forbiddenWordPrefix];
	}
	get hasCompoundWords() {
		return !!this.c[this.compoundCharacter];
	}
	get hasNonStrictWords() {
		return !!this.c[this.stripCaseAndAccentsPrefix];
	}
	get hasPreferredSuggestions() {
		return !!this.c[this.suggestionPrefix];
	}
	static createFrom(trie, options) {
		const root = new CTrieRoot(options);
		root.c = trie.c || Object.create(null);
		return root;
	}
};
/**
* Consolidate to DAWG
* @param root the root of the Trie tree
*/
function consolidate(root) {
	let count = 0;
	const signatures = /* @__PURE__ */ new Map();
	const cached = /* @__PURE__ */ new Map();
	const knownMap = /* @__PURE__ */ new Map();
	if (isCircular(root)) throw new Error("Trie is circular.");
	function signature(n) {
		return (n.f ? "*" : "") + (n.c ? JSON.stringify(Object.entries(n.c).map(([k, n]) => [k, cached.get(n)])) : "");
	}
	function findEow(n) {
		if (n.f && !n.c) return n;
		let r;
		// istanbul ignore else
		if (n.c) for (const c of Object.values(n.c)) {
			r = findEow(c);
			// istanbul ignore else
			if (r) break;
		}
		return r;
	}
	function compareMaps(a, b) {
		for (const e of a) if (b[e[0]] !== e[1]) return false;
		return a.length === b.size;
	}
	function deepCopy(n) {
		const k = knownMap.get(n);
		if (k) return k;
		const orig = n;
		if (n.c) {
			const children = Object.entries(n.c).map((c) => [c[0], deepCopy(c[1])]);
			if (!compareMaps(children, n.c)) n = {
				f: n.f,
				c: Object.fromEntries(children)
			};
		}
		const sig = signature(n);
		const ref = signatures.get(sig);
		if (ref) {
			knownMap.set(orig, ref);
			return ref;
		}
		Object.freeze(n);
		signatures.set(sig, n);
		cached.set(n, count++);
		knownMap.set(orig, n);
		return n;
	}
	function process(n) {
		if (cached.has(n)) return n;
		if (Object.isFrozen(n)) return knownMap.get(n) || deepCopy(n);
		if (n.c) {
			const children = Object.entries(n.c).sort((a, b) => a[0] < b[0] ? -1 : 1).map(([k, n]) => [k, process(n)]);
			n.c = Object.fromEntries(children);
		}
		const sig = signature(n);
		const ref = signatures.get(sig);
		if (ref) return ref;
		signatures.set(sig, n);
		cached.set(n, count++);
		return n;
	}
	const eow = findEow(root) || {
		f: FLAG_WORD,
		c: void 0
	};
	signatures.set(signature(eow), eow);
	cached.set(eow, count++);
	return trieNodeToRoot(process(root), root);
}
function decodeBTrie(data) {
	return TrieBlob.decodeBin(data);
}
const _defaultFindOptions = {
	matchCase: false,
	compoundMode: "compound",
	forbidPrefix: FORBID_PREFIX,
	compoundFix: COMPOUND_FIX,
	caseInsensitivePrefix: CASE_INSENSITIVE_PREFIX,
	legacyMinCompoundLength: 3,
	compoundSeparator: void 0
};
const knownCompoundModes = new Map([
	"none",
	"compound",
	"legacy"
].map((a) => [a, a]));
function findWordExact(root, word) {
	return isEndOfWordNode(walk$1(root, word));
}
function isEndOfWordNode(n) {
	return n?.f === FLAG_WORD;
}
function walk$1(root, word) {
	const w = [...word];
	let n = root;
	let i = 0;
	while (n && i < w.length) {
		const h = w[i++];
		n = n.c?.[h];
	}
	return n;
}
const createFindOptions = memorizeLastCall(_createFindOptions);
function _createFindOptions(options) {
	return mergeDefaults(options, _defaultFindOptions);
}
var TrieNodeTrie = class TrieNodeTrie {
	_iTrieRoot;
	info;
	_size;
	hasForbiddenWords;
	hasCompoundWords;
	hasNonStrictWords;
	hasPreferredSuggestions;
	root;
	constructor(root) {
		this.root = root;
		this.info = mergeOptionalWithDefaults(root);
		this.hasForbiddenWords = root.hasForbiddenWords;
		this.hasCompoundWords = root.hasCompoundWords;
		this.hasNonStrictWords = root.hasNonStrictWords;
		this.hasPreferredSuggestions = root.hasPreferredSuggestions;
	}
	wordToCharacters = (word) => [...word];
	get iTrieRoot() {
		return this._iTrieRoot || (this._iTrieRoot = trieRootToITrieRoot(this.root));
	}
	getRoot() {
		return this.iTrieRoot;
	}
	getNode(prefix) {
		return findNode$1(this.getRoot(), prefix);
	}
	*words(prefix) {
		if (!prefix) {
			yield* iteratorTrieWords$1(this.getRoot());
			return;
		}
		const node = this.getNode(prefix);
		if (!node) return;
		if (node.eow) yield prefix;
		for (const suffix of iteratorTrieWords$1(node)) yield prefix + suffix;
	}
	has(word) {
		return findWordExact(this.root, word);
	}
	isForbiddenWord(word) {
		return findWordExact(this.root.c[this.root.forbiddenWordPrefix], word);
	}
	get size() {
		return this._size ??= countNodes(this.root);
	}
	static createFromWords(words, options) {
		return new TrieNodeTrie(createTrieRootFromList(words, options));
	}
	static createFromWordsAndConsolidate(words, options) {
		return new TrieNodeTrie(consolidate(createTrieRootFromList(words, options)));
	}
};
function* toIterableIterator$2(i) {
	yield* i;
}
/**
* Operators used by Sequence
*/
function* filter$1(i, fnFilter) {
	for (const v of i) if (fnFilter(v)) yield v;
}
function* skip$1(i, n) {
	let a = 0;
	for (const t of i) {
		if (a >= n) yield t;
		a += 1;
	}
}
function* take$1(i, n) {
	let a = 0;
	if (n) for (const t of i) {
		if (a >= n) break;
		yield t;
		a += 1;
	}
}
/**
* Concat two iterables together
*/
function* concat$1(i, j) {
	yield* i;
	yield* j;
}
function* concatMap$1(i, fn) {
	for (const t of i) yield* fn(t);
}
/**
* Combine two iterables together using fnMap function.
*/
function* combine$1(i, j, fnMap) {
	const jit = j[Symbol.iterator]();
	for (const r of i) {
		const s = jit.next().value;
		yield fnMap(r, s);
	}
}
/**
* apply a mapping function to an Iterable.
*/
function map$1(i, fnMap) {
	function* fn(i, fnMap) {
		for (const v of i) yield fnMap(v);
	}
	return fn(i, fnMap);
}
function* scan$1(i, fnReduce, initValue) {
	let index = 0;
	if (initValue === void 0) {
		index = 1;
		const iter = i[Symbol.iterator]();
		let r = iter.next();
		if (!r.done) yield r.value;
		initValue = r.value;
		i = makeIterable(iter);
	}
	let prevValue = initValue;
	for (const t of i) {
		const nextValue = fnReduce(prevValue, t, index);
		yield nextValue;
		prevValue = nextValue;
		index += 1;
	}
}
function all$1(i, fn) {
	for (const t of i) if (!fn(t)) return false;
	return true;
}
function any$1(i, fn) {
	for (const t of i) if (fn(t)) return true;
	return false;
}
function count$1(i) {
	return reduce$1(i, (p) => p + 1, 0);
}
function first$1(i, fn, defaultValue) {
	fn = fn || (() => true);
	for (const t of i) if (fn(t)) return t;
	return defaultValue;
}
function forEach$1(i, fn) {
	let index = 0;
	for (const t of i) {
		fn(t, index);
		index += 1;
	}
}
function max$1(i, selector = (t) => t) {
	return reduce$1(i, (p, c) => selector(c) > selector(p) ? c : p, void 0);
}
function min$1(i, selector = (t) => t) {
	return reduce$1(i, (p, c) => selector(c) < selector(p) ? c : p, void 0);
}
function reduce$1(i, fnReduce, initialValue) {
	const iter = makeIterable(i[Symbol.iterator]());
	let index = 0;
	if (initialValue === void 0) {
		index = 1;
		initialValue = iter.next().value;
	}
	let prevValue = initialValue;
	for (const t of iter) {
		prevValue = fnReduce(prevValue, t, index);
		index += 1;
	}
	return prevValue;
}
async function reduceAsync$1(i, fnReduce, initialValue) {
	const iter = makeIterable(i[Symbol.iterator]());
	let index = 0;
	if (initialValue === void 0) {
		index = 1;
		initialValue = iter.next().value;
	}
	let previousValue = await initialValue;
	for (const p of iter) {
		const t = await p;
		previousValue = await fnReduce(previousValue, t, index);
		index += 1;
	}
	return previousValue;
}
/**
* Convert an Iterator into an IterableIterator
*/
function makeIterable(i) {
	function* fromIterator(i) {
		for (let r = i.next(); !r.done; r = i.next()) yield r.value;
	}
	function* fromIterable(i) {
		yield* i;
	}
	return isIterable$1(i) ? isIterableIterator(i) ? i : fromIterable(i) : fromIterator(i);
}
function isIterable$1(i) {
	return !!i[Symbol.iterator];
}
function isIterableIterator(i) {
	return typeof i.next == "function";
}
/**
* Operators used by Sequence
*/
function filter(fnFilter) {
	return (i) => filter$1(i, fnFilter);
}
function skip$2(n) {
	return (i) => skip$1(i, n);
}
function take(n) {
	return (i) => take$1(i, n);
}
/**
* Concat two iterables together
*/
function concat(j) {
	return (i) => concat$1(i, j);
}
function concatMap(fn) {
	return (i) => concatMap$1(i, fn);
}
/**
* Combine two iterables together using fnMap function.
*/
function combine$2(fnMap, j) {
	return (i) => combine$1(i, j, fnMap);
}
/**
* apply a mapping function to an Iterable.
*/
function map(fnMap) {
	return (i) => map$1(i, fnMap);
}
function scan(fnReduce, initValue) {
	return (i) => scan$1(i, fnReduce, initValue);
}
function all(fn) {
	return (i) => all$1(i, fn);
}
function any(fn) {
	return (i) => any$1(i, fn);
}
function count() {
	return (i) => count$1(i);
}
function first(fn, defaultValue) {
	return (i) => first$1(i, fn, defaultValue);
}
function forEach(fn) {
	return (i) => forEach$1(i, fn);
}
function max$2(selector) {
	return (i) => max$1(i, selector);
}
function min(selector) {
	return (i) => min$1(i, selector);
}
function reduce(fnReduce, initialValue) {
	return (i) => reduce$1(i, fnReduce, initialValue);
}
function reduceAsync(fnReduceAsync, initialValue) {
	return (i) => reduceAsync$1(i, fnReduceAsync, initialValue);
}
function pipe(...fns) {
	return (i) => {
		for (const fn of fns) i = fn ? fn(i) : i;
		return i;
	};
}
var ImplSequence = class ImplSequence {
	i;
	_iterator;
	constructor(i) {
		this.i = i;
	}
	get iter() {
		return typeof this.i === "function" ? this.i() : this.i;
	}
	get iterator() {
		if (!this._iterator) this._iterator = this.iter[Symbol.iterator]();
		return this._iterator;
	}
	inject(fn) {
		const iter = this.i;
		return () => fn(typeof iter === "function" ? iter() : iter);
	}
	chain(fn) {
		return new ImplSequence(this.inject(fn));
	}
	[Symbol.iterator]() {
		return this.iter[Symbol.iterator]();
	}
	next() {
		return this.iterator.next();
	}
	filter(fnFilter) {
		return this.chain(filter(fnFilter));
	}
	skip(n) {
		return this.chain(skip$2(n));
	}
	take(n) {
		return this.chain(take(n));
	}
	concat(j) {
		return this.chain(concat(j));
	}
	concatMap(fn) {
		return this.chain(concatMap(fn));
	}
	combine(fn, j) {
		return this.chain(combine$2(fn, j));
	}
	map(fn) {
		return this.chain(map(fn));
	}
	scan(fnReduce, initValue) {
		return this.chain(scan(fnReduce, initValue));
	}
	pipe(...fns) {
		if (!fns.length) return this;
		return this.chain(pipe.apply(null, fns));
	}
	all(fnFilter) {
		return all(fnFilter)(this.iter);
	}
	any(fnFilter) {
		return any(fnFilter)(this.iter);
	}
	count() {
		return count()(this.iter);
	}
	first(fnFilter, defaultValue) {
		return first(fnFilter, defaultValue)(this.iter);
	}
	forEach(fn) {
		return forEach(fn)(this.iter);
	}
	max(fnSelector) {
		return max$2(fnSelector)(this.iter);
	}
	min(fnSelector) {
		return min(fnSelector)(this.iter);
	}
	reduce(fnReduce, initValue) {
		return reduce(fnReduce, initValue)(this.iter);
	}
	reduceAsync(fnReduceAsync, initialValue) {
		return reduceAsync(fnReduceAsync, initialValue)(this.iter);
	}
	reduceToSequence(fnReduce, initialValue) {
		return this.chain(reduce(fnReduce, initialValue));
	}
	toArray() {
		return [...this.iter];
	}
	toIterable() {
		return toIterableIterator$2(this.iter);
	}
};
function genSequence(i) {
	return new ImplSequence(i);
}
const EOW$3 = "*";
const DATA$4 = EOW$3;
function* toIterableIterator$1(iter) {
	yield* iter;
}
function importTrie$5(linesX) {
	let radix = 16;
	const comment = /^\s*#/;
	const iter = toIterableIterator$1(linesX);
	function parseHeaderRows(headerRows) {
		const header = headerRows.slice(0, 2).join("\n");
		const headerReg = /^TrieXv1\nbase=(\d+)$/;
		/* istanbul ignore if */
		if (!headerReg.test(header)) throw new Error("Unknown file format");
		radix = Number.parseInt(header.replace(headerReg, "$1"), 10);
	}
	function readHeader(iter) {
		const headerRows = [];
		while (true) {
			const next = iter.next();
			if (next.done) break;
			const line = next.value.trim();
			if (!line || comment.test(line)) continue;
			if (line === DATA$4) break;
			headerRows.push(line);
		}
		parseHeaderRows(headerRows);
	}
	const regNotEscapedCommas = /(^|[^\\]),/g;
	const regUnescapeCommas = /__COMMA__/g;
	const regUnescape = /[\\](.)/g;
	const flagsWord = { f: FLAG_WORD };
	function splitLine(line) {
		return line.replaceAll(regNotEscapedCommas, "$1__COMMA__").split(regUnescapeCommas).map((a) => a.replaceAll(regUnescape, "$1"));
	}
	function decodeLine(line, nodes) {
		const isWord = line[0] === EOW$3;
		line = isWord ? line.slice(1) : line;
		const flags = isWord ? flagsWord : {};
		const children = splitLine(line).filter((a) => !!a).map((a) => [a[0], Number.parseInt(a.slice(1) || "0", radix)]).map(([k, i]) => [k, nodes[i]]);
		return {
			...children.length ? { c: Object.fromEntries(children) } : {},
			...flags
		};
	}
	readHeader(iter);
	return trieNodeToRoot(genSequence([DATA$4]).concat(iter).map((a) => a.replace(/\r?\n/, "")).filter((a) => !!a).reduce((acc, line) => {
		const { lines, nodes } = acc;
		const root = decodeLine(line, nodes);
		nodes[lines] = root;
		return {
			lines: lines + 1,
			root,
			nodes
		};
	}, {
		lines: 0,
		nodes: [],
		root: {}
	}).root, {});
}
const EOW$2 = "*";
const DATA$3 = "__DATA__";
function* toIterableIterator(iter) {
	yield* iter;
}
function importTrie$4(linesX) {
	let radix = 16;
	const comment = /^\s*#/;
	const iter = toIterableIterator(linesX);
	function parseHeaderRows(headerRows) {
		const header = headerRows.slice(0, 2).join("\n");
		const headerReg = /^TrieXv2\nbase=(\d+)$/;
		/* istanbul ignore if */
		if (!headerReg.test(header)) throw new Error("Unknown file format");
		radix = Number.parseInt(header.replace(headerReg, "$1"), 10);
	}
	function readHeader(iter) {
		const headerRows = [];
		while (true) {
			const next = iter.next();
			if (next.done) break;
			const line = next.value.trim();
			if (!line || comment.test(line)) continue;
			if (line === DATA$3) break;
			headerRows.push(line);
		}
		parseHeaderRows(headerRows);
	}
	function parseLine(line, base) {
		const isWord = line[1] === EOW$2;
		const refOffset = isWord ? 2 : 1;
		const refs = line.slice(refOffset).split(",").filter((a) => !!a).map((r) => Number.parseInt(r, base));
		return {
			letter: line[0],
			isWord,
			refs
		};
	}
	const flagsWord = { f: FLAG_WORD };
	function decodeLine(line, nodes) {
		const { letter, isWord, refs } = parseLine(line, radix);
		const flags = isWord ? flagsWord : {};
		const children = refs.map((r) => nodes[r]).sort((a, b) => a.s < b.s ? -1 : 1).map((n) => [n.s, n]);
		return {
			s: letter,
			...children.length ? { c: Object.fromEntries(children) } : {},
			...flags
		};
	}
	readHeader(iter);
	return trieNodeToRoot(genSequence(iter).map((a) => a.replace(/\r?\n/, "")).filter((a) => !!a).reduce((acc, line) => {
		const { nodes } = acc;
		const root = decodeLine(line, nodes);
		nodes.push(root);
		return {
			root,
			nodes
		};
	}, {
		nodes: [],
		root: {
			s: "",
			c: Object.create(null)
		}
	}).root, {});
}
/** End of word */
const EOW$1 = "$";
/** Move up the tree */
const BACK = "<";
/** End of Line (ignored) */
const EOL$1 = "\n";
/** Line Feed (ignored) */
const LF = "\r";
/** Start of Absolute Reference */
const REF = "#";
/** Start indexed of Reference  */
const REF_REL = "@";
/** End of Reference */
const EOR = ";";
/** Escape the next character */
const ESCAPE = "\\";
/**
* Trie file format v4
*
* Trie format v4 is very similar to v3. The v4 reader can even read v3 files.
* The motivation behind v4 is to reduce the cost of storing `.trie` files in git.
* When a word is added in v3, nearly the entire file is changed due to the absolute
* references. V4 adds an index sorted by the most frequently used reference to the least.
* Because git diff is line based, it is important to add line breaks at logical points.
* V3 added line breaks just to make sure the lines were not too long, V4 takes a different
* approach. Line breaks are added at two distinct points. First, at the start of each two
* letter prefix and second after approximately 50 words have been emitted.
*
* To improve readability and git diff, at the beginning of each two letter prefix,
* a comment is emitted.
*
* Example:
*
* ```
* /* ab */
* ```
*/
const REF_INDEX_BEGIN = "[";
const REF_INDEX_END = "]";
const INLINE_DATA_COMMENT_LINE = "/";
const specialCharacters$1 = stringToCharSet$2([
	EOW$1,
	BACK,
	EOL$1,
	REF,
	REF_REL,
	EOR,
	ESCAPE,
	LF,
	REF_INDEX_BEGIN,
	REF_INDEX_END,
	INLINE_DATA_COMMENT_LINE,
	..."0123456789",
	..."`~!@#$%^&*()_-+=[]{};:'\"<>,./?\\|"
].join(""));
const SPECIAL_CHARACTERS_MAP = [
	["\n", "\\n"],
	["\r", "\\r"],
	["\\", "\\\\"]
];
const specialCharacterMap$2 = stringToCharMap(SPECIAL_CHARACTERS_MAP);
const characterMap$1 = stringToCharMap(SPECIAL_CHARACTERS_MAP.map((a) => [a[1], a[0]]));
const specialPrefix$1 = stringToCharSet$2("~!");
const DATA$2 = "__DATA__";
function importTrie$3(linesX) {
	linesX = typeof linesX === "string" ? linesX.split(/^/m) : linesX;
	let radix = 10;
	const comment = /^\s*#/;
	const iter = tapIterable(pipeSync(linesX, opConcatMapSync((a) => a.split(/^/m))));
	function parseHeaderRows(headerRows) {
		const header = headerRows.slice(0, 2).join("\n");
		const headerReg = /^TrieXv[34]\nbase=(\d+)$/;
		/* istanbul ignore if */
		if (!headerReg.test(header)) throw new Error("Unknown file format");
		radix = Number.parseInt(header.replace(headerReg, "$1"), 10);
	}
	function readHeader(iter) {
		const headerRows = [];
		for (const value of iter) {
			const line = value.trim();
			if (!line || comment.test(line)) continue;
			if (line === DATA$2) break;
			headerRows.push(line);
		}
		parseHeaderRows(headerRows);
	}
	readHeader(iter);
	return parseStream$1(radix, iter);
}
const numbersSet = stringToCharSet$2("0123456789");
function parseStream$1(radix, iter) {
	const eow = Object.freeze({ f: 1 });
	let refIndex = [];
	const root = trieNodeToRoot({}, {});
	function parseReference(acc, s) {
		const isIndexRef = s === REF_REL;
		let ref = "";
		function parser(acc, s) {
			if (s === EOR || radix === 10 && !(s in numbersSet)) {
				const { root, nodes, stack } = acc;
				const r = Number.parseInt(ref, radix);
				const top = stack[stack.length - 1];
				const p = stack[stack.length - 2].node;
				const n = isIndexRef ? refIndex[r] : r;
				p.c && (p.c[top.s] = nodes[n]);
				const rr = {
					root,
					nodes,
					stack,
					parser: void 0
				};
				return s === EOR ? rr : parserMain(rr, s);
			}
			ref = ref + s;
			return acc;
		}
		const { nodes } = acc;
		nodes.pop();
		return {
			...acc,
			nodes,
			parser
		};
	}
	function parseEscapeCharacter(acc, _) {
		let prev = "";
		const parser = function(acc, s) {
			if (prev) {
				s = characterMap$1[prev + s] || s;
				return parseCharacter({
					...acc,
					parser: void 0
				}, s);
			}
			if (s === ESCAPE) {
				prev = s;
				return acc;
			}
			return parseCharacter({
				...acc,
				parser: void 0
			}, s);
		};
		return {
			...acc,
			parser
		};
	}
	function parseComment(acc, s) {
		const endOfComment = s;
		let isEscaped = false;
		function parser(acc, s) {
			if (isEscaped) {
				isEscaped = false;
				return acc;
			}
			if (s === ESCAPE) {
				isEscaped = true;
				return acc;
			}
			if (s === endOfComment) return {
				...acc,
				parser: void 0
			};
			return acc;
		}
		return {
			...acc,
			parser
		};
	}
	function parseCharacter(acc, s) {
		const parser = void 0;
		const { root, nodes, stack } = acc;
		const node = stack[stack.length - 1].node;
		const c = node.c ?? Object.create(null);
		const n = {
			f: void 0,
			c: void 0,
			n: nodes.length
		};
		c[s] = n;
		node.c = c;
		stack.push({
			node: n,
			s
		});
		nodes.push(n);
		return {
			root,
			nodes,
			stack,
			parser
		};
	}
	function parseEOW(acc, _) {
		const parser = parseBack;
		const { root, nodes, stack } = acc;
		const top = stack[stack.length - 1];
		const node = top.node;
		node.f = FLAG_WORD;
		if (!node.c) {
			top.node = eow;
			const p = stack[stack.length - 2].node;
			p.c && (p.c[top.s] = eow);
			nodes.pop();
		}
		stack.pop();
		return {
			root,
			nodes,
			stack,
			parser
		};
	}
	const charactersBack = stringToCharSet$2(BACK + "23456789");
	function parseBack(acc, s) {
		if (!(s in charactersBack)) return parserMain({
			...acc,
			parser: void 0
		}, s);
		let n = s === BACK ? 1 : Number.parseInt(s, 10) - 1;
		const { stack } = acc;
		while (n-- > 0) stack.pop();
		return {
			...acc,
			parser: parseBack
		};
	}
	function parseIgnore(acc, _) {
		return acc;
	}
	const parsers = createStringLookupMap([
		[EOW$1, parseEOW],
		[BACK, parseBack],
		[REF, parseReference],
		[REF_REL, parseReference],
		[ESCAPE, parseEscapeCharacter],
		[EOL$1, parseIgnore],
		[LF, parseIgnore],
		[INLINE_DATA_COMMENT_LINE, parseComment]
	]);
	function parserMain(acc, s) {
		return (acc.parser ?? parsers[s] ?? parseCharacter)(acc, s);
	}
	const charsetSpaces = stringToCharSet$2(" \r\n	");
	function parseReferenceIndex(acc, s) {
		let json = "";
		function parserStart(acc, s) {
			if (s === REF_INDEX_BEGIN) {
				json = json + s;
				return {
					...acc,
					parser
				};
			}
			if (s in charsetSpaces) return acc;
			return parserMain({
				...acc,
				parser: void 0
			}, s);
		}
		function parser(acc, s) {
			json = json + s;
			if (s === REF_INDEX_END) {
				refIndex = json.replaceAll(/[\s[\]]/g, "").split(",").map((n) => Number.parseInt(n, radix));
				return {
					...acc,
					parser: void 0
				};
			}
			return acc;
		}
		return parserStart({
			...acc,
			parser: parserStart
		}, s);
	}
	reduceSync(pipeSync(iter, opConcatMapSync((a) => [...a])), parserMain, {
		nodes: [root],
		root,
		stack: [{
			node: root,
			s: ""
		}],
		parser: parseReferenceIndex
	});
	return root;
}
function stringToCharSet$2(values) {
	const set = Object.create(null);
	const len = values.length;
	for (let i = 0; i < len; ++i) set[values[i]] = true;
	return set;
}
function stringToCharMap(values) {
	return createStringLookupMap(values);
}
function createStringLookupMap(values) {
	const map = Object.create(null);
	const len = values.length;
	for (let i = 0; i < len; ++i) map[values[i][0]] = values[i][1];
	return map;
}
/**
* Allows an iterable to be shared by multiple consumers.
* Each consumer takes from the iterable.
* @param iterable - the iterable to share
*/
function tapIterable(iterable) {
	let lastValue;
	let iter;
	function getNext() {
		if (lastValue && lastValue.done) return { ...lastValue };
		iter = iter || iterable[Symbol.iterator]();
		lastValue = iter.next();
		return lastValue;
	}
	function* iterableFn() {
		let next;
		while (!(next = getNext()).done) yield next.value;
	}
	return { [Symbol.iterator]: iterableFn };
}
const EOW = Object.freeze({
	f: 1,
	k: true
});
const compare$2 = new Intl.Collator().compare;
const specialCharacterMap$1 = new Map([
	["\n", "\\n"],
	["\r", "\\r"],
	["\\", "\\\\"]
]);
const characterMap = new Map([...specialCharacterMap$1].map((a) => [a[1], a[0]]));
const DATA$1 = "__DATA__";
function importTrieV3WithBuilder(builder, srcLines) {
	const timerStart = measurePerf$1("importTrieV3");
	const dataLines = typeof srcLines === "string" ? srcLines.split("\n") : Array.isArray(srcLines) ? srcLines : [...srcLines];
	let radix = 16;
	const comment = /^\s*#/;
	function parseHeaderRows(headerRows) {
		const header = headerRows.slice(0, 2).join("\n");
		const headerReg = /^TrieXv3\nbase=(\d+)$/;
		/* istanbul ignore if */
		if (!headerReg.test(header)) throw new Error("Unknown file format");
		radix = Number.parseInt(header.replace(headerReg, "$1"), 10);
	}
	function findStartOfData(data) {
		for (let i = 0; i < data.length; ++i) if (data[i].includes(DATA$1)) return i;
		return -1;
	}
	function readHeader(data) {
		const headerRows = [];
		for (const hLine of data) {
			const line = hLine.trim();
			if (!line || comment.test(line)) continue;
			if (line === DATA$1) break;
			headerRows.push(line);
		}
		parseHeaderRows(headerRows);
	}
	const startOfData = findStartOfData(dataLines);
	if (startOfData < 0) throw new Error("Unknown file format");
	readHeader(dataLines.slice(0, startOfData));
	let node = {
		cursor: builder.getCursor(),
		parser: void 0
	};
	const parser = parseStream(radix);
	const timerParse = measurePerf$1("importTrieV3.parse");
	for (let i = startOfData + 1; i < dataLines.length; ++i) {
		const line = dataLines[i];
		for (const c of line) node = parser(node, c);
	}
	timerParse();
	timerStart();
	return builder.build();
}
function parseStream(radix) {
	function parseReference(acc, _) {
		let ref = "";
		function parser(acc, s) {
			if (s === EOR) {
				const { cursor } = acc;
				const r = Number.parseInt(ref, radix);
				cursor.reference(r + 1);
				acc.parser = void 0;
				return acc;
			}
			ref = ref + s;
			return acc;
		}
		acc.parser = parser;
		return acc;
	}
	function parseEscapeCharacter(acc, _) {
		let prev = "";
		const parser = function(acc, s) {
			if (prev) {
				s = characterMap.get(prev + s) || s;
				acc.parser = void 0;
				return parseCharacter(acc, s);
			}
			if (s === ESCAPE) {
				prev = s;
				return acc;
			}
			acc.parser = void 0;
			return parseCharacter(acc, s);
		};
		acc.parser = parser;
		return acc;
	}
	function parseCharacter(acc, s) {
		acc.cursor.insertChar(s);
		acc.parser = void 0;
		return acc;
	}
	function parseEOW(acc, _) {
		acc.parser = parseBack;
		acc.cursor.markEOW();
		acc.cursor.backStep(1);
		return acc;
	}
	const charactersBack = stringToCharSet$1(BACK + "23456789");
	function parseBack(acc, s) {
		if (!(s in charactersBack)) {
			acc.parser = void 0;
			return parserMain(acc, s);
		}
		const n = s === BACK ? 1 : Number.parseInt(s, 10) - 1;
		acc.cursor.backStep(n);
		acc.parser = parseBack;
		return acc;
	}
	function parseIgnore(acc, _) {
		return acc;
	}
	const parsers = new Map([
		[EOW$1, parseEOW],
		[BACK, parseBack],
		[REF, parseReference],
		[ESCAPE, parseEscapeCharacter],
		[EOL$1, parseIgnore],
		[LF, parseIgnore]
	]);
	function parserMain(acc, s) {
		return (acc.parser ?? parsers.get(s) ?? parseCharacter)(acc, s);
	}
	return parserMain;
}
function stringToCharSet$1(values) {
	const set = Object.create(null);
	const len = values.length;
	for (let i = 0; i < len; ++i) set[values[i]] = true;
	return set;
}
function importTrieV3AsTrieBlob(srcLines) {
	return importTrieV3WithBuilder(new TrieBlobBuilder(), srcLines);
}
function decodeTrieData(raw) {
	if (typeof raw === "string") return decodeStringFormat(raw);
	const data = toUint8Array$1(raw);
	if (isBTrieData(data)) return decodeBTrie(data);
	return decodeStringFormat(new TextDecoder().decode(data));
}
function decodeStringFormat(data) {
	return importTrie$2(data);
}
const deserializers$1 = [
	(data) => new TrieNodeTrie(importTrie$5(data)),
	(data) => new TrieNodeTrie(importTrie$5(data)),
	(data) => new TrieNodeTrie(importTrie$4(data)),
	(data) => importTrieV3AsTrieBlob(data),
	(data) => new TrieNodeTrie(importTrie$3(data))
];
const headerReg$1 = /^\s*TrieXv(\d+)/m;
function importTrie$2(input) {
	const lines = Array.isArray(input) ? input : typeof input === "string" ? input.split("\n") : [...input];
	function parseHeaderRows(headerRows) {
		for (let i = 0; i < headerRows.length; ++i) {
			const match = headerRows[i].match(headerReg$1);
			if (match) return Number.parseInt(match[1], 10);
		}
		throw new Error("Unknown file format");
	}
	function readHeader(iter) {
		const headerRows = [];
		for (const entry of iter) {
			const line = entry.trim();
			headerRows.push(line);
			if (line === DATA$4 || line === DATA$3) break;
		}
		return headerRows;
	}
	const version = parseHeaderRows(readHeader(lines));
	const method = deserializers$1[version];
	if (!method) throw new Error(`Unsupported version: ${version}`);
	return method(lines);
}
function decodeTrie(raw) {
	const endPerf = measurePerf$1("decodeTrie");
	const t = new ITrieImpl(decodeTrieData(raw));
	endPerf();
	return t;
}
const specialCharacters = stringToCharSet([
	EOW$1,
	BACK,
	EOL$1,
	REF,
	EOR,
	ESCAPE,
	LF,
	"0123456789",
	"`~!@#$%^&*()_-+=[]{};:'\"<>,./?\\|"
].join(""));
const specialPrefix = stringToCharSet("~!");
function stringToCharSet(values) {
	const set = Object.create(null);
	const len = values.length;
	for (let i = 0; i < len; ++i) set[values[i]] = true;
	return set;
}
const codes$1 = [
	["af", "Afrikaans"],
	[
		"af-NA",
		"Afrikaans",
		"Namibia"
	],
	[
		"af-ZA",
		"Afrikaans",
		"South Africa"
	],
	["ak", "Akan"],
	[
		"ak-GH",
		"Akan",
		"Ghana"
	],
	["am", "Amharic"],
	[
		"am-ET",
		"Amharic",
		"Ethiopia"
	],
	["ar", "Arabic"],
	["ar-1", "Arabic"],
	[
		"ar-AE",
		"Arabic",
		"United Arab Emirates"
	],
	[
		"ar-BH",
		"Arabic",
		"Bahrain"
	],
	[
		"ar-DJ",
		"Arabic",
		"Djibouti"
	],
	[
		"ar-DZ",
		"Arabic",
		"Algeria"
	],
	[
		"ar-EG",
		"Arabic",
		"Egypt"
	],
	["ar-EH", "Arabic"],
	[
		"ar-ER",
		"Arabic",
		"Eritrea"
	],
	[
		"ar-IL",
		"Arabic",
		"Israel"
	],
	[
		"ar-IQ",
		"Arabic",
		"Iraq"
	],
	[
		"ar-JO",
		"Arabic",
		"Jordan"
	],
	[
		"ar-KM",
		"Arabic",
		"Comoros"
	],
	[
		"ar-KW",
		"Arabic",
		"Kuwait"
	],
	[
		"ar-LB",
		"Arabic",
		"Lebanon"
	],
	[
		"ar-LY",
		"Arabic",
		"Libya"
	],
	[
		"ar-MA",
		"Arabic",
		"Morocco"
	],
	[
		"ar-MR",
		"Arabic",
		"Mauritania"
	],
	[
		"ar-OM",
		"Arabic",
		"Oman"
	],
	["ar-PS", "Arabic"],
	[
		"ar-QA",
		"Arabic",
		"Qatar"
	],
	[
		"ar-SA",
		"Arabic",
		"Saudi Arabia"
	],
	[
		"ar-SD",
		"Arabic",
		"Sudan"
	],
	[
		"ar-SO",
		"Arabic",
		"Somalia"
	],
	["ar-SS", "Arabic"],
	[
		"ar-SY",
		"Arabic",
		"Syria"
	],
	[
		"ar-TD",
		"Arabic",
		"Chad"
	],
	[
		"ar-TN",
		"Arabic",
		"Tunisia"
	],
	[
		"ar-YE",
		"Arabic",
		"Yemen"
	],
	["as", "Assamese"],
	[
		"as-IN",
		"Assamese",
		"India"
	],
	["az", "Azerbaijani"],
	[
		"az-AZ",
		"Azerbaijani",
		"Azerbaijan"
	],
	["be", "Belarusian"],
	[
		"be-BY",
		"Belarusian",
		"Belarus"
	],
	["bg", "Bulgarian"],
	[
		"bg-BG",
		"Bulgarian",
		"Bulgaria"
	],
	["bm", "Bambara"],
	[
		"bm-ML",
		"Bambara",
		"Mali"
	],
	["bn", "Bengali"],
	[
		"bn-BD",
		"Bengali",
		"Bangladesh"
	],
	[
		"bn-IN",
		"Bengali",
		"India"
	],
	["bo", "Tibetan"],
	[
		"bo-CN",
		"Tibetan",
		"China"
	],
	[
		"bo-IN",
		"Tibetan",
		"India"
	],
	["br", "Breton"],
	[
		"br-FR",
		"Breton",
		"France"
	],
	["bs", "Bosnian"],
	[
		"bs-BA",
		"Bosnian",
		"Bosnia and Herzegovina"
	],
	["ca", "Catalan"],
	[
		"ca-AD",
		"Catalan",
		"Andorra"
	],
	[
		"ca-ES",
		"Catalan",
		"Spain"
	],
	[
		"ca-FR",
		"Catalan",
		"France"
	],
	[
		"ca-IT",
		"Catalan",
		"Italy"
	],
	["ce", "Chechen"],
	[
		"ce-RU",
		"Chechen",
		"Russia"
	],
	["cs", "Czech"],
	[
		"cs-CZ",
		"Czech",
		"Czech Republic"
	],
	["cu", "Old Slavonic"],
	[
		"cu-RU",
		"Old Slavonic",
		"Russia"
	],
	["cy", "Welsh"],
	[
		"cy-GB",
		"Welsh",
		"United Kingdom"
	],
	["da", "Danish"],
	[
		"da-DK",
		"Danish",
		"Denmark"
	],
	[
		"da-GL",
		"Danish",
		"Greenland"
	],
	["de", "German"],
	[
		"de-AT",
		"German",
		"Austria"
	],
	[
		"de-BE",
		"German",
		"Belgium"
	],
	[
		"de-CH",
		"German",
		"Switzerland"
	],
	[
		"de-DE",
		"German",
		"Germany"
	],
	[
		"de-IT",
		"German",
		"Italy"
	],
	[
		"de-LI",
		"German",
		"Liechtenstein"
	],
	[
		"de-LU",
		"German",
		"Luxembourg"
	],
	["dz", "Dzongkha"],
	[
		"dz-BT",
		"Dzongkha",
		"Bhutan"
	],
	["ee", "Ewe"],
	[
		"ee-GH",
		"Ewe",
		"Ghana"
	],
	[
		"ee-TG",
		"Ewe",
		"Togo"
	],
	[
		"el",
		"Greek",
		"Modern (1453-)"
	],
	[
		"el-CY",
		"Greek",
		"Cyprus"
	],
	[
		"el-GR",
		"Greek",
		"Greece"
	],
	["en", "English"],
	[
		"en-AG",
		"English",
		"Antigua and Barbuda"
	],
	[
		"en-AI",
		"English",
		"Anguilla"
	],
	[
		"en-AS",
		"English",
		"American Samoa"
	],
	[
		"en-AT",
		"English",
		"Austria"
	],
	[
		"en-AU",
		"English",
		"Australia"
	],
	[
		"en-BB",
		"English",
		"Barbados"
	],
	[
		"en-BE",
		"English",
		"Belgium"
	],
	[
		"en-BI",
		"English",
		"Burundi"
	],
	[
		"en-BM",
		"English",
		"Bermuda"
	],
	[
		"en-BS",
		"English",
		"Bahamas"
	],
	[
		"en-BW",
		"English",
		"Botswana"
	],
	[
		"en-BZ",
		"English",
		"Belize"
	],
	[
		"en-CA",
		"English",
		"Canada"
	],
	[
		"en-CC",
		"English",
		"Cocos (Keeling) Islands"
	],
	[
		"en-CH",
		"English",
		"Switzerland"
	],
	[
		"en-CK",
		"English",
		"Cook Islands"
	],
	[
		"en-CM",
		"English",
		"Cameroon"
	],
	[
		"en-CX",
		"English",
		"Christmas Island"
	],
	[
		"en-CY",
		"English",
		"Cyprus"
	],
	[
		"en-DE",
		"English",
		"Germany"
	],
	["en-DG", "English"],
	[
		"en-DK",
		"English",
		"Denmark"
	],
	[
		"en-DM",
		"English",
		"Dominica"
	],
	[
		"en-ER",
		"English",
		"Eritrea"
	],
	[
		"en-FI",
		"English",
		"Finland"
	],
	[
		"en-FJ",
		"English",
		"Fiji"
	],
	[
		"en-FK",
		"English",
		"Falkland Islands (Islas Malvinas)"
	],
	[
		"en-FM",
		"English",
		"Micronesia"
	],
	[
		"en-GB",
		"English",
		"United Kingdom"
	],
	[
		"en-GD",
		"English",
		"Grenada"
	],
	[
		"en-GG",
		"English",
		"Guernsey"
	],
	[
		"en-GH",
		"English",
		"Ghana"
	],
	[
		"en-GI",
		"English",
		"Gibraltar"
	],
	[
		"en-GM",
		"English",
		"Gambia"
	],
	[
		"en-GU",
		"English",
		"Guam"
	],
	[
		"en-GY",
		"English",
		"Guyana"
	],
	[
		"en-HK",
		"English",
		"Hong Kong"
	],
	[
		"en-IE",
		"English",
		"Ireland"
	],
	[
		"en-IL",
		"English",
		"Israel"
	],
	[
		"en-IM",
		"English",
		"Isle of Man"
	],
	[
		"en-IN",
		"English",
		"India"
	],
	[
		"en-IO",
		"English",
		"British Indian Ocean Territory"
	],
	[
		"en-JE",
		"English",
		"Jersey"
	],
	[
		"en-JM",
		"English",
		"Jamaica"
	],
	[
		"en-KE",
		"English",
		"Kenya"
	],
	[
		"en-KI",
		"English",
		"Kiribati"
	],
	[
		"en-KN",
		"English",
		"Saint Kitts and Nevis"
	],
	[
		"en-KY",
		"English",
		"Cayman Islands"
	],
	[
		"en-LC",
		"English",
		"Saint Lucia"
	],
	[
		"en-LR",
		"English",
		"Liberia"
	],
	[
		"en-LS",
		"English",
		"Lesotho"
	],
	[
		"en-MG",
		"English",
		"Madagascar"
	],
	[
		"en-MH",
		"English",
		"Marshall Islands"
	],
	[
		"en-MO",
		"English",
		"Macau"
	],
	[
		"en-MP",
		"English",
		"Northern Mariana Islands"
	],
	[
		"en-MS",
		"English",
		"Montserrat"
	],
	[
		"en-MT",
		"English",
		"Malta"
	],
	[
		"en-MU",
		"English",
		"Mauritius"
	],
	[
		"en-MW",
		"English",
		"Malawi"
	],
	[
		"en-MY",
		"English",
		"Malaysia"
	],
	[
		"en-NA",
		"English",
		"Namibia"
	],
	[
		"en-NF",
		"English",
		"Norfolk Island"
	],
	[
		"en-NG",
		"English",
		"Nigeria"
	],
	[
		"en-NL",
		"English",
		"Netherlands"
	],
	[
		"en-NR",
		"English",
		"Nauru"
	],
	[
		"en-NU",
		"English",
		"Niue"
	],
	[
		"en-NZ",
		"English",
		"New Zealand"
	],
	[
		"en-PG",
		"English",
		"Papua New Guinea"
	],
	[
		"en-PH",
		"English",
		"Philippines"
	],
	[
		"en-PK",
		"English",
		"Pakistan"
	],
	[
		"en-PN",
		"English",
		"Pitcairn Islands"
	],
	[
		"en-PR",
		"English",
		"Puerto Rico"
	],
	[
		"en-PW",
		"English",
		"Palau"
	],
	[
		"en-RW",
		"English",
		"Rwanda"
	],
	[
		"en-SB",
		"English",
		"Solomon Islands"
	],
	[
		"en-SC",
		"English",
		"Seychelles"
	],
	[
		"en-SD",
		"English",
		"Sudan"
	],
	[
		"en-SE",
		"English",
		"Sweden"
	],
	[
		"en-SG",
		"English",
		"Singapore"
	],
	[
		"en-SH",
		"English",
		"Saint Helena"
	],
	[
		"en-SI",
		"English",
		"Slovenia"
	],
	[
		"en-SL",
		"English",
		"Sierra Leone"
	],
	["en-SS", "English"],
	["en-SX", "English"],
	[
		"en-SZ",
		"English",
		"Swaziland"
	],
	[
		"en-TC",
		"English",
		"Turks and Caicos Islands"
	],
	[
		"en-TK",
		"English",
		"Tokelau"
	],
	[
		"en-TO",
		"English",
		"Tonga"
	],
	[
		"en-TT",
		"English",
		"Trinidad and Tobago"
	],
	[
		"en-TV",
		"English",
		"Tuvalu"
	],
	[
		"en-TZ",
		"English",
		"Tanzania"
	],
	[
		"en-UG",
		"English",
		"Uganda"
	],
	[
		"en-UM",
		"English",
		"Baker Island"
	],
	[
		"en-US",
		"English",
		"United States"
	],
	[
		"en-VC",
		"English",
		"Saint Vincent and the Grenadines"
	],
	[
		"en-VG",
		"English",
		"British Virgin Islands"
	],
	[
		"en-VI",
		"English",
		"U.S. Virgin Islands"
	],
	[
		"en-VU",
		"English",
		"Vanuatu"
	],
	[
		"en-WS",
		"English",
		"Samoa"
	],
	[
		"en-ZA",
		"English",
		"South Africa"
	],
	[
		"en-ZM",
		"English",
		"Zambia"
	],
	[
		"en-ZW",
		"English",
		"Zimbabwe"
	],
	["eo", "Esperanto"],
	["es", "Spanish"],
	[
		"es-AR",
		"Spanish",
		"Argentina"
	],
	[
		"es-BO",
		"Spanish",
		"Bolivia"
	],
	[
		"es-BR",
		"Spanish",
		"Brazil"
	],
	[
		"es-BZ",
		"Spanish",
		"Belize"
	],
	[
		"es-CL",
		"Spanish",
		"Chile"
	],
	[
		"es-CO",
		"Spanish",
		"Colombia"
	],
	[
		"es-CR",
		"Spanish",
		"Costa Rica"
	],
	[
		"es-CU",
		"Spanish",
		"Cuba"
	],
	[
		"es-DO",
		"Spanish",
		"Dominican Republic"
	],
	["es-EA", "Spanish"],
	[
		"es-EC",
		"Spanish",
		"Ecuador"
	],
	[
		"es-ES",
		"Spanish",
		"Spain"
	],
	[
		"es-GQ",
		"Spanish",
		"Equatorial Guinea"
	],
	[
		"es-GT",
		"Spanish",
		"Guatemala"
	],
	[
		"es-HN",
		"Spanish",
		"Honduras"
	],
	["es-IC", "Spanish"],
	[
		"es-MX",
		"Spanish",
		"Mexico"
	],
	[
		"es-NI",
		"Spanish",
		"Nicaragua"
	],
	[
		"es-PA",
		"Spanish",
		"Panama"
	],
	[
		"es-PE",
		"Spanish",
		"Peru"
	],
	[
		"es-PH",
		"Spanish",
		"Philippines"
	],
	[
		"es-PR",
		"Spanish",
		"Puerto Rico"
	],
	[
		"es-PY",
		"Spanish",
		"Paraguay"
	],
	[
		"es-SV",
		"Spanish",
		"El Salvador"
	],
	[
		"es-US",
		"Spanish",
		"United States"
	],
	[
		"es-UY",
		"Spanish",
		"Uruguay"
	],
	[
		"es-VE",
		"Spanish",
		"Venezuela"
	],
	["et", "Estonian"],
	[
		"et-EE",
		"Estonian",
		"Estonia"
	],
	["eu", "Basque"],
	[
		"eu-ES",
		"Basque",
		"Spain"
	],
	["fa", "Persian"],
	[
		"fa-AF",
		"Persian",
		"Afghanistan"
	],
	[
		"fa-IR",
		"Persian",
		"Iran"
	],
	["ff", "Fulah"],
	[
		"ff-CM",
		"Fulah",
		"Cameroon"
	],
	[
		"ff-GN",
		"Fulah",
		"Guinea"
	],
	[
		"ff-MR",
		"Fulah",
		"Mauritania"
	],
	[
		"ff-SN",
		"Fulah",
		"Senegal"
	],
	["fi", "Finnish"],
	[
		"fi-FI",
		"Finnish",
		"Finland"
	],
	["fo", "Faroese"],
	[
		"fo-DK",
		"Faroese",
		"Denmark"
	],
	[
		"fo-FO",
		"Faroese",
		"Faroe Islands"
	],
	["fr", "French"],
	[
		"fr-BE",
		"French",
		"Belgium"
	],
	[
		"fr-BF",
		"French",
		"Burkina Faso"
	],
	[
		"fr-BI",
		"French",
		"Burundi"
	],
	[
		"fr-BJ",
		"French",
		"Benin"
	],
	["fr-BL", "French"],
	[
		"fr-CA",
		"French",
		"Canada"
	],
	[
		"fr-CD",
		"French",
		"Congo"
	],
	[
		"fr-CF",
		"French",
		"Central African Republic"
	],
	[
		"fr-CG",
		"French",
		"Congo"
	],
	[
		"fr-CH",
		"French",
		"Switzerland"
	],
	["fr-CI", "French, Cote d'Ivoire (Ivory Coast)"],
	[
		"fr-CM",
		"French",
		"Cameroon"
	],
	[
		"fr-DJ",
		"French",
		"Djibouti"
	],
	[
		"fr-DZ",
		"French",
		"Algeria"
	],
	[
		"fr-FR",
		"French",
		"France"
	],
	[
		"fr-GA",
		"French",
		"Gabon"
	],
	[
		"fr-GF",
		"French",
		"French Guiana"
	],
	[
		"fr-GN",
		"French",
		"Guinea"
	],
	[
		"fr-GP",
		"French",
		"Saint Barthelemy"
	],
	[
		"fr-GQ",
		"French",
		"Equatorial Guinea"
	],
	[
		"fr-HT",
		"French",
		"Haiti"
	],
	[
		"fr-KM",
		"French",
		"Comoros"
	],
	[
		"fr-LU",
		"French",
		"Luxembourg"
	],
	[
		"fr-MA",
		"French",
		"Morocco"
	],
	[
		"fr-MC",
		"French",
		"Monaco"
	],
	["fr-MF", "French"],
	[
		"fr-MG",
		"French",
		"Madagascar"
	],
	[
		"fr-ML",
		"French",
		"Mali"
	],
	[
		"fr-MQ",
		"French",
		"Martinique"
	],
	[
		"fr-MR",
		"French",
		"Mauritania"
	],
	[
		"fr-MU",
		"French",
		"Mauritius"
	],
	[
		"fr-NC",
		"French",
		"New Caledonia"
	],
	[
		"fr-NE",
		"French",
		"Niger"
	],
	[
		"fr-PF",
		"French",
		"French Polynesia"
	],
	[
		"fr-PM",
		"French",
		"Saint Pierre and Miquelon"
	],
	[
		"fr-RE",
		"French",
		"Reunion"
	],
	[
		"fr-RW",
		"French",
		"Rwanda"
	],
	[
		"fr-SC",
		"French",
		"Seychelles"
	],
	[
		"fr-SN",
		"French",
		"Senegal"
	],
	[
		"fr-SY",
		"French",
		"Syria"
	],
	[
		"fr-TD",
		"French",
		"Chad"
	],
	[
		"fr-TG",
		"French",
		"Togo"
	],
	[
		"fr-TN",
		"French",
		"Tunisia"
	],
	[
		"fr-VU",
		"French",
		"Vanuatu"
	],
	[
		"fr-WF",
		"French",
		"Wallis and Futuna"
	],
	[
		"fr-YT",
		"French",
		"Mayotte"
	],
	["fy", "Western Frisian"],
	[
		"fy-NL",
		"Western Frisian",
		"Netherlands"
	],
	["ga", "Irish"],
	[
		"ga-IE",
		"Irish",
		"Ireland"
	],
	["gd", "Gaelic"],
	[
		"gd-GB",
		"Gaelic",
		"United Kingdom"
	],
	["gl", "Galician"],
	[
		"gl-ES",
		"Galician",
		"Spain"
	],
	["gu", "Gujarati"],
	[
		"gu-IN",
		"Gujarati",
		"India"
	],
	["gv", "Manx"],
	[
		"gv-IM",
		"Manx",
		"Isle of Man"
	],
	["ha", "Hausa"],
	[
		"ha-GH",
		"Hausa",
		"Ghana"
	],
	[
		"ha-NE",
		"Hausa",
		"Niger"
	],
	[
		"ha-NG",
		"Hausa",
		"Nigeria"
	],
	["he", "Hebrew"],
	[
		"he-IL",
		"Hebrew",
		"Israel"
	],
	["hi", "Hindi"],
	[
		"hi-IN",
		"Hindi",
		"India"
	],
	["hr", "Croatian"],
	[
		"hr-BA",
		"Croatian",
		"Bosnia and Herzegovina"
	],
	[
		"hr-HR",
		"Croatian",
		"Croatia"
	],
	["hu", "Hungarian"],
	[
		"hu-HU",
		"Hungarian",
		"Hungary"
	],
	["hy", "Armenian"],
	[
		"hy-AM",
		"Armenian",
		"Armenia"
	],
	["id", "Indonesian"],
	[
		"id-ID",
		"Indonesian",
		"Indonesia"
	],
	["ig", "Igbo"],
	[
		"ig-NG",
		"Igbo",
		"Nigeria"
	],
	["ii", "Sichuan Yi"],
	[
		"ii-CN",
		"Sichuan Yi",
		"China"
	],
	["is", "Icelandic"],
	[
		"is-IS",
		"Icelandic",
		"Iceland"
	],
	["it", "Italian"],
	[
		"it-CH",
		"Italian",
		"Switzerland"
	],
	[
		"it-IT",
		"Italian",
		"Italy"
	],
	[
		"it-SM",
		"Italian",
		"San Marino"
	],
	[
		"it-VA",
		"Italian",
		"Vatican City"
	],
	["ja", "Japanese"],
	[
		"ja-JP",
		"Japanese",
		"Japan"
	],
	["ka", "Georgian"],
	[
		"ka-GE",
		"Georgian",
		"Georgia"
	],
	["ki", "Kikuyu"],
	[
		"ki-KE",
		"Kikuyu",
		"Kenya"
	],
	["kk", "Kazakh"],
	[
		"kk-KZ",
		"Kazakh",
		"Kazakhstan"
	],
	["kl", "Kalaallisut"],
	[
		"kl-GL",
		"Kalaallisut",
		"Greenland"
	],
	["km", "Central Khmer"],
	[
		"km-KH",
		"Central Khmer",
		"Cambodia"
	],
	["kn", "Kannada"],
	[
		"kn-IN",
		"Kannada",
		"India"
	],
	["ko", "Korean"],
	[
		"ko-KP",
		"Korean",
		"Korea"
	],
	[
		"ko-KR",
		"Korean",
		"Korea"
	],
	["ks", "Kashmiri"],
	[
		"ks-IN",
		"Kashmiri",
		"India"
	],
	["kw", "Cornish"],
	[
		"kw-GB",
		"Cornish",
		"United Kingdom"
	],
	["ky", "Kirghiz"],
	[
		"ky-KG",
		"Kirghiz",
		"Kyrgyzstan"
	],
	["lb", "Luxembourgish"],
	[
		"lb-LU",
		"Luxembourgish",
		"Luxembourg"
	],
	["lg", "Ganda"],
	[
		"lg-UG",
		"Ganda",
		"Uganda"
	],
	["ln", "Lingala"],
	[
		"ln-AO",
		"Lingala",
		"Angola"
	],
	[
		"ln-CD",
		"Lingala",
		"Congo"
	],
	[
		"ln-CF",
		"Lingala",
		"Central African Republic"
	],
	[
		"ln-CG",
		"Lingala",
		"Congo"
	],
	["lo", "Lao"],
	[
		"lo-LA",
		"Lao",
		"Laos"
	],
	["lt", "Lithuanian"],
	[
		"lt-LT",
		"Lithuanian",
		"Lithuania"
	],
	["lu", "Luba-Katanga"],
	[
		"lu-CD",
		"Luba-Katanga",
		"Congo"
	],
	["lv", "Latvian"],
	[
		"lv-LV",
		"Latvian",
		"Latvia"
	],
	["mg", "Malagasy"],
	[
		"mg-MG",
		"Malagasy",
		"Madagascar"
	],
	["mk", "Macedonian"],
	[
		"mk-MK",
		"Macedonian",
		"Macedonia"
	],
	["ml", "Malayalam"],
	[
		"ml-IN",
		"Malayalam",
		"India"
	],
	["mn", "Mongolian"],
	[
		"mn-MN",
		"Mongolian",
		"Mongolia"
	],
	["mr", "Marathi"],
	[
		"mr-IN",
		"Marathi",
		"India"
	],
	["ms", "Malay"],
	[
		"ms-BN",
		"Malay",
		"Brunei"
	],
	[
		"ms-MY",
		"Malay",
		"Malaysia"
	],
	[
		"ms-SG",
		"Malay",
		"Singapore"
	],
	["mt", "Maltese"],
	[
		"mt-MT",
		"Maltese",
		"Malta"
	],
	["my", "Burmese"],
	[
		"my-MM",
		"Burmese",
		"Myanmar (Burma)"
	],
	["nb", "Bokml Norwegian"],
	[
		"nb-NO",
		"Bokml Norwegian",
		"Norway"
	],
	[
		"nb-SJ",
		"Bokml Norwegian",
		"Svalbard"
	],
	["nd", "Ndebele, North"],
	[
		"nd-ZW",
		"Ndebele, North",
		"Zimbabwe"
	],
	["ne", "Nepali"],
	[
		"ne-IN",
		"Nepali",
		"India"
	],
	[
		"ne-NP",
		"Nepali",
		"Nepal"
	],
	["nl", "Dutch"],
	[
		"nl-AW",
		"Dutch",
		"Aruba"
	],
	[
		"nl-BE",
		"Dutch",
		"Belgium"
	],
	["nl-BQ", "Dutch"],
	["nl-CW", "Dutch"],
	[
		"nl-NL",
		"Dutch",
		"Netherlands"
	],
	[
		"nl-SR",
		"Dutch",
		"Suriname"
	],
	["nl-SX", "Dutch"],
	["nn", "Norwegian Nynorsk"],
	[
		"nn-NO",
		"Norwegian Nynorsk",
		"Norway"
	],
	["om", "Oromo"],
	[
		"om-ET",
		"Oromo",
		"Ethiopia"
	],
	[
		"om-KE",
		"Oromo",
		"Kenya"
	],
	["or", "Oriya"],
	[
		"or-IN",
		"Oriya",
		"India"
	],
	["os", "Ossetian"],
	[
		"os-GE",
		"Ossetian",
		"Georgia"
	],
	[
		"os-RU",
		"Ossetian",
		"Russia"
	],
	["pa", "Panjabi"],
	[
		"pa-IN",
		"Panjabi",
		"India"
	],
	[
		"pa-PK",
		"Panjabi",
		"Pakistan"
	],
	["pl", "Polish"],
	[
		"pl-PL",
		"Polish",
		"Poland"
	],
	["ps", "Pushto"],
	[
		"ps-AF",
		"Pushto",
		"Afghanistan"
	],
	["pt", "Portuguese"],
	[
		"pt-AO",
		"Portuguese",
		"Angola"
	],
	[
		"pt-BR",
		"Portuguese",
		"Brazil"
	],
	[
		"pt-CH",
		"Portuguese",
		"Switzerland"
	],
	[
		"pt-CV",
		"Portuguese",
		"Cape Verde"
	],
	[
		"pt-GQ",
		"Portuguese",
		"Equatorial Guinea"
	],
	[
		"pt-GW",
		"Portuguese",
		"Guinea-Bissau"
	],
	[
		"pt-LU",
		"Portuguese",
		"Luxembourg"
	],
	[
		"pt-MO",
		"Portuguese",
		"Macau"
	],
	[
		"pt-MZ",
		"Portuguese",
		"Mozambique"
	],
	[
		"pt-PT",
		"Portuguese",
		"Portugal"
	],
	[
		"pt-ST",
		"Portuguese",
		"Sao Tome and Principe"
	],
	[
		"pt-TL",
		"Portuguese",
		"Timor-Leste (East Timor)"
	],
	["qu", "Quechua"],
	[
		"qu-BO",
		"Quechua",
		"Bolivia"
	],
	[
		"qu-EC",
		"Quechua",
		"Ecuador"
	],
	[
		"qu-PE",
		"Quechua",
		"Peru"
	],
	["rm", "Romansh"],
	[
		"rm-CH",
		"Romansh",
		"Switzerland"
	],
	["rn", "Rundi"],
	[
		"rn-BI",
		"Rundi",
		"Burundi"
	],
	["ro", "Romanian"],
	[
		"ro-MD",
		"Romanian",
		"Moldova"
	],
	[
		"ro-RO",
		"Romanian",
		"Romania"
	],
	["ru", "Russian"],
	[
		"ru-BY",
		"Russian",
		"Belarus"
	],
	[
		"ru-KG",
		"Russian",
		"Kyrgyzstan"
	],
	[
		"ru-KZ",
		"Russian",
		"Kazakhstan"
	],
	[
		"ru-MD",
		"Russian",
		"Moldova"
	],
	[
		"ru-RU",
		"Russian",
		"Russia"
	],
	[
		"ru-UA",
		"Russian",
		"Ukraine"
	],
	["rw", "Kinyarwanda"],
	[
		"rw-RW",
		"Kinyarwanda",
		"Rwanda"
	],
	["se", "Northern Sami"],
	[
		"se-FI",
		"Northern Sami",
		"Finland"
	],
	[
		"se-NO",
		"Northern Sami",
		"Norway"
	],
	[
		"se-SE",
		"Northern Sami",
		"Sweden"
	],
	["sg", "Sango"],
	[
		"sg-CF",
		"Sango",
		"Central African Republic"
	],
	["si", "Sinhala"],
	[
		"si-LK",
		"Sinhala",
		"Sri Lanka"
	],
	["sk", "Slovak"],
	[
		"sk-SK",
		"Slovak",
		"Slovakia"
	],
	["sl", "Slovenian"],
	[
		"sl-SI",
		"Slovenian",
		"Slovenia"
	],
	["sn", "Shona"],
	[
		"sn-ZW",
		"Shona",
		"Zimbabwe"
	],
	["so", "Somali"],
	[
		"so-DJ",
		"Somali",
		"Djibouti"
	],
	[
		"so-ET",
		"Somali",
		"Ethiopia"
	],
	[
		"so-KE",
		"Somali",
		"Kenya"
	],
	[
		"so-SO",
		"Somali",
		"Somalia"
	],
	["sq", "Albanian"],
	[
		"sq-AL",
		"Albanian",
		"Albania"
	],
	[
		"sq-MK",
		"Albanian",
		"Macedonia"
	],
	["sq-XK", "Albanian"],
	["sr", "Serbian"],
	[
		"sr-BA",
		"Serbian",
		"Bosnia and Herzegovina"
	],
	[
		"sr-ME",
		"Serbian",
		"Montenegro"
	],
	[
		"sr-RS",
		"Serbian",
		"Serbia"
	],
	["sr-XK", "Serbian"],
	["sv", "Swedish"],
	[
		"sv-AX",
		"Swedish",
		"Aland"
	],
	[
		"sv-FI",
		"Swedish",
		"Finland"
	],
	[
		"sv-SE",
		"Swedish",
		"Sweden"
	],
	["sw", "Swahili"],
	[
		"sw-CD",
		"Swahili",
		"Congo"
	],
	[
		"sw-KE",
		"Swahili",
		"Kenya"
	],
	[
		"sw-TZ",
		"Swahili",
		"Tanzania"
	],
	[
		"sw-UG",
		"Swahili",
		"Uganda"
	],
	["ta", "Tamil"],
	[
		"ta-IN",
		"Tamil",
		"India"
	],
	[
		"ta-LK",
		"Tamil",
		"Sri Lanka"
	],
	[
		"ta-MY",
		"Tamil",
		"Malaysia"
	],
	[
		"ta-SG",
		"Tamil",
		"Singapore"
	],
	["te", "Telugu"],
	[
		"te-IN",
		"Telugu",
		"India"
	],
	["th", "Thai"],
	[
		"th-TH",
		"Thai",
		"Thailand"
	],
	["ti", "Tigrinya"],
	[
		"ti-ER",
		"Tigrinya",
		"Eritrea"
	],
	[
		"ti-ET",
		"Tigrinya",
		"Ethiopia"
	],
	["tk", "Turkmen"],
	[
		"tk-TM",
		"Turkmen",
		"Turkmenistan"
	],
	["to", "Tonga (Tonga Islands)"],
	[
		"to-TO",
		"Tonga (Tonga Islands)",
		"Tonga"
	],
	["tr", "Turkish"],
	[
		"tr-CY",
		"Turkish",
		"Cyprus"
	],
	[
		"tr-TR",
		"Turkish",
		"Turkey"
	],
	["ug", "Uighur"],
	[
		"ug-CN",
		"Uighur",
		"China"
	],
	["uk", "Ukrainian"],
	[
		"uk-UA",
		"Ukrainian",
		"Ukraine"
	],
	["ur", "Urdu"],
	[
		"ur-IN",
		"Urdu",
		"India"
	],
	[
		"ur-PK",
		"Urdu",
		"Pakistan"
	],
	["uz", "Uzbek"],
	[
		"uz-AF",
		"Uzbek",
		"Afghanistan"
	],
	[
		"uz-UZ",
		"Uzbek",
		"Uzbekistan"
	],
	["vi", "Vietnamese"],
	[
		"vi-VN",
		"Vietnamese",
		"Vietnam"
	],
	["vo", "Volapk"],
	["yi", "Yiddish"],
	["yi-1", "Yiddish"],
	["yo", "Yoruba"],
	[
		"yo-BJ",
		"Yoruba",
		"Benin"
	],
	[
		"yo-NG",
		"Yoruba",
		"Nigeria"
	],
	["zh", "Chinese"],
	[
		"zh-CN",
		"Chinese",
		"China"
	],
	[
		"zh-HK",
		"Chinese",
		"Hong Kong"
	],
	[
		"zh-MO",
		"Chinese",
		"Macau"
	],
	[
		"zh-SG",
		"Chinese",
		"Singapore"
	],
	[
		"zh-TW",
		"Chinese",
		"China"
	],
	["zu", "Zulu"],
	[
		"zu-ZA",
		"Zulu",
		"South Africa"
	]
];
let codesByLocale;
var Locale = class {
	_raw;
	_locale;
	constructor(locale) {
		this._raw = locale;
		this._locale = normalizeLocale$1(locale);
	}
	get locale() {
		return this._locale;
	}
	localInfo() {
		return lookupLocaleInfo(this._locale);
	}
	isValid() {
		return isStandardLocale(this._locale);
	}
	toJSON() {
		return this.locale;
	}
	toString() {
		return this.locale;
	}
};
const regExTwoLetter = /^[a-z]{2}$/i;
const regExLocaleWithCountry = /^([a-z]{2})[_-]?([a-z]{2,3})$/i;
const regExValidLocale = /^([a-z]{2})(?:-([A-Z]{2,3}))?$/;
/**
* Attempt to normalize a locale.
* @param locale a locale string
*/
function normalizeLocale$1(locale) {
	locale = locale.trim();
	if (regExTwoLetter.test(locale)) return locale.toLowerCase();
	const m = locale.match(regExLocaleWithCountry);
	if (!m) return locale;
	return `${m[1].toLowerCase()}-${m[2].toUpperCase()}`;
}
function isStandardLocale(locale) {
	return regExValidLocale.test(locale);
}
function lookupLocaleInfo(locale) {
	codesByLocale = codesByLocale || buildLocaleLookup();
	return codesByLocale.get(locale);
}
function buildLocaleLookup() {
	const info = codes$1.map(([locale, language, country]) => ({
		locale,
		language,
		country
	}));
	return new Map(info.map((i) => [i.locale, i]));
}
function createLocale(locale) {
	return new Locale(locale);
}
function parseLocale$1(locales) {
	locales = typeof locales === "string" ? locales.split(",") : locales;
	return locales.map(createLocale);
}
const defaultEditCosts = {
	accentCosts: 1,
	baseCost: 100,
	capsCosts: 1,
	firstLetterPenalty: 4,
	nonAlphabetCosts: 110
};
const defaultHunspellCosts = {
	...defaultEditCosts,
	ioConvertCost: 30,
	keyboardCost: 99,
	mapCost: 25,
	replaceCosts: 75,
	tryCharCost: 100
};
function mapHunspellCosts(costs = {}) {
	return {
		...defaultHunspellCosts,
		...cleanCopy(costs)
	};
}
function mapEditCosts(costs = {}) {
	return {
		...defaultEditCosts,
		...cleanCopy(costs)
	};
}
/**
* Bring letters / strings together.
* - `['a', 'b'] => 'ab'`
* - `['a', 'bc'] => 'a(bc)'`
* @param letters - letters to join
*/
function joinLetters(letters) {
	return [...letters].map((a) => a.length > 1 || !a.length ? `(${a})` : a).join("");
}
function parseAlphabet(cs, locale, editCost) {
	const { cost, penalty } = cs;
	const alphabet = joinLetters([...pipeSync([...pipeSync(expandCharacterSet(cs.characters), opMapSync((c) => caseForms(c, locale).sort()))], opFlattenSync(), opMapSync((letter) => accentForms(letter)), opFlattenSync(), opUniqueSync())].sort());
	return [
		clean$1$1({
			map: alphabet,
			replace: cost,
			insDel: cost,
			swap: cost,
			penalty
		}),
		parseAlphabetCaps(cs.characters, locale, editCost),
		...calcCostsForAccentedLetters(alphabet, locale, editCost)
	];
}
function parseAlphabetCaps(alphabet, locale, editCost) {
	return {
		map: [...pipeSync(expandCharacterSet(alphabet), opMapSync((c) => caseForms(c, locale).sort()))].map((a) => joinLetters(a)).join("|"),
		replace: editCost.capsCosts
	};
}
function calcFirstCharacterReplaceDefs(alphabets, editCost) {
	return alphabets.map((cs) => calcFirstCharacterReplace(cs, editCost));
}
function calcFirstCharacterReplace(cs, editCost) {
	const mapOfFirstLetters = [...pipeSync(expandCharacterSet(cs.characters), opUniqueSync(), opMapSync((letter) => `(^${letter})`))].sort().join("") + "(^)";
	const penalty = editCost.firstLetterPenalty;
	return {
		map: mapOfFirstLetters,
		replace: cs.cost - penalty,
		penalty: penalty * 2
	};
}
function parseAccents(cs, _editCost) {
	const { cost, penalty } = cs;
	const accents = joinLetters([...pipeSync(expandCharacterSet(cs.characters), opMapSync((char) => stripNonAccents(char)))]);
	if (!accents) return void 0;
	return clean$1$1({
		map: accents,
		replace: cost,
		insDel: cost,
		penalty
	});
}
function calcCostsForAccentedLetters(simpleMap, locale, costs) {
	const charactersWithAccents = [...pipeSync(splitMap(simpleMap), opMapSync((char) => caseForms(char, locale)), opFlattenSync(), opMapSync((char) => [...accentForms(char)]), opFilterSync((forms) => forms.length > 1))];
	const replaceAccentMap = [...pipeSync(charactersWithAccents, opMapSync((forms) => new Set([...forms, ...forms.map((char) => stripAccents(char))])), opMapSync((forms) => [...forms].sort()), opFilterSync((forms) => forms.length > 1), opMapSync(joinLetters), opUniqueSync())].join("|");
	const cost = costs.accentCosts;
	const costToReplaceAccent = !replaceAccentMap ? [] : [{
		map: replaceAccentMap,
		replace: cost
	}];
	const normalizeMap = charactersWithAccents.map((a) => a.sort()).map(joinLetters).join("|");
	const costToNormalizeAccent = !normalizeMap ? [] : [{
		map: normalizeMap,
		replace: 0
	}];
	return [...costToReplaceAccent, ...costToNormalizeAccent];
}
/**
* Splits a simple map string into its parts.
* - `abc` => `a`, `b`, `c`
* - `a(bc)` => `a`, `bc`
* @param map - string of characters
*/
function* splitMap(map) {
	let seq = "";
	let mode = 0;
	for (const char of map) {
		if (mode && char === ")") {
			yield seq;
			mode = 0;
			continue;
		}
		if (mode) {
			seq += char;
			continue;
		}
		if (char === "(") {
			mode = 1;
			seq = "";
			continue;
		}
		yield char;
	}
}
function hunspellInformationToSuggestionCostDef(hunInfo, locales) {
	const costs = calcCosts(hunInfo.costs, locales);
	const operations = [
		affKey,
		affKeyCaps,
		affMap,
		affMapAccents,
		affMapCaps,
		affNoTry,
		affRepConv,
		affTry,
		affTryAccents,
		affTryFirstCharacterReplace
	];
	function parseAff(aff, costs) {
		const regSupportedAff = /^(?:MAP|KEY|TRY|NO-TRY|ICONV|OCONV|REP)\s/;
		const rejectAff = /^(?:MAP|KEY|TRY|ICONV|OCONV|REP)\s+\d+$/;
		return [...pipeSync(aff.split("\n").map((a) => a.replace(/#.*/, "")).map((a) => a.trim()).filter((a) => regSupportedAff.test(a)).filter((a) => !rejectAff.test(a)), opMapSync((line) => pipeSync(operations, opMapSync((fn) => fn(line, costs)), opMapSync(asArrayOf), opFlattenSync())), opFlattenSync(), opFilterSync(isDefined$1$1))];
	}
	return parseAff(hunInfo.aff, costs);
}
function calcCosts(costs = {}, locale) {
	const useLocale = locale?.length ? locale.map((loc) => loc.locale) : void 0;
	return {
		...mapHunspellCosts(costs),
		locale: useLocale
	};
}
const regExpMap = /^(?:MAP)\s+(\S+)$/;
function affMap(line, costs) {
	const m = line.match(regExpMap);
	if (!m) return void 0;
	const map = m[1];
	const cost = costs.mapCost;
	return {
		map,
		replace: cost,
		swap: cost
	};
}
const regExpTry = /^(?:TRY)\s+(\S+)$/;
function affTry(line, costs) {
	const m = line.match(regExpTry);
	if (!m) return void 0;
	const cost = costs.tryCharCost;
	const characters = m[1];
	return parseAlphabet({
		characters,
		cost
	}, costs.locale, costs);
}
function affTryFirstCharacterReplace(line, costs) {
	const m = line.match(regExpTry);
	if (!m) return void 0;
	const characters = m[1];
	const cost = costs.tryCharCost;
	return calcFirstCharacterReplace({
		characters,
		cost
	}, costs);
}
const regExpNoTry = /^NO-TRY\s+(\S+)$/;
function affNoTry(line, costs) {
	const m = line.match(regExpNoTry);
	if (!m) return void 0;
	return {
		map: m[1],
		insDel: Math.max(costs.nonAlphabetCosts - costs.tryCharCost, 0),
		penalty: costs.nonAlphabetCosts + costs.tryCharCost
	};
}
const regExpRepConv = /^(?:REP|(?:I|O)CONV)\s+(\S+)\s+(\S+)$/;
function affRepConv(line, costs) {
	const m = line.match(regExpRepConv);
	if (!m) return void 0;
	const cost = line.startsWith("REP") ? costs.replaceCosts : costs.ioConvertCost;
	const from = m[1];
	let into = m[2];
	into = into.replace(/^0$/, "");
	if (from.startsWith("^") && !into.startsWith("^")) into = "^" + into;
	if (from.endsWith("$") && !into.endsWith("$")) into = into + "$";
	return {
		map: joinLetters([from, into]),
		replace: cost
	};
}
const regExpKey = /^(?:KEY)\s+(\S+)$/;
function affKey(line, costs) {
	const m = line.match(regExpKey);
	if (!m) return void 0;
	const kbd = m[1];
	const pairs = [...splitMap(kbd)].map(reducer((p, v) => ({
		a: p.b,
		b: v
	}), {
		a: "|",
		b: "|"
	})).filter((ab) => ab.a !== "|" && ab.b !== "|").map(({ a, b }) => joinLetters([a, b]));
	const pairsUpper = pairs.map((p) => p.toLocaleUpperCase(costs.locale));
	const map = unique([...pairs, ...pairsUpper]).join("|");
	const cost = costs.keyboardCost;
	return {
		map,
		replace: cost,
		swap: cost
	};
}
function affKeyCaps(line, costs) {
	const m = line.match(regExpKey);
	if (!m) return void 0;
	return parseCaps(m[1], costs);
}
function affMapCaps(line, costs) {
	const m = line.match(regExpMap);
	if (!m) return void 0;
	return parseCaps(m[1], costs);
}
function affTryAccents(line, costs) {
	const m = line.match(regExpTry);
	if (!m) return void 0;
	return calcCostsForAccentedLetters(m[1], costs.locale, costs);
}
function affMapAccents(line, costs) {
	const m = line.match(regExpMap);
	if (!m) return void 0;
	return calcCostsForAccentedLetters(m[1], costs.locale, costs);
}
function parseCaps(value, costs) {
	const locale = costs.locale;
	const map = unique([...splitMap(value)].filter((a) => a !== "|").map((s) => caseForms(s, locale)).filter((forms) => forms.length > 1).map(joinLetters)).join("|");
	const cost = costs.capsCosts;
	if (!map) return void 0;
	return {
		map,
		replace: cost
	};
}
function reducer(fn, initialVal) {
	let acc = initialVal;
	return (val, i) => acc = fn(acc, val, i);
}
function asArrayOf(v) {
	return Array.isArray(v) ? v : [v];
}
function mapDictionaryInformation(dictInfo) {
	const _locale = dictInfo.locale;
	const locale = _locale ? parseLocale$1(_locale).filter((loc) => loc.isValid()) : void 0;
	const locales = locale?.map((loc) => loc.locale);
	const costs = mapEditCosts(dictInfo.costs);
	const defsEC = dictInfo.suggestionEditCosts || [];
	const defsHI = dictInfo.hunspellInformation ? hunspellInformationToSuggestionCostDef(dictInfo.hunspellInformation, locale) : [];
	return [
		...defsEC,
		...processAlphabet(dictInfo.alphabet, locales, costs),
		...processAccents(dictInfo.accents, costs),
		...defsHI
	];
}
function processAlphabet(alphabet, locale, editCost) {
	const csAlphabet = toCharSets(alphabet, "a-zA-Z", editCost.baseCost);
	return [...pipeSync(csAlphabet, opMapSync((cs) => parseAlphabet(cs, locale, editCost)), opFlattenSync()), ...calcFirstCharacterReplaceDefs(csAlphabet, editCost)];
}
function toCharSets(cs, defaultValue, cost, penalty) {
	cs = cs ?? defaultValue;
	if (!cs) return [];
	if (typeof cs === "string") cs = [{
		characters: cs,
		cost
	}];
	if (penalty !== void 0) cs.forEach((cs) => cs.penalty = penalty);
	return cs;
}
function processAccents(accents, editCost) {
	return toCharSets(accents, "-", editCost.accentCosts).map((cs) => parseAccents(cs, editCost)).filter(isDefined$1$1);
}
function mapDictionaryInformationToAdjustment(dictInfo) {
	if (!dictInfo.adjustments) return [];
	return dictInfo.adjustments.map(mapAdjustment);
}
function mapAdjustment(adj) {
	const { id, regexp, penalty } = adj;
	return {
		id,
		regexp: new RegExp(regexp),
		penalty
	};
}
const defaultDefs = [{
	map: "1234567890-.",
	insDel: 1,
	penalty: 200
}];
const defaultAdjustments = [
	{
		id: "compound-case-change",
		regexp: /\p{Ll}\p{Lu}/gu,
		penalty: 1e3
	},
	{
		id: "short-compounds-1",
		regexp: /^[^]{0,2}(?=)|[^]{0,2}(?=|$)/gm,
		penalty: 100
	},
	{
		id: "short-compounds-3",
		regexp: /^[^]{3}(?=)|[^]{3}(?=|$)/gm,
		penalty: 50
	}
];
function mapDictionaryInformationToWeightMap(dictInfo) {
	const defs = [...mapDictionaryInformation(dictInfo), ...defaultDefs];
	const adjustments = mapDictionaryInformationToAdjustment(dictInfo);
	const map = createWeightMap(...defs);
	addAdjustment(map, ...defaultAdjustments, ...adjustments);
	return map;
}
const baseCost = opCosts.baseCost;
const postSwapCost = opCosts.swapCost - baseCost;
const mapSubCost = opCosts.visuallySimilar;
const maxCostScale = opCosts.wordLengthCostFactor;
/**
* Normalize word unicode.
* @param text - text to normalize
* @returns returns a word normalized to `NFC`
*/
const normalizeWord = (text) => text.normalize();
/**
* generate case insensitive forms of a word
* @param text - text to convert
* @returns the forms of the word.
*/
const normalizeWordForCaseInsensitive = (text) => {
	const t = text.toLowerCase();
	return [t, t.normalize("NFD").replaceAll(/\p{M}/gu, "")];
};
const BATCH_SIZE = 0;
const _defaultOptions = {
	commentCharacter: LINE_COMMENT,
	optionalCompoundCharacter: OPTIONAL_COMPOUND_FIX,
	compoundCharacter: COMPOUND_FIX,
	forbiddenPrefix: FORBID_PREFIX,
	caseInsensitivePrefix: CASE_INSENSITIVE_PREFIX,
	keepExactPrefix: IDENTITY_PREFIX,
	stripCaseAndAccents: true,
	stripCaseAndAccentsKeepDuplicate: false,
	stripCaseAndAccentsOnForbidden: false,
	split: false,
	splitKeepBoth: false,
	splitSeparator: /[\s,;]/g,
	keepOptionalCompoundCharacter: false,
	suggestionPrefix: SUGGESTION_PREFIX,
	disableSuggestionHandling: false,
	makeWordsForbidden: false
};
Object.freeze(_defaultOptions);
const cSpellToolDirective = "cspell-dictionary:";
/**
* Normalizes a dictionary words based upon prefix / suffixes.
* Case insensitive versions are also generated.
* @param options - defines prefixes used when parsing lines.
* @returns words that have been normalized.
*/
function createDictionaryLineParserMapper(options) {
	const _options = options || _defaultOptions;
	const { commentCharacter = _defaultOptions.commentCharacter, optionalCompoundCharacter: optionalCompound = _defaultOptions.optionalCompoundCharacter, compoundCharacter: compound = _defaultOptions.compoundCharacter, caseInsensitivePrefix: ignoreCase = _defaultOptions.caseInsensitivePrefix, forbiddenPrefix: forbidden = _defaultOptions.forbiddenPrefix, keepExactPrefix: keepCase = _defaultOptions.keepExactPrefix, splitSeparator = _defaultOptions.splitSeparator, splitKeepBoth = _defaultOptions.splitKeepBoth, stripCaseAndAccentsKeepDuplicate = _defaultOptions.stripCaseAndAccentsKeepDuplicate, stripCaseAndAccentsOnForbidden = _defaultOptions.stripCaseAndAccentsOnForbidden, keepOptionalCompoundCharacter = _defaultOptions.keepOptionalCompoundCharacter, makeWordsForbidden = _defaultOptions.makeWordsForbidden } = _options;
	let { stripCaseAndAccents = !makeWordsForbidden && _defaultOptions.stripCaseAndAccents, split = _defaultOptions.split, suggestionPrefix = _defaultOptions.suggestionPrefix } = _options;
	const disableSuggestionHandling = _options.disableSuggestionHandling || [
		"",
		" ",
		"	",
		"\0"
	].includes(suggestionPrefix);
	if (disableSuggestionHandling) suggestionPrefix = SUGGESTIONS_DISABLED;
	function isString(line) {
		return typeof line === "string";
	}
	function trim(line) {
		return line.trim();
	}
	function removeComments(line) {
		const idx = line.indexOf(commentCharacter);
		if (idx < 0) return line;
		const idxDirective = line.indexOf(cSpellToolDirective, idx);
		if (idxDirective >= 0) {
			const flags = line.slice(idxDirective).split(/[\s,;]/g).map((s) => s.trim()).filter((a) => !!a);
			for (const flag of flags) switch (flag) {
				case "split":
					split = true;
					break;
				case "no-split":
					split = false;
					break;
				case "no-generate-alternatives":
					stripCaseAndAccents = false;
					break;
				case "generate-alternatives":
					stripCaseAndAccents = true;
					break;
			}
		}
		return line.slice(0, idx).trim();
	}
	function filterEmptyLines(line) {
		return !!line;
	}
	function* mapOptionalPrefix(line) {
		if (line[0] === optionalCompound) {
			const t = line.slice(1);
			yield t;
			yield compound + t;
		} else yield line;
	}
	function* mapOptionalSuffix(line) {
		if (line.slice(-1) === optionalCompound) {
			const t = line.slice(0, -1);
			yield t;
			yield t + compound;
		} else yield line;
	}
	const doNotNormalizePrefix = Object.create(null);
	[
		ignoreCase,
		keepCase,
		"\""
	].forEach((prefix) => doNotNormalizePrefix[prefix] = true);
	if (!stripCaseAndAccentsOnForbidden) doNotNormalizePrefix[forbidden] = true;
	function removeDoublePrefix(w) {
		return w.startsWith(ignoreCase + ignoreCase) ? w.slice(1) : w;
	}
	function stripKeepCasePrefixAndQuotes(word) {
		word = word.replaceAll(/"(.*?)"/g, "$1");
		return word[0] === keepCase ? word.slice(1) : word;
	}
	function _normalize(word) {
		return normalizeWord(stripKeepCasePrefixAndQuotes(word));
	}
	function* handleForbiddenPrefix(words) {
		if (!makeWordsForbidden) {
			yield* words;
			return;
		}
		const f = forbidden;
		const ff = f + f;
		const sug = suggestionPrefix;
		for (const word of words) {
			if (word.startsWith(sug)) {
				yield word;
				continue;
			}
			yield (f + word).replaceAll(ff, "");
		}
	}
	function* mapNormalize(word) {
		const nWord = _normalize(word);
		const forms = /* @__PURE__ */ new Set();
		forms.add(nWord);
		if (stripCaseAndAccents && !(word[0] in doNotNormalizePrefix)) for (const n of normalizeWordForCaseInsensitive(nWord)) (stripCaseAndAccentsKeepDuplicate || n !== nWord) && forms.add(ignoreCase + n);
		yield* forms;
	}
	function* splitWords(lines) {
		for (const line of lines) {
			if (split) {
				yield* splitLine(line.includes("\"") ? line.replaceAll(/".*?"/g, (quoted) => " " + quoted.replaceAll(/(\s)/g, "\\$1") + " ") : line, splitSeparator).map((escaped) => escaped.replaceAll("\\", ""));
				if (!splitKeepBoth) continue;
			}
			yield line;
		}
	}
	function* splitLines(paragraphs) {
		for (const paragraph of paragraphs) yield* paragraph.split("\n");
	}
	/**
	* Handle suggestion lines.
	* `:` is the default suggestions prefix.
	*
	* The format can be:
	* - `:word:suggestion1` # word with a single preferred suggestion (note: it is only a suggestion.)
	* - `:word : suggestion1` # word with a single preferred suggestion (space will be removed).
	* - `:word:suggestion1,suggestion2` # word with multiple preferred suggestions
	* - `:word -> suggestion1, suggestion2` # word with multiple preferred suggestions (alternate format)
	* - `:word:suggestion1,suggestion2` # this is purely a suggestion entry.
	* - `!word:suggestion1,suggestion2` # forbidden word with suggestions.
	* - `word:suggestion1,suggestion2` # normal word with suggestions, the word is included in the dictionary.
	*
	* They are stored in the dictionary with the following format:
	*   `<prefix><word><suggestionPrefix><index><suggestionPrefix><suggestion>`
	*
	*
	* Example forbidden word with suggestions:
	* - `!word` the word itself
	* - `!word:0:first_suggestion` the word itself
	* - `!word:1:second_suggestion` the word itself
	* @param lines
	*/
	function* handleSuggestions(lines) {
		if (disableSuggestionHandling) {
			yield* lines;
			return;
		}
		for (const line of lines) yield* handleSuggestion(line);
	}
	const r = /^\s*(?<prefix>[!:~]*)(?<word>.*?)(?:->|:([0-9a-f]{1,2}:)?)(?<suggestions>.*)$/;
	const suggestionSequence = /* @__PURE__ */ new Map();
	const knownSuggestions = /* @__PURE__ */ new Set();
	function addSuggestion(word, suggestion) {
		const p = suggestionPrefix;
		const pp = p + p;
		const n = suggestionSequence.get(word) || 0;
		const k = word + pp + suggestion;
		if (knownSuggestions.has(k)) return;
		knownSuggestions.add(k);
		suggestionSequence.set(word, n + 1);
		return k.replace(pp, p + n.toString(16) + p);
	}
	function* handleSuggestion(line) {
		const hasAltFormat = line.includes("->");
		if (!line.includes(":") && !hasAltFormat) {
			yield line;
			return;
		}
		const m = line.match(r);
		if (!m || !m.groups) {
			yield line;
			return;
		}
		const prefix = m.groups["prefix"] || "";
		const word = (m.groups["word"] || "").trim();
		const suggestions = (m.groups["suggestions"] || "").split(",").map((s) => s.trim()).filter((s) => !!s);
		if (!prefix.includes(":")) yield prefix + word;
		const ww = ":" + word;
		yield ww;
		for (let i = 0; i < suggestions.length; i++) {
			const sug = addSuggestion(ww, suggestions[i]);
			if (sug) yield sug;
		}
	}
	const mapCompounds = keepOptionalCompoundCharacter ? [] : [opConcatMapSync(mapOptionalPrefix), opConcatMapSync(mapOptionalSuffix)];
	const optionalOperators = [];
	if (options?.sortBatchSize) optionalOperators.push(createBatchAndSortLines(options.sortBatchSize));
	return opCombineSync(opFilterSync(isString), splitLines, opMapSync(removeComments), splitWords, opMapSync(trim), opFilterSync(filterEmptyLines), handleSuggestions, ...mapCompounds, opConcatMapSync(mapNormalize), handleForbiddenPrefix, opMapSync(removeDoublePrefix), ...optionalOperators);
}
/**
* Normalizes a dictionary words based upon prefix / suffixes.
* Case insensitive versions are also generated.
* @param lines - one word per line
* @param _options - defines prefixes used when parsing lines.
* @returns words that have been normalized.
*/
function parseDictionaryLines(lines, options) {
	return createDictionaryLineParserMapper(options)(typeof lines === "string" ? [lines] : lines);
}
function parseLinesToDictionary(lines, options) {
	const endPerf = measurePerf$1("parseLinesToDictionary");
	const dictLines = parseDictionaryLines(lines, mergeOptions(_defaultOptions, options));
	const words = [...new Set(dictLines)].sort();
	const { optimize, useStringTable } = options || {};
	const t = buildITrieFromWords(words, trieInfoFromOptions(options), {
		optimize,
		useStringTable
	});
	endPerf();
	return t;
}
function parseDictionary(text, options) {
	return parseLinesToDictionary(typeof text === "string" ? text.split("\n") : text, options);
}
function trieInfoFromOptions(options) {
	const info = extractTrieInfo(options);
	const sugPrefix = info.suggestionPrefix ?? SUGGESTION_PREFIX;
	if (options?.disableSuggestionHandling || sugPrefix !== SUGGESTION_PREFIX) info.suggestionPrefix = SUGGESTIONS_DISABLED;
	return info;
}
function mergeOptions(base, ...partials) {
	const opt = { ...base };
	for (const p of partials) {
		if (!p) continue;
		Object.assign(opt, p);
	}
	return opt;
}
const RegExpToEncode = /\\([\s,;])/g;
const RegExpDecode = /<<(%[\da-f]{2})>>/gi;
function encodeLine(line) {
	return line.replaceAll(RegExpToEncode, (_, v) => "<<" + encodeURIComponent(v) + ">>");
}
function decodeLine(line) {
	return line.replaceAll(RegExpDecode, (_, v) => "\\" + decodeURIComponent(v));
}
function splitLine(line, regExp) {
	return encodeLine(line).split(regExp).map((line) => decodeLine(line));
}
function createBatchAndSortLines(batchSize = BATCH_SIZE) {
	if (batchSize <= 1) return (s) => s;
	function* batchAndSortLines(lines) {
		const maxSize = batchSize;
		const batch = Array(maxSize);
		let i = 0;
		for (const line of lines) {
			batch[i++] = line;
			if (i >= maxSize) {
				batch.sort();
				yield* batch;
				i = 0;
			}
		}
		batch.length = i;
		batch.sort();
		yield* batch;
	}
	return batchAndSortLines;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/text.js
const regExAllUpper = /^(?:\p{Lu}\p{M}?)+$/u;
const regExAccents = /\p{M}/gu;
function isUpperCase(word) {
	return !!regExAllUpper.test(word);
}
function ucFirst(word) {
	return word.slice(0, 1).toUpperCase() + word.slice(1);
}
function removeAccents(text) {
	return text.normalize("NFD").replaceAll(regExAccents, "");
}
function removeUnboundAccents(text) {
	return text.replaceAll(regExAccents, "");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/SpellingDictionaryMethods.js
const defaultNumSuggestions = 10;
function wordSearchForms(word, isDictionaryCaseSensitive, ignoreCase) {
	const forms = /* @__PURE__ */ new Set();
	word = word.normalize("NFC");
	const wordLc = word.toLowerCase();
	if (ignoreCase) if (isDictionaryCaseSensitive) forms.add(wordLc);
	else {
		forms.add(wordLc);
		forms.add(removeUnboundAccents(wordLc));
	}
	else if (isDictionaryCaseSensitive) {
		forms.add(word);
		forms.add(wordLc);
		if (isUpperCase(word)) forms.add(ucFirst(wordLc));
	} else {
		forms.add(wordLc);
		forms.add(removeUnboundAccents(wordLc));
	}
	return forms;
}
function wordSuggestForms(word) {
	word = word.normalize("NFC");
	const forms = new Set([word]);
	const wordLc = word.toLowerCase();
	forms.add(wordLc);
	return forms;
}
const DEFAULT_HAS_OPTIONS = Object.freeze({});
function hasOptionToSearchOption(opt) {
	return canonicalSearchOptions(!opt ? DEFAULT_HAS_OPTIONS : opt);
}
const canonicalSearchOptionsMap = /* @__PURE__ */ new Map();
const knownCanonicalOptions = /* @__PURE__ */ new WeakMap();
/**
* Find the canonical form for SearchOptions. Useful Maps and WeakMaps.
* @param opt - options to normalize
* @returns SearchOptions - the canonical form
*/
function canonicalSearchOptions(opt) {
	const known = knownCanonicalOptions.get(opt);
	if (known) return known;
	const { ignoreCase, useCompounds } = opt;
	const foundLevel1Map = canonicalSearchOptionsMap.get(ignoreCase);
	const useLevel1Map = foundLevel1Map || /* @__PURE__ */ new Map();
	if (!foundLevel1Map) canonicalSearchOptionsMap.set(ignoreCase, useLevel1Map);
	const foundCanOpts = useLevel1Map.get(useCompounds);
	const canOpts = foundCanOpts || Object.freeze({
		ignoreCase,
		useCompounds
	});
	if (!foundCanOpts) useLevel1Map.set(useCompounds, canOpts);
	knownCanonicalOptions.set(opt, canOpts);
	return canOpts;
}
function createWeightMapFromDictionaryInformation(di) {
	return di ? mapDictionaryInformationToWeightMap(di) : void 0;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/CachingDictionary.js
let dictionaryCounter = 0;
const DefaultAutoCacheSize = 1e3;
let logRequests = false;
const log$1 = [];
const startTime = performance.now();
var CachedDict = class {
	dict;
	options;
	name;
	id = ++dictionaryCounter;
	has;
	#has;
	constructor(dict, options) {
		this.dict = dict;
		this.options = options;
		this.name = dict.name;
		const has = autoCache((word) => this.dict.has(word, this.options), DefaultAutoCacheSize);
		const hasAndLog = (word) => {
			const time = performance.now() - startTime;
			const misses = has.misses;
			const value = has(word);
			if (logRequests) {
				const miss = has.misses > misses;
				log$1.push({
					time,
					method: "has",
					word,
					value,
					miss
				});
			}
			return value;
		};
		this.#has = has;
		this.has = logRequests ? hasAndLog : has;
	}
	isNoSuggestWord = autoCache((word) => this.dict.isNoSuggestWord(word, this.options), DefaultAutoCacheSize);
	isForbidden = autoCache((word) => this.dict.isForbidden(word), DefaultAutoCacheSize);
	getPreferredSuggestions = autoCache((word) => this.dict.getPreferredSuggestions?.(word), DefaultAutoCacheSize);
	suggest = (word, suggestOptions) => this.dict.suggest(word, suggestOptions);
	stats() {
		return {
			name: this.name,
			id: this.id,
			has: extractStats(this.#has),
			isNoSuggestWord: extractStats(this.isNoSuggestWord),
			isForbidden: extractStats(this.isForbidden),
			getPreferredSuggestions: extractStats(this.getPreferredSuggestions)
		};
	}
};
const knownDicts = /* @__PURE__ */ new Map();
/**
* create a caching dictionary
* @param dict - Dictionary to cache the search results.
* @param options - Search options to use.
* @returns CachingDictionary
*/
function createCachingDictionary(dict, options) {
	options = canonicalSearchOptions(options);
	let knownOptions = knownDicts.get(options);
	if (!knownOptions) {
		knownOptions = /* @__PURE__ */ new WeakMap();
		knownDicts.set(options, knownOptions);
	}
	const known = knownOptions.get(dict);
	if (known) return known;
	const cached = new CachedDict(dict, options);
	knownOptions.set(dict, cached);
	return cached;
}
/**
* Enable or disable logging of dictionary requests. Every call to `has` will be logged.
*
* This should be set prior to creating any caching dictionaries to ensure all requests are logged.
*
* @param enabled - optional - if undefined, it will toggle the setting.
* @returns the current state of logging.
*/
function dictionaryCacheEnableLogging(enabled = !logRequests) {
	if (enabled && !logRequests) knownDicts.clear();
	logRequests = enabled;
	return logRequests;
}
/**
* Get the log of dictionary requests.
* @returns the log
*/
function dictionaryCacheGetLog() {
	return log$1;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/AutoResolve.js
function autoResolveWeak$1(map, key, resolve) {
	const found = map.get(key);
	if (found !== void 0 || map.has(key)) return found;
	const value = resolve(key);
	map.set(key, value);
	return value;
}
var AutoResolveWeakCache$1 = class {
	map = /* @__PURE__ */ new WeakMap();
	get(k, resolve) {
		return resolve ? autoResolveWeak$1(this.map, k, resolve) : this.map.get(k);
	}
	has(k) {
		return this.map.has(k);
	}
	set(k, v) {
		this.map.set(k, v);
		return this;
	}
};
function createAutoResolveWeakCache$1() {
	return new AutoResolveWeakCache$1();
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/util.js
function isDefined$4(v) {
	return v !== void 0;
}

//#endregion
//#region ../node_modules/.pnpm/fast-equals@6.0.0/node_modules/fast-equals/dist/es/index.mjs
const { getOwnPropertyNames, getOwnPropertySymbols } = Object;
const { hasOwnProperty: hasOwnProperty$2 } = Object.prototype;
/**
* Combine two comparators into a single comparators.
*/
function combineComparators(comparatorA, comparatorB) {
	return function isEqual(a, b, state) {
		return comparatorA(a, b, state) && comparatorB(a, b, state);
	};
}
/**
* Wrap the provided `areItemsEqual` method to manage the circular state, allowing
* for circular references to be safely included in the comparison without creating
* stack overflows.
*/
function createIsCircular(areItemsEqual) {
	return function isCircular(a, b, state) {
		if (!a || !b || typeof a !== "object" || typeof b !== "object") return areItemsEqual(a, b, state);
		const { cache } = state;
		const cachedA = cache.get(a);
		const cachedB = cache.get(b);
		if (cachedA && cachedB) return cachedA === b && cachedB === a;
		cache.set(a, b);
		cache.set(b, a);
		const result = areItemsEqual(a, b, state);
		cache.delete(a);
		cache.delete(b);
		return result;
	};
}
/**
* Get the properties to strictly examine, which include both own properties that are
* not enumerable and symbol properties.
*/
function getStrictProperties(object) {
	return getOwnPropertyNames(object).concat(getOwnPropertySymbols(object));
}
/**
* Whether the object contains the property passed as an own property.
*/
const hasOwn = Object.hasOwn || ((object, property) => hasOwnProperty$2.call(object, property));
const PREACT_VNODE = "__v";
const PREACT_OWNER = "__o";
const REACT_OWNER = "_owner";
const { getOwnPropertyDescriptor, keys: keys$2 } = Object;
/**
* Whether the values passed are equal based on a [SameValue](https://262.ecma-international.org/7.0/#sec-samevalue) basis.
* Simplified, this maps to if the two values are referentially equal to one another (`a === b`) or both are `NaN`.
*
* @note
* When available in the environment, this is just a re-export of the global
* [`Object.is`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is) method.
*/
const sameValueEqual = Object.is || function sameValueEqual(a, b) {
	return a === b ? a !== 0 || 1 / a === 1 / b : a !== a && b !== b;
};
/**
* Whether the values passed are equal based on a
* [Strict Equality Comparison](https://262.ecma-international.org/7.0/#sec-strict-equality-comparison) basis.
* Simplified, this maps to if the two values are referentially equal to one another (`a === b`).
*
* @note
* This is mainly available as a convenience function, such as being a default when a function to determine equality between
* two objects is used.
*/
function strictEqual(a, b) {
	return a === b;
}
/**
* Whether the array buffers are equal in value.
*/
function areArrayBuffersEqual(a, b) {
	return a.byteLength === b.byteLength && areTypedArraysEqual(new Uint8Array(a), new Uint8Array(b));
}
/**
* Whether the arrays are equal in value.
*/
function areArraysEqual(a, b, state) {
	let index = a.length;
	if (b.length !== index) return false;
	while (index-- > 0) if (!state.equals(a[index], b[index], index, index, a, b, state)) return false;
	return true;
}
/**
* Whether the dataviews are equal in value.
*/
function areDataViewsEqual(a, b) {
	return a.byteLength === b.byteLength && areTypedArraysEqual(new Uint8Array(a.buffer, a.byteOffset, a.byteLength), new Uint8Array(b.buffer, b.byteOffset, b.byteLength));
}
/**
* Whether the dates passed are equal in value.
*/
function areDatesEqual(a, b) {
	return sameValueEqual(a.getTime(), b.getTime());
}
/**
* Whether the errors passed are equal in value.
*/
function areErrorsEqual(a, b) {
	return a.name === b.name && a.message === b.message && a.cause === b.cause && a.stack === b.stack;
}
/**
* Whether the `Map`s are equal in value.
*/
function areMapsEqual(a, b, state) {
	const size = a.size;
	if (size !== b.size) return false;
	if (!size) return true;
	const matchedIndices = new Array(size);
	const aIterable = a.entries();
	let aResult;
	let bResult;
	let index = 0;
	while (aResult = aIterable.next()) {
		if (aResult.done) break;
		const bIterable = b.entries();
		let hasMatch = false;
		let matchIndex = 0;
		while (bResult = bIterable.next()) {
			if (bResult.done) break;
			if (matchedIndices[matchIndex]) {
				matchIndex++;
				continue;
			}
			const aEntry = aResult.value;
			const bEntry = bResult.value;
			if (state.equals(aEntry[0], bEntry[0], index, matchIndex, a, b, state) && state.equals(aEntry[1], bEntry[1], aEntry[0], bEntry[0], a, b, state)) {
				hasMatch = matchedIndices[matchIndex] = true;
				break;
			}
			matchIndex++;
		}
		if (!hasMatch) return false;
		index++;
	}
	return true;
}
/**
* Whether the objects are equal in value.
*/
function areObjectsEqual(a, b, state) {
	const properties = keys$2(a);
	let index = properties.length;
	if (keys$2(b).length !== index) return false;
	while (index-- > 0) if (!isPropertyEqual(a, b, state, properties[index])) return false;
	return true;
}
/**
* Whether the objects are equal in value with strict property checking.
*/
function areObjectsEqualStrict(a, b, state) {
	const properties = getStrictProperties(a);
	let index = properties.length;
	if (getStrictProperties(b).length !== index) return false;
	let property;
	let descriptorA;
	let descriptorB;
	while (index-- > 0) {
		property = properties[index];
		if (!isPropertyEqual(a, b, state, property)) return false;
		descriptorA = getOwnPropertyDescriptor(a, property);
		descriptorB = getOwnPropertyDescriptor(b, property);
		if ((descriptorA || descriptorB) && (!descriptorA || !descriptorB || descriptorA.configurable !== descriptorB.configurable || descriptorA.enumerable !== descriptorB.enumerable || descriptorA.writable !== descriptorB.writable)) return false;
	}
	return true;
}
/**
* Whether the primitive wrappers passed are equal in value.
*/
function arePrimitiveWrappersEqual(a, b) {
	return sameValueEqual(a.valueOf(), b.valueOf());
}
/**
* Whether the regexps passed are equal in value.
*/
function areRegExpsEqual(a, b) {
	return a.source === b.source && a.flags === b.flags;
}
/**
* Whether the `Set`s are equal in value.
*/
function areSetsEqual(a, b, state) {
	const size = a.size;
	if (size !== b.size) return false;
	if (!size) return true;
	const matchedIndices = new Array(size);
	const aIterable = a.values();
	let aResult;
	let bResult;
	while (aResult = aIterable.next()) {
		if (aResult.done) break;
		const bIterable = b.values();
		let hasMatch = false;
		let matchIndex = 0;
		while (bResult = bIterable.next()) {
			if (bResult.done) break;
			if (!matchedIndices[matchIndex] && state.equals(aResult.value, bResult.value, aResult.value, bResult.value, a, b, state)) {
				hasMatch = matchedIndices[matchIndex] = true;
				break;
			}
			matchIndex++;
		}
		if (!hasMatch) return false;
	}
	return true;
}
/**
* Whether the TypedArray instances are equal in value.
*/
function areTypedArraysEqual(a, b) {
	let index = a.byteLength;
	if (b.byteLength !== index || a.byteOffset !== b.byteOffset) return false;
	while (index-- > 0) if (a[index] !== b[index]) return false;
	return true;
}
/**
* Whether the URL instances are equal in value.
*/
function areUrlsEqual(a, b) {
	return a.hostname === b.hostname && a.pathname === b.pathname && a.protocol === b.protocol && a.port === b.port && a.hash === b.hash && a.username === b.username && a.password === b.password;
}
function isPropertyEqual(a, b, state, property) {
	if ((property === REACT_OWNER || property === PREACT_OWNER || property === PREACT_VNODE) && (a.$$typeof || b.$$typeof)) return true;
	return hasOwn(b, property) && state.equals(a[property], b[property], property, property, a, b, state);
}
const toString = Object.prototype.toString;
/**
* Create a comparator method based on the type-specific equality comparators passed.
*/
function createEqualityComparator(config) {
	const supportedComparatorMap = createSupportedComparatorMap(config);
	const { areArraysEqual, areDatesEqual, areFunctionsEqual, areMapsEqual, areNumbersEqual, areObjectsEqual, areRegExpsEqual, areSetsEqual, getUnsupportedCustomComparator } = config;
	/**
	* compare the value of the two objects and return true if they are equivalent in values
	*/
	return function comparator(a, b, state) {
		if (a === b) return true;
		if (a == null || b == null) return false;
		const type = typeof a;
		if (type !== typeof b) return false;
		if (type !== "object") {
			if (type === "number" || type === "bigint") return areNumbersEqual(a, b, state);
			if (type === "function") return areFunctionsEqual(a, b, state);
			return false;
		}
		const constructor = a.constructor;
		if (constructor !== b.constructor) return false;
		if (constructor === Object) return areObjectsEqual(a, b, state);
		if (constructor === Array) return areArraysEqual(a, b, state);
		if (constructor === Date) return areDatesEqual(a, b, state);
		if (constructor === RegExp) return areRegExpsEqual(a, b, state);
		if (constructor === Map) return areMapsEqual(a, b, state);
		if (constructor === Set) return areSetsEqual(a, b, state);
		if (constructor === Promise) return false;
		if (Array.isArray(a)) return areArraysEqual(a, b, state);
		const tag = toString.call(a);
		const supportedComparator = supportedComparatorMap[tag];
		if (supportedComparator) return supportedComparator(a, b, state);
		const unsupportedCustomComparator = getUnsupportedCustomComparator && getUnsupportedCustomComparator(a, b, state, tag);
		if (unsupportedCustomComparator) return unsupportedCustomComparator(a, b, state);
		return false;
	};
}
/**
* Create the configuration object used for building comparators.
*/
function createEqualityComparatorConfig({ circular, createCustomConfig, strict }) {
	let config = {
		areArrayBuffersEqual,
		areArraysEqual: strict ? areObjectsEqualStrict : areArraysEqual,
		areDataViewsEqual,
		areDatesEqual,
		areErrorsEqual,
		areFunctionsEqual: strictEqual,
		areMapsEqual: strict ? combineComparators(areMapsEqual, areObjectsEqualStrict) : areMapsEqual,
		areNumbersEqual: sameValueEqual,
		areObjectsEqual: strict ? areObjectsEqualStrict : areObjectsEqual,
		arePrimitiveWrappersEqual,
		areRegExpsEqual,
		areSetsEqual: strict ? combineComparators(areSetsEqual, areObjectsEqualStrict) : areSetsEqual,
		areTypedArraysEqual: strict ? combineComparators(areTypedArraysEqual, areObjectsEqualStrict) : areTypedArraysEqual,
		areUrlsEqual,
		getUnsupportedCustomComparator: void 0
	};
	if (createCustomConfig) config = Object.assign({}, config, createCustomConfig(config));
	if (circular) {
		const areArraysEqual = createIsCircular(config.areArraysEqual);
		const areMapsEqual = createIsCircular(config.areMapsEqual);
		const areObjectsEqual = createIsCircular(config.areObjectsEqual);
		const areSetsEqual = createIsCircular(config.areSetsEqual);
		config = Object.assign({}, config, {
			areArraysEqual,
			areMapsEqual,
			areObjectsEqual,
			areSetsEqual
		});
	}
	return config;
}
/**
* Default equality comparator pass-through, used as the standard `isEqual` creator for
* use inside the built comparator.
*/
function createInternalEqualityComparator(compare) {
	return function(a, b, _indexOrKeyA, _indexOrKeyB, _parentA, _parentB, state) {
		return compare(a, b, state);
	};
}
/**
* Create the `isEqual` function used by the consuming application.
*/
function createIsEqual({ circular, comparator, createState, equals, strict }) {
	if (createState) return function isEqual(a, b) {
		const { cache = circular ? /* @__PURE__ */ new WeakMap() : void 0, meta } = createState();
		return comparator(a, b, {
			cache,
			equals,
			meta,
			strict
		});
	};
	if (circular) return function isEqual(a, b) {
		return comparator(a, b, {
			cache: /* @__PURE__ */ new WeakMap(),
			equals,
			meta: void 0,
			strict
		});
	};
	const state = {
		cache: void 0,
		equals,
		meta: void 0,
		strict
	};
	return function isEqual(a, b) {
		return comparator(a, b, state);
	};
}
/**
* Create a map of `toString()` values to their respective handlers for `tag`-based lookups.
*/
function createSupportedComparatorMap({ areArrayBuffersEqual, areArraysEqual, areDataViewsEqual, areDatesEqual, areErrorsEqual, areFunctionsEqual, areMapsEqual, areNumbersEqual, areObjectsEqual, arePrimitiveWrappersEqual, areRegExpsEqual, areSetsEqual, areTypedArraysEqual, areUrlsEqual }) {
	return {
		"[object Arguments]": areObjectsEqual,
		"[object Array]": areArraysEqual,
		"[object ArrayBuffer]": areArrayBuffersEqual,
		"[object AsyncGeneratorFunction]": areFunctionsEqual,
		"[object BigInt]": areNumbersEqual,
		"[object BigInt64Array]": areTypedArraysEqual,
		"[object BigUint64Array]": areTypedArraysEqual,
		"[object Boolean]": arePrimitiveWrappersEqual,
		"[object DataView]": areDataViewsEqual,
		"[object Date]": areDatesEqual,
		"[object Error]": areErrorsEqual,
		"[object Float16Array]": areTypedArraysEqual,
		"[object Float32Array]": areTypedArraysEqual,
		"[object Float64Array]": areTypedArraysEqual,
		"[object Function]": areFunctionsEqual,
		"[object GeneratorFunction]": areFunctionsEqual,
		"[object Int8Array]": areTypedArraysEqual,
		"[object Int16Array]": areTypedArraysEqual,
		"[object Int32Array]": areTypedArraysEqual,
		"[object Map]": areMapsEqual,
		"[object Number]": arePrimitiveWrappersEqual,
		"[object Object]": (a, b, state) => typeof a.then !== "function" && typeof b.then !== "function" && areObjectsEqual(a, b, state),
		"[object RegExp]": areRegExpsEqual,
		"[object Set]": areSetsEqual,
		"[object String]": arePrimitiveWrappersEqual,
		"[object URL]": areUrlsEqual,
		"[object Uint8Array]": areTypedArraysEqual,
		"[object Uint8ClampedArray]": areTypedArraysEqual,
		"[object Uint16Array]": areTypedArraysEqual,
		"[object Uint32Array]": areTypedArraysEqual
	};
}
/**
* Whether the items passed are deeply-equal in value.
*/
const deepEqual = createCustomEqual();
/**
* Whether the items passed are deeply-equal in value based on strict comparison.
*/
const strictDeepEqual = createCustomEqual({ strict: true });
/**
* Whether the items passed are deeply-equal in value, including circular references.
*/
const circularDeepEqual = createCustomEqual({ circular: true });
/**
* Whether the items passed are deeply-equal in value, including circular references,
* based on strict comparison.
*/
const strictCircularDeepEqual = createCustomEqual({
	circular: true,
	strict: true
});
/**
* Whether the items passed are shallowly-equal in value.
*/
const shallowEqual = createCustomEqual({ createInternalComparator: () => sameValueEqual });
/**
* Whether the items passed are shallowly-equal in value based on strict comparison
*/
const strictShallowEqual = createCustomEqual({
	strict: true,
	createInternalComparator: () => sameValueEqual
});
/**
* Whether the items passed are shallowly-equal in value, including circular references.
*/
const circularShallowEqual = createCustomEqual({
	circular: true,
	createInternalComparator: () => sameValueEqual
});
/**
* Whether the items passed are shallowly-equal in value, including circular references,
* based on strict comparison.
*/
const strictCircularShallowEqual = createCustomEqual({
	circular: true,
	createInternalComparator: () => sameValueEqual,
	strict: true
});
/**
* Create a custom equality comparison method.
*
* This can be done to create very targeted comparisons in extreme hot-path scenarios
* where the standard methods are not performant enough, but can also be used to provide
* support for legacy environments that do not support expected features like
* `RegExp.prototype.flags` out of the box.
*/
function createCustomEqual(options = {}) {
	const { circular = false, createInternalComparator: createCustomInternalComparator, createState, strict = false } = options;
	const comparator = createEqualityComparator(createEqualityComparatorConfig(options));
	return createIsEqual({
		circular,
		comparator,
		createState,
		equals: createCustomInternalComparator ? createCustomInternalComparator(comparator) : createInternalEqualityComparator(comparator),
		strict
	});
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-performance-monitor@9.6.4/node_modules/@cspell/cspell-performance-monitor/dist/index.js
const symbolCSpell = Symbol.for("cspell");
const globalThisCSpell = globalThis;
function _measurePerfStart(name, enabled) {
	if (!enabled) return;
	performance.mark(name + "-start");
}
function _measurePerfEnd(name, enabled) {
	if (!enabled) return;
	performance.mark(name + "-end");
	performance.measure(name, name + "-start", name + "-end");
}
/**
* Creates performance marks and measures the time taken between them.
* @param name - name of the performance entry
* @returns a function to stop the timer.
*/
function measurePerf(name) {
	const enabled = isEnabledPerformanceMeasurements();
	_measurePerfStart(name, enabled);
	return makeDisposableFunction(() => {
		_measurePerfEnd(name, enabled);
	});
}
function makeDisposableFunction(fn) {
	const disposableFn = fn;
	disposableFn[Symbol.dispose] = fn;
	disposableFn[Symbol.asyncDispose] = () => (fn(), Promise.resolve());
	return disposableFn;
}
/**
* Enable or disable performance measurements.
* @param enable - true to enable, false to disable. Default is true.
*/
function enablePerformanceMeasurements(enable = true) {
	globalThisCSpell[symbolCSpell] ??= {};
	globalThisCSpell[symbolCSpell].enablePerformanceMeasurements = enable;
}
function isEnabledPerformanceMeasurements() {
	return !!globalThisCSpell[symbolCSpell]?.enablePerformanceMeasurements;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/simpleCache.js
var SimpleWeakCache = class {
	size;
	L0 = /* @__PURE__ */ new WeakMap();
	L1 = /* @__PURE__ */ new WeakMap();
	L2 = /* @__PURE__ */ new WeakMap();
	sizeL0 = 0;
	constructor(size) {
		this.size = size;
	}
	has(key) {
		for (const c of this.caches()) if (c.has(key)) return true;
		return false;
	}
	get(key) {
		for (const c of this.caches()) {
			const entry = c.get(key);
			if (entry) {
				if (c !== this.L0) this._set(key, entry);
				return entry.v;
			}
		}
	}
	set(key, value) {
		this._set(key, { v: value });
	}
	_set(key, entry) {
		if (this.L0.has(key)) {
			this.L0.set(key, entry);
			return this;
		}
		if (this.sizeL0 >= this.size) this.rotate();
		this.sizeL0 += 1;
		this.L0.set(key, entry);
	}
	caches() {
		return [
			this.L0,
			this.L1,
			this.L2
		];
	}
	rotate() {
		this.L2 = this.L1;
		this.L1 = this.L0;
		this.L0 = /* @__PURE__ */ new WeakMap();
		this.sizeL0 = 0;
	}
};
var AutoWeakCache = class extends SimpleWeakCache {
	factory;
	constructor(factory, size) {
		super(size);
		this.factory = factory;
	}
	get(key) {
		const v = super.get(key);
		if (v !== void 0) return v;
		const val = this.factory(key);
		this.set(key, val);
		return val;
	}
};
/**
* This will cache between `size` and 3 x `size` items.
* It has three stashes, L0, L1, and L2. Each can contain `size` items.
* When L0 is full, its items are given to L1 and L1's are given to L2, and L2 is empties.
*
* The stashes are searched in order, L0...L2. If an item is found in L1, or L2, it is
* promoted to L0.
*/
var SimpleCache$1 = class {
	size;
	L0 = /* @__PURE__ */ new Map();
	L1 = /* @__PURE__ */ new Map();
	L2 = /* @__PURE__ */ new Map();
	constructor(size) {
		this.size = size;
	}
	has(key) {
		for (const c of this.caches()) if (c.has(key)) return true;
		return false;
	}
	get(key) {
		for (const c of this.caches()) {
			const entry = c.get(key);
			if (entry) {
				if (c !== this.L0) this._set(key, entry);
				return entry.v;
			}
		}
	}
	set(key, value) {
		this._set(key, { v: value });
	}
	_set(key, entry) {
		if (this.L0.has(key)) {
			this.L0.set(key, entry);
			return this;
		}
		if (this.L0.size >= this.size) this.rotate();
		this.L0.set(key, entry);
	}
	caches() {
		return [
			this.L0,
			this.L1,
			this.L2
		];
	}
	rotate() {
		this.L2 = this.L1;
		this.L1 = this.L0;
		this.L0 = /* @__PURE__ */ new Map();
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/SpellingDictionary.js
const defaultOptions = Object.freeze({ weightMap: void 0 });

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/clean.js
/**
* Delete all `undefined` fields from an object.
* @param src - object to be cleaned
*/
function clean$2(src) {
	const r = src;
	for (const key of Object.keys(r)) if (r[key] === void 0) delete r[key];
	return r;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/regexHelper.js
/**
* Escape a string so it can be used as an exact match within a RegExp.
* @param s - string to escape
* @returns - the escaped string.
*/
function escapeRegEx$2(s) {
	return s.replaceAll(/[|\\{}()[\]^$+*?.]/g, "\\$&").replaceAll("-", "\\x2d");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/repMap.js
function createMapper(repMap, ignoreCharset) {
	if (!repMap && !ignoreCharset) return void 0;
	repMap = repMap || [];
	const charsetMap = charsetToRepMapRegEx(ignoreCharset);
	if (charsetMap) repMap = [...repMap, ...charsetMap];
	if (!repMap.filter(([match, _]) => !!match).length) return;
	const regEx = createMapperRegExp(repMap);
	const values = repMap.filter(([match, _]) => !!match).map(([_, into]) => into);
	function resolve(m, ...matches) {
		const index = matches.findIndex((a) => !!a);
		return 0 <= index && index < values.length ? values[index] : m;
	}
	function fn(s) {
		return s.replace(regEx, resolve);
	}
	return {
		test: regexpRemoveFlags(regEx, "gm"),
		fn
	};
}
function charsetToRepMapRegEx(charset, replaceWith = "") {
	if (!charset) return void 0;
	return charset.split("|").map((chars) => `[${chars.replaceAll(/[\][\\]/g, "\\$&")}]`).map((map) => [map, replaceWith]);
}
function charsetToRepMap(charset, replaceWith = "") {
	if (!charset) return void 0;
	return charset.split("|").flatMap((chars) => [...expandCharacterSet(chars)]).map((char) => [char, replaceWith]);
}
function expandReplaceMap(repMap) {
	return repMap.flatMap(([from, replaceWith]) => from.split("|").map((w) => [w, replaceWith]));
}
function createMapperRegExp(repMap) {
	const filteredMap = repMap.filter(([match, _]) => !!match);
	if (!filteredMap.length) return /$^/;
	const regExStr = filteredMap.map(([from, _]) => from).map((s) => {
		try {
			const r = /\(/.test(s) ? s.replaceAll(/\((?=.*\))/g, "(?:").replaceAll("(?:?", "(?") : s;
			new RegExp(r);
			s = r;
		} catch {
			return escapeRegEx$2(s);
		}
		return s;
	}).map((s) => `(${s})`).join("|");
	return new RegExp(regExStr, "g");
}
function createRepMapper(repMap, ignoreCharset) {
	if (!repMap?.length && !ignoreCharset) return void 0;
	let tRepMap = repMap || [];
	const charsetMap = charsetToRepMapRegEx(ignoreCharset);
	if (charsetMap) tRepMap = [...tRepMap, ...charsetMap];
	const regEx = createMapperRegExp(tRepMap);
	const trie = createTrie(repMap, ignoreCharset);
	return {
		test: regexpRemoveFlags(regEx, "gm"),
		fn: (word) => {
			return applyEdits(word, calcAllEdits(trie, word));
		}
	};
}
function applyEdits(word, edits) {
	if (!edits.length) return [word];
	const letterEdits = [];
	for (let i = 0; i < word.length; ++i) letterEdits[i] = {
		edits: [{
			b: i,
			e: i + 1,
			r: word[i]
		}],
		suffixes: []
	};
	letterEdits[word.length] = {
		edits: [],
		suffixes: [""]
	};
	for (const edit of edits) letterEdits[edit.b].edits.push(edit);
	for (let i = word.length - 1; i >= 0; --i) {
		const le = letterEdits[i];
		const sfx = le.suffixes;
		for (const edit of le.edits) {
			const pfx = edit.r;
			const nSfx = letterEdits[edit.e].suffixes;
			for (const s of nSfx) sfx.push(pfx + s);
		}
	}
	return [...new Set(letterEdits[0].suffixes)];
}
function calcAllEdits(root, word) {
	const edits = [];
	function walk(node, b, e) {
		if (node.rep) node.rep.forEach((r) => edits.push({
			b,
			e,
			r
		}));
		if (e === word.length || !node.children) return;
		const n = node.children[word[e]];
		if (!n) return;
		walk(n, b, e + 1);
	}
	for (let i = 0; i < word.length; ++i) walk(root, i, i);
	return edits;
}
function createTrie(repMap, ignoreCharset) {
	const expanded = expandReplaceMap([repMap, charsetToRepMap(ignoreCharset)].filter(isDefined$4).flat());
	const trieRoot = Object.create(null);
	expanded.forEach(([match, replaceWith]) => addToTrie(trieRoot, match, replaceWith));
	return trieRoot;
}
function addToTrie(node, match, replaceWith) {
	while (match) {
		const children = node.children || (node.children = Object.create(null));
		const k = match[0];
		node = children[k] || (children[k] = Object.create(null));
		match = match.slice(1);
	}
	const s = new Set(node.rep || []);
	s.add(replaceWith);
	node.rep = [...s];
}
function regexpRemoveFlags(re, flagsToRemove) {
	const toRemove = new Set(flagsToRemove);
	const flags = [...re.flags].filter((f) => !toRemove.has(f)).join("");
	return new RegExp(re.source, flags);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/defaults.js
const ignoreCase = true;
const isForbiddenIgnoreCaseAndAccents = false;

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/SpellingDictionaryFromTrie.js
var SpellingDictionaryFromTrie = class {
	trie;
	name;
	options;
	source;
	_size = 0;
	knownWords = /* @__PURE__ */ new Set();
	unknownWords = /* @__PURE__ */ new Set();
	mapWord;
	remapWord;
	repMapper;
	type = "SpellingDictionaryFromTrie";
	isDictionaryCaseSensitive;
	containsNoSuggestWords;
	#ignoreForbiddenWords = false;
	#findWordOptionsCaseSensitive = { caseSensitive: true };
	#findWordOptionsNotCaseSensitive = { caseSensitive: false };
	weightMap;
	constructor(trie, name, options, source = "from trie", size) {
		this.trie = trie;
		this.name = name;
		this.options = options;
		this.source = source;
		const mapWord = createMapper(options.repMap, options.dictionaryInformation?.ignore);
		const repMapper = createRepMapper(options.repMap, options.dictionaryInformation?.ignore);
		this.mapWord = mapWord?.fn;
		this.remapWord = repMapper?.fn;
		this.repMapper = repMapper;
		this.isDictionaryCaseSensitive = options.caseSensitive ?? true;
		this.containsNoSuggestWords = options.noSuggest || false;
		this._size = size || 0;
		this.weightMap = options.weightMap || createWeightMapFromDictionaryInformation(options.dictionaryInformation);
		this.#ignoreForbiddenWords = !!options.ignoreForbiddenWords;
		if (this.#ignoreForbiddenWords) {
			this.#findWordOptionsCaseSensitive.checkForbidden = true;
			this.#findWordOptionsNotCaseSensitive.checkForbidden = true;
		}
	}
	get size() {
		if (!this._size) {
			const i = this.trie.iterate();
			let deeper = true;
			let size = 0;
			for (let r = i.next(); !r.done; r = i.next(deeper)) {
				size += 1;
				deeper = r.value.text.length < 5;
			}
			this._size = size;
		}
		return this._size;
	}
	has(word, hasOptions) {
		const { useCompounds, ignoreCase } = this.resolveOptions(hasOptions);
		const r = this._find(word, useCompounds, ignoreCase, void 0);
		return r && !r.forbidden && !!r.found || false;
	}
	find(word, hasOptions) {
		const { useCompounds, ignoreCase } = this.resolveOptions(hasOptions);
		const r = this._find(word, useCompounds, ignoreCase, hasOptions?.compoundSeparator);
		const { forbidden = this.#isForbidden(word) } = r || {};
		if (this.#ignoreForbiddenWords && forbidden) return;
		if (!r && !forbidden) return void 0;
		const { found = forbidden ? word : false } = r || {};
		return {
			found,
			forbidden,
			noSuggest: found !== false && this.containsNoSuggestWords
		};
	}
	resolveOptions(hasOptions) {
		const { useCompounds = this.options.useCompounds, ignoreCase: ignoreCase$2 = ignoreCase } = hasOptionToSearchOption(hasOptions);
		return {
			useCompounds,
			ignoreCase: ignoreCase$2
		};
	}
	_find = (word, useCompounds, ignoreCase, compoundSeparator) => this.findAnyForm(word, useCompounds, ignoreCase, compoundSeparator);
	findAnyForm(word, useCompounds, ignoreCase, compoundSeparator) {
		const outerForms = outerWordForms(word, this.repMapper);
		for (const form of outerForms) {
			const r = this._findAnyForm(form, useCompounds, ignoreCase, compoundSeparator);
			if (r) return r;
		}
	}
	_findAnyForm(mWord, useCompounds, ignoreCase, compoundSeparator) {
		let opts = ignoreCase ? this.#findWordOptionsNotCaseSensitive : this.#findWordOptionsCaseSensitive;
		if (compoundSeparator) opts = {
			...opts,
			compoundSeparator
		};
		const findResult = this.trie.findWord(mWord, opts);
		if (findResult.found !== false) return findResult;
		const forms = wordSearchForms(mWord, this.isDictionaryCaseSensitive, ignoreCase);
		for (const w of forms) {
			const findResult = this.trie.findWord(w, opts);
			if (findResult.found !== false) return findResult;
		}
		if (useCompounds) {
			const optsUseCompounds = {
				...opts,
				useLegacyWordCompounds: useCompounds
			};
			for (const w of forms) {
				const findResult = this.trie.findWord(w, optsUseCompounds);
				if (findResult.found !== false) return findResult;
			}
		}
	}
	isNoSuggestWord(word, options) {
		return this.containsNoSuggestWords ? this.has(word, options) : false;
	}
	isForbidden(word, _ignoreCaseAndAccents) {
		return this.#ignoreForbiddenWords ? false : this.#isForbidden(word, _ignoreCaseAndAccents);
	}
	#isForbidden(word, _ignoreCaseAndAccents) {
		return this.trie.isForbiddenWord(word);
	}
	suggest(word, suggestOptions = {}) {
		return this._suggest(word, suggestOptions);
	}
	_suggest(word, suggestOptions) {
		const { numSuggestions = defaultNumSuggestions, numChanges, includeTies, ignoreCase, timeout } = suggestOptions;
		function filter(_word) {
			return true;
		}
		const collector = suggestionCollector(word, clean$2({
			numSuggestions,
			filter,
			changeLimit: numChanges,
			includeTies,
			ignoreCase,
			timeout,
			weightMap: this.weightMap
		}));
		this.genSuggestions(collector, suggestOptions);
		return collector.suggestions.map((r) => ({
			...r,
			word: r.word
		}));
	}
	genSuggestions(collector, suggestOptions) {
		if (this.options.noSuggest) return;
		const _compoundMethod = suggestOptions.compoundMethod ?? (this.options.useCompounds ? CompoundWordsMethod.JOIN_WORDS : CompoundWordsMethod.NONE);
		for (const w of wordSuggestForms(collector.word)) this.trie.genSuggestions(impersonateCollector(collector, w), _compoundMethod);
	}
	getPreferredSuggestions(word) {
		if (!this.trie.hasPreferredSuggestions) return [];
		return [...this.trie.getPreferredSuggestions(word)].map((sug, i) => ({
			word: sug,
			cost: i + 1,
			isPreferred: true
		}));
	}
	getErrors() {
		return [];
	}
};
/**
* Create a dictionary from a trie file.
* @param data - contents of a trie file.
* @param name - name of dictionary
* @param source - filename or uri
* @param options - options.
* @returns SpellingDictionary
*/
function createSpellingDictionaryFromTrieFile(data, name, source, options) {
	const endPerf = measurePerf("createSpellingDictionaryFromTrieFile");
	const d = new SpellingDictionaryFromTrie(decodeTrie(data), name, options, source);
	endPerf();
	return d;
}
const isAsciiRange = /^[\u0000-\u007F]*$/;
function* outerWordForms(word, repMapper) {
	const sent = /* @__PURE__ */ new Set();
	let w = word;
	const ww = w;
	yield w;
	if (!isAsciiRange.test(w)) {
		sent.add(w);
		w = word.normalize("NFC");
		if (w !== ww) {
			yield w;
			sent.add(w);
		}
		w = word.normalize("NFD");
		if (w !== ww && !sent.has(w)) {
			yield w;
			sent.add(w);
		}
	}
	if (!repMapper) return;
	const mapWord = repMapper.fn;
	if (!sent.size) {
		if (!repMapper.test.test(ww)) return;
		for (const m of mapWord(ww)) if (m !== ww && !sent.has(m)) {
			yield m;
			sent.add(m);
		}
		return;
	}
	for (const f of sent) for (const m of mapWord(f)) if (m !== ww && !sent.has(m)) {
		yield m;
		sent.add(m);
	}
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/createSpellingDictionary.js
const cachedDictionaries = new AutoWeakCache(_createSpellingDictionary, 64);
const maxSetSize = 3;
const cachedParamsByWordList = new SimpleCache$1(64);
/**
* Create a SpellingDictionary
* @param wordList - list of words
* @param name - name of dictionary
* @param source - filename or uri
* @param options - dictionary options
* @returns a Spelling Dictionary
*/
function createSpellingDictionary(wordList, name, source, options, disableSuggestionsHandling) {
	const params = [
		wordList,
		name,
		source.toString(),
		options,
		disableSuggestionsHandling
	];
	if (!Array.isArray(wordList)) return _createSpellingDictionary(params);
	const cached = cachedParamsByWordList.get(name) || /* @__PURE__ */ new Set();
	for (const cachedParams of cached) if (deepEqual(params, cachedParams)) return cachedDictionaries.get(cachedParams);
	if (cached.size > maxSetSize) cached.clear();
	cached.add(params);
	cachedParamsByWordList.set(name, cached);
	return cachedDictionaries.get(params);
}
function _createSpellingDictionary(params) {
	const endPerf = measurePerf("createSpellingDictionary");
	const [wordList, name, source, options, disableSuggestionHandling = false] = params;
	const trie = buildITrieFromWords(parseDictionaryLines(wordList, {
		stripCaseAndAccents: options?.supportNonStrictSearches ?? true,
		disableSuggestionHandling
	}));
	const opts = { ...options || defaultOptions };
	if (opts.weightMap === void 0 && opts.dictionaryInformation) opts.weightMap = createWeightMapFromDictionaryInformation(opts.dictionaryInformation);
	const d = new SpellingDictionaryFromTrie(trie, name, opts, source);
	endPerf();
	return d;
}
function createFailedToLoadDictionary(name, sourceUrl, error, options) {
	const sourceHref = typeof sourceUrl === "string" ? sourceUrl : sourceUrl.href;
	const source = sourceHref.startsWith("file:") ? fileURLToPath(sourceUrl) : sourceHref;
	options = options || {};
	return {
		name,
		source,
		type: "error",
		containsNoSuggestWords: false,
		has: () => false,
		find: () => void 0,
		isNoSuggestWord: () => false,
		isForbidden: () => false,
		suggest: () => [],
		mapWord: void 0,
		genSuggestions: () => {},
		size: 0,
		options,
		isDictionaryCaseSensitive: false,
		getErrors: () => [error]
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/util/textMappers.js
function* mapperRemoveCaseAndAccents(words) {
	for (const word of words) {
		const lc = word.toLowerCase();
		yield lc;
		const woAccents = removeAccents(lc);
		if (lc !== woAccents) yield woAccents;
	}
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/Typos/util.js
function normalizeTyposDefValue(value) {
	if (!value) return false;
	if (typeof value === "string") return value;
	const unique = [...new Set(value)];
	return unique.length > 1 ? unique : unique.length === 1 ? unique[0] : false;
}
function mergeDefEntry(targetDef, key, value) {
	const curValue = targetDef[key];
	if (!curValue) {
		targetDef[key] = normalizeTyposDefValue(value);
		return targetDef;
	}
	if (!value) return targetDef;
	const newValue = Array.isArray(curValue) ? curValue : [curValue];
	if (Array.isArray(value)) newValue.push(...value);
	else newValue.push(value);
	targetDef[key] = normalizeTyposDefValue(newValue);
	return targetDef;
}
/**
* Merge in place the entries `fromDef` into `targetDef`
* @param targetDef - the target
* @param fromDef - the source
* @returns the target
*/
function mergeDef(targetDef, fromDef) {
	for (const key of Object.keys(fromDef)) mergeDefEntry(targetDef, key, fromDef[key]);
	return targetDef;
}
/**
* Append an entry to a TyposDef.
* @param def - modified in place
* @param entry- entry to add.
* @returns def
*/
function appendToDef(def, entry) {
	if (!entry) return def;
	if (typeof entry === "string") {
		if (!def[entry]) def[entry] = false;
		return def;
	}
	if (Array.isArray(entry)) {
		const [key, ...sugs] = entry.map((s) => s.trim());
		if (!key) return def;
		return mergeDefEntry(def, key, sugs.map((s) => s.trim()).filter((s) => !!s));
	}
	return mergeDef(def, entry);
}
function createTyposDef(entries) {
	const def = Object.create(null);
	if (!entries) return def;
	for (const [key, value] of entries) def[key] = isDefined$3(value) ? value : false;
	return def;
}
/**
* Extract all suggestions.
* @param typosDef - the def
* @returns the set of suggestions.
*/
function extractAllSuggestions(typosDef) {
	const allSugs = pipeSync$1(Object.values(typosDef), opFilterSync$1(hasSuggestions), opConcatMapSync$1((v) => Array.isArray(v) ? v : [v]));
	return new Set(allSugs);
}
/**
* Extract all words that have been explicitly ignore because they contains the `ignorePrefix`.
* @param typosDef - the def
* @param ignorePrefix - prefix
* @returns set of ignored words with the prefix removed.
*/
function extractIgnoreValues(typosDef, ignorePrefix) {
	const pfxLen = ignorePrefix.length;
	return new Set(Object.keys(typosDef).filter((k) => k.startsWith(ignorePrefix)).map((k) => k.slice(pfxLen)));
}
function isDefined$3(v) {
	return v !== void 0 && v !== null;
}
function isString(v) {
	return typeof v === "string";
}
function isArray(v) {
	return Array.isArray(v);
}
function hasSuggestions(v) {
	return isString(v) || isArray(v);
}
function assert$2(condition, message = "Assert Failed") {
	if (condition) return;
	throw new Error(message);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/Typos/typosParser.js
function assertString(v) {
	assert$2(typeof v === "string", "A string was expected.");
	return true;
}
const suggestionsSeparator = /[,]/;
const typoEntrySeparator = /[\n;]/;
const sugFormatRegex = /^\s*(?:[!~:])*(?<word>.*?)(?<separator>(->|:([0-9a-f]{1,2}:)?))(?<sugs>.*)$/;
function normalize$1(s) {
	return s.normalize();
}
function trimAndFilter(lines) {
	return lines.map((s) => s.trim()).filter((s) => !!s).map(normalize$1);
}
function cleanSugs(rawSugs) {
	const sugs = trimAndFilter(rawSugs);
	return sugs.length === 1 ? sugs[0] : sugs.length ? sugs : false;
}
function splitSuggestionsValue(value) {
	return cleanSugs(value.split(suggestionsSeparator));
}
function sanitizeIntoTypoDef(dirtyDef) {
	if (!dirtyDef || typeof dirtyDef !== "object") return void 0;
	const def = createTyposDef();
	for (const [rawKey, value] of Object.entries(dirtyDef)) {
		const key = normalize$1(rawKey.trim());
		if (!key) continue;
		if (typeof value === "string") {
			def[key] = splitSuggestionsValue(value);
			continue;
		}
		if (Array.isArray(value)) {
			def[key] = cleanSugs(value.filter(assertString));
			continue;
		}
		assert$2(value === false, "Unexpected suggestion type.");
		def[key] = false;
	}
	return def;
}
/**
* Parse Typos Entries
*
* Format:
* - `word:suggestion`
* - `word->suggestion`
* - `word: first, second, third suggestions`
*
* Note:
* ```plaintext
* yellow:blue, green
* ```
* Is the same as multiple entries with the same key and different suggestions.
* ```plaintext
* yellow:blue
* yellow:green
* ```
*
* Used to process entries found in a `cspell.json` file.
* @param entries - entries to process
* @returns a TyposDef
*/
function processEntriesToTyposDef(entries) {
	const result = sanitizeIntoTypoDef(isIterable(entries) ? reduceToTyposDef(entries) : entries);
	assert$2(result);
	return result;
}
function reduceToTyposDef(entries) {
	const def = createTyposDef();
	for (const entry of entries) appendToDef(def, parseTyposLine(entry));
	return def;
}
/**
* Tries to parse an entry.
* @param line - any valid TypoEntry.
* @returns a valid TypoEntry
*/
function parseTyposLine(line) {
	if (!line) return void 0;
	if (typeof line === "string") {
		const def = createTyposDef();
		for (const subEntry of splitIntoLines(line)) {
			const [left, right] = splitEntry(subEntry);
			const typo = left.trim();
			if (!right) return typo;
			def[typo] = splitSuggestionsValue(right);
		}
		return def;
	}
	if (Array.isArray(line)) {
		const [key, ...sugs] = line.filter(assertString).map((s) => s.trim());
		if (!key) return void 0;
		return [key, ...sugs];
	}
	return sanitizeIntoTypoDef(line);
}
/**
* Split text into multiple lines
* @param content - text content
* @returns
*/
function splitIntoLines(content) {
	return trimAndFilter(normalize$1(content).split(typoEntrySeparator));
}
/**
* Split a typo entry into key and value
* Entry format:
* - `word:suggestion`
* - `word->suggestion`
* - `word: first, second, third suggestions`
* - sequencing values are ignored, e.g.: `:0:`, `:1:`, `:a:`
*   - `word:0:first`
*   - `word:1:second`
* @param line - the line of text
* @returns
*/
function splitEntry(line) {
	const m = line.match(sugFormatRegex);
	if (!m?.groups) return [line.trim(), void 0];
	return [m.groups.word.trim(), m.groups.sugs.trim()];
}
function isIterable(v) {
	return Symbol.iterator in v;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/TyposDictionary.js
var TyposDictionaryImpl = class {
	name;
	source;
	typosDef;
	containsNoSuggestWords;
	options = {};
	type = "typos";
	size;
	mapWord = void 0;
	ignoreWords;
	/**
	* Note: ignoreWordsLower is only suggestions with the case and accents removed.
	* The logic is that if someone explicity ignored an upper case version, it does not
	* mean that the lower case version is ok.
	*/
	suggestions;
	suggestionsLower;
	explicitIgnoreWords;
	constructor(name, source, typosDef, ignoreList) {
		this.name = name;
		this.source = source;
		this.typosDef = typosDef;
		this.size = Object.keys(typosDef).length;
		this.explicitIgnoreWords = extractIgnoreValues(typosDef, "!");
		this.suggestions = extractAllSuggestions(typosDef);
		this.ignoreWords = new Set(pipeSync$1(this.explicitIgnoreWords, opAppendSync$1(ignoreList || [])));
		this.suggestionsLower = new Set(pipeSync$1(this.suggestions, mapperRemoveCaseAndAccents));
		this.containsNoSuggestWords = this.ignoreWords.size > 0;
	}
	/**
	* A Forbidden word list does not "have" valid words.
	* Therefore it always returns false.
	* @param _word - the word
	* @param _options - options
	* @returns always false
	*/
	has(_word, _options) {
		return false;
	}
	/** A more detailed search for a word, might take longer than `has` */
	find(word, options) {
		const result = this._findForms(word, options?.ignoreCase ?? ignoreCase);
		if (result === false) return void 0;
		const { found, ignore } = result;
		return {
			found,
			forbidden: !ignore,
			noSuggest: ignore
		};
	}
	_findForms(word, ignoreCaseAndAccents) {
		const lcWord = word.toLowerCase();
		if (this.ignoreWords.has(word)) return {
			found: word,
			ignore: true
		};
		if (this.suggestions.has(word)) return false;
		if (ignoreCaseAndAccents) {
			if (this.suggestionsLower.has(lcWord)) return false;
			if (this.ignoreWords.has(lcWord)) return {
				found: lcWord,
				ignore: true
			};
		}
		if (word in this.typosDef) return {
			found: word,
			ignore: false
		};
		if (lcWord in this.typosDef) return {
			found: lcWord,
			ignore: false
		};
		return false;
	}
	isForbidden(word, ignoreCaseAndAccents = isForbiddenIgnoreCaseAndAccents) {
		const found = this._findForms(word, ignoreCaseAndAccents);
		return found !== false && !found.ignore;
	}
	isNoSuggestWord(word, options) {
		return this.find(word, options)?.noSuggest ?? false;
	}
	/**
	* Determine if the word can appear in a list of suggestions.
	* @param word - word
	* @param ignoreCaseAndAccents - ignore case.
	* @returns true if a word is suggested, otherwise false.
	*/
	isSuggestedWord(word, ignoreCaseAndAccents = isForbiddenIgnoreCaseAndAccents) {
		if (this.suggestions.has(word)) return true;
		const lcWord = word.toLowerCase();
		return ignoreCaseAndAccents && (this.suggestions.has(lcWord) || this.suggestionsLower.has(lcWord));
	}
	suggest(word) {
		return this.getPreferredSuggestions(word);
	}
	_suggest(word) {
		if (this.ignoreWords.has(word)) return [];
		if (!(word in this.typosDef)) return void 0;
		const sug = this.typosDef[word];
		const isPreferred = true;
		if (!sug) return [];
		if (typeof sug === "string") return [{
			word: sug,
			cost: 1,
			isPreferred
		}];
		return sug.map((word, index) => ({
			word,
			cost: index + 1,
			isPreferred
		}));
	}
	genSuggestions(collector) {
		this.suggest(collector.word).forEach((result) => collector.add(result));
	}
	getPreferredSuggestions(word) {
		return this._suggest(word) || this._suggest(word.toLowerCase()) || [];
	}
	isDictionaryCaseSensitive = true;
	getErrors() {
		return [];
	}
};
const createCache$4 = createAutoResolveWeakCache$1();
/**
* Create a dictionary where all words are to be forbidden.
* @param entries - list of Typos Entries
* @param name - name of dictionary
* @param source - source
* @returns
*/
function createTyposDictionary(entries, name, source) {
	return createCache$4.get(entries, () => {
		return new TyposDictionaryImpl(name, source, processEntriesToTyposDef(entries));
	});
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/FlagWordsDictionary.js
var FlagWordsDictionaryTrie = class extends SpellingDictionaryFromTrie {
	name;
	source;
	containsNoSuggestWords = false;
	options = {};
	constructor(trie, name, source) {
		super(trie, name, defaultOptions, source);
		this.name = name;
		this.source = source;
	}
	/**
	* A Forbidden word list does not "have" valid words.
	* Therefore it always returns false.
	* @param _word - the word
	* @param _options - options
	* @returns always false
	*/
	has(_word, _options) {
		return false;
	}
	find(word, hasOptions) {
		const f = super.find(word, hasOptions);
		if (!f || !f.forbidden) return void 0;
		return f;
	}
	suggest() {
		return [];
	}
	genSuggestions() {}
	isDictionaryCaseSensitive = true;
	terms() {
		return this.trie.words();
	}
};
var FlagWordsDictionary = class {
	name;
	source;
	dictTypos;
	dictTrie;
	containsNoSuggestWords = false;
	options = {};
	type = "flag-words";
	mapWord = void 0;
	constructor(name, source, dictTypos, dictTrie) {
		this.name = name;
		this.source = source;
		this.dictTypos = dictTypos;
		this.dictTrie = dictTrie;
	}
	/**
	* A Forbidden word list does not "have" valid words.
	* Therefore it always returns false.
	* @param word - the word
	* @param options - options
	* @returns always false
	*/
	has(word, options) {
		return this.dictTypos.has(word, options) || this.dictTrie?.has(word, options) || false;
	}
	/** A more detailed search for a word, might take longer than `has` */
	find(word, options) {
		const findTypos = this.dictTypos.find(word, options);
		if (findTypos) return findTypos;
		const ignoreCase$1 = options?.ignoreCase ?? ignoreCase;
		if (this.dictTypos.isSuggestedWord(word, ignoreCase$1)) return void 0;
		return this.dictTrie?.find(word, options);
	}
	isForbidden(word, ignoreCaseAndAccents = isForbiddenIgnoreCaseAndAccents) {
		return this.find(word, { ignoreCase: ignoreCaseAndAccents })?.forbidden || false;
	}
	isNoSuggestWord(word, options) {
		return this.dictTrie?.isNoSuggestWord(word, options) || this.dictTypos.isNoSuggestWord(word, options);
	}
	suggest(word, suggestOptions = {}) {
		return this.dictTypos.suggest(word, suggestOptions);
	}
	getPreferredSuggestions(word) {
		return this.dictTypos.getPreferredSuggestions(word);
	}
	genSuggestions() {}
	get size() {
		return this.dictTypos.size + (this.dictTrie?.size || 0);
	}
	isDictionaryCaseSensitive = true;
	getErrors() {
		return [];
	}
	*terms() {
		if (this.dictTrie) {
			yield* this.dictTrie.terms();
			return;
		}
	}
};
const createCache$3 = createAutoResolveWeakCache$1();
/**
* Create a dictionary where all words are to be forbidden.
* @param wordList - list of words
* @param name
* @param source
* @param options
* @returns SpellingDictionary
*/
function createFlagWordsDictionary(wordList, name, source) {
	return createCache$3.get(wordList, () => {
		const testSpecialCharacters = /[~*+]/;
		const { t: specialWords, f: typoWords } = bisect(parseDictionaryLines(wordList, { stripCaseAndAccents: false }), (line) => testSpecialCharacters.test(line));
		const trieDict = new FlagWordsDictionaryTrie(parseDictionary(specialWords, {
			stripCaseAndAccents: false,
			makeWordsForbidden: true
		}), name, source);
		const typosDict = createTyposDictionary(typoWords, name, source);
		if (!specialWords.size) return typosDict;
		return new FlagWordsDictionary(name, source, typosDict, trieDict);
	});
}
function bisect(values, predicate) {
	const t = /* @__PURE__ */ new Set();
	const f = /* @__PURE__ */ new Set();
	for (const v of values) if (predicate(v)) t.add(v);
	else f.add(v);
	return {
		t,
		f
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/IgnoreWordsDictionary.js
const NormalizeForm = "NFC";
var IgnoreWordsDictionary = class {
	name;
	source;
	dict;
	dictNonStrict;
	containsNoSuggestWords = true;
	options = {};
	type = "ignore";
	mapWord = void 0;
	constructor(name, source, words) {
		this.name = name;
		this.source = source;
		this.dict = new Set(words);
		this.dictNonStrict = new Set(pipeSync$1(this.dict, opFilterSync$1((w) => w.startsWith("~")), opMapSync$1((w) => w.slice(1))));
	}
	/**
	* A Forbidden word list does not "have" valid words.
	* Therefore it always returns false.
	* @param _word - the word
	* @param _options - options
	* @returns always false
	*/
	has(word, options) {
		const nWord = word.normalize(NormalizeForm);
		if (this.dict.has(nWord)) return true;
		const lcWord = nWord.toLowerCase();
		if (this.dict.has(lcWord)) return true;
		return (options?.ignoreCase ?? ignoreCase) && (this.dictNonStrict.has(nWord) || this.dictNonStrict.has(lcWord));
	}
	/** A more detailed search for a word, might take longer than `has` */
	find(word, options) {
		const nWord = word.normalize(NormalizeForm);
		if (this.dict.has(nWord)) return {
			found: nWord,
			forbidden: false,
			noSuggest: true
		};
		const lcWord = nWord.toLowerCase();
		if (this.dict.has(lcWord)) return {
			found: lcWord,
			forbidden: false,
			noSuggest: true
		};
		if (!(options?.ignoreCase ?? ignoreCase)) return void 0;
		if (this.dictNonStrict.has(nWord)) return {
			found: nWord,
			forbidden: false,
			noSuggest: true
		};
		return this.dictNonStrict.has(lcWord) && {
			found: lcWord,
			forbidden: false,
			noSuggest: true
		} || void 0;
	}
	isForbidden(_word, _ignoreCase) {
		return false;
	}
	isNoSuggestWord(word, options) {
		return this.has(word, options);
	}
	suggest() {
		return [];
	}
	genSuggestions() {}
	get size() {
		return this.dict.size;
	}
	isDictionaryCaseSensitive = true;
	getErrors() {
		return [];
	}
};
const createCache$2 = createAutoResolveWeakCache$1();
/**
* Create a dictionary where all words are to be ignored.
* Ignored words override forbidden words.
* @param wordList - list of words
* @param name - name of dictionary
* @param source - dictionary source
* @returns
*/
function createIgnoreWordsDictionary(wordList, name, source, options) {
	return createCache$2.get(wordList, () => {
		const testSpecialCharacters = /[*+]/;
		const words = [...parseDictionaryLines(wordList, { stripCaseAndAccents: options?.supportNonStrictSearches ?? true })].map((w) => w.normalize(NormalizeForm));
		if (words.some((word) => testSpecialCharacters.test(word))) return createSpellingDictionary(words, name, source, {
			caseSensitive: true,
			noSuggest: true,
			weightMap: void 0,
			supportNonStrictSearches: true
		});
		return new IgnoreWordsDictionary(name, source, words);
	});
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/SpellingDictionaryCollection.js
var SpellingDictionaryCollectionImpl = class {
	dictionaries;
	name;
	options = { weightMap: void 0 };
	mapWord = void 0;
	type = "SpellingDictionaryCollection";
	source;
	isDictionaryCaseSensitive;
	containsNoSuggestWords;
	constructor(dictionaries, name, source) {
		this.dictionaries = dictionaries;
		this.name = name;
		this.dictionaries = this.dictionaries.sort((a, b) => b.size - a.size);
		this.source = source || dictionaries.map((d) => d.name).join(", ");
		this.isDictionaryCaseSensitive = this.dictionaries.reduce((a, b) => a || b.isDictionaryCaseSensitive, false);
		this.containsNoSuggestWords = this.dictionaries.reduce((a, b) => a || b.containsNoSuggestWords, false);
	}
	has(word, hasOptions) {
		const options = hasOptionToSearchOption(hasOptions);
		return !!isWordInAnyDictionary(this.dictionaries, word, options) && !this.isForbidden(word);
	}
	find(word, hasOptions) {
		const options = hasOptionToSearchOption(hasOptions);
		return findInAnyDictionary(this.dictionaries, word, options);
	}
	isNoSuggestWord(word, options) {
		return this._isNoSuggestWord(word, options);
	}
	isForbidden(word, ignoreCaseAndAccents) {
		const ignoreCase = ignoreCaseAndAccents ?? isForbiddenIgnoreCaseAndAccents;
		return !!this._isForbiddenInDict(word, ignoreCase) && !this.isNoSuggestWord(word, { ignoreCase });
	}
	suggest(word, suggestOptions = {}) {
		return this._suggest(word, suggestOptions);
	}
	_suggest(word, suggestOptions) {
		const { numSuggestions = defaultNumSuggestions, numChanges, ignoreCase, includeTies, timeout } = suggestOptions;
		const prefixNoCase = CASE_INSENSITIVE_PREFIX;
		const filter = (word, _cost) => {
			return (ignoreCase || word[0] !== prefixNoCase) && !this.isForbidden(word) && !this.isNoSuggestWord(word, suggestOptions);
		};
		const collector = suggestionCollector(word, {
			numSuggestions,
			filter,
			changeLimit: numChanges,
			includeTies,
			ignoreCase,
			timeout
		});
		this.genSuggestions(collector, suggestOptions);
		return collector.suggestions;
	}
	get size() {
		return this.dictionaries.reduce((a, b) => a + b.size, 0);
	}
	getPreferredSuggestions(word) {
		const sugs = this.dictionaries.flatMap((dict) => dict.getPreferredSuggestions?.(word)).filter(isDefined$4);
		if (sugs.length <= 1) return sugs;
		const unique = /* @__PURE__ */ new Set();
		return sugs.filter((sug) => {
			if (unique.has(sug.word)) return false;
			unique.add(sug.word);
			return true;
		});
	}
	genSuggestions(collector, suggestOptions) {
		const _suggestOptions = { ...suggestOptions };
		const { compoundMethod = CompoundWordsMethod.SEPARATE_WORDS } = suggestOptions;
		_suggestOptions.compoundMethod = this.options.useCompounds ? CompoundWordsMethod.JOIN_WORDS : compoundMethod;
		this.dictionaries.forEach((dict) => dict.genSuggestions(collector, _suggestOptions));
	}
	getErrors() {
		return this.dictionaries.reduce((errors, dict) => [...errors, ...dict.getErrors?.() || []], []);
	}
	_isForbiddenInDict(word, ignoreCase) {
		return isWordForbiddenInAnyDictionary(this.dictionaries, word, ignoreCase);
	}
	_isNoSuggestWord = (word, options) => {
		if (!this.containsNoSuggestWords) return false;
		return !!isNoSuggestWordInAnyDictionary(this.dictionaries, word, options || {});
	};
};
function createCollection(dictionaries, name, source) {
	return new SpellingDictionaryCollectionImpl(dictionaries, name, source);
}
function isWordInAnyDictionary(dicts, word, options) {
	return dicts.find((dict) => dict.has(word, options));
}
function findInAnyDictionary(dicts, word, options) {
	const found = dicts.map((dict) => dict.find(word, options)).filter(isDefined$4);
	if (!found.length) return void 0;
	return found.reduce((a, b) => ({
		found: a.forbidden ? a.found : b.forbidden ? b.found : a.found || b.found,
		forbidden: a.forbidden || b.forbidden,
		noSuggest: a.noSuggest || b.noSuggest
	}));
}
function isNoSuggestWordInAnyDictionary(dicts, word, options) {
	return dicts.find((dict) => dict.isNoSuggestWord(word, options));
}
function isWordForbiddenInAnyDictionary(dicts, word, ignoreCase) {
	return dicts.find((dict) => dict.isForbidden(word, ignoreCase));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/SuggestDictionary.js
var SuggestDictionaryImpl = class {
	name;
	source;
	typosDef;
	containsNoSuggestWords = false;
	options = {};
	type = "suggest";
	size;
	mapWord = void 0;
	/**
	* Note: ignoreWordsLower is only suggestions with the case and accents removed.
	* The logic is that if someone explicity ignored an upper case version, it does not
	* mean that the lower case version is ok.
	*/
	suggestions;
	suggestionsLower;
	constructor(name, source, typosDef) {
		this.name = name;
		this.source = source;
		this.typosDef = typosDef;
		this.size = Object.keys(typosDef).length;
		this.suggestions = extractAllSuggestions(typosDef);
		this.suggestionsLower = new Set(pipeSync$1(this.suggestions, mapperRemoveCaseAndAccents));
	}
	/**
	* A Forbidden word list does not "have" valid words.
	* Therefore it always returns false.
	* @param _word - the word
	* @param _options - options
	* @returns always false
	*/
	has(_word, _options) {
		return false;
	}
	/** A more detailed search for a word, might take longer than `has` */
	find(_word, _options) {}
	isForbidden(_word, _ignoreCaseAndAccents) {
		return false;
	}
	isNoSuggestWord(_word, _options) {
		return false;
	}
	/**
	* Determine if the word can appear in a list of suggestions.
	* @param word - word
	* @param ignoreCaseAndAccents - ignore case.
	* @returns true if a word is suggested, otherwise false.
	*/
	isSuggestedWord(word, ignoreCaseAndAccents = isForbiddenIgnoreCaseAndAccents) {
		if (this.suggestions.has(word)) return true;
		if (!ignoreCaseAndAccents) return false;
		const lcWord = word.toLowerCase();
		return this.suggestions.has(lcWord) || this.suggestionsLower.has(lcWord);
	}
	suggest(word) {
		return this.getPreferredSuggestions(word);
	}
	_suggest(word) {
		if (!(word in this.typosDef)) return void 0;
		const sug = this.typosDef[word];
		const isPreferred = true;
		if (!sug) return [];
		if (typeof sug === "string") return [{
			word: sug,
			cost: 1,
			isPreferred
		}];
		return sug.map((word, index) => ({
			word,
			cost: index + 1,
			isPreferred
		}));
	}
	getPreferredSuggestions(word) {
		return this._suggest(word) || this._suggest(word.toLowerCase()) || [];
	}
	genSuggestions(collector) {
		this.suggest(collector.word).forEach((result) => collector.add(result));
	}
	isDictionaryCaseSensitive = true;
	getErrors() {
		return [];
	}
};
const createCache$1 = createAutoResolveWeakCache$1();
/**
* Create a dictionary where all words are to be forbidden.
* @param entries - list of Typos Entries
* @param name - name of dictionary
* @param source - source
* @returns
*/
function createSuggestDictionary(entries, name, source) {
	return createCache$1.get(entries, () => {
		return new SuggestDictionaryImpl(name, source, processEntriesToTyposDef(entries));
	});
}

//#endregion
//#region ../node_modules/.pnpm/cspell-dictionary@9.6.4/node_modules/cspell-dictionary/dist/SpellingDictionary/createInlineSpellingDictionary.js
const cache$3 = createAutoResolveWeakCache$1();
function createInlineSpellingDictionary(inlineDict, source) {
	return cache$3.get(inlineDict, () => {
		const { words, flagWords, ignoreWords, suggestWords, name, supportNonStrictSearches } = inlineDict;
		const options = { supportNonStrictSearches };
		return createCollection([
			words && createSpellingDictionary(words, name + "-words", source, inlineDict),
			flagWords && createFlagWordsDictionary(flagWords, name + "-flag-words", source),
			ignoreWords && createIgnoreWordsDictionary(ignoreWords, name + "-ignore-words", source, options),
			suggestWords && createSuggestDictionary(suggestWords, name + "-suggest", source)
		].filter(isDefined$4), name, source);
	});
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+url@9.6.4/node_modules/@cspell/url/dist/index.js
const isURLRegEx = /^(\w[\w-]{1,63}:\/|data:|stdin:)/i;
/**
* Try to make a URL.
* @param url
* @param relativeTo - optional URL, if given, url will be parsed as relative.
* @returns a URL
*/
function toURL$2(url, relativeTo) {
	return normalizeWindowsUrl(url instanceof URL ? url : new URL(url, relativeTo));
}
/**
* Try to determine the parent directory URL of the uri.
* If it is not a hierarchical URL, then it will return the URL.
* @param url - url to extract the dirname from.
* @returns a URL
*/
function urlParent(url) {
	url = toURL$2(url);
	if (url.protocol === "data:") return url;
	const hasTrailingSlash = url.pathname.endsWith("/");
	if (!url.pathname.startsWith("/")) {
		if (!url.pathname) return url;
		const pathname = url.pathname.split("/").slice(0, hasTrailingSlash ? -2 : -1).join("/") + "/";
		return new URL(url.protocol + (url.host ? "//" + url.host : "") + pathname + url.search + url.hash);
	}
	return new URL(hasTrailingSlash ? ".." : ".", url);
}
/**
* Alias of {@link urlParent}
* Try to determine the parent directory URL of the uri.
* If it is not a hierarchical URL, then it will return the URL.
* @param url - url to extract the dirname from.
* @returns a URL
*/
const urlDirname = urlParent;
/**
* return the basename (last portion of the URL pathname) of a path. It does NOT remove the trailing slash.
* @param path - URL pathname to extract the basename from.
*/
function basenameOfUrlPathname(path) {
	const adj = path.endsWith("/") ? 2 : 0;
	const idx = path.lastIndexOf("/", path.length - adj);
	return idx >= 0 ? path.slice(idx + 1) : path;
}
function isUrlLike(filename) {
	return filename instanceof URL || isURLRegEx.test(filename);
}
/**
*
* @param url - url to check
* @param protocol - protocol to check against - e.g. 'file:', 'http:', 'https:'
* @returns
*/
function hasProtocol(url, protocol) {
	protocol = protocol.endsWith(":") ? protocol : protocol + ":";
	return typeof url === "string" ? url.startsWith(protocol) : url.protocol === protocol;
}
/**
* Attempts to add a trailing slash to the URL pathname if it does not already have one.
* Some If the pathname doesn't start with a `/`, a trailing slash is not added.
* @param url - a URL
* @returns
*/
function addTrailingSlash(url) {
	if (url.pathname.endsWith("/")) return url;
	const urlWithSlash = new URL(url.href);
	urlWithSlash.pathname += "/";
	return urlWithSlash;
}
/**
* Calculate the relative path to go from `urlFrom` to `urlTo`.
* The protocol is not evaluated. Only the `url.pathname` is used.
* @param urlFrom
* @param urlTo
* @returns the relative path
*/
function urlRelative(urlFrom, urlTo) {
	return urlToUrlRelative(toURL$2(urlFrom), toURL$2(urlTo));
}
/**
* Calculate the relative path to go from `urlFrom` to `urlTo`.
* The protocol is not evaluated. Only the `url.pathname` is used.
* @param urlFrom
* @param urlTo
* @returns the relative path
*/
function urlToUrlRelative(urlFrom, urlTo) {
	let pFrom = urlFrom.pathname;
	const pTo = urlTo.pathname;
	if (pFrom === pTo) return "";
	pFrom = pFrom.endsWith("/") ? pFrom : new URL("./", urlFrom).pathname;
	if (pTo.startsWith(pFrom)) return decodeURIComponent(pTo.slice(pFrom.length));
	const p0 = pFrom;
	const p1 = pTo;
	if (p1.startsWith(p0)) return decodeURIComponent(p0 === p1 ? "" : p1.slice(p0.lastIndexOf("/") + 1));
	const p0Parts = p0.split("/").slice(0, -1);
	const p1Parts = p1.split("/");
	let i = 0;
	for (i = 0; i < p0Parts.length && i < p1Parts.length - 1 && p0Parts[i] === p1Parts[i]; ++i);
	const rel = "../".repeat(p0Parts.length - i) + p1Parts.slice(i).join("/");
	return decodeURIComponent(rel.length < p1.length ? rel : p1);
}
const regExpWindowsPath = /^[\\/]([a-zA-Z]:[\\/])/;
const badUncLocalhostUrl = /^(\/+[a-zA-Z])\$/;
/**
* Ensure that a windows file url is correctly formatted with a capitol letter for the drive.
*
* @param url - URL to check.
* @returns a new URL if modified or converted from a string.
*/
function normalizeWindowsUrl(url) {
	url = typeof url === "string" ? new URL(url) : url;
	if (url.protocol === "file:") {
		let pathname = url.pathname.replaceAll("%3A", ":").replaceAll("%3a", ":").replaceAll("%24", "$");
		if (!url.host) pathname = pathname.replace(badUncLocalhostUrl, "$1:");
		pathname = pathname.replace(regExpWindowsPath, (d) => d.toUpperCase());
		if (pathname !== url.pathname) {
			url = new URL(url);
			url.pathname = pathname;
			return fixUncUrl(url);
		}
	}
	return fixUncUrl(url);
}
/**
* There is a bug is NodeJS that sometimes causes UNC paths converted to a URL to be prefixed with `file:////`.
* @param url - URL to check.
* @returns fixed URL if needed.
*/
function fixUncUrl(url) {
	if (url.href.startsWith("file:////")) return new URL(url.href.replace(/^file:\/{4}/, "file://"));
	return url;
}
const regMatchFilename = /filename=([^;,]*)/;
/**
* Try to determine the base name of a URL.
* @param url
* @returns the base name of a URL, including the trailing `/` if present.
*/
function urlBasename(url) {
	function guessDataUrlName(header) {
		const filenameMatch = header.match(regMatchFilename);
		if (filenameMatch) return filenameMatch[1];
		return header.split(";", 1)[0].replaceAll(/\W/g, ".");
	}
	url = toURL$2(url);
	if (url.protocol === "data:") return guessDataUrlName(url.pathname.split(",", 1)[0]);
	return basenameOfUrlPathname(url.pathname);
}
function isDataURL(url) {
	return hasProtocol(url, "data:");
}
const isWindows$2 = process.platform === "win32";
const windowsUrlPathRegExp = /^\/[a-zA-Z]:\//;
function isWindowsPathnameWithDriveLatter(pathname) {
	return windowsUrlPathRegExp.test(pathname);
}
/**
* @param url - URL or string to check if it is a file URL.
* @returns true if the URL is a file URL.
*/
function isFileURL(url) {
	return hasProtocol(url, "file:");
}
/**
* Convert a URL into a string. If it is a file URL, convert it to a path.
* @param url - URL
* @returns path or href
*/
function toFilePathOrHref(url) {
	return isFileURL(url) && url.toString().startsWith("file:///") ? toFilePath(url) : url.toString();
}
function toFilePath(url) {
	try {
		if (isWindows$2) {
			const u = new URL(url);
			if (!isWindowsPathnameWithDriveLatter(u.pathname)) {
				const cwdUrl = pathToFileURL(process.cwd());
				if (cwdUrl.hostname) return fileURLToPath(new URL(u.pathname, cwdUrl));
				u.pathname = `/${cwdUrl.pathname.split("/")[1]}${u.pathname}`;
				return fileURLToPath(u);
			}
		}
		return pathWindowsDriveLetterToUpper(fileURLToPath(url));
	} catch {
		return url.toString();
	}
}
const regExpWindowsPathDriveLetter$1 = /^([a-zA-Z]):[\\/]/;
function pathWindowsDriveLetterToUpper(absoluteFilePath) {
	return absoluteFilePath.replace(regExpWindowsPathDriveLetter$1, (s) => s.toUpperCase());
}
const regExpWindowsFileUrl = /^file:\/\/\/[a-zA-Z]:\//;
/**
* Test if a url is a file url with a windows path. It does check for UNC paths.
* @param url - the url
* @returns true if the url is a file url with a windows path with a drive letter.
*/
function isWindowsFileUrl(url) {
	return regExpWindowsFileUrl.test(url.toString());
}
const isWindowsPathRegEx = regExpWindowsPathDriveLetter$1;
const isWindowsPathname = regExpWindowsPath;
const percentRegEx = /%/g;
const backslashRegEx = /\\/g;
const newlineRegEx = /\n/g;
const carriageReturnRegEx = /\r/g;
const tabRegEx = /\t/g;
const questionRegex = /\?/g;
const hashRegex = /#/g;
const ProtocolFile = "file:";
var FileUrlBuilder = class {
	windows;
	path;
	cwd;
	constructor(options = {}) {
		const sep = options.path?.sep;
		this.windows = options.windows ?? (sep ? sep === "\\" : void 0) ?? isWindows$2;
		this.path = options.path ?? (this.windows ? path.win32 : path.posix);
		this.cwd = options.cwd ?? this.pathToFileURL(this.path.resolve() + "/", this.rootFileURL());
		assert(this.path.sep === (this.windows ? "\\" : "/"), `Path separator should match OS type Windows: ${this.windows === true ? "true" : (this.windows ?? "undefined") || "false"}, sep: ${this.path.sep}, options: ` + JSON.stringify({
			isWindows: isWindows$2,
			sep: `${sep}`,
			windows: options.windows,
			pathSep: options.path?.sep,
			n: options.path?.normalize("path/file.txt"),
			cwd: options.cwd?.href,
			win32: this.path === path.win32,
			posix: this.path === path.posix,
			"win32.normalize": this.path.normalize === path.win32.normalize,
			"posix.normalize": this.path.normalize === path.posix.normalize
		}) + ``);
	}
	/**
	* Encode special characters in a file path to use in a URL.
	* @param filepath
	* @returns
	*/
	encodePathChars(filepath) {
		filepath = filepath.replaceAll(percentRegEx, "%25");
		if (!this.windows && !isWindows$2 && filepath.includes("\\")) filepath = filepath.replaceAll(backslashRegEx, "%5C");
		filepath = filepath.replaceAll(newlineRegEx, "%0A");
		filepath = filepath.replaceAll(carriageReturnRegEx, "%0D");
		filepath = filepath.replaceAll(tabRegEx, "%09");
		return filepath;
	}
	/**
	* Normalize a file path for use in a URL.
	* ```js
	* const url = new URL(normalizeFilePathForUrl('path\\to\\file.txt'), 'file:///Users/user/');
	* // Result: file:///Users/user/path/to/file.txt
	* ```
	* @param filePath
	* @returns a normalized file path for use as a relative path in a URL.
	*/
	normalizeFilePathForUrl(filePath) {
		filePath = this.encodePathChars(filePath);
		filePath = filePath.replaceAll(questionRegex, "%3F");
		filePath = filePath.replaceAll(hashRegex, "%23");
		return filePath.replaceAll("\\", "/").replace(isWindowsPathRegEx, (drive) => `/${drive}`.toUpperCase());
	}
	/**
	* Try to make a file URL.
	* - if filenameOrUrl is already a URL, it is returned as is.
	* @param filenameOrUrl
	* @param relativeTo - optional URL, if given, filenameOrUrl will be parsed as relative.
	* @returns a URL
	*/
	toFileURL(filenameOrUrl, relativeTo) {
		return normalizeWindowsUrl(this.#toFileURL(filenameOrUrl, relativeTo));
	}
	/**
	* Try to make a file URL.
	* - if filenameOrUrl is already a URL, it is returned as is.
	* @param filenameOrUrl
	* @param relativeTo - optional URL, if given, filenameOrUrl will be parsed as relative.
	* @returns a URL
	*/
	#toFileURL(filenameOrUrl, relativeTo) {
		if (typeof filenameOrUrl !== "string") return filenameOrUrl;
		if (isUrlLike(filenameOrUrl)) return normalizeWindowsUrl(new URL(filenameOrUrl));
		relativeTo ??= this.cwd;
		isWindows$2 && (filenameOrUrl = filenameOrUrl.replaceAll("\\", "/"));
		if (this.isAbsolute(filenameOrUrl) && isFileURL(relativeTo)) {
			const pathname = this.normalizeFilePathForUrl(filenameOrUrl);
			if (isWindowsFileUrl(relativeTo) && !isWindowsPathnameWithDriveLatter(pathname)) {
				const relFilePrefix = relativeTo.toString().slice(0, 10);
				return normalizeWindowsUrl(new URL(relFilePrefix + pathname));
			}
			return normalizeWindowsUrl(new URL("file://" + pathname));
		}
		if (isUrlLike(relativeTo)) {
			const pathname = this.normalizeFilePathForUrl(filenameOrUrl);
			return normalizeWindowsUrl(new URL(pathname, relativeTo));
		}
		const appendSlash = filenameOrUrl.endsWith("/") ? "/" : "";
		const pathname = this.normalizeFilePathForUrl(this.path.resolve(relativeTo.toString(), filenameOrUrl)) + appendSlash;
		return normalizeWindowsUrl(new URL("file://" + pathname));
	}
	/**
	* Try to make a URL for a directory.
	* - if dirOrUrl is already a URL, a slash is appended to the pathname.
	* @param dirOrUrl - directory path to convert to a file URL.
	* @param relativeTo - optional URL, if given, filenameOrUrl will be parsed as relative.
	* @returns a URL
	*/
	toFileDirURL(dirOrUrl, relativeTo) {
		return addTrailingSlash(this.toFileURL(dirOrUrl, relativeTo));
	}
	urlToFilePathOrHref(url) {
		url = this.toFileURL(url);
		return this.#urlToFilePathOrHref(url);
	}
	#urlToFilePathOrHref(url) {
		if (url.protocol !== ProtocolFile || url.hostname) return url.href;
		return pathWindowsDriveLetterToUpper((this.path === path ? toFilePathOrHref(url) : decodeURIComponent(url.pathname.split("/").join(this.path.sep))).replace(isWindowsPathname, "$1"));
	}
	/**
	* Calculate the relative path to go from `urlFrom` to `urlTo`.
	* The protocol is not evaluated. Only the `url.pathname` is used.
	* The result: `new URL(relative(urlFrom, urlTo), urlFrom).pathname === urlTo.pathname`
	* @param urlFrom
	* @param urlTo
	* @returns the relative path
	*/
	relative(urlFrom, urlTo) {
		if (urlFrom.protocol === urlTo.protocol && urlFrom.protocol === ProtocolFile) {
			if (urlFrom.href === urlTo.href) return "";
			urlFrom = urlFrom.pathname.endsWith("/") ? urlFrom : new URL("./", urlFrom);
			const fromPath = urlFrom.pathname;
			const toPath = urlTo.pathname;
			if (toPath.startsWith(fromPath)) return decodeURIComponent(toPath.slice(fromPath.length));
			const pFrom = this.#urlToFilePathOrHref(urlFrom);
			const pTo = this.#urlToFilePathOrHref(urlTo);
			const toIsDir = urlTo.pathname.endsWith("/");
			let pathname = this.normalizeFilePathForUrl(this.path.relative(pFrom, pTo));
			if (toIsDir && !pathname.endsWith("/")) pathname += "/";
			return decodeURIComponent(pathname);
		}
		return decodeURIComponent(urlToUrlRelative(urlFrom, urlTo));
	}
	/**
	* Get the parent directory of a URL.
	* @param url
	*/
	urlDirname(url) {
		return urlParent(this.toFileURL(url));
	}
	pathToFileURL(pathname, relativeToURL) {
		return new URL(this.normalizeFilePathForUrl(pathname), relativeToURL || this.cwd);
	}
	rootFileURL(filePath) {
		const path = this.path;
		const p = path.parse(path.normalize(path.resolve(filePath ?? ".")));
		return new URL(this.normalizeFilePathForUrl(p.root), this.#getFsRootURL());
	}
	#getFsRootURL() {
		if (this.path === path) return pathToFileURL("/");
		const p = this.path.resolve("/");
		return new URL(this.normalizeFilePathForUrl(p), "file:///");
	}
	/**
	* Determine if a filePath is absolute.
	*
	* @param filePath
	* @returns true if `URL` or `path.isAbsolute(filePath)`
	*/
	isAbsolute(filePath) {
		return isUrlLike(filePath) || this.path.isAbsolute(filePath);
	}
	isUrlLike(url) {
		return isUrlLike(url);
	}
};
const fileUrlBuilder$1 = new FileUrlBuilder();
/**
* Try to make a file URL.
* - if filenameOrUrl is already a URL, it is returned as is.
* -
* @param filenameOrUrl
* @param relativeTo - optional URL, if given, filenameOrUrl will be parsed as relative.
* @returns a URL
*/
function toFileURL(filenameOrUrl, relativeTo) {
	return fileUrlBuilder$1.toFileURL(filenameOrUrl, relativeTo);
}
/**
* Converts a file path to a URL and adds a trailing slash.
* @param dir - url to a directory
* @returns a URL
*/
function toFileDirURL(dir) {
	return fileUrlBuilder$1.toFileDirURL(dir);
}

//#endregion
//#region ../node_modules/.pnpm/picomatch@4.0.3/node_modules/picomatch/lib/constants.js
var require_constants = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const WIN_SLASH = "\\\\/";
	const WIN_NO_SLASH = `[^${WIN_SLASH}]`;
	/**
	* Posix glob regex
	*/
	const DOT_LITERAL = "\\.";
	const PLUS_LITERAL = "\\+";
	const QMARK_LITERAL = "\\?";
	const SLASH_LITERAL = "\\/";
	const ONE_CHAR = "(?=.)";
	const QMARK = "[^/]";
	const END_ANCHOR = `(?:${SLASH_LITERAL}|$)`;
	const START_ANCHOR = `(?:^|${SLASH_LITERAL})`;
	const DOTS_SLASH = `${DOT_LITERAL}{1,2}${END_ANCHOR}`;
	const POSIX_CHARS = {
		DOT_LITERAL,
		PLUS_LITERAL,
		QMARK_LITERAL,
		SLASH_LITERAL,
		ONE_CHAR,
		QMARK,
		END_ANCHOR,
		DOTS_SLASH,
		NO_DOT: `(?!${DOT_LITERAL})`,
		NO_DOTS: `(?!${START_ANCHOR}${DOTS_SLASH})`,
		NO_DOT_SLASH: `(?!${DOT_LITERAL}{0,1}${END_ANCHOR})`,
		NO_DOTS_SLASH: `(?!${DOTS_SLASH})`,
		QMARK_NO_DOT: `[^.${SLASH_LITERAL}]`,
		STAR: `${QMARK}*?`,
		START_ANCHOR,
		SEP: "/"
	};
	/**
	* Windows glob regex
	*/
	const WINDOWS_CHARS = {
		...POSIX_CHARS,
		SLASH_LITERAL: `[${WIN_SLASH}]`,
		QMARK: WIN_NO_SLASH,
		STAR: `${WIN_NO_SLASH}*?`,
		DOTS_SLASH: `${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$)`,
		NO_DOT: `(?!${DOT_LITERAL})`,
		NO_DOTS: `(?!(?:^|[${WIN_SLASH}])${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,
		NO_DOT_SLASH: `(?!${DOT_LITERAL}{0,1}(?:[${WIN_SLASH}]|$))`,
		NO_DOTS_SLASH: `(?!${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,
		QMARK_NO_DOT: `[^.${WIN_SLASH}]`,
		START_ANCHOR: `(?:^|[${WIN_SLASH}])`,
		END_ANCHOR: `(?:[${WIN_SLASH}]|$)`,
		SEP: "\\"
	};
	/**
	* POSIX Bracket Regex
	*/
	const POSIX_REGEX_SOURCE = {
		alnum: "a-zA-Z0-9",
		alpha: "a-zA-Z",
		ascii: "\\x00-\\x7F",
		blank: " \\t",
		cntrl: "\\x00-\\x1F\\x7F",
		digit: "0-9",
		graph: "\\x21-\\x7E",
		lower: "a-z",
		print: "\\x20-\\x7E ",
		punct: "\\-!\"#$%&'()\\*+,./:;<=>?@[\\]^_`{|}~",
		space: " \\t\\r\\n\\v\\f",
		upper: "A-Z",
		word: "A-Za-z0-9_",
		xdigit: "A-Fa-f0-9"
	};
	module.exports = {
		MAX_LENGTH: 1024 * 64,
		POSIX_REGEX_SOURCE,
		REGEX_BACKSLASH: /\\(?![*+?^${}(|)[\]])/g,
		REGEX_NON_SPECIAL_CHARS: /^[^@![\].,$*+?^{}()|\\/]+/,
		REGEX_SPECIAL_CHARS: /[-*+?.^${}(|)[\]]/,
		REGEX_SPECIAL_CHARS_BACKREF: /(\\?)((\W)(\3*))/g,
		REGEX_SPECIAL_CHARS_GLOBAL: /([-*+?.^${}(|)[\]])/g,
		REGEX_REMOVE_BACKSLASH: /(?:\[.*?[^\\]\]|\\(?=.))/g,
		REPLACEMENTS: {
			__proto__: null,
			"***": "*",
			"**/**": "**",
			"**/**/**": "**"
		},
		CHAR_0: 48,
		CHAR_9: 57,
		CHAR_UPPERCASE_A: 65,
		CHAR_LOWERCASE_A: 97,
		CHAR_UPPERCASE_Z: 90,
		CHAR_LOWERCASE_Z: 122,
		CHAR_LEFT_PARENTHESES: 40,
		CHAR_RIGHT_PARENTHESES: 41,
		CHAR_ASTERISK: 42,
		CHAR_AMPERSAND: 38,
		CHAR_AT: 64,
		CHAR_BACKWARD_SLASH: 92,
		CHAR_CARRIAGE_RETURN: 13,
		CHAR_CIRCUMFLEX_ACCENT: 94,
		CHAR_COLON: 58,
		CHAR_COMMA: 44,
		CHAR_DOT: 46,
		CHAR_DOUBLE_QUOTE: 34,
		CHAR_EQUAL: 61,
		CHAR_EXCLAMATION_MARK: 33,
		CHAR_FORM_FEED: 12,
		CHAR_FORWARD_SLASH: 47,
		CHAR_GRAVE_ACCENT: 96,
		CHAR_HASH: 35,
		CHAR_HYPHEN_MINUS: 45,
		CHAR_LEFT_ANGLE_BRACKET: 60,
		CHAR_LEFT_CURLY_BRACE: 123,
		CHAR_LEFT_SQUARE_BRACKET: 91,
		CHAR_LINE_FEED: 10,
		CHAR_NO_BREAK_SPACE: 160,
		CHAR_PERCENT: 37,
		CHAR_PLUS: 43,
		CHAR_QUESTION_MARK: 63,
		CHAR_RIGHT_ANGLE_BRACKET: 62,
		CHAR_RIGHT_CURLY_BRACE: 125,
		CHAR_RIGHT_SQUARE_BRACKET: 93,
		CHAR_SEMICOLON: 59,
		CHAR_SINGLE_QUOTE: 39,
		CHAR_SPACE: 32,
		CHAR_TAB: 9,
		CHAR_UNDERSCORE: 95,
		CHAR_VERTICAL_LINE: 124,
		CHAR_ZERO_WIDTH_NOBREAK_SPACE: 65279,
		extglobChars(chars) {
			return {
				"!": {
					type: "negate",
					open: "(?:(?!(?:",
					close: `))${chars.STAR})`
				},
				"?": {
					type: "qmark",
					open: "(?:",
					close: ")?"
				},
				"+": {
					type: "plus",
					open: "(?:",
					close: ")+"
				},
				"*": {
					type: "star",
					open: "(?:",
					close: ")*"
				},
				"@": {
					type: "at",
					open: "(?:",
					close: ")"
				}
			};
		},
		globChars(win32) {
			return win32 === true ? WINDOWS_CHARS : POSIX_CHARS;
		}
	};
}));

//#endregion
//#region ../node_modules/.pnpm/picomatch@4.0.3/node_modules/picomatch/lib/utils.js
var require_utils = /* @__PURE__ */ __commonJSMin(((exports) => {
	const { REGEX_BACKSLASH, REGEX_REMOVE_BACKSLASH, REGEX_SPECIAL_CHARS, REGEX_SPECIAL_CHARS_GLOBAL } = require_constants();
	exports.isObject = (val) => val !== null && typeof val === "object" && !Array.isArray(val);
	exports.hasRegexChars = (str) => REGEX_SPECIAL_CHARS.test(str);
	exports.isRegexChar = (str) => str.length === 1 && exports.hasRegexChars(str);
	exports.escapeRegex = (str) => str.replace(REGEX_SPECIAL_CHARS_GLOBAL, "\\$1");
	exports.toPosixSlashes = (str) => str.replace(REGEX_BACKSLASH, "/");
	exports.isWindows = () => {
		if (typeof navigator !== "undefined" && navigator.platform) {
			const platform = navigator.platform.toLowerCase();
			return platform === "win32" || platform === "windows";
		}
		if (typeof process !== "undefined" && process.platform) return process.platform === "win32";
		return false;
	};
	exports.removeBackslashes = (str) => {
		return str.replace(REGEX_REMOVE_BACKSLASH, (match) => {
			return match === "\\" ? "" : match;
		});
	};
	exports.escapeLast = (input, char, lastIdx) => {
		const idx = input.lastIndexOf(char, lastIdx);
		if (idx === -1) return input;
		if (input[idx - 1] === "\\") return exports.escapeLast(input, char, idx - 1);
		return `${input.slice(0, idx)}\\${input.slice(idx)}`;
	};
	exports.removePrefix = (input, state = {}) => {
		let output = input;
		if (output.startsWith("./")) {
			output = output.slice(2);
			state.prefix = "./";
		}
		return output;
	};
	exports.wrapOutput = (input, state = {}, options = {}) => {
		let output = `${options.contains ? "" : "^"}(?:${input})${options.contains ? "" : "$"}`;
		if (state.negated === true) output = `(?:^(?!${output}).*$)`;
		return output;
	};
	exports.basename = (path, { windows } = {}) => {
		const segs = path.split(windows ? /[\\/]/ : "/");
		const last = segs[segs.length - 1];
		if (last === "") return segs[segs.length - 2];
		return last;
	};
}));

//#endregion
//#region ../node_modules/.pnpm/picomatch@4.0.3/node_modules/picomatch/lib/scan.js
var require_scan = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const utils = require_utils();
	const { CHAR_ASTERISK, CHAR_AT, CHAR_BACKWARD_SLASH, CHAR_COMMA, CHAR_DOT, CHAR_EXCLAMATION_MARK, CHAR_FORWARD_SLASH, CHAR_LEFT_CURLY_BRACE, CHAR_LEFT_PARENTHESES, CHAR_LEFT_SQUARE_BRACKET, CHAR_PLUS, CHAR_QUESTION_MARK, CHAR_RIGHT_CURLY_BRACE, CHAR_RIGHT_PARENTHESES, CHAR_RIGHT_SQUARE_BRACKET } = require_constants();
	const isPathSeparator = (code) => {
		return code === CHAR_FORWARD_SLASH || code === CHAR_BACKWARD_SLASH;
	};
	const depth = (token) => {
		if (token.isPrefix !== true) token.depth = token.isGlobstar ? Infinity : 1;
	};
	/**
	* Quickly scans a glob pattern and returns an object with a handful of
	* useful properties, like `isGlob`, `path` (the leading non-glob, if it exists),
	* `glob` (the actual pattern), `negated` (true if the path starts with `!` but not
	* with `!(`) and `negatedExtglob` (true if the path starts with `!(`).
	*
	* ```js
	* const pm = require('picomatch');
	* console.log(pm.scan('foo/bar/*.js'));
	* { isGlob: true, input: 'foo/bar/*.js', base: 'foo/bar', glob: '*.js' }
	* ```
	* @param {String} `str`
	* @param {Object} `options`
	* @return {Object} Returns an object with tokens and regex source string.
	* @api public
	*/
	const scan = (input, options) => {
		const opts = options || {};
		const length = input.length - 1;
		const scanToEnd = opts.parts === true || opts.scanToEnd === true;
		const slashes = [];
		const tokens = [];
		const parts = [];
		let str = input;
		let index = -1;
		let start = 0;
		let lastIndex = 0;
		let isBrace = false;
		let isBracket = false;
		let isGlob = false;
		let isExtglob = false;
		let isGlobstar = false;
		let braceEscaped = false;
		let backslashes = false;
		let negated = false;
		let negatedExtglob = false;
		let finished = false;
		let braces = 0;
		let prev;
		let code;
		let token = {
			value: "",
			depth: 0,
			isGlob: false
		};
		const eos = () => index >= length;
		const peek = () => str.charCodeAt(index + 1);
		const advance = () => {
			prev = code;
			return str.charCodeAt(++index);
		};
		while (index < length) {
			code = advance();
			let next;
			if (code === CHAR_BACKWARD_SLASH) {
				backslashes = token.backslashes = true;
				code = advance();
				if (code === CHAR_LEFT_CURLY_BRACE) braceEscaped = true;
				continue;
			}
			if (braceEscaped === true || code === CHAR_LEFT_CURLY_BRACE) {
				braces++;
				while (eos() !== true && (code = advance())) {
					if (code === CHAR_BACKWARD_SLASH) {
						backslashes = token.backslashes = true;
						advance();
						continue;
					}
					if (code === CHAR_LEFT_CURLY_BRACE) {
						braces++;
						continue;
					}
					if (braceEscaped !== true && code === CHAR_DOT && (code = advance()) === CHAR_DOT) {
						isBrace = token.isBrace = true;
						isGlob = token.isGlob = true;
						finished = true;
						if (scanToEnd === true) continue;
						break;
					}
					if (braceEscaped !== true && code === CHAR_COMMA) {
						isBrace = token.isBrace = true;
						isGlob = token.isGlob = true;
						finished = true;
						if (scanToEnd === true) continue;
						break;
					}
					if (code === CHAR_RIGHT_CURLY_BRACE) {
						braces--;
						if (braces === 0) {
							braceEscaped = false;
							isBrace = token.isBrace = true;
							finished = true;
							break;
						}
					}
				}
				if (scanToEnd === true) continue;
				break;
			}
			if (code === CHAR_FORWARD_SLASH) {
				slashes.push(index);
				tokens.push(token);
				token = {
					value: "",
					depth: 0,
					isGlob: false
				};
				if (finished === true) continue;
				if (prev === CHAR_DOT && index === start + 1) {
					start += 2;
					continue;
				}
				lastIndex = index + 1;
				continue;
			}
			if (opts.noext !== true) {
				if ((code === CHAR_PLUS || code === CHAR_AT || code === CHAR_ASTERISK || code === CHAR_QUESTION_MARK || code === CHAR_EXCLAMATION_MARK) === true && peek() === CHAR_LEFT_PARENTHESES) {
					isGlob = token.isGlob = true;
					isExtglob = token.isExtglob = true;
					finished = true;
					if (code === CHAR_EXCLAMATION_MARK && index === start) negatedExtglob = true;
					if (scanToEnd === true) {
						while (eos() !== true && (code = advance())) {
							if (code === CHAR_BACKWARD_SLASH) {
								backslashes = token.backslashes = true;
								code = advance();
								continue;
							}
							if (code === CHAR_RIGHT_PARENTHESES) {
								isGlob = token.isGlob = true;
								finished = true;
								break;
							}
						}
						continue;
					}
					break;
				}
			}
			if (code === CHAR_ASTERISK) {
				if (prev === CHAR_ASTERISK) isGlobstar = token.isGlobstar = true;
				isGlob = token.isGlob = true;
				finished = true;
				if (scanToEnd === true) continue;
				break;
			}
			if (code === CHAR_QUESTION_MARK) {
				isGlob = token.isGlob = true;
				finished = true;
				if (scanToEnd === true) continue;
				break;
			}
			if (code === CHAR_LEFT_SQUARE_BRACKET) {
				while (eos() !== true && (next = advance())) {
					if (next === CHAR_BACKWARD_SLASH) {
						backslashes = token.backslashes = true;
						advance();
						continue;
					}
					if (next === CHAR_RIGHT_SQUARE_BRACKET) {
						isBracket = token.isBracket = true;
						isGlob = token.isGlob = true;
						finished = true;
						break;
					}
				}
				if (scanToEnd === true) continue;
				break;
			}
			if (opts.nonegate !== true && code === CHAR_EXCLAMATION_MARK && index === start) {
				negated = token.negated = true;
				start++;
				continue;
			}
			if (opts.noparen !== true && code === CHAR_LEFT_PARENTHESES) {
				isGlob = token.isGlob = true;
				if (scanToEnd === true) {
					while (eos() !== true && (code = advance())) {
						if (code === CHAR_LEFT_PARENTHESES) {
							backslashes = token.backslashes = true;
							code = advance();
							continue;
						}
						if (code === CHAR_RIGHT_PARENTHESES) {
							finished = true;
							break;
						}
					}
					continue;
				}
				break;
			}
			if (isGlob === true) {
				finished = true;
				if (scanToEnd === true) continue;
				break;
			}
		}
		if (opts.noext === true) {
			isExtglob = false;
			isGlob = false;
		}
		let base = str;
		let prefix = "";
		let glob = "";
		if (start > 0) {
			prefix = str.slice(0, start);
			str = str.slice(start);
			lastIndex -= start;
		}
		if (base && isGlob === true && lastIndex > 0) {
			base = str.slice(0, lastIndex);
			glob = str.slice(lastIndex);
		} else if (isGlob === true) {
			base = "";
			glob = str;
		} else base = str;
		if (base && base !== "" && base !== "/" && base !== str) {
			if (isPathSeparator(base.charCodeAt(base.length - 1))) base = base.slice(0, -1);
		}
		if (opts.unescape === true) {
			if (glob) glob = utils.removeBackslashes(glob);
			if (base && backslashes === true) base = utils.removeBackslashes(base);
		}
		const state = {
			prefix,
			input,
			start,
			base,
			glob,
			isBrace,
			isBracket,
			isGlob,
			isExtglob,
			isGlobstar,
			negated,
			negatedExtglob
		};
		if (opts.tokens === true) {
			state.maxDepth = 0;
			if (!isPathSeparator(code)) tokens.push(token);
			state.tokens = tokens;
		}
		if (opts.parts === true || opts.tokens === true) {
			let prevIndex;
			for (let idx = 0; idx < slashes.length; idx++) {
				const n = prevIndex ? prevIndex + 1 : start;
				const i = slashes[idx];
				const value = input.slice(n, i);
				if (opts.tokens) {
					if (idx === 0 && start !== 0) {
						tokens[idx].isPrefix = true;
						tokens[idx].value = prefix;
					} else tokens[idx].value = value;
					depth(tokens[idx]);
					state.maxDepth += tokens[idx].depth;
				}
				if (idx !== 0 || value !== "") parts.push(value);
				prevIndex = i;
			}
			if (prevIndex && prevIndex + 1 < input.length) {
				const value = input.slice(prevIndex + 1);
				parts.push(value);
				if (opts.tokens) {
					tokens[tokens.length - 1].value = value;
					depth(tokens[tokens.length - 1]);
					state.maxDepth += tokens[tokens.length - 1].depth;
				}
			}
			state.slashes = slashes;
			state.parts = parts;
		}
		return state;
	};
	module.exports = scan;
}));

//#endregion
//#region ../node_modules/.pnpm/picomatch@4.0.3/node_modules/picomatch/lib/parse.js
var require_parse$1 = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const constants = require_constants();
	const utils = require_utils();
	/**
	* Constants
	*/
	const { MAX_LENGTH, POSIX_REGEX_SOURCE, REGEX_NON_SPECIAL_CHARS, REGEX_SPECIAL_CHARS_BACKREF, REPLACEMENTS } = constants;
	/**
	* Helpers
	*/
	const expandRange = (args, options) => {
		if (typeof options.expandRange === "function") return options.expandRange(...args, options);
		args.sort();
		const value = `[${args.join("-")}]`;
		try {
			new RegExp(value);
		} catch (ex) {
			return args.map((v) => utils.escapeRegex(v)).join("..");
		}
		return value;
	};
	/**
	* Create the message for a syntax error
	*/
	const syntaxError = (type, char) => {
		return `Missing ${type}: "${char}" - use "\\\\${char}" to match literal characters`;
	};
	/**
	* Parse the given input string.
	* @param {String} input
	* @param {Object} options
	* @return {Object}
	*/
	const parse = (input, options) => {
		if (typeof input !== "string") throw new TypeError("Expected a string");
		input = REPLACEMENTS[input] || input;
		const opts = { ...options };
		const max = typeof opts.maxLength === "number" ? Math.min(MAX_LENGTH, opts.maxLength) : MAX_LENGTH;
		let len = input.length;
		if (len > max) throw new SyntaxError(`Input length: ${len}, exceeds maximum allowed length: ${max}`);
		const bos = {
			type: "bos",
			value: "",
			output: opts.prepend || ""
		};
		const tokens = [bos];
		const capture = opts.capture ? "" : "?:";
		const PLATFORM_CHARS = constants.globChars(opts.windows);
		const EXTGLOB_CHARS = constants.extglobChars(PLATFORM_CHARS);
		const { DOT_LITERAL, PLUS_LITERAL, SLASH_LITERAL, ONE_CHAR, DOTS_SLASH, NO_DOT, NO_DOT_SLASH, NO_DOTS_SLASH, QMARK, QMARK_NO_DOT, STAR, START_ANCHOR } = PLATFORM_CHARS;
		const globstar = (opts) => {
			return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`;
		};
		const nodot = opts.dot ? "" : NO_DOT;
		const qmarkNoDot = opts.dot ? QMARK : QMARK_NO_DOT;
		let star = opts.bash === true ? globstar(opts) : STAR;
		if (opts.capture) star = `(${star})`;
		if (typeof opts.noext === "boolean") opts.noextglob = opts.noext;
		const state = {
			input,
			index: -1,
			start: 0,
			dot: opts.dot === true,
			consumed: "",
			output: "",
			prefix: "",
			backtrack: false,
			negated: false,
			brackets: 0,
			braces: 0,
			parens: 0,
			quotes: 0,
			globstar: false,
			tokens
		};
		input = utils.removePrefix(input, state);
		len = input.length;
		const extglobs = [];
		const braces = [];
		const stack = [];
		let prev = bos;
		let value;
		/**
		* Tokenizing helpers
		*/
		const eos = () => state.index === len - 1;
		const peek = state.peek = (n = 1) => input[state.index + n];
		const advance = state.advance = () => input[++state.index] || "";
		const remaining = () => input.slice(state.index + 1);
		const consume = (value = "", num = 0) => {
			state.consumed += value;
			state.index += num;
		};
		const append = (token) => {
			state.output += token.output != null ? token.output : token.value;
			consume(token.value);
		};
		const negate = () => {
			let count = 1;
			while (peek() === "!" && (peek(2) !== "(" || peek(3) === "?")) {
				advance();
				state.start++;
				count++;
			}
			if (count % 2 === 0) return false;
			state.negated = true;
			state.start++;
			return true;
		};
		const increment = (type) => {
			state[type]++;
			stack.push(type);
		};
		const decrement = (type) => {
			state[type]--;
			stack.pop();
		};
		/**
		* Push tokens onto the tokens array. This helper speeds up
		* tokenizing by 1) helping us avoid backtracking as much as possible,
		* and 2) helping us avoid creating extra tokens when consecutive
		* characters are plain text. This improves performance and simplifies
		* lookbehinds.
		*/
		const push = (tok) => {
			if (prev.type === "globstar") {
				const isBrace = state.braces > 0 && (tok.type === "comma" || tok.type === "brace");
				const isExtglob = tok.extglob === true || extglobs.length && (tok.type === "pipe" || tok.type === "paren");
				if (tok.type !== "slash" && tok.type !== "paren" && !isBrace && !isExtglob) {
					state.output = state.output.slice(0, -prev.output.length);
					prev.type = "star";
					prev.value = "*";
					prev.output = star;
					state.output += prev.output;
				}
			}
			if (extglobs.length && tok.type !== "paren") extglobs[extglobs.length - 1].inner += tok.value;
			if (tok.value || tok.output) append(tok);
			if (prev && prev.type === "text" && tok.type === "text") {
				prev.output = (prev.output || prev.value) + tok.value;
				prev.value += tok.value;
				return;
			}
			tok.prev = prev;
			tokens.push(tok);
			prev = tok;
		};
		const extglobOpen = (type, value) => {
			const token = {
				...EXTGLOB_CHARS[value],
				conditions: 1,
				inner: ""
			};
			token.prev = prev;
			token.parens = state.parens;
			token.output = state.output;
			const output = (opts.capture ? "(" : "") + token.open;
			increment("parens");
			push({
				type,
				value,
				output: state.output ? "" : ONE_CHAR
			});
			push({
				type: "paren",
				extglob: true,
				value: advance(),
				output
			});
			extglobs.push(token);
		};
		const extglobClose = (token) => {
			let output = token.close + (opts.capture ? ")" : "");
			let rest;
			if (token.type === "negate") {
				let extglobStar = star;
				if (token.inner && token.inner.length > 1 && token.inner.includes("/")) extglobStar = globstar(opts);
				if (extglobStar !== star || eos() || /^\)+$/.test(remaining())) output = token.close = `)$))${extglobStar}`;
				if (token.inner.includes("*") && (rest = remaining()) && /^\.[^\\/.]+$/.test(rest)) output = token.close = `)${parse(rest, {
					...options,
					fastpaths: false
				}).output})${extglobStar})`;
				if (token.prev.type === "bos") state.negatedExtglob = true;
			}
			push({
				type: "paren",
				extglob: true,
				value,
				output
			});
			decrement("parens");
		};
		/**
		* Fast paths
		*/
		if (opts.fastpaths !== false && !/(^[*!]|[/()[\]{}"])/.test(input)) {
			let backslashes = false;
			let output = input.replace(REGEX_SPECIAL_CHARS_BACKREF, (m, esc, chars, first, rest, index) => {
				if (first === "\\") {
					backslashes = true;
					return m;
				}
				if (first === "?") {
					if (esc) return esc + first + (rest ? QMARK.repeat(rest.length) : "");
					if (index === 0) return qmarkNoDot + (rest ? QMARK.repeat(rest.length) : "");
					return QMARK.repeat(chars.length);
				}
				if (first === ".") return DOT_LITERAL.repeat(chars.length);
				if (first === "*") {
					if (esc) return esc + first + (rest ? star : "");
					return star;
				}
				return esc ? m : `\\${m}`;
			});
			if (backslashes === true) if (opts.unescape === true) output = output.replace(/\\/g, "");
			else output = output.replace(/\\+/g, (m) => {
				return m.length % 2 === 0 ? "\\\\" : m ? "\\" : "";
			});
			if (output === input && opts.contains === true) {
				state.output = input;
				return state;
			}
			state.output = utils.wrapOutput(output, state, options);
			return state;
		}
		/**
		* Tokenize input until we reach end-of-string
		*/
		while (!eos()) {
			value = advance();
			if (value === "\0") continue;
			/**
			* Escaped characters
			*/
			if (value === "\\") {
				const next = peek();
				if (next === "/" && opts.bash !== true) continue;
				if (next === "." || next === ";") continue;
				if (!next) {
					value += "\\";
					push({
						type: "text",
						value
					});
					continue;
				}
				const match = /^\\+/.exec(remaining());
				let slashes = 0;
				if (match && match[0].length > 2) {
					slashes = match[0].length;
					state.index += slashes;
					if (slashes % 2 !== 0) value += "\\";
				}
				if (opts.unescape === true) value = advance();
				else value += advance();
				if (state.brackets === 0) {
					push({
						type: "text",
						value
					});
					continue;
				}
			}
			/**
			* If we're inside a regex character class, continue
			* until we reach the closing bracket.
			*/
			if (state.brackets > 0 && (value !== "]" || prev.value === "[" || prev.value === "[^")) {
				if (opts.posix !== false && value === ":") {
					const inner = prev.value.slice(1);
					if (inner.includes("[")) {
						prev.posix = true;
						if (inner.includes(":")) {
							const idx = prev.value.lastIndexOf("[");
							const pre = prev.value.slice(0, idx);
							const posix = POSIX_REGEX_SOURCE[prev.value.slice(idx + 2)];
							if (posix) {
								prev.value = pre + posix;
								state.backtrack = true;
								advance();
								if (!bos.output && tokens.indexOf(prev) === 1) bos.output = ONE_CHAR;
								continue;
							}
						}
					}
				}
				if (value === "[" && peek() !== ":" || value === "-" && peek() === "]") value = `\\${value}`;
				if (value === "]" && (prev.value === "[" || prev.value === "[^")) value = `\\${value}`;
				if (opts.posix === true && value === "!" && prev.value === "[") value = "^";
				prev.value += value;
				append({ value });
				continue;
			}
			/**
			* If we're inside a quoted string, continue
			* until we reach the closing double quote.
			*/
			if (state.quotes === 1 && value !== "\"") {
				value = utils.escapeRegex(value);
				prev.value += value;
				append({ value });
				continue;
			}
			/**
			* Double quotes
			*/
			if (value === "\"") {
				state.quotes = state.quotes === 1 ? 0 : 1;
				if (opts.keepQuotes === true) push({
					type: "text",
					value
				});
				continue;
			}
			/**
			* Parentheses
			*/
			if (value === "(") {
				increment("parens");
				push({
					type: "paren",
					value
				});
				continue;
			}
			if (value === ")") {
				if (state.parens === 0 && opts.strictBrackets === true) throw new SyntaxError(syntaxError("opening", "("));
				const extglob = extglobs[extglobs.length - 1];
				if (extglob && state.parens === extglob.parens + 1) {
					extglobClose(extglobs.pop());
					continue;
				}
				push({
					type: "paren",
					value,
					output: state.parens ? ")" : "\\)"
				});
				decrement("parens");
				continue;
			}
			/**
			* Square brackets
			*/
			if (value === "[") {
				if (opts.nobracket === true || !remaining().includes("]")) {
					if (opts.nobracket !== true && opts.strictBrackets === true) throw new SyntaxError(syntaxError("closing", "]"));
					value = `\\${value}`;
				} else increment("brackets");
				push({
					type: "bracket",
					value
				});
				continue;
			}
			if (value === "]") {
				if (opts.nobracket === true || prev && prev.type === "bracket" && prev.value.length === 1) {
					push({
						type: "text",
						value,
						output: `\\${value}`
					});
					continue;
				}
				if (state.brackets === 0) {
					if (opts.strictBrackets === true) throw new SyntaxError(syntaxError("opening", "["));
					push({
						type: "text",
						value,
						output: `\\${value}`
					});
					continue;
				}
				decrement("brackets");
				const prevValue = prev.value.slice(1);
				if (prev.posix !== true && prevValue[0] === "^" && !prevValue.includes("/")) value = `/${value}`;
				prev.value += value;
				append({ value });
				if (opts.literalBrackets === false || utils.hasRegexChars(prevValue)) continue;
				const escaped = utils.escapeRegex(prev.value);
				state.output = state.output.slice(0, -prev.value.length);
				if (opts.literalBrackets === true) {
					state.output += escaped;
					prev.value = escaped;
					continue;
				}
				prev.value = `(${capture}${escaped}|${prev.value})`;
				state.output += prev.value;
				continue;
			}
			/**
			* Braces
			*/
			if (value === "{" && opts.nobrace !== true) {
				increment("braces");
				const open = {
					type: "brace",
					value,
					output: "(",
					outputIndex: state.output.length,
					tokensIndex: state.tokens.length
				};
				braces.push(open);
				push(open);
				continue;
			}
			if (value === "}") {
				const brace = braces[braces.length - 1];
				if (opts.nobrace === true || !brace) {
					push({
						type: "text",
						value,
						output: value
					});
					continue;
				}
				let output = ")";
				if (brace.dots === true) {
					const arr = tokens.slice();
					const range = [];
					for (let i = arr.length - 1; i >= 0; i--) {
						tokens.pop();
						if (arr[i].type === "brace") break;
						if (arr[i].type !== "dots") range.unshift(arr[i].value);
					}
					output = expandRange(range, opts);
					state.backtrack = true;
				}
				if (brace.comma !== true && brace.dots !== true) {
					const out = state.output.slice(0, brace.outputIndex);
					const toks = state.tokens.slice(brace.tokensIndex);
					brace.value = brace.output = "\\{";
					value = output = "\\}";
					state.output = out;
					for (const t of toks) state.output += t.output || t.value;
				}
				push({
					type: "brace",
					value,
					output
				});
				decrement("braces");
				braces.pop();
				continue;
			}
			/**
			* Pipes
			*/
			if (value === "|") {
				if (extglobs.length > 0) extglobs[extglobs.length - 1].conditions++;
				push({
					type: "text",
					value
				});
				continue;
			}
			/**
			* Commas
			*/
			if (value === ",") {
				let output = value;
				const brace = braces[braces.length - 1];
				if (brace && stack[stack.length - 1] === "braces") {
					brace.comma = true;
					output = "|";
				}
				push({
					type: "comma",
					value,
					output
				});
				continue;
			}
			/**
			* Slashes
			*/
			if (value === "/") {
				if (prev.type === "dot" && state.index === state.start + 1) {
					state.start = state.index + 1;
					state.consumed = "";
					state.output = "";
					tokens.pop();
					prev = bos;
					continue;
				}
				push({
					type: "slash",
					value,
					output: SLASH_LITERAL
				});
				continue;
			}
			/**
			* Dots
			*/
			if (value === ".") {
				if (state.braces > 0 && prev.type === "dot") {
					if (prev.value === ".") prev.output = DOT_LITERAL;
					const brace = braces[braces.length - 1];
					prev.type = "dots";
					prev.output += value;
					prev.value += value;
					brace.dots = true;
					continue;
				}
				if (state.braces + state.parens === 0 && prev.type !== "bos" && prev.type !== "slash") {
					push({
						type: "text",
						value,
						output: DOT_LITERAL
					});
					continue;
				}
				push({
					type: "dot",
					value,
					output: DOT_LITERAL
				});
				continue;
			}
			/**
			* Question marks
			*/
			if (value === "?") {
				if (!(prev && prev.value === "(") && opts.noextglob !== true && peek() === "(" && peek(2) !== "?") {
					extglobOpen("qmark", value);
					continue;
				}
				if (prev && prev.type === "paren") {
					const next = peek();
					let output = value;
					if (prev.value === "(" && !/[!=<:]/.test(next) || next === "<" && !/<([!=]|\w+>)/.test(remaining())) output = `\\${value}`;
					push({
						type: "text",
						value,
						output
					});
					continue;
				}
				if (opts.dot !== true && (prev.type === "slash" || prev.type === "bos")) {
					push({
						type: "qmark",
						value,
						output: QMARK_NO_DOT
					});
					continue;
				}
				push({
					type: "qmark",
					value,
					output: QMARK
				});
				continue;
			}
			/**
			* Exclamation
			*/
			if (value === "!") {
				if (opts.noextglob !== true && peek() === "(") {
					if (peek(2) !== "?" || !/[!=<:]/.test(peek(3))) {
						extglobOpen("negate", value);
						continue;
					}
				}
				if (opts.nonegate !== true && state.index === 0) {
					negate();
					continue;
				}
			}
			/**
			* Plus
			*/
			if (value === "+") {
				if (opts.noextglob !== true && peek() === "(" && peek(2) !== "?") {
					extglobOpen("plus", value);
					continue;
				}
				if (prev && prev.value === "(" || opts.regex === false) {
					push({
						type: "plus",
						value,
						output: PLUS_LITERAL
					});
					continue;
				}
				if (prev && (prev.type === "bracket" || prev.type === "paren" || prev.type === "brace") || state.parens > 0) {
					push({
						type: "plus",
						value
					});
					continue;
				}
				push({
					type: "plus",
					value: PLUS_LITERAL
				});
				continue;
			}
			/**
			* Plain text
			*/
			if (value === "@") {
				if (opts.noextglob !== true && peek() === "(" && peek(2) !== "?") {
					push({
						type: "at",
						extglob: true,
						value,
						output: ""
					});
					continue;
				}
				push({
					type: "text",
					value
				});
				continue;
			}
			/**
			* Plain text
			*/
			if (value !== "*") {
				if (value === "$" || value === "^") value = `\\${value}`;
				const match = REGEX_NON_SPECIAL_CHARS.exec(remaining());
				if (match) {
					value += match[0];
					state.index += match[0].length;
				}
				push({
					type: "text",
					value
				});
				continue;
			}
			/**
			* Stars
			*/
			if (prev && (prev.type === "globstar" || prev.star === true)) {
				prev.type = "star";
				prev.star = true;
				prev.value += value;
				prev.output = star;
				state.backtrack = true;
				state.globstar = true;
				consume(value);
				continue;
			}
			let rest = remaining();
			if (opts.noextglob !== true && /^\([^?]/.test(rest)) {
				extglobOpen("star", value);
				continue;
			}
			if (prev.type === "star") {
				if (opts.noglobstar === true) {
					consume(value);
					continue;
				}
				const prior = prev.prev;
				const before = prior.prev;
				const isStart = prior.type === "slash" || prior.type === "bos";
				const afterStar = before && (before.type === "star" || before.type === "globstar");
				if (opts.bash === true && (!isStart || rest[0] && rest[0] !== "/")) {
					push({
						type: "star",
						value,
						output: ""
					});
					continue;
				}
				const isBrace = state.braces > 0 && (prior.type === "comma" || prior.type === "brace");
				const isExtglob = extglobs.length && (prior.type === "pipe" || prior.type === "paren");
				if (!isStart && prior.type !== "paren" && !isBrace && !isExtglob) {
					push({
						type: "star",
						value,
						output: ""
					});
					continue;
				}
				while (rest.slice(0, 3) === "/**") {
					const after = input[state.index + 4];
					if (after && after !== "/") break;
					rest = rest.slice(3);
					consume("/**", 3);
				}
				if (prior.type === "bos" && eos()) {
					prev.type = "globstar";
					prev.value += value;
					prev.output = globstar(opts);
					state.output = prev.output;
					state.globstar = true;
					consume(value);
					continue;
				}
				if (prior.type === "slash" && prior.prev.type !== "bos" && !afterStar && eos()) {
					state.output = state.output.slice(0, -(prior.output + prev.output).length);
					prior.output = `(?:${prior.output}`;
					prev.type = "globstar";
					prev.output = globstar(opts) + (opts.strictSlashes ? ")" : "|$)");
					prev.value += value;
					state.globstar = true;
					state.output += prior.output + prev.output;
					consume(value);
					continue;
				}
				if (prior.type === "slash" && prior.prev.type !== "bos" && rest[0] === "/") {
					const end = rest[1] !== void 0 ? "|$" : "";
					state.output = state.output.slice(0, -(prior.output + prev.output).length);
					prior.output = `(?:${prior.output}`;
					prev.type = "globstar";
					prev.output = `${globstar(opts)}${SLASH_LITERAL}|${SLASH_LITERAL}${end})`;
					prev.value += value;
					state.output += prior.output + prev.output;
					state.globstar = true;
					consume(value + advance());
					push({
						type: "slash",
						value: "/",
						output: ""
					});
					continue;
				}
				if (prior.type === "bos" && rest[0] === "/") {
					prev.type = "globstar";
					prev.value += value;
					prev.output = `(?:^|${SLASH_LITERAL}|${globstar(opts)}${SLASH_LITERAL})`;
					state.output = prev.output;
					state.globstar = true;
					consume(value + advance());
					push({
						type: "slash",
						value: "/",
						output: ""
					});
					continue;
				}
				state.output = state.output.slice(0, -prev.output.length);
				prev.type = "globstar";
				prev.output = globstar(opts);
				prev.value += value;
				state.output += prev.output;
				state.globstar = true;
				consume(value);
				continue;
			}
			const token = {
				type: "star",
				value,
				output: star
			};
			if (opts.bash === true) {
				token.output = ".*?";
				if (prev.type === "bos" || prev.type === "slash") token.output = nodot + token.output;
				push(token);
				continue;
			}
			if (prev && (prev.type === "bracket" || prev.type === "paren") && opts.regex === true) {
				token.output = value;
				push(token);
				continue;
			}
			if (state.index === state.start || prev.type === "slash" || prev.type === "dot") {
				if (prev.type === "dot") {
					state.output += NO_DOT_SLASH;
					prev.output += NO_DOT_SLASH;
				} else if (opts.dot === true) {
					state.output += NO_DOTS_SLASH;
					prev.output += NO_DOTS_SLASH;
				} else {
					state.output += nodot;
					prev.output += nodot;
				}
				if (peek() !== "*") {
					state.output += ONE_CHAR;
					prev.output += ONE_CHAR;
				}
			}
			push(token);
		}
		while (state.brackets > 0) {
			if (opts.strictBrackets === true) throw new SyntaxError(syntaxError("closing", "]"));
			state.output = utils.escapeLast(state.output, "[");
			decrement("brackets");
		}
		while (state.parens > 0) {
			if (opts.strictBrackets === true) throw new SyntaxError(syntaxError("closing", ")"));
			state.output = utils.escapeLast(state.output, "(");
			decrement("parens");
		}
		while (state.braces > 0) {
			if (opts.strictBrackets === true) throw new SyntaxError(syntaxError("closing", "}"));
			state.output = utils.escapeLast(state.output, "{");
			decrement("braces");
		}
		if (opts.strictSlashes !== true && (prev.type === "star" || prev.type === "bracket")) push({
			type: "maybe_slash",
			value: "",
			output: `${SLASH_LITERAL}?`
		});
		if (state.backtrack === true) {
			state.output = "";
			for (const token of state.tokens) {
				state.output += token.output != null ? token.output : token.value;
				if (token.suffix) state.output += token.suffix;
			}
		}
		return state;
	};
	/**
	* Fast paths for creating regular expressions for common glob patterns.
	* This can significantly speed up processing and has very little downside
	* impact when none of the fast paths match.
	*/
	parse.fastpaths = (input, options) => {
		const opts = { ...options };
		const max = typeof opts.maxLength === "number" ? Math.min(MAX_LENGTH, opts.maxLength) : MAX_LENGTH;
		const len = input.length;
		if (len > max) throw new SyntaxError(`Input length: ${len}, exceeds maximum allowed length: ${max}`);
		input = REPLACEMENTS[input] || input;
		const { DOT_LITERAL, SLASH_LITERAL, ONE_CHAR, DOTS_SLASH, NO_DOT, NO_DOTS, NO_DOTS_SLASH, STAR, START_ANCHOR } = constants.globChars(opts.windows);
		const nodot = opts.dot ? NO_DOTS : NO_DOT;
		const slashDot = opts.dot ? NO_DOTS_SLASH : NO_DOT;
		const capture = opts.capture ? "" : "?:";
		const state = {
			negated: false,
			prefix: ""
		};
		let star = opts.bash === true ? ".*?" : STAR;
		if (opts.capture) star = `(${star})`;
		const globstar = (opts) => {
			if (opts.noglobstar === true) return star;
			return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`;
		};
		const create = (str) => {
			switch (str) {
				case "*": return `${nodot}${ONE_CHAR}${star}`;
				case ".*": return `${DOT_LITERAL}${ONE_CHAR}${star}`;
				case "*.*": return `${nodot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`;
				case "*/*": return `${nodot}${star}${SLASH_LITERAL}${ONE_CHAR}${slashDot}${star}`;
				case "**": return nodot + globstar(opts);
				case "**/*": return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${ONE_CHAR}${star}`;
				case "**/*.*": return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`;
				case "**/.*": return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${DOT_LITERAL}${ONE_CHAR}${star}`;
				default: {
					const match = /^(.*?)\.(\w+)$/.exec(str);
					if (!match) return;
					const source = create(match[1]);
					if (!source) return;
					return source + DOT_LITERAL + match[2];
				}
			}
		};
		let source = create(utils.removePrefix(input, state));
		if (source && opts.strictSlashes !== true) source += `${SLASH_LITERAL}?`;
		return source;
	};
	module.exports = parse;
}));

//#endregion
//#region ../node_modules/.pnpm/picomatch@4.0.3/node_modules/picomatch/lib/picomatch.js
var require_picomatch$1 = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const scan = require_scan();
	const parse = require_parse$1();
	const utils = require_utils();
	const constants = require_constants();
	const isObject = (val) => val && typeof val === "object" && !Array.isArray(val);
	/**
	* Creates a matcher function from one or more glob patterns. The
	* returned function takes a string to match as its first argument,
	* and returns true if the string is a match. The returned matcher
	* function also takes a boolean as the second argument that, when true,
	* returns an object with additional information.
	*
	* ```js
	* const picomatch = require('picomatch');
	* // picomatch(glob[, options]);
	*
	* const isMatch = picomatch('*.!(*a)');
	* console.log(isMatch('a.a')); //=> false
	* console.log(isMatch('a.b')); //=> true
	* ```
	* @name picomatch
	* @param {String|Array} `globs` One or more glob patterns.
	* @param {Object=} `options`
	* @return {Function=} Returns a matcher function.
	* @api public
	*/
	const picomatch = (glob, options, returnState = false) => {
		if (Array.isArray(glob)) {
			const fns = glob.map((input) => picomatch(input, options, returnState));
			const arrayMatcher = (str) => {
				for (const isMatch of fns) {
					const state = isMatch(str);
					if (state) return state;
				}
				return false;
			};
			return arrayMatcher;
		}
		const isState = isObject(glob) && glob.tokens && glob.input;
		if (glob === "" || typeof glob !== "string" && !isState) throw new TypeError("Expected pattern to be a non-empty string");
		const opts = options || {};
		const posix = opts.windows;
		const regex = isState ? picomatch.compileRe(glob, options) : picomatch.makeRe(glob, options, false, true);
		const state = regex.state;
		delete regex.state;
		let isIgnored = () => false;
		if (opts.ignore) {
			const ignoreOpts = {
				...options,
				ignore: null,
				onMatch: null,
				onResult: null
			};
			isIgnored = picomatch(opts.ignore, ignoreOpts, returnState);
		}
		const matcher = (input, returnObject = false) => {
			const { isMatch, match, output } = picomatch.test(input, regex, options, {
				glob,
				posix
			});
			const result = {
				glob,
				state,
				regex,
				posix,
				input,
				output,
				match,
				isMatch
			};
			if (typeof opts.onResult === "function") opts.onResult(result);
			if (isMatch === false) {
				result.isMatch = false;
				return returnObject ? result : false;
			}
			if (isIgnored(input)) {
				if (typeof opts.onIgnore === "function") opts.onIgnore(result);
				result.isMatch = false;
				return returnObject ? result : false;
			}
			if (typeof opts.onMatch === "function") opts.onMatch(result);
			return returnObject ? result : true;
		};
		if (returnState) matcher.state = state;
		return matcher;
	};
	/**
	* Test `input` with the given `regex`. This is used by the main
	* `picomatch()` function to test the input string.
	*
	* ```js
	* const picomatch = require('picomatch');
	* // picomatch.test(input, regex[, options]);
	*
	* console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\/([^/]*?))$/));
	* // { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' }
	* ```
	* @param {String} `input` String to test.
	* @param {RegExp} `regex`
	* @return {Object} Returns an object with matching info.
	* @api public
	*/
	picomatch.test = (input, regex, options, { glob, posix } = {}) => {
		if (typeof input !== "string") throw new TypeError("Expected input to be a string");
		if (input === "") return {
			isMatch: false,
			output: ""
		};
		const opts = options || {};
		const format = opts.format || (posix ? utils.toPosixSlashes : null);
		let match = input === glob;
		let output = match && format ? format(input) : input;
		if (match === false) {
			output = format ? format(input) : input;
			match = output === glob;
		}
		if (match === false || opts.capture === true) if (opts.matchBase === true || opts.basename === true) match = picomatch.matchBase(input, regex, options, posix);
		else match = regex.exec(output);
		return {
			isMatch: Boolean(match),
			match,
			output
		};
	};
	/**
	* Match the basename of a filepath.
	*
	* ```js
	* const picomatch = require('picomatch');
	* // picomatch.matchBase(input, glob[, options]);
	* console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true
	* ```
	* @param {String} `input` String to test.
	* @param {RegExp|String} `glob` Glob pattern or regex created by [.makeRe](#makeRe).
	* @return {Boolean}
	* @api public
	*/
	picomatch.matchBase = (input, glob, options) => {
		return (glob instanceof RegExp ? glob : picomatch.makeRe(glob, options)).test(utils.basename(input));
	};
	/**
	* Returns true if **any** of the given glob `patterns` match the specified `string`.
	*
	* ```js
	* const picomatch = require('picomatch');
	* // picomatch.isMatch(string, patterns[, options]);
	*
	* console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true
	* console.log(picomatch.isMatch('a.a', 'b.*')); //=> false
	* ```
	* @param {String|Array} str The string to test.
	* @param {String|Array} patterns One or more glob patterns to use for matching.
	* @param {Object} [options] See available [options](#options).
	* @return {Boolean} Returns true if any patterns match `str`
	* @api public
	*/
	picomatch.isMatch = (str, patterns, options) => picomatch(patterns, options)(str);
	/**
	* Parse a glob pattern to create the source string for a regular
	* expression.
	*
	* ```js
	* const picomatch = require('picomatch');
	* const result = picomatch.parse(pattern[, options]);
	* ```
	* @param {String} `pattern`
	* @param {Object} `options`
	* @return {Object} Returns an object with useful properties and output to be used as a regex source string.
	* @api public
	*/
	picomatch.parse = (pattern, options) => {
		if (Array.isArray(pattern)) return pattern.map((p) => picomatch.parse(p, options));
		return parse(pattern, {
			...options,
			fastpaths: false
		});
	};
	/**
	* Scan a glob pattern to separate the pattern into segments.
	*
	* ```js
	* const picomatch = require('picomatch');
	* // picomatch.scan(input[, options]);
	*
	* const result = picomatch.scan('!./foo/*.js');
	* console.log(result);
	* { prefix: '!./',
	*   input: '!./foo/*.js',
	*   start: 3,
	*   base: 'foo',
	*   glob: '*.js',
	*   isBrace: false,
	*   isBracket: false,
	*   isGlob: true,
	*   isExtglob: false,
	*   isGlobstar: false,
	*   negated: true }
	* ```
	* @param {String} `input` Glob pattern to scan.
	* @param {Object} `options`
	* @return {Object} Returns an object with
	* @api public
	*/
	picomatch.scan = (input, options) => scan(input, options);
	/**
	* Compile a regular expression from the `state` object returned by the
	* [parse()](#parse) method.
	*
	* @param {Object} `state`
	* @param {Object} `options`
	* @param {Boolean} `returnOutput` Intended for implementors, this argument allows you to return the raw output from the parser.
	* @param {Boolean} `returnState` Adds the state to a `state` property on the returned regex. Useful for implementors and debugging.
	* @return {RegExp}
	* @api public
	*/
	picomatch.compileRe = (state, options, returnOutput = false, returnState = false) => {
		if (returnOutput === true) return state.output;
		const opts = options || {};
		const prepend = opts.contains ? "" : "^";
		const append = opts.contains ? "" : "$";
		let source = `${prepend}(?:${state.output})${append}`;
		if (state && state.negated === true) source = `^(?!${source}).*$`;
		const regex = picomatch.toRegex(source, options);
		if (returnState === true) regex.state = state;
		return regex;
	};
	/**
	* Create a regular expression from a parsed glob pattern.
	*
	* ```js
	* const picomatch = require('picomatch');
	* const state = picomatch.parse('*.js');
	* // picomatch.compileRe(state[, options]);
	*
	* console.log(picomatch.compileRe(state));
	* //=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
	* ```
	* @param {String} `state` The object returned from the `.parse` method.
	* @param {Object} `options`
	* @param {Boolean} `returnOutput` Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result.
	* @param {Boolean} `returnState` Implementors may use this argument to return the state from the parsed glob with the returned regular expression.
	* @return {RegExp} Returns a regex created from the given pattern.
	* @api public
	*/
	picomatch.makeRe = (input, options = {}, returnOutput = false, returnState = false) => {
		if (!input || typeof input !== "string") throw new TypeError("Expected a non-empty string");
		let parsed = {
			negated: false,
			fastpaths: true
		};
		if (options.fastpaths !== false && (input[0] === "." || input[0] === "*")) parsed.output = parse.fastpaths(input, options);
		if (!parsed.output) parsed = parse(input, options);
		return picomatch.compileRe(parsed, options, returnOutput, returnState);
	};
	/**
	* Create a regular expression from the given regex source string.
	*
	* ```js
	* const picomatch = require('picomatch');
	* // picomatch.toRegex(source[, options]);
	*
	* const { output } = picomatch.parse('*.js');
	* console.log(picomatch.toRegex(output));
	* //=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
	* ```
	* @param {String} `source` Regular expression source string.
	* @param {Object} `options`
	* @return {RegExp}
	* @api public
	*/
	picomatch.toRegex = (source, options) => {
		try {
			const opts = options || {};
			return new RegExp(source, opts.flags || (opts.nocase ? "i" : ""));
		} catch (err) {
			if (options && options.debug === true) throw err;
			return /$^/;
		}
	};
	/**
	* Picomatch constants.
	* @return {Object}
	*/
	picomatch.constants = constants;
	/**
	* Expose "picomatch"
	*/
	module.exports = picomatch;
}));

//#endregion
//#region ../node_modules/.pnpm/picomatch@4.0.3/node_modules/picomatch/index.js
var require_picomatch = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const pico = require_picomatch$1();
	const utils = require_utils();
	function picomatch(glob, options, returnState = false) {
		if (options && (options.windows === null || options.windows === void 0)) options = {
			...options,
			windows: utils.isWindows()
		};
		return pico(glob, options, returnState);
	}
	Object.assign(picomatch, pico);
	module.exports = picomatch;
}));

//#endregion
//#region ../node_modules/.pnpm/cspell-glob@9.6.4/node_modules/cspell-glob/dist/index.js
var import_picomatch = /* @__PURE__ */ __toESM(require_picomatch(), 1);
const { posix: posix$2 } = Path;
/** test for glob patterns starting with `**` */
const isGlobalPatternRegExp = /^!*[*]{2}/;
const hasGlobCharactersRegExp = /[*?{}[\]]/;
const fileUrlBuilder = new FileUrlBuilder();
const GlobPlaceHolders = { cwd: "${cwd}" };
const GlobPatterns = {
	suffixAny: "/**",
	suffixDir: "/**/*",
	prefixAny: "**/"
};
let cacheCalls = 0;
let cacheMisses = 0;
let cachePath = Path;
let cacheRoot = "<>";
const cache$2 = /* @__PURE__ */ new Map();
/**
* This function tries its best to determine if `fileOrGlob` is a path to a file or a glob pattern.
* @param fileOrGlob - file (with absolute path) or glob.
* @param root - absolute path to the directory that will be considered the root when testing the glob pattern.
* @param path - optional node path methods - used for testing
*/
function fileOrGlobToGlob(fileOrGlob, root, path = Path) {
	if (cacheRoot !== root || cachePath !== path) {
		cache$2.clear();
		cacheCalls = 0;
		cacheMisses = 0;
		cacheRoot = root;
		cachePath = path;
	}
	++cacheCalls;
	const found = cache$2.get(fileOrGlob);
	if (found) return found;
	++cacheMisses;
	const pattern = _fileOrGlobToGlob(fileOrGlob, root, path);
	cache$2.set(fileOrGlob, pattern);
	return pattern;
}
/**
* This function tries its best to determine if `fileOrGlob` is a path to a file or a glob pattern.
* @param fileOrGlob - file (with absolute path) or glob.
* @param root - absolute path to the directory that will be considered the root when testing the glob pattern.
* @param path - optional node path methods - used for testing
*/
function _fileOrGlobToGlob(fileOrGlob, root, path = Path) {
	const toForwardSlash = path.sep === "\\" ? (p) => p.replaceAll("\\", "/") : (p) => p;
	const builder = urlBuilder(path);
	fileOrGlob = typeof fileOrGlob === "string" ? toForwardSlash(fileOrGlob) : fileOrGlob;
	const rootUrl = builder.toFileDirURL(root);
	root = builder.urlToFilePathOrHref(rootUrl);
	return toGlobPatternWithRoot(fileOrGlob, root, builder);
}
function toGlobPatternWithRoot(glob, root, builder) {
	function toPattern() {
		if (isGlobPatternWithRoot(glob)) return fixPatternRoot({ ...glob }, builder);
		const rootUrl = builder.toFileDirURL(root);
		if (typeof glob === "string") return filePathOrGlobToGlob(glob, rootUrl, builder);
		const pattern = {
			isGlobalPattern: isGlobalGlob(glob.glob),
			...glob,
			root: glob.root ?? root
		};
		fixPatternRoot(pattern, builder);
		fixPatternGlob(pattern, builder);
		return pattern;
	}
	const pattern = toPattern();
	if (pattern.glob.startsWith(GlobPlaceHolders.cwd)) {
		pattern.root = GlobPlaceHolders.cwd;
		pattern.glob = pattern.glob.replace(GlobPlaceHolders.cwd, "");
	}
	return pattern;
}
function isGlobPatternWithOptionalRoot(g) {
	return typeof g !== "string" && typeof g.glob === "string";
}
function isGlobPatternWithRoot(g) {
	if (typeof g === "string") return false;
	return typeof g.root === "string" && "isGlobalPattern" in g;
}
function isGlobPatternNormalized(g) {
	if (!isGlobPatternWithRoot(g)) return false;
	const gr = g;
	return "rawGlob" in gr && "rawRoot" in gr && typeof gr.rawGlob === "string";
}
function isGlobPatternNormalizedToRoot(g, options) {
	if (!isGlobPatternNormalized(g)) return false;
	return g.root === options.root;
}
function urlBuilder(path = Path) {
	return path === Path ? fileUrlBuilder : new FileUrlBuilder({ path });
}
/**
* @param pattern glob pattern
* @param nested when true add `**/<glob>/**`
* @returns the set of matching globs.
*/
function normalizePattern$2(pattern, nested) {
	pattern = pattern.replace(/^(!!)+/, "");
	const isNeg = pattern.startsWith("!");
	const prefix = isNeg ? "!" : "";
	pattern = isNeg ? pattern.slice(1) : pattern;
	return (nested ? normalizePatternNested(pattern) : normalizePatternGeneral(pattern)).map((p) => prefix + p);
}
function normalizePatternNested(pattern) {
	if (!pattern.includes("/")) {
		if (pattern === "**") return ["**"];
		return ["**/" + pattern, "**/" + pattern + "/**"];
	}
	const hasLeadingSlash = pattern.startsWith("/");
	pattern = hasLeadingSlash ? pattern.slice(1) : pattern;
	if (pattern.endsWith("/")) return hasLeadingSlash || pattern.slice(0, -1).includes("/") ? [pattern + "**/*"] : ["**/" + pattern + "**/*"];
	if (pattern.endsWith("**")) return [pattern];
	return [pattern, pattern + "/**"];
}
function normalizePatternGeneral(pattern) {
	pattern = pattern.startsWith("/") ? pattern.slice(1) : pattern;
	pattern = pattern.endsWith("/") ? pattern + "**/*" : pattern;
	return [pattern];
}
/**
*
* @param patterns - glob patterns to normalize.
* @param options - Normalization options.
*/
function normalizeGlobPatterns(patterns, options) {
	function* normalize() {
		for (const glob of patterns) {
			if (isGlobPatternNormalized(glob)) {
				yield isGlobPatternNormalizedToRoot(glob, options) ? glob : normalizeGlobToRoot(glob, options.root, options.nodePath || Path);
				continue;
			}
			yield* normalizeGlobPattern(glob, options);
		}
	}
	return [...normalize()];
}
function normalizeGlobPattern(g, options) {
	const { root, nodePath: path = Path, nested } = options;
	const builder = urlBuilder(path);
	const cwd = options.cwd ?? path.resolve();
	const cwdUrl = builder.toFileDirURL(cwd);
	const rootUrl = builder.toFileDirURL(root, cwdUrl);
	const gIsGlobalPattern = isGlobPatternWithRoot(g) ? g.isGlobalPattern : void 0;
	g = !isGlobPatternWithOptionalRoot(g) ? { glob: g } : g;
	const gr = {
		...g,
		root: g.root ?? root
	};
	const rawRoot = gr.root;
	const rawGlob = g.glob;
	gr.glob = trimGlob(g.glob);
	if (gr.glob.startsWith(GlobPlaceHolders.cwd)) {
		gr.glob = gr.glob.replace(GlobPlaceHolders.cwd, "");
		gr.root = GlobPlaceHolders.cwd;
	}
	if (gr.root.startsWith(GlobPlaceHolders.cwd)) {
		const relRoot = gr.root.replace(GlobPlaceHolders.cwd, "./");
		const r = builder.toFileDirURL(relRoot, cwdUrl);
		r.pathname = posix$2.normalize(r.pathname);
		gr.root = builder.urlToFilePathOrHref(r);
	}
	const isGlobalPattern = gIsGlobalPattern ?? isGlobalGlob(gr.glob);
	gr.root = builder.urlToFilePathOrHref(builder.toFileDirURL(gr.root, rootUrl));
	return normalizePattern$2(gr.glob, nested).map((glob) => ({
		...gr,
		glob,
		rawGlob,
		rawRoot,
		isGlobalPattern
	}));
}
/**
* Try to adjust the root of a glob to match a new root. If it is not possible, the original glob is returned.
* Note: this does NOT generate absolutely correct glob patterns. The results are intended to be used as a
* first pass only filter. Followed by testing against the original glob/root pair.
* @param glob - glob to map
* @param root - new root to use if possible
* @param path - Node Path modules to use (testing only)
*/
function normalizeGlobToRoot(glob, root, path) {
	const builder = urlBuilder(path);
	glob = { ...glob };
	fixPatternRoot(glob, builder);
	const rootURL = builder.toFileDirURL(root);
	root = builder.urlToFilePathOrHref(rootURL);
	if (glob.root === root) return glob;
	const globRootUrl = builder.toFileDirURL(glob.root);
	const relFromRootToGlob = builder.relative(rootURL, globRootUrl);
	if (!relFromRootToGlob) return glob;
	if (glob.isGlobalPattern) return {
		...glob,
		root
	};
	const relFromGlobToRoot = builder.relative(globRootUrl, rootURL);
	const globIsUnderRoot = isRelativeValueNested(relFromRootToGlob);
	const rootIsUnderGlob = isRelativeValueNested(relFromGlobToRoot);
	if (!globIsUnderRoot && !rootIsUnderGlob) return glob;
	const isNeg = glob.glob.startsWith("!");
	const g = isNeg ? glob.glob.slice(1) : glob.glob;
	const prefix = isNeg ? "!" : "";
	if (globIsUnderRoot) {
		const relGlob = relFromRootToGlob;
		return {
			...glob,
			glob: prefix + posix$2.join(relGlob, g),
			root
		};
	}
	const rebasedGlob = rebaseGlob(g, nRel(relFromRootToGlob), nRel(relFromGlobToRoot));
	return rebasedGlob ? {
		...glob,
		glob: prefix + rebasedGlob,
		root
	} : glob;
}
function nRel(rel) {
	return rel.endsWith("/") ? rel : rel + "/";
}
function isRelativeValueNested(rel) {
	return !rel || !(rel === ".." || rel.startsWith("../") || rel.startsWith("/"));
}
/**
* Rebase a glob string to a new root.
* @param glob - glob string
* @param fromRootToGlob - relative path from root to globRoot
* @param fromGlobToRoot - relative path from globRoot to root
*/
function rebaseGlob(glob, fromRootToGlob, fromGlobToRoot) {
	if (!fromGlobToRoot || fromGlobToRoot === "/") return glob;
	if (fromRootToGlob.startsWith("../") && !fromGlobToRoot.startsWith("../") && glob.startsWith("**")) return glob;
	fromRootToGlob = nRel(fromRootToGlob);
	fromGlobToRoot = nRel(fromGlobToRoot);
	const relToParts = fromRootToGlob.split("/");
	const relFromParts = fromGlobToRoot.split("/");
	if (glob.startsWith(fromGlobToRoot) && fromRootToGlob === "../".repeat(relToParts.length - 1)) return glob.slice(fromGlobToRoot.length);
	const lastRelIdx = relToParts.findIndex((s) => s !== "..");
	const lastRel = lastRelIdx < 0 ? relToParts.length : lastRelIdx;
	const globParts = [...relToParts.slice(lastRel).filter((a) => a), ...glob.split("/")];
	relToParts.length = lastRel;
	if (fromRootToGlob.startsWith("../") && relFromParts.length !== relToParts.length + 1) return fromRootToGlob + (glob.startsWith("/") ? glob.slice(1) : glob);
	for (let i = 0; i < relFromParts.length && i < globParts.length; ++i) {
		const relSeg = relFromParts[i];
		const globSeg = globParts[i];
		if (!relSeg || globSeg === "**") return globParts.slice(i).join("/");
		if (relSeg !== globSeg && globSeg !== "*") break;
	}
	return fromRootToGlob + (glob.startsWith("/") ? glob.slice(1) : glob);
}
/**
* Trims any trailing spaces, tabs, line-feeds, new-lines, and comments
* @param glob - glob string
* @returns trimmed glob
*/
function trimGlob(glob) {
	glob = globRemoveComment(glob);
	glob = trimGlobLeft(glob);
	glob = trimGlobRight(glob);
	return glob;
}
function globRemoveComment(glob) {
	return glob.replace(/(?<=^|\s)#.*/, "");
}
const spaces = {
	" ": true,
	"	": true,
	"\n": true,
	"\r": true
};
/**
* Trim any trailing spaces, tabs, line-feeds, or new-lines
* Handles a trailing \<space>
* @param glob - glob string
* @returns glob string with space to the right removed.
*/
function trimGlobRight(glob) {
	let i = glob.length - 1;
	while (i >= 0 && glob[i] in spaces) --i;
	if (glob[i] === "\\") ++i;
	++i;
	return i ? glob.slice(0, i) : "";
}
/**
* Trim any leading spaces, tabs, line-feeds, or new-lines
* @param glob - any string
* @returns string with leading spaces removed.
*/
function trimGlobLeft(glob) {
	return glob.trimStart();
}
/**
* Test if a glob pattern has a leading `**`.
* @param glob - the glob
* @returns true if the glob pattern starts with `**`
*/
function isGlobalGlob(glob) {
	return isGlobalPatternRegExp.test(glob);
}
function hasGlobCharacters(glob) {
	return hasGlobCharactersRegExp.test(glob);
}
function isGlobPart(part) {
	if (part === GlobPlaceHolders.cwd) return false;
	return hasGlobCharacters(part);
}
/**
* Split a glob into a path and a glob portion.
* The path portion does not contain any glob characters.
* Path might be empty. The glob portion should always be non-empty.
* @param glob - glob string pattern
* @returns
*/
function splitGlob(glob) {
	const parts = glob.split("/");
	const p = parts.findIndex(isGlobPart);
	const s = p < 0 ? parts.length - 1 : p;
	return createSplitGlob(s ? parts.slice(0, s).join("/") + "/" : void 0, parts.slice(s).join("/"));
}
/**
* Split a glob into a path and a glob portion.
* The path portion does not contain any glob characters.
* Path might be empty. The glob portion should always be non-empty.
* @param glob - glob string pattern
* @param relOnly - Indicates that only `..` and `.` path segments are considered for the path.
* @returns
*/
function splitGlobRel(glob) {
	const parts = glob.split("/");
	if (!parts.includes("..") && !parts.includes(".")) return {
		path: void 0,
		glob
	};
	const firstGlobPartIdx = parts.findIndex(isGlobPart);
	const lastRelIdx = Math.max(parts.lastIndexOf(".."), parts.lastIndexOf("."));
	const p = firstGlobPartIdx >= 0 ? Math.min(firstGlobPartIdx, lastRelIdx + 1) : lastRelIdx + 1;
	const s = p < 0 ? parts.length - 1 : p;
	return createSplitGlob(s ? parts.slice(0, s).join("/") + "/" : void 0, parts.slice(s).join("/"));
}
function createSplitGlob(path, glob) {
	glob = path ? "/" + glob : glob;
	glob = glob.startsWith("/**") ? glob.slice(1) : glob;
	return {
		path,
		glob
	};
}
function rootToUrl(root, builder) {
	if (root.startsWith(GlobPlaceHolders.cwd)) return new URL(builder.normalizeFilePathForUrl(root.replace(GlobPlaceHolders.cwd, ".")), builder.cwd);
	return builder.toFileDirURL(root);
}
function fixPatternRoot(glob, builder) {
	if (glob.root.startsWith(GlobPlaceHolders.cwd)) return glob;
	glob.root = builder.urlToFilePathOrHref(rootToUrl(glob.root, builder));
	return glob;
}
/**
* Adjust the glob pattern in case it is a file or a relative glob.
* @param glob
* @param builder
* @returns
*/
function fixPatternGlob(glob, builder) {
	const rootURL = builder.toFileURL(glob.root);
	const split = splitGlobRel(glob.glob);
	glob.glob = split.glob;
	if (split.path !== void 0) {
		const relRootPath = split.path.startsWith("/") ? "." + split.path : split.path;
		glob.root = builder.urlToFilePathOrHref(builder.toFileDirURL(relRootPath, glob.root));
	}
	fixPatternRelativeToRoot(glob, rootURL, builder);
}
function fixPatternRelativeToRoot(glob, root, builder) {
	if (glob.root.startsWith(GlobPlaceHolders.cwd)) return;
	const rel = builder.relative(root, builder.toFileDirURL(glob.root));
	if (rel.startsWith("/") || rel.startsWith("../")) return;
	glob.root = builder.urlToFilePathOrHref(root);
	glob.glob = rel + glob.glob;
}
function filePathOrGlobToGlob(filePathOrGlob, root, builder) {
	const isGlobalPattern = isGlobalGlob(filePathOrGlob);
	const { path, glob } = builder.isAbsolute(filePathOrGlob) ? splitGlob(filePathOrGlob) : splitGlobRel(filePathOrGlob);
	const url = builder.toFileDirURL(path || "./", root);
	return {
		root: builder.urlToFilePathOrHref(url),
		glob,
		isGlobalPattern
	};
}
function workaroundPicomatchBug(glob) {
	const obj = {};
	return glob.split("/").map((s) => obj[s] ? `{${s},${s}}` : s).join("/");
}
let idGlobMatcher = 0;
var GlobMatcher = class {
	/**
	* @param filename full path of file to match against.
	* @returns a GlobMatch - information about the match.
	*/
	matchEx;
	path;
	patterns;
	patternsNormalizedToRoot;
	/**
	* path or href of the root directory.
	*/
	root;
	dot;
	options;
	/**
	* Instance ID
	*/
	id;
	constructor(patterns, rootOrOptions, _nodePath) {
		this.id = idGlobMatcher++;
		const options = typeof rootOrOptions === "string" || rootOrOptions instanceof URL ? { root: rootOrOptions.toString() } : rootOrOptions ?? {};
		const mode = options.mode ?? "exclude";
		const isExcludeMode = mode !== "include";
		const nodePath = options.nodePath ?? _nodePath ?? Path;
		this.path = nodePath;
		const cwd = options.cwd ?? nodePath.resolve();
		const dot = options.dot ?? isExcludeMode;
		const nested = options.nested ?? isExcludeMode;
		const nobrace = options.nobrace;
		const root = options.root ?? nodePath.resolve();
		const builder = new FileUrlBuilder({ path: nodePath });
		const rootURL = builder.toFileDirURL(root);
		const normalizedRoot = builder.urlToFilePathOrHref(rootURL);
		this.options = {
			root: normalizedRoot,
			dot,
			nodePath,
			nested,
			mode,
			nobrace,
			cwd
		};
		patterns = Array.isArray(patterns) ? patterns : typeof patterns === "string" ? patterns.split(/\r?\n/g) : [patterns];
		const globPatterns = normalizeGlobPatterns(patterns, this.options);
		this.patternsNormalizedToRoot = globPatterns.map((g) => normalizeGlobToRoot(g, normalizedRoot, nodePath)).filter((g) => builder.relative(builder.toFileDirURL(g.root), rootURL) === "");
		this.patterns = globPatterns;
		this.root = normalizedRoot;
		this.dot = dot;
		this.matchEx = buildMatcherFn(this.id, this.patterns, this.options);
	}
	/**
	* Check to see if a filename matches any of the globs.
	* If filename is relative, it is considered relative to the root.
	* If filename is absolute and contained within the root, it will be made relative before being tested for a glob match.
	* If filename is absolute and not contained within the root, it will be tested as is.
	* @param filename full path of the file to check.
	*/
	match(filename) {
		return this.matchEx(filename).matched;
	}
};
/**
* This function attempts to emulate .gitignore functionality as much as possible.
*
* The resulting matcher function: (filename: string) => GlobMatch
*
* If filename is relative, it is considered relative to the root.
* If filename is absolute and contained within the root, it will be made relative before being tested for a glob match.
* If filename is absolute and not contained within the root, it will return a GlobMatchNoRule.
*
* @param patterns - the contents of a .gitignore style file or an array of individual glob rules.
* @param options - defines root and other options
* @returns a function given a filename returns true if it matches.
*/
function buildMatcherFn(_id, patterns, options) {
	const { nodePath, dot, nobrace } = options;
	const builder = new FileUrlBuilder({ path: nodePath });
	const makeReOptions = {
		dot,
		nobrace
	};
	const suffixDir = GlobPatterns.suffixDir;
	const rules = patterns.map((pattern, index) => ({
		pattern,
		index
	})).filter((r) => !!r.pattern.glob).filter((r) => !r.pattern.glob.startsWith("#")).map(({ pattern, index }) => {
		const matchNeg = pattern.glob.match(/^!/);
		const glob = pattern.glob.replace(/^!/, "");
		const isNeg = matchNeg && matchNeg[0].length & 1 && true || false;
		const reg = import_picomatch.default.makeRe(workaroundPicomatchBug(glob), makeReOptions);
		return {
			pattern,
			index,
			isNeg,
			fn: pattern.glob.endsWith(suffixDir) ? (filename) => {
				return reg.test(filename) || filename.endsWith("/") && reg.test(filename + " ");
			} : (filename) => {
				return reg.test(filename);
			},
			reg
		};
	});
	const negRules = rules.filter((r) => r.isNeg);
	const posRules = rules.filter((r) => !r.isNeg);
	const mapRoots = /* @__PURE__ */ new Map();
	const fn = (filename) => {
		const fileUrl = builder.toFileURL(filename);
		const relFilePathname = builder.relative(new URL("file:///"), fileUrl);
		let lastRoot = new URL("placeHolder://");
		let lastRel = "";
		function rootToUrl(root) {
			const found = mapRoots.get(root);
			if (found) return found;
			const url = builder.toFileDirURL(root);
			mapRoots.set(root, url);
			return url;
		}
		function relativeToRoot(root) {
			if (root.href !== lastRoot.href) {
				lastRoot = root;
				lastRel = builder.relative(root, fileUrl);
			}
			return lastRel;
		}
		function testRules(rules, matched) {
			for (const rule of rules) {
				const pattern = rule.pattern;
				const root = pattern.root;
				const rootURL = rootToUrl(root);
				const isRelPat = !pattern.isGlobalPattern;
				let fname = relFilePathname;
				if (isRelPat) {
					const relPathToFile = relativeToRoot(rootURL);
					if (!isRelativeValueNested(relPathToFile)) continue;
					fname = relPathToFile;
				}
				if (rule.fn(fname)) return {
					matched,
					glob: pattern.glob,
					root,
					pattern,
					index: rule.index,
					isNeg: rule.isNeg
				};
			}
		}
		return testRules(negRules, false) || testRules(posRules, true) || { matched: false };
	};
	return fn;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/globs/getGlobMatcher.js
const simpleGlobCache = /* @__PURE__ */ new Map();
let globCache = /* @__PURE__ */ new WeakMap();
onClearCache(() => {
	globCache = /* @__PURE__ */ new WeakMap();
	simpleGlobCache.clear();
});
const emptyIgnorePaths = [];
function getGlobMatcherForExcluding(glob) {
	if (!glob || Array.isArray(glob) && !glob.length) return getGlobMatcherGlobGlob(emptyIgnorePaths);
	return typeof glob === "string" ? getGlobMatcherGlobString(glob) : getGlobMatcherGlobGlob(glob);
}
function getGlobMatcherGlobString(glob) {
	const cached = simpleGlobCache.get(glob);
	if (cached) return cached;
	const m = new GlobMatcher(glob);
	simpleGlobCache.set(glob, m);
	return m;
}
function getGlobMatcherGlobGlob(glob) {
	const cached = globCache.get(glob);
	if (cached) return cached;
	const m = new GlobMatcher(glob);
	globCache.set(glob, m);
	return m;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/globs/checkFilenameMatchesGlob.js
/**
* @param filename - filename
* @param globs - globs
* @returns true if it matches
*/
function checkFilenameMatchesExcludeGlob(filename, globs) {
	return getGlobMatcherForExcluding(globs).match(filename);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/AutoResolve.js
function autoResolve$1(map, key, resolve) {
	const found = map.get(key);
	if (found !== void 0 || map.has(key)) return found;
	const value = resolve(key);
	map.set(key, value);
	return value;
}
var CacheStatsTracker = class {
	hits = 0;
	misses = 0;
	resolved = 0;
	deletes = 0;
	sets = 0;
	clears = 0;
	disposals = 0;
	stats() {
		return {
			hits: this.hits,
			misses: this.misses,
			resolved: this.resolved,
			deletes: this.deletes,
			sets: this.sets,
			clears: this.clears,
			disposals: this.disposals
		};
	}
	clear() {
		this.hits = 0;
		this.misses = 0;
		this.resolved = 0;
		this.deletes = 0;
		this.sets = 0;
		++this.clears;
	}
};
var AutoResolveCache = class {
	map = /* @__PURE__ */ new Map();
	get(k, resolve) {
		return resolve ? autoResolve$1(this.map, k, resolve) : this.map.get(k);
	}
	has(k) {
		return this.map.has(k);
	}
	set(k, v) {
		this.map.set(k, v);
		return this;
	}
	delete(k) {
		return this.map.delete(k);
	}
	clear() {
		this.map.clear();
	}
	dispose() {
		this.clear();
	}
};
function createAutoResolveCache() {
	return new AutoResolveCache();
}
function autoResolveWeak(map, key, resolve) {
	const found = map.get(key);
	if (found !== void 0 || map.has(key)) return found;
	const value = resolve(key);
	map.set(key, value);
	return value;
}
var AutoResolveWeakCache = class {
	_map = /* @__PURE__ */ new WeakMap();
	_stats = new CacheStatsTracker();
	get(k, resolve) {
		const map = this._map;
		const found = map.get(k);
		if (found !== void 0 || map.has(k)) {
			++this._stats.hits;
			return found;
		}
		++this._stats.misses;
		if (!resolve) return;
		++this._stats.resolved;
		const value = resolve(k);
		map.set(k, value);
		return value;
	}
	get map() {
		return this._map;
	}
	has(k) {
		return this._map.has(k);
	}
	set(k, v) {
		++this._stats.sets;
		this._map.set(k, v);
		return this;
	}
	clear() {
		this._stats.clear();
		this._map = /* @__PURE__ */ new WeakMap();
	}
	delete(k) {
		++this._stats.deletes;
		return this._map.delete(k);
	}
	dispose() {
		++this._stats.disposals;
		this.clear();
	}
	stats() {
		return this._stats.stats();
	}
};
function createAutoResolveWeakCache() {
	return new AutoResolveWeakCache();
}
var AutoResolveWeakWeakCache = class {
	_map = /* @__PURE__ */ new WeakMap();
	_stats = new CacheStatsTracker();
	get(k, resolve) {
		const map = this._map;
		const found = map.get(k);
		const foundValue = found?.deref();
		if (found !== void 0 && foundValue) {
			++this._stats.hits;
			return foundValue;
		}
		++this._stats.misses;
		if (!resolve) {
			if (found) map.delete(k);
			return;
		}
		++this._stats.resolved;
		const value = resolve(k);
		map.set(k, new WeakRef(value));
		return value;
	}
	get map() {
		return this._map;
	}
	has(k) {
		return !!this._map.get(k)?.deref();
	}
	set(k, v) {
		++this._stats.sets;
		this._map.set(k, new WeakRef(v));
		return this;
	}
	clear() {
		this._stats.clear();
		this._map = /* @__PURE__ */ new WeakMap();
	}
	delete(k) {
		++this._stats.deletes;
		return this._map.delete(k);
	}
	dispose() {
		++this._stats.disposals;
		this.clear();
	}
	stats() {
		return this._stats.stats();
	}
};
function createAutoResolveWeakWeakCache() {
	return new AutoResolveWeakWeakCache();
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/pkg-info.mjs
/**
* This is the url of the current file, but it might be undefined if the environment does not support it.
*/
const url = import.meta.url;
function calcSrcDirectory() {
	try {
		return __dirname;
	} catch {
		return url ? fileURLToPath(new URL("./", url)) : process.cwd();
	}
}
const srcDirectory = calcSrcDirectory();

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/url.js
/**
* This is a URL that can be used for searching for modules.
* @returns URL for the source directory
*/
function getSourceDirectoryUrl() {
	return toFileDirURL(srcDirectory);
}
function cwdURL() {
	return toFileDirURL("./");
}
function toFileUrl(file) {
	return toFileURL(file, cwdURL());
}
function fileURLOrPathToPath(filenameOrURL) {
	return toFilePathOrHref(filenameOrURL);
}
const regExpWindowsPathDriveLetter = /^([a-zA-Z]):[\\]/;
function windowsDriveLetterToUpper(absoluteFilePath) {
	return absoluteFilePath.replace(regExpWindowsPathDriveLetter, (s) => s.toUpperCase());
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/util.js
const uniqueFn$1 = uniqueFilterFnGenerator$1;
function uniqueFilterFnGenerator$1(extractFn) {
	const values = /* @__PURE__ */ new Set();
	const extractor = extractFn || ((a) => a);
	return (v) => {
		const vv = extractor(v);
		const ret = !values.has(vv);
		values.add(vv);
		return ret;
	};
}
/**
* Delete all `undefined` and `null` fields from an object.
* @param src - object to be cleaned
*/
function clean$1(src) {
	const r = src;
	for (const key of Object.keys(r)) if (r[key] === void 0 || r[key] === null) delete r[key];
	return r;
}
function scanMap(accFn, init) {
	let acc = init;
	let first = true;
	return function(value) {
		if (first && acc === void 0) {
			first = false;
			acc = value;
			return acc;
		}
		acc = accFn(acc, value);
		return acc;
	};
}
function isDefined$2(v) {
	return v !== void 0;
}
/**
* Shallow is Equal test.
* @param a - array of values
* @param b - array of values
* @returns true if the values of `a` are exactly equal to the values of `b`
*/
function isArrayEqual(a, b) {
	if (a === b) return true;
	let isMatch = a.length === b.length;
	for (let i = 0; i < a.length && isMatch; ++i) isMatch = a[i] === b[i];
	return isMatch;
}
/**
* Determine if two sets intersect
* @param a - first Set
* @param b - second Set
* @returns true iff any element of `a` is in `b`
*/
function doSetsIntersect(a, b) {
	function compare(a, b) {
		for (const item of a) if (b.has(item)) return true;
		return false;
	}
	return a.size <= b.size ? compare(a, b) : compare(b, a);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/constants.js
const configSettingsFileVersion0_1 = "0.1";
const configSettingsFileVersion0_2 = "0.2";
const currentSettingsFileVersion = configSettingsFileVersion0_2;
const ENV_CSPELL_GLOB_ROOT = "CSPELL_GLOB_ROOT";
const defaultConfigFileModuleRef = "@cspell/cspell-bundled-dicts/cspell-default.json";

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/internal/CSpellSettingsInternalDef.js
const SymbolCSpellSettingsInternal = Symbol("CSpellSettingsInternal");
function cleanCSpellSettingsInternal(parts) {
	return parts ? Object.assign(clean$1(parts), { [SymbolCSpellSettingsInternal]: true }) : { [SymbolCSpellSettingsInternal]: true };
}
function createCSpellSettingsInternal(parts) {
	return cleanCSpellSettingsInternal({ ...parts });
}
function isCSpellSettingsInternal(cs) {
	return !!cs[SymbolCSpellSettingsInternal];
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-resolver@9.6.4/node_modules/@cspell/cspell-resolver/dist/requireResolve.js
var require_requireResolve = /* @__PURE__ */ __commonJSMin(((exports) => {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.requireResolve = requireResolve;
	function requireResolve(filename, paths) {
		try {
			return __require$1.resolve(filename, paths ? { paths } : void 0);
		} catch {
			return;
		}
	}
}));

//#endregion
//#region ../node_modules/.pnpm/ini@4.1.1/node_modules/ini/lib/ini.js
var require_ini = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const { hasOwnProperty } = Object.prototype;
	const encode = (obj, opt = {}) => {
		if (typeof opt === "string") opt = { section: opt };
		opt.align = opt.align === true;
		opt.newline = opt.newline === true;
		opt.sort = opt.sort === true;
		opt.whitespace = opt.whitespace === true || opt.align === true;
		/* istanbul ignore next */
		opt.platform = opt.platform || typeof process !== "undefined" && process.platform;
		opt.bracketedArray = opt.bracketedArray !== false;
		/* istanbul ignore next */
		const eol = opt.platform === "win32" ? "\r\n" : "\n";
		const separator = opt.whitespace ? " = " : "=";
		const children = [];
		const keys = opt.sort ? Object.keys(obj).sort() : Object.keys(obj);
		let padToChars = 0;
		if (opt.align) padToChars = safe(keys.filter((k) => obj[k] === null || Array.isArray(obj[k]) || typeof obj[k] !== "object").map((k) => Array.isArray(obj[k]) ? `${k}[]` : k).concat([""]).reduce((a, b) => safe(a).length >= safe(b).length ? a : b)).length;
		let out = "";
		const arraySuffix = opt.bracketedArray ? "[]" : "";
		for (const k of keys) {
			const val = obj[k];
			if (val && Array.isArray(val)) for (const item of val) out += safe(`${k}${arraySuffix}`).padEnd(padToChars, " ") + separator + safe(item) + eol;
			else if (val && typeof val === "object") children.push(k);
			else out += safe(k).padEnd(padToChars, " ") + separator + safe(val) + eol;
		}
		if (opt.section && out.length) out = "[" + safe(opt.section) + "]" + (opt.newline ? eol + eol : eol) + out;
		for (const k of children) {
			const nk = splitSections(k, ".").join("\\.");
			const section = (opt.section ? opt.section + "." : "") + nk;
			const child = encode(obj[k], {
				...opt,
				section
			});
			if (out.length && child.length) out += eol;
			out += child;
		}
		return out;
	};
	function splitSections(str, separator) {
		var lastMatchIndex = 0;
		var lastSeparatorIndex = 0;
		var nextIndex = 0;
		var sections = [];
		do {
			nextIndex = str.indexOf(separator, lastMatchIndex);
			if (nextIndex !== -1) {
				lastMatchIndex = nextIndex + separator.length;
				if (nextIndex > 0 && str[nextIndex - 1] === "\\") continue;
				sections.push(str.slice(lastSeparatorIndex, nextIndex));
				lastSeparatorIndex = nextIndex + separator.length;
			}
		} while (nextIndex !== -1);
		sections.push(str.slice(lastSeparatorIndex));
		return sections;
	}
	const decode = (str, opt = {}) => {
		opt.bracketedArray = opt.bracketedArray !== false;
		const out = Object.create(null);
		let p = out;
		let section = null;
		const re = /^\[([^\]]*)\]\s*$|^([^=]+)(=(.*))?$/i;
		const lines = str.split(/[\r\n]+/g);
		const duplicates = {};
		for (const line of lines) {
			if (!line || line.match(/^\s*[;#]/) || line.match(/^\s*$/)) continue;
			const match = line.match(re);
			if (!match) continue;
			if (match[1] !== void 0) {
				section = unsafe(match[1]);
				if (section === "__proto__") {
					p = Object.create(null);
					continue;
				}
				p = out[section] = out[section] || Object.create(null);
				continue;
			}
			const keyRaw = unsafe(match[2]);
			let isArray;
			if (opt.bracketedArray) isArray = keyRaw.length > 2 && keyRaw.slice(-2) === "[]";
			else {
				duplicates[keyRaw] = (duplicates?.[keyRaw] || 0) + 1;
				isArray = duplicates[keyRaw] > 1;
			}
			const key = isArray ? keyRaw.slice(0, -2) : keyRaw;
			if (key === "__proto__") continue;
			const valueRaw = match[3] ? unsafe(match[4]) : true;
			const value = valueRaw === "true" || valueRaw === "false" || valueRaw === "null" ? JSON.parse(valueRaw) : valueRaw;
			if (isArray) {
				if (!hasOwnProperty.call(p, key)) p[key] = [];
				else if (!Array.isArray(p[key])) p[key] = [p[key]];
			}
			if (Array.isArray(p[key])) p[key].push(value);
			else p[key] = value;
		}
		const remove = [];
		for (const k of Object.keys(out)) {
			if (!hasOwnProperty.call(out, k) || typeof out[k] !== "object" || Array.isArray(out[k])) continue;
			const parts = splitSections(k, ".");
			p = out;
			const l = parts.pop();
			const nl = l.replace(/\\\./g, ".");
			for (const part of parts) {
				if (part === "__proto__") continue;
				if (!hasOwnProperty.call(p, part) || typeof p[part] !== "object") p[part] = Object.create(null);
				p = p[part];
			}
			if (p === out && nl === l) continue;
			p[nl] = out[k];
			remove.push(k);
		}
		for (const del of remove) delete out[del];
		return out;
	};
	const isQuoted = (val) => {
		return val.startsWith("\"") && val.endsWith("\"") || val.startsWith("'") && val.endsWith("'");
	};
	const safe = (val) => {
		if (typeof val !== "string" || val.match(/[=\r\n]/) || val.match(/^\[/) || val.length > 1 && isQuoted(val) || val !== val.trim()) return JSON.stringify(val);
		return val.split(";").join("\\;").split("#").join("\\#");
	};
	const unsafe = (val, doUnesc) => {
		val = (val || "").trim();
		if (isQuoted(val)) {
			if (val.charAt(0) === "'") val = val.slice(1, -1);
			try {
				val = JSON.parse(val);
			} catch {}
		} else {
			let esc = false;
			let unesc = "";
			for (let i = 0, l = val.length; i < l; i++) {
				const c = val.charAt(i);
				if (esc) {
					if ("\\;#".indexOf(c) !== -1) unesc += c;
					else unesc += "\\" + c;
					esc = false;
				} else if (";#".indexOf(c) !== -1) break;
				else if (c === "\\") esc = true;
				else unesc += c;
			}
			if (esc) unesc += "\\";
			return unesc.trim();
		}
		return val;
	};
	module.exports = {
		parse: decode,
		decode,
		stringify: encode,
		encode,
		safe,
		unsafe
	};
}));

//#endregion
//#region ../node_modules/.pnpm/global-directory@4.0.1/node_modules/global-directory/index.js
var import_ini = /* @__PURE__ */ __toESM(require_ini(), 1);
const isWindows$1 = process$1.platform === "win32";
const readRc = (filePath) => {
	try {
		return import_ini.default.parse(fs.readFileSync(filePath, "utf8")).prefix;
	} catch {}
};
const getEnvNpmPrefix = () => Object.keys(process$1.env).reduce((prefix, name) => /^npm_config_prefix$/i.test(name) ? process$1.env[name] : prefix, void 0);
const getGlobalNpmrc = () => {
	if (isWindows$1 && process$1.env.APPDATA) return path.join(process$1.env.APPDATA, "/npm/etc/npmrc");
	if (process$1.execPath.includes("/Cellar/node")) {
		const homebrewPrefix = process$1.execPath.slice(0, process$1.execPath.indexOf("/Cellar/node"));
		return path.join(homebrewPrefix, "/lib/node_modules/npm/npmrc");
	}
	if (process$1.execPath.endsWith("/bin/node")) {
		const installDir = path.dirname(path.dirname(process$1.execPath));
		return path.join(installDir, "/etc/npmrc");
	}
};
const getDefaultNpmPrefix = () => {
	if (isWindows$1) {
		const { APPDATA } = process$1.env;
		return APPDATA ? path.join(APPDATA, "npm") : path.dirname(process$1.execPath);
	}
	return path.dirname(path.dirname(process$1.execPath));
};
const getNpmPrefix = () => {
	const envPrefix = getEnvNpmPrefix();
	if (envPrefix) return envPrefix;
	const homePrefix = readRc(path.join(os$1.homedir(), ".npmrc"));
	if (homePrefix) return homePrefix;
	if (process$1.env.PREFIX) return process$1.env.PREFIX;
	const globalPrefix = readRc(getGlobalNpmrc());
	if (globalPrefix) return globalPrefix;
	return getDefaultNpmPrefix();
};
const npmPrefix = path.resolve(getNpmPrefix());
const getYarnWindowsDirectory = () => {
	if (isWindows$1 && process$1.env.LOCALAPPDATA) {
		const dir = path.join(process$1.env.LOCALAPPDATA, "Yarn");
		if (fs.existsSync(dir)) return dir;
	}
	return false;
};
const getYarnPrefix = () => {
	if (process$1.env.PREFIX) return process$1.env.PREFIX;
	const windowsPrefix = getYarnWindowsDirectory();
	if (windowsPrefix) return windowsPrefix;
	const configPrefix = path.join(os$1.homedir(), ".config/yarn");
	if (fs.existsSync(configPrefix)) return configPrefix;
	const homePrefix = path.join(os$1.homedir(), ".yarn-config");
	if (fs.existsSync(homePrefix)) return homePrefix;
	return npmPrefix;
};
const globalDirectory = {};
globalDirectory.npm = {};
globalDirectory.npm.prefix = npmPrefix;
globalDirectory.npm.packages = path.join(npmPrefix, isWindows$1 ? "node_modules" : "lib/node_modules");
globalDirectory.npm.binaries = isWindows$1 ? npmPrefix : path.join(npmPrefix, "bin");
const yarnPrefix = path.resolve(getYarnPrefix());
globalDirectory.yarn = {};
globalDirectory.yarn.prefix = yarnPrefix;
globalDirectory.yarn.packages = path.join(yarnPrefix, getYarnWindowsDirectory() ? "Data/global/node_modules" : "global/node_modules");
globalDirectory.yarn.binaries = path.join(globalDirectory.yarn.packages, ".bin");
var global_directory_default = globalDirectory;

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-resolver@9.6.4/node_modules/@cspell/cspell-resolver/dist/resolveGlobal.mjs
var import_requireResolve = require_requireResolve();
function resolveGlobal(modulesName) {
	return (0, import_requireResolve.requireResolve)(modulesName, [global_directory_default.npm.packages, global_directory_default.yarn.packages]);
}

//#endregion
//#region ../node_modules/.pnpm/import-meta-resolve@4.2.0/node_modules/import-meta-resolve/lib/errors.js
/**
* @typedef ErrnoExceptionFields
* @property {number | undefined} [errnode]
* @property {string | undefined} [code]
* @property {string | undefined} [path]
* @property {string | undefined} [syscall]
* @property {string | undefined} [url]
*
* @typedef {Error & ErrnoExceptionFields} ErrnoException
*/
/**
* @typedef {(...parameters: Array<any>) => string} MessageFunction
*/
const own$1 = {}.hasOwnProperty;
const classRegExp = /^([A-Z][a-z\d]*)+$/;
const kTypes = new Set([
	"string",
	"function",
	"number",
	"object",
	"Function",
	"Object",
	"boolean",
	"bigint",
	"symbol"
]);
const codes = {};
/**
* Create a list string in the form like 'A and B' or 'A, B, ..., and Z'.
* We cannot use Intl.ListFormat because it's not available in
* --without-intl builds.
*
* @param {Array<string>} array
*   An array of strings.
* @param {string} [type]
*   The list type to be inserted before the last element.
* @returns {string}
*/
function formatList(array, type = "and") {
	return array.length < 3 ? array.join(` ${type} `) : `${array.slice(0, -1).join(", ")}, ${type} ${array[array.length - 1]}`;
}
/** @type {Map<string, MessageFunction | string>} */
const messages = /* @__PURE__ */ new Map();
const nodeInternalPrefix = "__node_internal_";
/** @type {number} */
let userStackTraceLimit;
codes.ERR_INVALID_ARG_TYPE = createError(
	"ERR_INVALID_ARG_TYPE",
	/**
	* @param {string} name
	* @param {Array<string> | string} expected
	* @param {unknown} actual
	*/
	(name, expected, actual) => {
		assert.ok(typeof name === "string", "'name' must be a string");
		if (!Array.isArray(expected)) expected = [expected];
		let message = "The ";
		if (name.endsWith(" argument")) message += `${name} `;
		else {
			const type = name.includes(".") ? "property" : "argument";
			message += `"${name}" ${type} `;
		}
		message += "must be ";
		/** @type {Array<string>} */
		const types = [];
		/** @type {Array<string>} */
		const instances = [];
		/** @type {Array<string>} */
		const other = [];
		for (const value of expected) {
			assert.ok(typeof value === "string", "All expected entries have to be of type string");
			if (kTypes.has(value)) types.push(value.toLowerCase());
			else if (classRegExp.exec(value) === null) {
				assert.ok(value !== "object", "The value \"object\" should be written as \"Object\"");
				other.push(value);
			} else instances.push(value);
		}
		if (instances.length > 0) {
			const pos = types.indexOf("object");
			if (pos !== -1) {
				types.slice(pos, 1);
				instances.push("Object");
			}
		}
		if (types.length > 0) {
			message += `${types.length > 1 ? "one of type" : "of type"} ${formatList(types, "or")}`;
			if (instances.length > 0 || other.length > 0) message += " or ";
		}
		if (instances.length > 0) {
			message += `an instance of ${formatList(instances, "or")}`;
			if (other.length > 0) message += " or ";
		}
		if (other.length > 0) if (other.length > 1) message += `one of ${formatList(other, "or")}`;
		else {
			if (other[0].toLowerCase() !== other[0]) message += "an ";
			message += `${other[0]}`;
		}
		message += `. Received ${determineSpecificType(actual)}`;
		return message;
	},
	TypeError
);
codes.ERR_INVALID_MODULE_SPECIFIER = createError(
	"ERR_INVALID_MODULE_SPECIFIER",
	/**
	* @param {string} request
	* @param {string} reason
	* @param {string} [base]
	*/
	(request, reason, base = void 0) => {
		return `Invalid module "${request}" ${reason}${base ? ` imported from ${base}` : ""}`;
	},
	TypeError
);
codes.ERR_INVALID_PACKAGE_CONFIG = createError(
	"ERR_INVALID_PACKAGE_CONFIG",
	/**
	* @param {string} path
	* @param {string} [base]
	* @param {string} [message]
	*/
	(path, base, message) => {
		return `Invalid package config ${path}${base ? ` while importing ${base}` : ""}${message ? `. ${message}` : ""}`;
	},
	Error
);
codes.ERR_INVALID_PACKAGE_TARGET = createError(
	"ERR_INVALID_PACKAGE_TARGET",
	/**
	* @param {string} packagePath
	* @param {string} key
	* @param {unknown} target
	* @param {boolean} [isImport=false]
	* @param {string} [base]
	*/
	(packagePath, key, target, isImport = false, base = void 0) => {
		const relatedError = typeof target === "string" && !isImport && target.length > 0 && !target.startsWith("./");
		if (key === ".") {
			assert.ok(isImport === false);
			return `Invalid "exports" main target ${JSON.stringify(target)} defined in the package config ${packagePath}package.json${base ? ` imported from ${base}` : ""}${relatedError ? "; targets must start with \"./\"" : ""}`;
		}
		return `Invalid "${isImport ? "imports" : "exports"}" target ${JSON.stringify(target)} defined for '${key}' in the package config ${packagePath}package.json${base ? ` imported from ${base}` : ""}${relatedError ? "; targets must start with \"./\"" : ""}`;
	},
	Error
);
codes.ERR_MODULE_NOT_FOUND = createError(
	"ERR_MODULE_NOT_FOUND",
	/**
	* @param {string} path
	* @param {string} base
	* @param {boolean} [exactUrl]
	*/
	(path, base, exactUrl = false) => {
		return `Cannot find ${exactUrl ? "module" : "package"} '${path}' imported from ${base}`;
	},
	Error
);
codes.ERR_NETWORK_IMPORT_DISALLOWED = createError("ERR_NETWORK_IMPORT_DISALLOWED", "import of '%s' by %s is not supported: %s", Error);
codes.ERR_PACKAGE_IMPORT_NOT_DEFINED = createError(
	"ERR_PACKAGE_IMPORT_NOT_DEFINED",
	/**
	* @param {string} specifier
	* @param {string} packagePath
	* @param {string} base
	*/
	(specifier, packagePath, base) => {
		return `Package import specifier "${specifier}" is not defined${packagePath ? ` in package ${packagePath}package.json` : ""} imported from ${base}`;
	},
	TypeError
);
codes.ERR_PACKAGE_PATH_NOT_EXPORTED = createError(
	"ERR_PACKAGE_PATH_NOT_EXPORTED",
	/**
	* @param {string} packagePath
	* @param {string} subpath
	* @param {string} [base]
	*/
	(packagePath, subpath, base = void 0) => {
		if (subpath === ".") return `No "exports" main defined in ${packagePath}package.json${base ? ` imported from ${base}` : ""}`;
		return `Package subpath '${subpath}' is not defined by "exports" in ${packagePath}package.json${base ? ` imported from ${base}` : ""}`;
	},
	Error
);
codes.ERR_UNSUPPORTED_DIR_IMPORT = createError("ERR_UNSUPPORTED_DIR_IMPORT", "Directory import '%s' is not supported resolving ES modules imported from %s", Error);
codes.ERR_UNSUPPORTED_RESOLVE_REQUEST = createError("ERR_UNSUPPORTED_RESOLVE_REQUEST", "Failed to resolve module specifier \"%s\" from \"%s\": Invalid relative URL or base scheme is not hierarchical.", TypeError);
codes.ERR_UNKNOWN_FILE_EXTENSION = createError(
	"ERR_UNKNOWN_FILE_EXTENSION",
	/**
	* @param {string} extension
	* @param {string} path
	*/
	(extension, path) => {
		return `Unknown file extension "${extension}" for ${path}`;
	},
	TypeError
);
codes.ERR_INVALID_ARG_VALUE = createError(
	"ERR_INVALID_ARG_VALUE",
	/**
	* @param {string} name
	* @param {unknown} value
	* @param {string} [reason='is invalid']
	*/
	(name, value, reason = "is invalid") => {
		let inspected = inspect(value);
		if (inspected.length > 128) inspected = `${inspected.slice(0, 128)}...`;
		return `The ${name.includes(".") ? "property" : "argument"} '${name}' ${reason}. Received ${inspected}`;
	},
	TypeError
);
/**
* Utility function for registering the error codes. Only used here. Exported
* *only* to allow for testing.
* @param {string} sym
* @param {MessageFunction | string} value
* @param {ErrorConstructor} constructor
* @returns {new (...parameters: Array<any>) => Error}
*/
function createError(sym, value, constructor) {
	messages.set(sym, value);
	return makeNodeErrorWithCode(constructor, sym);
}
/**
* @param {ErrorConstructor} Base
* @param {string} key
* @returns {ErrorConstructor}
*/
function makeNodeErrorWithCode(Base, key) {
	return NodeError;
	/**
	* @param {Array<unknown>} parameters
	*/
	function NodeError(...parameters) {
		const limit = Error.stackTraceLimit;
		if (isErrorStackTraceLimitWritable()) Error.stackTraceLimit = 0;
		const error = new Base();
		if (isErrorStackTraceLimitWritable()) Error.stackTraceLimit = limit;
		const message = getMessage(key, parameters, error);
		Object.defineProperties(error, {
			message: {
				value: message,
				enumerable: false,
				writable: true,
				configurable: true
			},
			toString: {
				value() {
					return `${this.name} [${key}]: ${this.message}`;
				},
				enumerable: false,
				writable: true,
				configurable: true
			}
		});
		captureLargerStackTrace(error);
		error.code = key;
		return error;
	}
}
/**
* @returns {boolean}
*/
function isErrorStackTraceLimitWritable() {
	try {
		if (v8.startupSnapshot.isBuildingSnapshot()) return false;
	} catch {}
	const desc = Object.getOwnPropertyDescriptor(Error, "stackTraceLimit");
	if (desc === void 0) return Object.isExtensible(Error);
	return own$1.call(desc, "writable") && desc.writable !== void 0 ? desc.writable : desc.set !== void 0;
}
/**
* This function removes unnecessary frames from Node.js core errors.
* @template {(...parameters: unknown[]) => unknown} T
* @param {T} wrappedFunction
* @returns {T}
*/
function hideStackFrames(wrappedFunction) {
	const hidden = nodeInternalPrefix + wrappedFunction.name;
	Object.defineProperty(wrappedFunction, "name", { value: hidden });
	return wrappedFunction;
}
const captureLargerStackTrace = hideStackFrames(
	/**
	* @param {Error} error
	* @returns {Error}
	*/
	function(error) {
		const stackTraceLimitIsWritable = isErrorStackTraceLimitWritable();
		if (stackTraceLimitIsWritable) {
			userStackTraceLimit = Error.stackTraceLimit;
			Error.stackTraceLimit = Number.POSITIVE_INFINITY;
		}
		Error.captureStackTrace(error);
		if (stackTraceLimitIsWritable) Error.stackTraceLimit = userStackTraceLimit;
		return error;
	}
);
/**
* @param {string} key
* @param {Array<unknown>} parameters
* @param {Error} self
* @returns {string}
*/
function getMessage(key, parameters, self) {
	const message = messages.get(key);
	assert.ok(message !== void 0, "expected `message` to be found");
	if (typeof message === "function") {
		assert.ok(message.length <= parameters.length, `Code: ${key}; The provided arguments length (${parameters.length}) does not match the required ones (${message.length}).`);
		return Reflect.apply(message, self, parameters);
	}
	const regex = /%[dfijoOs]/g;
	let expectedLength = 0;
	while (regex.exec(message) !== null) expectedLength++;
	assert.ok(expectedLength === parameters.length, `Code: ${key}; The provided arguments length (${parameters.length}) does not match the required ones (${expectedLength}).`);
	if (parameters.length === 0) return message;
	parameters.unshift(message);
	return Reflect.apply(format, null, parameters);
}
/**
* Determine the specific type of a value for type-mismatch errors.
* @param {unknown} value
* @returns {string}
*/
function determineSpecificType(value) {
	if (value === null || value === void 0) return String(value);
	if (typeof value === "function" && value.name) return `function ${value.name}`;
	if (typeof value === "object") {
		if (value.constructor && value.constructor.name) return `an instance of ${value.constructor.name}`;
		return `${inspect(value, { depth: -1 })}`;
	}
	let inspected = inspect(value, { colors: false });
	if (inspected.length > 28) inspected = `${inspected.slice(0, 25)}...`;
	return `type ${typeof value} (${inspected})`;
}

//#endregion
//#region ../node_modules/.pnpm/import-meta-resolve@4.2.0/node_modules/import-meta-resolve/lib/package-json-reader.js
/**
* @import {ErrnoException} from './errors.js'
*
* @typedef {'commonjs' | 'module' | 'none'} PackageType
*
* @typedef PackageConfig
* @property {string} pjsonPath
* @property {boolean} exists
* @property {string | undefined} [main]
* @property {string | undefined} [name]
* @property {PackageType} type
* @property {Record<string, unknown> | undefined} [exports]
* @property {Record<string, unknown> | undefined} [imports]
*/
const hasOwnProperty$1 = {}.hasOwnProperty;
const { ERR_INVALID_PACKAGE_CONFIG: ERR_INVALID_PACKAGE_CONFIG$1 } = codes;
/** @type {Map<string, PackageConfig>} */
const cache$1 = /* @__PURE__ */ new Map();
/**
* @param {string} jsonPath
* @param {{specifier: URL | string, base?: URL}} options
* @returns {PackageConfig}
*/
function read(jsonPath, { base, specifier }) {
	const existing = cache$1.get(jsonPath);
	if (existing) return existing;
	/** @type {string | undefined} */
	let string;
	try {
		string = fs.readFileSync(path.toNamespacedPath(jsonPath), "utf8");
	} catch (error) {
		const exception = error;
		if (exception.code !== "ENOENT") throw exception;
	}
	/** @type {PackageConfig} */
	const result = {
		exists: false,
		pjsonPath: jsonPath,
		main: void 0,
		name: void 0,
		type: "none",
		exports: void 0,
		imports: void 0
	};
	if (string !== void 0) {
		/** @type {Record<string, unknown>} */
		let parsed;
		try {
			parsed = JSON.parse(string);
		} catch (error_) {
			const cause = error_;
			const error = new ERR_INVALID_PACKAGE_CONFIG$1(jsonPath, (base ? `"${specifier}" from ` : "") + fileURLToPath(base || specifier), cause.message);
			error.cause = cause;
			throw error;
		}
		result.exists = true;
		if (hasOwnProperty$1.call(parsed, "name") && typeof parsed.name === "string") result.name = parsed.name;
		if (hasOwnProperty$1.call(parsed, "main") && typeof parsed.main === "string") result.main = parsed.main;
		if (hasOwnProperty$1.call(parsed, "exports")) result.exports = parsed.exports;
		if (hasOwnProperty$1.call(parsed, "imports")) result.imports = parsed.imports;
		if (hasOwnProperty$1.call(parsed, "type") && (parsed.type === "commonjs" || parsed.type === "module")) result.type = parsed.type;
	}
	cache$1.set(jsonPath, result);
	return result;
}
/**
* @param {URL | string} resolved
* @returns {PackageConfig}
*/
function getPackageScopeConfig(resolved) {
	let packageJSONUrl = new URL("package.json", resolved);
	while (true) {
		if (packageJSONUrl.pathname.endsWith("node_modules/package.json")) break;
		const packageConfig = read(fileURLToPath(packageJSONUrl), { specifier: resolved });
		if (packageConfig.exists) return packageConfig;
		const lastPackageJSONUrl = packageJSONUrl;
		packageJSONUrl = new URL("../package.json", packageJSONUrl);
		if (packageJSONUrl.pathname === lastPackageJSONUrl.pathname) break;
	}
	return {
		pjsonPath: fileURLToPath(packageJSONUrl),
		exists: false,
		type: "none"
	};
}
/**
* Returns the package type for a given URL.
* @param {URL} url - The URL to get the package type for.
* @returns {PackageType}
*/
function getPackageType(url) {
	return getPackageScopeConfig(url).type;
}

//#endregion
//#region ../node_modules/.pnpm/import-meta-resolve@4.2.0/node_modules/import-meta-resolve/lib/get-format.js
const { ERR_UNKNOWN_FILE_EXTENSION } = codes;
const hasOwnProperty = {}.hasOwnProperty;
/** @type {Record<string, string>} */
const extensionFormatMap = {
	__proto__: null,
	".cjs": "commonjs",
	".js": "module",
	".json": "json",
	".mjs": "module"
};
/**
* @param {string | null} mime
* @returns {string | null}
*/
function mimeToFormat(mime) {
	if (mime && /\s*(text|application)\/javascript\s*(;\s*charset=utf-?8\s*)?/i.test(mime)) return "module";
	if (mime === "application/json") return "json";
	return null;
}
/**
* @callback ProtocolHandler
* @param {URL} parsed
* @param {{parentURL: string, source?: Buffer}} context
* @param {boolean} ignoreErrors
* @returns {string | null | void}
*/
/**
* @type {Record<string, ProtocolHandler>}
*/
const protocolHandlers = {
	__proto__: null,
	"data:": getDataProtocolModuleFormat,
	"file:": getFileProtocolModuleFormat,
	"http:": getHttpProtocolModuleFormat,
	"https:": getHttpProtocolModuleFormat,
	"node:"() {
		return "builtin";
	}
};
/**
* @param {URL} parsed
*/
function getDataProtocolModuleFormat(parsed) {
	const { 1: mime } = /^([^/]+\/[^;,]+)[^,]*?(;base64)?,/.exec(parsed.pathname) || [
		null,
		null,
		null
	];
	return mimeToFormat(mime);
}
/**
* Returns the file extension from a URL.
*
* Should give similar result to
* `require('node:path').extname(require('node:url').fileURLToPath(url))`
* when used with a `file:` URL.
*
* @param {URL} url
* @returns {string}
*/
function extname$1(url) {
	const pathname = url.pathname;
	let index = pathname.length;
	while (index--) {
		const code = pathname.codePointAt(index);
		if (code === 47) return "";
		if (code === 46) return pathname.codePointAt(index - 1) === 47 ? "" : pathname.slice(index);
	}
	return "";
}
/**
* @type {ProtocolHandler}
*/
function getFileProtocolModuleFormat(url, _context, ignoreErrors) {
	const value = extname$1(url);
	if (value === ".js") {
		const packageType = getPackageType(url);
		if (packageType !== "none") return packageType;
		return "commonjs";
	}
	if (value === "") {
		const packageType = getPackageType(url);
		if (packageType === "none" || packageType === "commonjs") return "commonjs";
		return "module";
	}
	const format = extensionFormatMap[value];
	if (format) return format;
	if (ignoreErrors) return;
	throw new ERR_UNKNOWN_FILE_EXTENSION(value, fileURLToPath(url));
}
function getHttpProtocolModuleFormat() {}
/**
* @param {URL} url
* @param {{parentURL: string}} context
* @returns {string | null}
*/
function defaultGetFormatWithoutErrors(url, context) {
	const protocol = url.protocol;
	if (!hasOwnProperty.call(protocolHandlers, protocol)) return null;
	return protocolHandlers[protocol](url, context, true) || null;
}

//#endregion
//#region ../node_modules/.pnpm/import-meta-resolve@4.2.0/node_modules/import-meta-resolve/lib/utils.js
const { ERR_INVALID_ARG_VALUE } = codes;
const DEFAULT_CONDITIONS = Object.freeze(["node", "import"]);
const DEFAULT_CONDITIONS_SET = new Set(DEFAULT_CONDITIONS);
/**
* Returns the default conditions for ES module loading.
*/
function getDefaultConditions() {
	return DEFAULT_CONDITIONS;
}
/**
* Returns the default conditions for ES module loading, as a Set.
*/
function getDefaultConditionsSet() {
	return DEFAULT_CONDITIONS_SET;
}
/**
* @param {Array<string>} [conditions]
* @returns {Set<string>}
*/
function getConditionsSet(conditions) {
	if (conditions !== void 0 && conditions !== getDefaultConditions()) {
		if (!Array.isArray(conditions)) throw new ERR_INVALID_ARG_VALUE("conditions", conditions, "expected an array");
		return new Set(conditions);
	}
	return getDefaultConditionsSet();
}

//#endregion
//#region ../node_modules/.pnpm/import-meta-resolve@4.2.0/node_modules/import-meta-resolve/lib/resolve.js
/**
* @import {Stats} from 'node:fs'
* @import {ErrnoException} from './errors.js'
* @import {PackageConfig} from './package-json-reader.js'
*/
const RegExpPrototypeSymbolReplace = RegExp.prototype[Symbol.replace];
const { ERR_NETWORK_IMPORT_DISALLOWED, ERR_INVALID_MODULE_SPECIFIER, ERR_INVALID_PACKAGE_CONFIG, ERR_INVALID_PACKAGE_TARGET, ERR_MODULE_NOT_FOUND, ERR_PACKAGE_IMPORT_NOT_DEFINED, ERR_PACKAGE_PATH_NOT_EXPORTED, ERR_UNSUPPORTED_DIR_IMPORT, ERR_UNSUPPORTED_RESOLVE_REQUEST } = codes;
const own = {}.hasOwnProperty;
const invalidSegmentRegEx = /(^|\\|\/)((\.|%2e)(\.|%2e)?|(n|%6e|%4e)(o|%6f|%4f)(d|%64|%44)(e|%65|%45)(_|%5f)(m|%6d|%4d)(o|%6f|%4f)(d|%64|%44)(u|%75|%55)(l|%6c|%4c)(e|%65|%45)(s|%73|%53))?(\\|\/|$)/i;
const deprecatedInvalidSegmentRegEx = /(^|\\|\/)((\.|%2e)(\.|%2e)?|(n|%6e|%4e)(o|%6f|%4f)(d|%64|%44)(e|%65|%45)(_|%5f)(m|%6d|%4d)(o|%6f|%4f)(d|%64|%44)(u|%75|%55)(l|%6c|%4c)(e|%65|%45)(s|%73|%53))(\\|\/|$)/i;
const invalidPackageNameRegEx = /^\.|%|\\/;
const patternRegEx = /\*/g;
const encodedSeparatorRegEx = /%2f|%5c/i;
/** @type {Set<string>} */
const emittedPackageWarnings = /* @__PURE__ */ new Set();
const doubleSlashRegEx = /[/\\]{2}/;
/**
*
* @param {string} target
* @param {string} request
* @param {string} match
* @param {URL} packageJsonUrl
* @param {boolean} internal
* @param {URL} base
* @param {boolean} isTarget
*/
function emitInvalidSegmentDeprecation(target, request, match, packageJsonUrl, internal, base, isTarget) {
	if (process$1.noDeprecation) return;
	const pjsonPath = fileURLToPath(packageJsonUrl);
	const double = doubleSlashRegEx.exec(isTarget ? target : request) !== null;
	process$1.emitWarning(`Use of deprecated ${double ? "double slash" : "leading or trailing slash matching"} resolving "${target}" for module request "${request}" ${request === match ? "" : `matched to "${match}" `}in the "${internal ? "imports" : "exports"}" field module resolution of the package at ${pjsonPath}${base ? ` imported from ${fileURLToPath(base)}` : ""}.`, "DeprecationWarning", "DEP0166");
}
/**
* @param {URL} url
* @param {URL} packageJsonUrl
* @param {URL} base
* @param {string} [main]
* @returns {void}
*/
function emitLegacyIndexDeprecation(url, packageJsonUrl, base, main) {
	if (process$1.noDeprecation) return;
	if (defaultGetFormatWithoutErrors(url, { parentURL: base.href }) !== "module") return;
	const urlPath = fileURLToPath(url.href);
	const packagePath = fileURLToPath(new URL(".", packageJsonUrl));
	const basePath = fileURLToPath(base);
	if (!main) process$1.emitWarning(`No "main" or "exports" field defined in the package.json for ${packagePath} resolving the main entry point "${urlPath.slice(packagePath.length)}", imported from ${basePath}.\nDefault "index" lookups for the main are deprecated for ES modules.`, "DeprecationWarning", "DEP0151");
	else if (path.resolve(packagePath, main) !== urlPath) process$1.emitWarning(`Package ${packagePath} has a "main" field set to "${main}", excluding the full filename and extension to the resolved file at "${urlPath.slice(packagePath.length)}", imported from ${basePath}.\n Automatic extension resolution of the "main" field is deprecated for ES modules.`, "DeprecationWarning", "DEP0151");
}
/**
* @param {string} path
* @returns {Stats | undefined}
*/
function tryStatSync(path) {
	try {
		return statSync(path);
	} catch {}
}
/**
* Legacy CommonJS main resolution:
* 1. let M = pkg_url + (json main field)
* 2. TRY(M, M.js, M.json, M.node)
* 3. TRY(M/index.js, M/index.json, M/index.node)
* 4. TRY(pkg_url/index.js, pkg_url/index.json, pkg_url/index.node)
* 5. NOT_FOUND
*
* @param {URL} url
* @returns {boolean}
*/
function fileExists(url) {
	const stats = statSync(url, { throwIfNoEntry: false });
	const isFile = stats ? stats.isFile() : void 0;
	return isFile === null || isFile === void 0 ? false : isFile;
}
/**
* @param {URL} packageJsonUrl
* @param {PackageConfig} packageConfig
* @param {URL} base
* @returns {URL}
*/
function legacyMainResolve(packageJsonUrl, packageConfig, base) {
	/** @type {URL | undefined} */
	let guess;
	if (packageConfig.main !== void 0) {
		guess = new URL(packageConfig.main, packageJsonUrl);
		if (fileExists(guess)) return guess;
		const tries = [
			`./${packageConfig.main}.js`,
			`./${packageConfig.main}.json`,
			`./${packageConfig.main}.node`,
			`./${packageConfig.main}/index.js`,
			`./${packageConfig.main}/index.json`,
			`./${packageConfig.main}/index.node`
		];
		let i = -1;
		while (++i < tries.length) {
			guess = new URL(tries[i], packageJsonUrl);
			if (fileExists(guess)) break;
			guess = void 0;
		}
		if (guess) {
			emitLegacyIndexDeprecation(guess, packageJsonUrl, base, packageConfig.main);
			return guess;
		}
	}
	const tries = [
		"./index.js",
		"./index.json",
		"./index.node"
	];
	let i = -1;
	while (++i < tries.length) {
		guess = new URL(tries[i], packageJsonUrl);
		if (fileExists(guess)) break;
		guess = void 0;
	}
	if (guess) {
		emitLegacyIndexDeprecation(guess, packageJsonUrl, base, packageConfig.main);
		return guess;
	}
	throw new ERR_MODULE_NOT_FOUND(fileURLToPath(new URL(".", packageJsonUrl)), fileURLToPath(base));
}
/**
* @param {URL} resolved
* @param {URL} base
* @param {boolean} [preserveSymlinks]
* @returns {URL}
*/
function finalizeResolution(resolved, base, preserveSymlinks) {
	if (encodedSeparatorRegEx.exec(resolved.pathname) !== null) throw new ERR_INVALID_MODULE_SPECIFIER(resolved.pathname, "must not include encoded \"/\" or \"\\\" characters", fileURLToPath(base));
	/** @type {string} */
	let filePath;
	try {
		filePath = fileURLToPath(resolved);
	} catch (error) {
		const cause = error;
		Object.defineProperty(cause, "input", { value: String(resolved) });
		Object.defineProperty(cause, "module", { value: String(base) });
		throw cause;
	}
	const stats = tryStatSync(filePath.endsWith("/") ? filePath.slice(-1) : filePath);
	if (stats && stats.isDirectory()) {
		const error = new ERR_UNSUPPORTED_DIR_IMPORT(filePath, fileURLToPath(base));
		error.url = String(resolved);
		throw error;
	}
	if (!stats || !stats.isFile()) {
		const error = new ERR_MODULE_NOT_FOUND(filePath || resolved.pathname, base && fileURLToPath(base), true);
		error.url = String(resolved);
		throw error;
	}
	if (!preserveSymlinks) {
		const real = realpathSync(filePath);
		const { search, hash } = resolved;
		resolved = pathToFileURL(real + (filePath.endsWith(path.sep) ? "/" : ""));
		resolved.search = search;
		resolved.hash = hash;
	}
	return resolved;
}
/**
* @param {string} specifier
* @param {URL | undefined} packageJsonUrl
* @param {URL} base
* @returns {Error}
*/
function importNotDefined(specifier, packageJsonUrl, base) {
	return new ERR_PACKAGE_IMPORT_NOT_DEFINED(specifier, packageJsonUrl && fileURLToPath(new URL(".", packageJsonUrl)), fileURLToPath(base));
}
/**
* @param {string} subpath
* @param {URL} packageJsonUrl
* @param {URL} base
* @returns {Error}
*/
function exportsNotFound(subpath, packageJsonUrl, base) {
	return new ERR_PACKAGE_PATH_NOT_EXPORTED(fileURLToPath(new URL(".", packageJsonUrl)), subpath, base && fileURLToPath(base));
}
/**
* @param {string} request
* @param {string} match
* @param {URL} packageJsonUrl
* @param {boolean} internal
* @param {URL} [base]
* @returns {never}
*/
function throwInvalidSubpath(request, match, packageJsonUrl, internal, base) {
	throw new ERR_INVALID_MODULE_SPECIFIER(request, `request is not a valid match in pattern "${match}" for the "${internal ? "imports" : "exports"}" resolution of ${fileURLToPath(packageJsonUrl)}`, base && fileURLToPath(base));
}
/**
* @param {string} subpath
* @param {unknown} target
* @param {URL} packageJsonUrl
* @param {boolean} internal
* @param {URL} [base]
* @returns {Error}
*/
function invalidPackageTarget(subpath, target, packageJsonUrl, internal, base) {
	target = typeof target === "object" && target !== null ? JSON.stringify(target, null, "") : `${target}`;
	return new ERR_INVALID_PACKAGE_TARGET(fileURLToPath(new URL(".", packageJsonUrl)), subpath, target, internal, base && fileURLToPath(base));
}
/**
* @param {string} target
* @param {string} subpath
* @param {string} match
* @param {URL} packageJsonUrl
* @param {URL} base
* @param {boolean} pattern
* @param {boolean} internal
* @param {boolean} isPathMap
* @param {Set<string> | undefined} conditions
* @returns {URL}
*/
function resolvePackageTargetString(target, subpath, match, packageJsonUrl, base, pattern, internal, isPathMap, conditions) {
	if (subpath !== "" && !pattern && target[target.length - 1] !== "/") throw invalidPackageTarget(match, target, packageJsonUrl, internal, base);
	if (!target.startsWith("./")) {
		if (internal && !target.startsWith("../") && !target.startsWith("/")) {
			let isURL = false;
			try {
				new URL(target);
				isURL = true;
			} catch {}
			if (!isURL) return packageResolve(pattern ? RegExpPrototypeSymbolReplace.call(patternRegEx, target, () => subpath) : target + subpath, packageJsonUrl, conditions);
		}
		throw invalidPackageTarget(match, target, packageJsonUrl, internal, base);
	}
	if (invalidSegmentRegEx.exec(target.slice(2)) !== null) if (deprecatedInvalidSegmentRegEx.exec(target.slice(2)) === null) {
		if (!isPathMap) {
			const request = pattern ? match.replace("*", () => subpath) : match + subpath;
			emitInvalidSegmentDeprecation(pattern ? RegExpPrototypeSymbolReplace.call(patternRegEx, target, () => subpath) : target, request, match, packageJsonUrl, internal, base, true);
		}
	} else throw invalidPackageTarget(match, target, packageJsonUrl, internal, base);
	const resolved = new URL(target, packageJsonUrl);
	const resolvedPath = resolved.pathname;
	const packagePath = new URL(".", packageJsonUrl).pathname;
	if (!resolvedPath.startsWith(packagePath)) throw invalidPackageTarget(match, target, packageJsonUrl, internal, base);
	if (subpath === "") return resolved;
	if (invalidSegmentRegEx.exec(subpath) !== null) {
		const request = pattern ? match.replace("*", () => subpath) : match + subpath;
		if (deprecatedInvalidSegmentRegEx.exec(subpath) === null) {
			if (!isPathMap) emitInvalidSegmentDeprecation(pattern ? RegExpPrototypeSymbolReplace.call(patternRegEx, target, () => subpath) : target, request, match, packageJsonUrl, internal, base, false);
		} else throwInvalidSubpath(request, match, packageJsonUrl, internal, base);
	}
	if (pattern) return new URL(RegExpPrototypeSymbolReplace.call(patternRegEx, resolved.href, () => subpath));
	return new URL(subpath, resolved);
}
/**
* @param {string} key
* @returns {boolean}
*/
function isArrayIndex(key) {
	const keyNumber = Number(key);
	if (`${keyNumber}` !== key) return false;
	return keyNumber >= 0 && keyNumber < 4294967295;
}
/**
* @param {URL} packageJsonUrl
* @param {unknown} target
* @param {string} subpath
* @param {string} packageSubpath
* @param {URL} base
* @param {boolean} pattern
* @param {boolean} internal
* @param {boolean} isPathMap
* @param {Set<string> | undefined} conditions
* @returns {URL | null}
*/
function resolvePackageTarget(packageJsonUrl, target, subpath, packageSubpath, base, pattern, internal, isPathMap, conditions) {
	if (typeof target === "string") return resolvePackageTargetString(target, subpath, packageSubpath, packageJsonUrl, base, pattern, internal, isPathMap, conditions);
	if (Array.isArray(target)) {
		/** @type {Array<unknown>} */
		const targetList = target;
		if (targetList.length === 0) return null;
		/** @type {ErrnoException | null | undefined} */
		let lastException;
		let i = -1;
		while (++i < targetList.length) {
			const targetItem = targetList[i];
			/** @type {URL | null} */
			let resolveResult;
			try {
				resolveResult = resolvePackageTarget(packageJsonUrl, targetItem, subpath, packageSubpath, base, pattern, internal, isPathMap, conditions);
			} catch (error) {
				const exception = error;
				lastException = exception;
				if (exception.code === "ERR_INVALID_PACKAGE_TARGET") continue;
				throw error;
			}
			if (resolveResult === void 0) continue;
			if (resolveResult === null) {
				lastException = null;
				continue;
			}
			return resolveResult;
		}
		if (lastException === void 0 || lastException === null) return null;
		throw lastException;
	}
	if (typeof target === "object" && target !== null) {
		const keys = Object.getOwnPropertyNames(target);
		let i = -1;
		while (++i < keys.length) {
			const key = keys[i];
			if (isArrayIndex(key)) throw new ERR_INVALID_PACKAGE_CONFIG(fileURLToPath(packageJsonUrl), base, "\"exports\" cannot contain numeric property keys.");
		}
		i = -1;
		while (++i < keys.length) {
			const key = keys[i];
			if (key === "default" || conditions && conditions.has(key)) {
				const conditionalTarget = target[key];
				const resolveResult = resolvePackageTarget(packageJsonUrl, conditionalTarget, subpath, packageSubpath, base, pattern, internal, isPathMap, conditions);
				if (resolveResult === void 0) continue;
				return resolveResult;
			}
		}
		return null;
	}
	if (target === null) return null;
	throw invalidPackageTarget(packageSubpath, target, packageJsonUrl, internal, base);
}
/**
* @param {unknown} exports
* @param {URL} packageJsonUrl
* @param {URL} base
* @returns {boolean}
*/
function isConditionalExportsMainSugar(exports, packageJsonUrl, base) {
	if (typeof exports === "string" || Array.isArray(exports)) return true;
	if (typeof exports !== "object" || exports === null) return false;
	const keys = Object.getOwnPropertyNames(exports);
	let isConditionalSugar = false;
	let i = 0;
	let keyIndex = -1;
	while (++keyIndex < keys.length) {
		const key = keys[keyIndex];
		const currentIsConditionalSugar = key === "" || key[0] !== ".";
		if (i++ === 0) isConditionalSugar = currentIsConditionalSugar;
		else if (isConditionalSugar !== currentIsConditionalSugar) throw new ERR_INVALID_PACKAGE_CONFIG(fileURLToPath(packageJsonUrl), base, "\"exports\" cannot contain some keys starting with '.' and some not. The exports object must either be an object of package subpath keys or an object of main entry condition name keys only.");
	}
	return isConditionalSugar;
}
/**
* @param {string} match
* @param {URL} pjsonUrl
* @param {URL} base
*/
function emitTrailingSlashPatternDeprecation(match, pjsonUrl, base) {
	if (process$1.noDeprecation) return;
	const pjsonPath = fileURLToPath(pjsonUrl);
	if (emittedPackageWarnings.has(pjsonPath + "|" + match)) return;
	emittedPackageWarnings.add(pjsonPath + "|" + match);
	process$1.emitWarning(`Use of deprecated trailing slash pattern mapping "${match}" in the "exports" field module resolution of the package at ${pjsonPath}${base ? ` imported from ${fileURLToPath(base)}` : ""}. Mapping specifiers ending in "/" is no longer supported.`, "DeprecationWarning", "DEP0155");
}
/**
* @param {URL} packageJsonUrl
* @param {string} packageSubpath
* @param {Record<string, unknown>} packageConfig
* @param {URL} base
* @param {Set<string> | undefined} conditions
* @returns {URL}
*/
function packageExportsResolve(packageJsonUrl, packageSubpath, packageConfig, base, conditions) {
	let exports = packageConfig.exports;
	if (isConditionalExportsMainSugar(exports, packageJsonUrl, base)) exports = { ".": exports };
	if (own.call(exports, packageSubpath) && !packageSubpath.includes("*") && !packageSubpath.endsWith("/")) {
		const target = exports[packageSubpath];
		const resolveResult = resolvePackageTarget(packageJsonUrl, target, "", packageSubpath, base, false, false, false, conditions);
		if (resolveResult === null || resolveResult === void 0) throw exportsNotFound(packageSubpath, packageJsonUrl, base);
		return resolveResult;
	}
	let bestMatch = "";
	let bestMatchSubpath = "";
	const keys = Object.getOwnPropertyNames(exports);
	let i = -1;
	while (++i < keys.length) {
		const key = keys[i];
		const patternIndex = key.indexOf("*");
		if (patternIndex !== -1 && packageSubpath.startsWith(key.slice(0, patternIndex))) {
			if (packageSubpath.endsWith("/")) emitTrailingSlashPatternDeprecation(packageSubpath, packageJsonUrl, base);
			const patternTrailer = key.slice(patternIndex + 1);
			if (packageSubpath.length >= key.length && packageSubpath.endsWith(patternTrailer) && patternKeyCompare(bestMatch, key) === 1 && key.lastIndexOf("*") === patternIndex) {
				bestMatch = key;
				bestMatchSubpath = packageSubpath.slice(patternIndex, packageSubpath.length - patternTrailer.length);
			}
		}
	}
	if (bestMatch) {
		const target = exports[bestMatch];
		const resolveResult = resolvePackageTarget(packageJsonUrl, target, bestMatchSubpath, bestMatch, base, true, false, packageSubpath.endsWith("/"), conditions);
		if (resolveResult === null || resolveResult === void 0) throw exportsNotFound(packageSubpath, packageJsonUrl, base);
		return resolveResult;
	}
	throw exportsNotFound(packageSubpath, packageJsonUrl, base);
}
/**
* @param {string} a
* @param {string} b
*/
function patternKeyCompare(a, b) {
	const aPatternIndex = a.indexOf("*");
	const bPatternIndex = b.indexOf("*");
	const baseLengthA = aPatternIndex === -1 ? a.length : aPatternIndex + 1;
	const baseLengthB = bPatternIndex === -1 ? b.length : bPatternIndex + 1;
	if (baseLengthA > baseLengthB) return -1;
	if (baseLengthB > baseLengthA) return 1;
	if (aPatternIndex === -1) return 1;
	if (bPatternIndex === -1) return -1;
	if (a.length > b.length) return -1;
	if (b.length > a.length) return 1;
	return 0;
}
/**
* @param {string} name
* @param {URL} base
* @param {Set<string>} [conditions]
* @returns {URL}
*/
function packageImportsResolve(name, base, conditions) {
	if (name === "#" || name.startsWith("#/") || name.endsWith("/")) throw new ERR_INVALID_MODULE_SPECIFIER(name, "is not a valid internal imports specifier name", fileURLToPath(base));
	/** @type {URL | undefined} */
	let packageJsonUrl;
	const packageConfig = getPackageScopeConfig(base);
	if (packageConfig.exists) {
		packageJsonUrl = pathToFileURL(packageConfig.pjsonPath);
		const imports = packageConfig.imports;
		if (imports) if (own.call(imports, name) && !name.includes("*")) {
			const resolveResult = resolvePackageTarget(packageJsonUrl, imports[name], "", name, base, false, true, false, conditions);
			if (resolveResult !== null && resolveResult !== void 0) return resolveResult;
		} else {
			let bestMatch = "";
			let bestMatchSubpath = "";
			const keys = Object.getOwnPropertyNames(imports);
			let i = -1;
			while (++i < keys.length) {
				const key = keys[i];
				const patternIndex = key.indexOf("*");
				if (patternIndex !== -1 && name.startsWith(key.slice(0, -1))) {
					const patternTrailer = key.slice(patternIndex + 1);
					if (name.length >= key.length && name.endsWith(patternTrailer) && patternKeyCompare(bestMatch, key) === 1 && key.lastIndexOf("*") === patternIndex) {
						bestMatch = key;
						bestMatchSubpath = name.slice(patternIndex, name.length - patternTrailer.length);
					}
				}
			}
			if (bestMatch) {
				const target = imports[bestMatch];
				const resolveResult = resolvePackageTarget(packageJsonUrl, target, bestMatchSubpath, bestMatch, base, true, true, false, conditions);
				if (resolveResult !== null && resolveResult !== void 0) return resolveResult;
			}
		}
	}
	throw importNotDefined(name, packageJsonUrl, base);
}
/**
* @param {string} specifier
* @param {URL} base
*/
function parsePackageName(specifier, base) {
	let separatorIndex = specifier.indexOf("/");
	let validPackageName = true;
	let isScoped = false;
	if (specifier[0] === "@") {
		isScoped = true;
		if (separatorIndex === -1 || specifier.length === 0) validPackageName = false;
		else separatorIndex = specifier.indexOf("/", separatorIndex + 1);
	}
	const packageName = separatorIndex === -1 ? specifier : specifier.slice(0, separatorIndex);
	if (invalidPackageNameRegEx.exec(packageName) !== null) validPackageName = false;
	if (!validPackageName) throw new ERR_INVALID_MODULE_SPECIFIER(specifier, "is not a valid package name", fileURLToPath(base));
	return {
		packageName,
		packageSubpath: "." + (separatorIndex === -1 ? "" : specifier.slice(separatorIndex)),
		isScoped
	};
}
/**
* @param {string} specifier
* @param {URL} base
* @param {Set<string> | undefined} conditions
* @returns {URL}
*/
function packageResolve(specifier, base, conditions) {
	if (builtinModules.includes(specifier)) return new URL("node:" + specifier);
	const { packageName, packageSubpath, isScoped } = parsePackageName(specifier, base);
	const packageConfig = getPackageScopeConfig(base);
	/* c8 ignore next 16 */
	if (packageConfig.exists) {
		const packageJsonUrl = pathToFileURL(packageConfig.pjsonPath);
		if (packageConfig.name === packageName && packageConfig.exports !== void 0 && packageConfig.exports !== null) return packageExportsResolve(packageJsonUrl, packageSubpath, packageConfig, base, conditions);
	}
	let packageJsonUrl = new URL("./node_modules/" + packageName + "/package.json", base);
	let packageJsonPath = fileURLToPath(packageJsonUrl);
	/** @type {string} */
	let lastPath;
	do {
		const stat = tryStatSync(packageJsonPath.slice(0, -13));
		if (!stat || !stat.isDirectory()) {
			lastPath = packageJsonPath;
			packageJsonUrl = new URL((isScoped ? "../../../../node_modules/" : "../../../node_modules/") + packageName + "/package.json", packageJsonUrl);
			packageJsonPath = fileURLToPath(packageJsonUrl);
			continue;
		}
		const packageConfig = read(packageJsonPath, {
			base,
			specifier
		});
		if (packageConfig.exports !== void 0 && packageConfig.exports !== null) return packageExportsResolve(packageJsonUrl, packageSubpath, packageConfig, base, conditions);
		if (packageSubpath === ".") return legacyMainResolve(packageJsonUrl, packageConfig, base);
		return new URL(packageSubpath, packageJsonUrl);
	} while (packageJsonPath.length !== lastPath.length);
	throw new ERR_MODULE_NOT_FOUND(packageName, fileURLToPath(base), false);
}
/**
* @param {string} specifier
* @returns {boolean}
*/
function isRelativeSpecifier(specifier) {
	if (specifier[0] === ".") {
		if (specifier.length === 1 || specifier[1] === "/") return true;
		if (specifier[1] === "." && (specifier.length === 2 || specifier[2] === "/")) return true;
	}
	return false;
}
/**
* @param {string} specifier
* @returns {boolean}
*/
function shouldBeTreatedAsRelativeOrAbsolutePath(specifier) {
	if (specifier === "") return false;
	if (specifier[0] === "/") return true;
	return isRelativeSpecifier(specifier);
}
/**
* The Resolver Algorithm Specification as detailed in the Node docs (which is
* sync and slightly lower-level than `resolve`).
*
* @param {string} specifier
*   `/example.js`, `./example.js`, `../example.js`, `some-package`, `fs`, etc.
* @param {URL} base
*   Full URL (to a file) that `specifier` is resolved relative from.
* @param {Set<string>} [conditions]
*   Conditions.
* @param {boolean} [preserveSymlinks]
*   Keep symlinks instead of resolving them.
* @returns {URL}
*   A URL object to the found thing.
*/
function moduleResolve(specifier, base, conditions, preserveSymlinks) {
	if (conditions === void 0) conditions = getConditionsSet();
	const protocol = base.protocol;
	const isRemote = protocol === "data:" || protocol === "http:" || protocol === "https:";
	/** @type {URL | undefined} */
	let resolved;
	if (shouldBeTreatedAsRelativeOrAbsolutePath(specifier)) try {
		resolved = new URL(specifier, base);
	} catch (error_) {
		const error = new ERR_UNSUPPORTED_RESOLVE_REQUEST(specifier, base);
		error.cause = error_;
		throw error;
	}
	else if (protocol === "file:" && specifier[0] === "#") resolved = packageImportsResolve(specifier, base, conditions);
	else try {
		resolved = new URL(specifier);
	} catch (error_) {
		if (isRemote && !builtinModules.includes(specifier)) {
			const error = new ERR_UNSUPPORTED_RESOLVE_REQUEST(specifier, base);
			error.cause = error_;
			throw error;
		}
		resolved = packageResolve(specifier, base, conditions);
	}
	assert.ok(resolved !== void 0, "expected to be defined");
	if (resolved.protocol !== "file:") return resolved;
	return finalizeResolution(resolved, base, preserveSymlinks);
}
/**
* @param {string} specifier
* @param {URL | undefined} parsed
* @param {URL | undefined} parsedParentURL
*/
function checkIfDisallowedImport(specifier, parsed, parsedParentURL) {
	if (parsedParentURL) {
		const parentProtocol = parsedParentURL.protocol;
		if (parentProtocol === "http:" || parentProtocol === "https:") {
			if (shouldBeTreatedAsRelativeOrAbsolutePath(specifier)) {
				const parsedProtocol = parsed?.protocol;
				if (parsedProtocol && parsedProtocol !== "https:" && parsedProtocol !== "http:") throw new ERR_NETWORK_IMPORT_DISALLOWED(specifier, parsedParentURL, "remote imports cannot import from a local location.");
				return { url: parsed?.href || "" };
			}
			if (builtinModules.includes(specifier)) throw new ERR_NETWORK_IMPORT_DISALLOWED(specifier, parsedParentURL, "remote imports cannot import from a local location.");
			throw new ERR_NETWORK_IMPORT_DISALLOWED(specifier, parsedParentURL, "only relative and absolute specifiers are supported.");
		}
	}
}
/**
* Checks if a value has the shape of a WHATWG URL object.
*
* Using a symbol or instanceof would not be able to recognize URL objects
* coming from other implementations (e.g. in Electron), so instead we are
* checking some well known properties for a lack of a better test.
*
* We use `href` and `protocol` as they are the only properties that are
* easy to retrieve and calculate due to the lazy nature of the getters.
*
* @template {unknown} Value
* @param {Value} self
* @returns {Value is URL}
*/
function isURL(self) {
	return Boolean(self && typeof self === "object" && "href" in self && typeof self.href === "string" && "protocol" in self && typeof self.protocol === "string" && self.href && self.protocol);
}
/**
* Validate user-input in `context` supplied by a custom loader.
*
* @param {unknown} parentURL
* @returns {asserts parentURL is URL | string | undefined}
*/
function throwIfInvalidParentURL(parentURL) {
	if (parentURL === void 0) return;
	if (typeof parentURL !== "string" && !isURL(parentURL)) throw new codes.ERR_INVALID_ARG_TYPE("parentURL", ["string", "URL"], parentURL);
}
/**
* @param {string} specifier
* @param {{parentURL?: string, conditions?: Array<string>}} context
* @returns {{url: string, format?: string | null}}
*/
function defaultResolve(specifier, context = {}) {
	const { parentURL } = context;
	assert.ok(parentURL !== void 0, "expected `parentURL` to be defined");
	throwIfInvalidParentURL(parentURL);
	/** @type {URL | undefined} */
	let parsedParentURL;
	if (parentURL) try {
		parsedParentURL = new URL(parentURL);
	} catch {}
	/** @type {URL | undefined} */
	let parsed;
	/** @type {string | undefined} */
	let protocol;
	try {
		parsed = shouldBeTreatedAsRelativeOrAbsolutePath(specifier) ? new URL(specifier, parsedParentURL) : new URL(specifier);
		protocol = parsed.protocol;
		if (protocol === "data:") return {
			url: parsed.href,
			format: null
		};
	} catch {}
	const maybeReturn = checkIfDisallowedImport(specifier, parsed, parsedParentURL);
	if (maybeReturn) return maybeReturn;
	if (protocol === void 0 && parsed) protocol = parsed.protocol;
	if (protocol === "node:") return { url: specifier };
	if (parsed && parsed.protocol === "node:") return { url: specifier };
	const conditions = getConditionsSet(context.conditions);
	const url = moduleResolve(specifier, new URL(parentURL), conditions, false);
	return {
		url: url.href,
		format: defaultGetFormatWithoutErrors(url, { parentURL })
	};
}

//#endregion
//#region ../node_modules/.pnpm/import-meta-resolve@4.2.0/node_modules/import-meta-resolve/index.js
/**
* @typedef {import('./lib/errors.js').ErrnoException} ErrnoException
*/
/**
* Match `import.meta.resolve` except that `parent` is required (you can pass
* `import.meta.url`).
*
* @param {string} specifier
*   The module specifier to resolve relative to parent
*   (`/example.js`, `./example.js`, `../example.js`, `some-package`, `fs`,
*   etc).
* @param {string} parent
*   The absolute parent module URL to resolve from.
*   You must pass `import.meta.url` or something else.
* @returns {string}
*   Returns a string to a full `file:`, `data:`, or `node:` URL
*   to the found thing.
*/
function resolve$2(specifier, parent) {
	if (!parent) throw new Error("Please pass `parent`: `import-meta-resolve` cannot ponyfill that");
	try {
		return defaultResolve(specifier, { parentURL: parent }).url;
	} catch (error) {
		const exception = error;
		if ((exception.code === "ERR_UNSUPPORTED_DIR_IMPORT" || exception.code === "ERR_MODULE_NOT_FOUND") && typeof exception.url === "string") return exception.url;
		throw error;
	}
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+dynamic-import@9.6.4/node_modules/@cspell/dynamic-import/dist/esm/dynamicImport.mjs
const isWindowsPath = /^[a-z]:\\/i;
/**
* Dynamically import a module using `import`.
* @param moduleName - name of module, or relative path.
* @param paths - search paths
* @returns the loaded module.
*/
async function dynamicImportFrom(moduleName, paths) {
	paths = Array.isArray(paths) ? paths : paths ? [paths] : void 0;
	const modulesNameToImport = normalizeModuleName(moduleName);
	if (!paths || !paths.length || typeof moduleName !== "string") try {
		return await import(modulesNameToImport.toString());
	} catch (e) {
		throw toError$3(e);
	}
	return await import(importResolveModuleName(moduleName, paths).href);
}
/**
* Use Import.meta.resolve logic to try and determine possible locations for a module.
* @param moduleName - name of module, relative path, or absolute path.
* @param paths - Places to start resolving from.
* @returns location of module
*/
function importResolveModuleName(moduleName, paths) {
	const modulesNameToImport = normalizeModuleName(moduleName);
	let lastError = void 0;
	for (const parent of paths) try {
		const url = typeof parent === "string" ? parent.startsWith("file://") ? new URL(parent) : dirToUrl(parent) : parent;
		const resolvedURL = new URL(resolve$2(modulesNameToImport.toString(), url.toString()));
		try {
			if (statSync(resolvedURL).isFile()) return resolvedURL;
		} catch {
			const error = /* @__PURE__ */ new Error(`Cannot find module ${moduleName}`);
			error.code = "ERR_MODULE_NOT_FOUND";
			lastError = error;
		}
	} catch (err) {
		lastError = err;
	}
	throw lastError;
}
function normalizeModuleName(moduleName) {
	return typeof moduleName === "string" && isWindowsPath.test(moduleName) ? toFileURL(moduleName) : moduleName;
}
function toError$3(e) {
	if (isError$3(e)) return e;
	return new Error(e?.toString());
}
function isError$3(e) {
	return e instanceof Error;
}
function dirToUrl(dir) {
	return toFileDirURL(resolve(dir));
}

//#endregion
//#region ../node_modules/.pnpm/resolve-from@5.0.0/node_modules/resolve-from/index.js
var require_resolve_from$1 = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const path$5 = __require$1("path");
	const Module$1 = __require$1("module");
	const fs$3 = __require$1("fs");
	const resolveFrom = (fromDirectory, moduleId, silent) => {
		if (typeof fromDirectory !== "string") throw new TypeError(`Expected \`fromDir\` to be of type \`string\`, got \`${typeof fromDirectory}\``);
		if (typeof moduleId !== "string") throw new TypeError(`Expected \`moduleId\` to be of type \`string\`, got \`${typeof moduleId}\``);
		try {
			fromDirectory = fs$3.realpathSync(fromDirectory);
		} catch (error) {
			if (error.code === "ENOENT") fromDirectory = path$5.resolve(fromDirectory);
			else if (silent) return;
			else throw error;
		}
		const fromFile = path$5.join(fromDirectory, "noop.js");
		const resolveFileName = () => Module$1._resolveFilename(moduleId, {
			id: fromFile,
			filename: fromFile,
			paths: Module$1._nodeModulePaths(fromDirectory)
		});
		if (silent) try {
			return resolveFileName();
		} catch (error) {
			return;
		}
		return resolveFileName();
	};
	module.exports = (fromDirectory, moduleId) => resolveFrom(fromDirectory, moduleId);
	module.exports.silent = (fromDirectory, moduleId) => resolveFrom(fromDirectory, moduleId, true);
}));

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-service-bus@9.6.4/node_modules/@cspell/cspell-service-bus/dist/esm/errors.js
var ErrorUnhandledRequest = class extends Error {
	request;
	constructor(request) {
		super(`Unhandled Request: ${request.type}`);
		this.request = request;
	}
};
var ErrorServiceRequestDepthExceeded = class extends Error {
	request;
	depth;
	constructor(request, depth) {
		super(`Service Request Depth ${depth} Exceeded: ${request.type}`);
		this.request = request;
		this.depth = depth;
	}
};
var UnhandledHandlerError = class extends Error {
	handlerName;
	handlerDescription;
	cause;
	constructor(handlerName, handlerDescription, cause) {
		super(`Unhandled Error in Handler: ${handlerName}`);
		this.handlerName = handlerName;
		this.handlerDescription = handlerDescription;
		this.cause = cause;
	}
};

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-service-bus@9.6.4/node_modules/@cspell/cspell-service-bus/dist/esm/request.js
var BaseServiceRequest = class {
	type;
	params;
	__r;
	constructor(type, params) {
		this.type = type;
		this.params = params;
	}
};
var ServiceRequestCls = class extends BaseServiceRequest {
	constructor(type, params) {
		super(type, params);
	}
};
function createResponse(value, _req) {
	return { value };
}
function createResponseFail(_request, error) {
	return { error };
}
function isServiceResponseSuccess(res) {
	return "value" in res && res.error === void 0;
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-service-bus@9.6.4/node_modules/@cspell/cspell-service-bus/dist/esm/bus.js
const MAX_DEPTH = 10;
var ServiceBus = class {
	handlers = [];
	constructor(handlers = []) {
		handlers.forEach((h) => this.addHandler(h));
	}
	addHandler(handler, name = "anonymous", description) {
		const { fn, name: _name, description: _description } = typeof handler === "function" ? {
			fn: handler,
			name,
			description
		} : handler;
		this.handlers.push({
			fn,
			name: _name,
			description: _description
		});
		return this;
	}
	dispatch(request) {
		let depth = 0;
		const dispatcher = { dispatch };
		const handler = this.reduceHandlers(this.handlers, request, dispatcher, this.defaultHandler);
		function dispatch(request) {
			++depth;
			if (depth >= MAX_DEPTH) return createResponseFail(request, new ErrorServiceRequestDepthExceeded(request, depth));
			const response = handler(request);
			--depth;
			return response;
		}
		return dispatch(request);
	}
	defaultHandler(request) {
		return createResponseFail(request, new ErrorUnhandledRequest(request));
	}
	reduceHandlers(handlers, request, dispatcher, defaultHandler) {
		return handlers.map((m) => ({
			...m,
			fn: m.fn(dispatcher)
		})).reduce((next, h) => {
			const fn = h.fn(next);
			return (req) => {
				try {
					return fn(req);
				} catch (e) {
					return createResponseFail(request, new UnhandledHandlerError(h.name, h.description, e));
				}
			};
		}, defaultHandler);
	}
};

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-service-bus@9.6.4/node_modules/@cspell/cspell-service-bus/dist/esm/createRequestHandler.js
function createRequestHandler(requestDef, fn, name, description) {
	return createIsRequestHandler(requestDef.is, fn, name ?? requestDef.type, description);
}
function createIsRequestHandlerFn(isA, fn) {
	return (dispatcher) => (next) => (request) => isA(request) ? fn(request, next, dispatcher) : next(request);
}
function createIsRequestHandler(isA, fn, name, description) {
	return {
		fn: createIsRequestHandlerFn(isA, fn),
		name,
		description
	};
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-service-bus@9.6.4/node_modules/@cspell/cspell-service-bus/dist/esm/requestFactory.js
function requestFactory(requestType) {
	class RequestClass extends ServiceRequestCls {
		static type = requestType;
		constructor(params) {
			super(requestType, params);
		}
		static is(req) {
			return req instanceof RequestClass && req.type === requestType;
		}
		static create(params) {
			return new RequestClass(params);
		}
		static createRequestHandler(fn, name, description) {
			return createRequestHandler(RequestClass, fn, name, description);
		}
		static __request;
	}
	return RequestClass;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-io@9.6.4/node_modules/cspell-io/dist/index.js
var CFileReference = class CFileReference {
	/**
	* Use to ensure the nominal type separation between CFileReference and FileReference
	* See: https://github.com/microsoft/TypeScript/wiki/FAQ#when-and-why-are-classes-nominal
	*/
	_;
	gz;
	constructor(url, encoding, baseFilename, gz) {
		this.url = url;
		this.encoding = encoding;
		this.baseFilename = baseFilename;
		this.gz = gz ?? (baseFilename?.endsWith(".gz") || void 0) ?? (url.pathname.endsWith(".gz") || void 0);
	}
	static isCFileReference(obj) {
		return obj instanceof CFileReference;
	}
	static from(fileReference, encoding, baseFilename, gz) {
		if (CFileReference.isCFileReference(fileReference)) return fileReference;
		if (fileReference instanceof URL) return new CFileReference(fileReference, encoding, baseFilename, gz);
		return new CFileReference(fileReference.url, fileReference.encoding, fileReference.baseFilename, fileReference.gz);
	}
	toJson() {
		return {
			url: this.url.href,
			encoding: this.encoding,
			baseFilename: this.baseFilename,
			gz: this.gz
		};
	}
};
/**
*
* @param file - a URL, file path, or FileReference
* @param encoding - optional encoding used to decode the file.
* @param baseFilename - optional base filename used with data URLs.
* @param gz - optional flag to indicate if the file is gzipped.
* @returns a FileReference
*/
function toFileReference(file, encoding, baseFilename, gz) {
	const fileReference = typeof file === "string" ? toFileURL(file) : file;
	if (fileReference instanceof URL) return new CFileReference(fileReference, encoding, baseFilename, gz);
	return CFileReference.from(fileReference);
}
function isFileReference(ref) {
	return CFileReference.isCFileReference(ref) || !(ref instanceof URL) && typeof ref !== "string";
}
function toFileResourceRequest(file, encoding, signal) {
	const fileReference = typeof file === "string" ? toFileURL(file) : file;
	if (fileReference instanceof URL) return {
		url: fileReference,
		encoding,
		signal
	};
	return {
		url: fileReference.url,
		encoding: encoding ?? fileReference.encoding,
		signal
	};
}
var ErrorNotImplemented = class extends Error {
	constructor(method, options) {
		super(`Method ${method} is not supported.`, options);
		this.method = method;
	}
};
var AssertionError = class extends Error {
	constructor(message, options) {
		super(message, options);
		this.message = message;
	}
};
function assert$1(value, message) {
	if (!value) throw new AssertionError(message ?? "Assertion failed");
}
function toUint8Array(data) {
	if (data instanceof Uint8Array) return data;
	return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
}
function arrayBufferViewToBuffer(data) {
	if (data instanceof Buffer$1) return data;
	return Buffer$1.from(data.buffer, data.byteOffset, data.byteLength);
}
function copyArrayBufferView(data) {
	return new Uint8Array(data.buffer.slice(data.byteOffset, data.byteOffset + data.byteLength));
}
function swap16(data) {
	arrayBufferViewToBuffer(data).swap16();
	return data;
}
function swapBytes(data) {
	return swap16(copyArrayBufferView(data));
}
const BOM_BE = 65279;
const BOM_LE = 65534;
const decoderUTF8 = new TextDecoder("utf8");
const decoderUTF16LE = new TextDecoder("utf-16le");
const decoderUTF16BE = createTextDecoderUtf16BE();
const encoderUTF8 = new TextEncoder();
function decodeUtf16LE(data) {
	const buf = toUint8Array(data);
	const bom = buf[0] << 8 | buf[1];
	return decoderUTF16LE.decode(bom === BOM_LE ? buf.subarray(2) : buf);
}
function decodeUtf16BE(data) {
	const buf = toUint8Array(data);
	const bom = buf[0] << 8 | buf[1];
	return decoderUTF16BE.decode(bom === BOM_BE ? buf.subarray(2) : buf);
}
function decodeToString(data, encoding) {
	if (isGZipped(data)) return decodeToString(decompressBuffer(data), encoding);
	const buf = toUint8Array(data);
	const bom = buf[0] << 8 | buf[1];
	if (bom === BOM_BE || buf[0] === 0 && buf[1] !== 0) return decodeUtf16BE(buf);
	if (bom === BOM_LE || buf[0] !== 0 && buf[1] === 0) return decodeUtf16LE(buf);
	if (!encoding) return decoderUTF8.decode(buf);
	switch (encoding) {
		case "utf-16be":
		case "utf16be": return decodeUtf16BE(buf);
		case "utf-16le":
		case "utf16le": return decodeUtf16LE(buf);
		case "utf-8":
		case "utf8": return decoderUTF8.decode(buf);
	}
	throw new UnsupportedEncodingError(encoding);
}
function decode(data, encoding) {
	switch (encoding) {
		case "base64":
		case "base64url":
		case "hex": return arrayBufferViewToBuffer(data).toString(encoding);
	}
	return decodeToString(data, encoding);
}
function encodeString$1(str, encoding, bom) {
	switch (encoding) {
		case void 0:
		case "utf-8":
		case "utf8": return encoderUTF8.encode(str);
		case "utf-16be":
		case "utf16be": return encodeUtf16BE(str, bom);
		case "utf-16le":
		case "utf16le": return encodeUtf16LE(str, bom);
	}
	return Buffer$1.from(str, encoding);
}
function encodeUtf16LE(str, bom = true) {
	const buf = Buffer$1.from(str, "utf16le");
	if (bom) {
		const target = Buffer$1.alloc(buf.length + 2);
		target.writeUint16LE(BOM_BE);
		buf.copy(target, 2);
		return target;
	}
	return buf;
}
function encodeUtf16BE(str, bom = true) {
	return swap16(encodeUtf16LE(str, bom));
}
function createTextDecoderUtf16BE() {
	try {
		return new TextDecoder("utf-16be");
	} catch {
		return {
			encoding: "utf-16be",
			fatal: false,
			ignoreBOM: false,
			decode: (input) => decoderUTF16LE.decode(swapBytes(input))
		};
	}
}
var UnsupportedEncodingError = class extends Error {
	constructor(encoding) {
		super(`Unsupported encoding: ${encoding}`);
	}
};
function isGZipped(data) {
	if (typeof data === "string") return false;
	const buf = toUint8Array(data);
	return buf[0] === 31 && buf[1] === 139;
}
function decompressBuffer(data) {
	if (!isGZipped(data)) return data;
	return gunzipSync(arrayBufferViewToBuffer(data));
}
async function decompress(data, method = "gzip") {
	const ds = new DecompressionStream(method || "deflate-raw");
	const writer = ds.writable.getWriter();
	writer.write(data);
	writer.close();
	const reader = ds.readable.getReader();
	const chunks = [];
	let size = 0;
	while (true) {
		const chunk = await reader.read();
		if (chunk.done) break;
		chunks.push(chunk.value);
		size += chunk.value.length;
	}
	const result = new Uint8Array(size);
	for (let offset = 0, i = 0; i < chunks.length; i++) {
		result.set(chunks[i], offset);
		offset += chunks[i].length;
	}
	return result;
}
var CFileResource = class CFileResource {
	baseFilename;
	url;
	content;
	encoding;
	#gz;
	#text;
	#data;
	constructor(url, content, encoding, baseFilename, gz) {
		this.url = url;
		this.content = content;
		this.encoding = encoding;
		this.baseFilename = baseFilename ?? (url.protocol !== "data:" && url.pathname.split("/").pop() || void 0);
		this.#gz = gz;
	}
	get gz() {
		if (this.#gz !== void 0) return this.#gz;
		if (this.url.pathname.endsWith(".gz")) return true;
		if (typeof this.content === "string") return false;
		return isGZipped(this.content);
	}
	getText(encoding) {
		if (this.#text !== void 0) return this.#text;
		const text = typeof this.content === "string" ? this.content : decode(this.content, encoding ?? this.encoding);
		this.#text = text;
		return text;
	}
	async getBytes(unzip) {
		if (unzip !== false && this.#data !== void 0) return this.#data;
		if (typeof this.content === "string") {
			this.#data = encodeString$1(this.content, this.encoding);
			return this.#data;
		}
		if (unzip ?? isGZipped(this.content)) {
			this.#data = await decompress(this.content, "gzip");
			return this.#data;
		}
		return this.content;
	}
	toJson() {
		return {
			url: this.url.href,
			content: this.getText(),
			encoding: this.encoding,
			baseFilename: this.baseFilename,
			gz: this.gz
		};
	}
	static isCFileResource(obj) {
		return obj instanceof CFileResource;
	}
	static from(urlOrFileResource, content, encoding, baseFilename, gz) {
		if (CFileResource.isCFileResource(urlOrFileResource)) {
			if (content) {
				const { url, encoding, baseFilename, gz } = urlOrFileResource;
				return new CFileResource(url, content, encoding, baseFilename, gz);
			}
			return urlOrFileResource;
		}
		if (urlOrFileResource instanceof URL) {
			assert$1(content !== void 0);
			return new CFileResource(urlOrFileResource, content, encoding, baseFilename, gz);
		}
		if (content !== void 0) {
			const fileRef = urlOrFileResource;
			return new CFileResource(fileRef.url, content, fileRef.encoding, fileRef.baseFilename, fileRef.gz);
		}
		assert$1("content" in urlOrFileResource && urlOrFileResource.content !== void 0);
		const fileResource = urlOrFileResource;
		return new CFileResource(fileResource.url, fileResource.content, fileResource.encoding, fileResource.baseFilename, fileResource.gz);
	}
};
function fromFileResource(fileResource, encoding) {
	return CFileResource.from(encoding ? {
		...fileResource,
		encoding
	} : fileResource);
}
/**
* Compare two Stats to see if they have the same value.
* @param left - Stats
* @param right - Stats
* @returns 0 - equal; 1 - left > right; -1 left < right
*/
function compareStats(left, right) {
	if (left === right) return 0;
	if (left.eTag || right.eTag) return left.eTag === right.eTag ? 0 : (left.eTag || "") < (right.eTag || "") ? -1 : 1;
	const diff = left.size - right.size || left.mtimeMs - right.mtimeMs;
	return diff < 0 ? -1 : diff > 0 ? 1 : 0;
}
function urlOrReferenceToUrl(urlOrReference) {
	return urlOrReference instanceof URL ? urlOrReference : urlOrReference.url;
}
function toReadFileOptions(options) {
	if (!options) return options;
	if (typeof options === "string") return { encoding: options };
	return options;
}
function toError$1$1(e) {
	if (e instanceof Error) return e;
	if (typeof e === "object" && e && "message" in e && typeof e.message === "string") return new Error(e.message, { cause: e });
	return new Error(e && e.toString());
}
let FileType = /* @__PURE__ */ function(FileType) {
	/**
	* The file type is unknown.
	*/
	FileType[FileType["Unknown"] = 0] = "Unknown";
	/**
	* A regular file.
	*/
	FileType[FileType["File"] = 1] = "File";
	/**
	* A directory.
	*/
	FileType[FileType["Directory"] = 2] = "Directory";
	/**
	* A symbolic link.
	*/
	FileType[FileType["SymbolicLink"] = 64] = "SymbolicLink";
	return FileType;
}({});
/**
* Generates a string of the following format:
*
* `data:[mediaType][;charset=<encoding>[;base64],<data>`
*
* - `encoding` - defaults to `utf8` for text data
* @param data
* @param mediaType - The mediaType is a [MIME](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types) type string
* @param attributes - Additional attributes
*/
function encodeDataUrl(data, mediaType, attributes) {
	if (typeof data === "string") return encodeString(data, mediaType, attributes);
	return `data:${mediaType}${encodeAttributes(attributes || [])};base64,${arrayBufferViewToBuffer(data).toString("base64url")}`;
}
function toDataUrl(data, mediaType, attributes) {
	return new URL(encodeDataUrl(data, mediaType, attributes));
}
function encodeString(data, mediaType, attributes) {
	mediaType = mediaType || "text/plain";
	attributes = attributes || [];
	const asUrlComp = encodeURIComponent(data);
	const asBase64 = Buffer$1.from(data).toString("base64url");
	const useBase64 = asBase64.length < asUrlComp.length - 7;
	const encoded = useBase64 ? asBase64 : asUrlComp;
	const attribMap = new Map([["charset", "utf-8"], ...attributes]);
	attribMap.set("charset", "utf-8");
	const attribs = encodeAttributes(attribMap);
	return `data:${mediaType}${attribs}${useBase64 ? ";base64" : ""},${encoded}`;
}
function encodeAttributes(attributes) {
	return [...attributes].map(([key, value]) => `;${key}=${encodeURIComponent(value)}`).join("");
}
const dataUrlRegExHead = /^data:(?<mediaType>[^;,]*)(?<attributes>(?:;[^=]+=[^;,]*)*)(?<base64>;base64)?$/;
function decodeDataUrl(url) {
	url = url.toString();
	const [head, encodedData] = url.split(",", 2);
	if (!head || encodedData === void 0) throw new Error("Not a data url");
	const match = head.match(dataUrlRegExHead);
	if (!match || !match.groups) throw new Error("Not a data url");
	const mediaType = match.groups["mediaType"] || "";
	const rawAttributes = (match.groups["attributes"] || "").split(";").filter((a) => !!a).map((entry) => entry.split("=", 2)).map(([key, value]) => [key, decodeURIComponent(value)]);
	const attributes = new Map(rawAttributes);
	const encoding = attributes.get("charset");
	return {
		mediaType,
		data: !!match.groups["base64"] ? Buffer$1.from(encodedData, "base64url") : Buffer$1.from(decodeURIComponent(encodedData)),
		encoding,
		attributes
	};
}
function guessMimeType(filename) {
	if (filename.endsWith(".trie")) return {
		mimeType: "application/vnd.cspell.dictionary+trie",
		encoding: "utf-8"
	};
	if (filename.endsWith(".trie.gz")) return { mimeType: "application/vnd.cspell.dictionary+trie.gz" };
	if (filename.endsWith(".txt")) return {
		mimeType: "text/plain",
		encoding: "utf-8"
	};
	if (filename.endsWith(".txt.gz")) return { mimeType: "application/gzip" };
	if (filename.endsWith(".gz")) return { mimeType: "application/gzip" };
	if (filename.endsWith(".json")) return {
		mimeType: "application/json",
		encoding: "utf-8"
	};
	if (filename.endsWith(".yaml") || filename.endsWith(".yml")) return {
		mimeType: "application/x-yaml",
		encoding: "utf-8"
	};
}
/** alias of global.fetch, useful for mocking */
const _fetch = globalThis.fetch;
var FetchUrlError = class FetchUrlError extends Error {
	constructor(message, code, status, url) {
		super(message);
		this.code = code;
		this.status = status;
		this.url = url;
		this.name = "FetchUrlError";
	}
	static create(url, status, message) {
		if (status === 404) return new FetchUrlError(message || "URL not found.", "ENOENT", status, url);
		if (status >= 400 && status < 500) return new FetchUrlError(message || "Permission denied.", "EACCES", status, url);
		return new FetchUrlError(message || "Fatal Error", "ECONNREFUSED", status, url);
	}
	static fromError(url, e) {
		const cause = getCause(e);
		if (cause) return new FetchUrlError(cause.message, cause.code, void 0, url);
		if (isNodeError$1(e)) return new FetchUrlError(e.message, e.code, void 0, url);
		return new FetchUrlError(e.message, void 0, void 0, url);
	}
};
function isNodeError$1(e) {
	if (e instanceof Error && "code" in e && typeof e.code === "string") return true;
	if (e && typeof e === "object" && "code" in e && typeof e.code === "string") return true;
	return false;
}
function isError$2(e) {
	return e instanceof Error;
}
function isErrorWithOptionalCause(e) {
	return isError$2(e) && (!("cause" in e) || isNodeError$1(e.cause) || isNodeError$1(e));
}
function getCause(e) {
	return isErrorWithOptionalCause(e) ? e.cause : void 0;
}
function toFetchUrlError(err, url) {
	return err instanceof FetchUrlError ? err : FetchUrlError.fromError(url, toError$2(err));
}
function toError$2(err) {
	return err instanceof Error ? err : new Error("Unknown Error", { cause: err });
}
async function fetchHead(request) {
	const url = toURL$1(request);
	try {
		const r = await _fetch(url, { method: "HEAD" });
		if (!r.ok) throw FetchUrlError.create(url, r.status);
		return r.headers;
	} catch (e) {
		throw toFetchUrlError(e, url);
	}
}
async function fetchURL(url, signal) {
	try {
		const response = await _fetch(signal ? new Request(url, { signal }) : url);
		if (!response.ok) throw FetchUrlError.create(url, response.status);
		return await response.bytes();
	} catch (e) {
		throw toFetchUrlError(e, url);
	}
}
function toURL$1(url) {
	return typeof url === "string" ? new URL(url) : url;
}
async function getStatHttp(url) {
	const headers = await fetchHead(url);
	const eTag = headers.get("etag") || void 0;
	const guessSize = Number.parseInt(headers.get("content-length") || "0", 10);
	return {
		size: eTag ? -1 : guessSize,
		mtimeMs: 0,
		eTag
	};
}
const RequestFsReadFile = requestFactory("fs:readFile");
const RequestFsReadFileTextSync = requestFactory("fs:readFileSync");
const RequestFsStat = requestFactory("fs:stat");
const RequestFsStatSync = requestFactory("fs:statSync");
const RequestFsWriteFile = requestFactory("fs:writeFile");
const RequestZlibInflate = requestFactory("zlib:inflate");
const RequestFsReadDirectory = requestFactory("fs:readDir");
const isGzFileRegExp = /\.gz($|[?#])/;
function isGzFile(url) {
	return isGzFileRegExp.test(typeof url === "string" ? url : url.pathname);
}
const pGzip = promisify(gzip);
/**
* Handle Binary File Reads
*/
const handleRequestFsReadFile = RequestFsReadFile.createRequestHandler(({ params }) => {
	const baseFilename = urlBasename(params.url);
	return createResponse(promises.readFile(fileURLToPath(params.url)).then((content) => CFileResource.from(params.url, content, params.encoding, baseFilename)));
}, void 0, "Node: Read Binary File.");
/**
* Handle Binary File Sync Reads
*/
const handleRequestFsReadFileSync = RequestFsReadFileTextSync.createRequestHandler(({ params }) => createResponse(CFileResource.from({
	...params,
	content: readFileSync$1(fileURLToPath(params.url))
})), void 0, "Node: Sync Read Binary File.");
/**
* Handle Binary File Reads
*/
const handleRequestFsReadDirectory = RequestFsReadDirectory.createRequestHandler(({ params }) => {
	return createResponse(promises.readdir(fileURLToPath(params.url), { withFileTypes: true }).then((entries) => direntToDirEntries(params.url, entries)));
}, void 0, "Node: Read Directory.");
/**
* Handle deflating gzip data
*/
const handleRequestZlibInflate = RequestZlibInflate.createRequestHandler(({ params }) => createResponse(gunzipSync(arrayBufferViewToBuffer(params.data))), void 0, "Node: gz deflate.");
const supportedFetchProtocols = {
	"http:": true,
	"https:": true
};
/**
* Handle fetching a file from http
*/
const handleRequestFsReadFileHttp = RequestFsReadFile.createRequestHandler((req, next) => {
	const { url, signal, encoding } = req.params;
	if (!(url.protocol in supportedFetchProtocols)) return next(req);
	return createResponse(fetchURL(url, signal).then((content) => CFileResource.from({
		url,
		encoding,
		content
	})));
}, void 0, "Node: Read Http(s) file.");
/**
* Handle decoding a data url
*/
const handleRequestFsReadFileSyncData = RequestFsReadFileTextSync.createRequestHandler((req, next) => {
	const { url, encoding } = req.params;
	if (url.protocol !== "data:") return next(req);
	const data = decodeDataUrl(url);
	return createResponse(CFileResource.from({
		url,
		content: data.data,
		encoding,
		baseFilename: data.attributes.get("filename")
	}));
}, void 0, "Node: Read data: urls.");
/**
* Handle decoding a data url
*/
const handleRequestFsReadFileData = RequestFsReadFile.createRequestHandler((req, next, dispatcher) => {
	const { url } = req.params;
	if (url.protocol !== "data:") return next(req);
	const res = dispatcher.dispatch(RequestFsReadFileTextSync.create(req.params));
	if (!isServiceResponseSuccess(res)) return res;
	return createResponse(Promise.resolve(res.value));
}, void 0, "Node: Read data: urls.");
/**
* Handle fs:stat
*/
const handleRequestFsStat = RequestFsStat.createRequestHandler(({ params }) => createResponse(toPromiseStats(promises.stat(fileURLToPath(params.url)))), void 0, "Node: fs.stat.");
function toStats(stat) {
	return {
		size: stat.size,
		mtimeMs: stat.mtimeMs,
		fileType: toFileType(stat)
	};
}
function toPromiseStats(pStat) {
	return pStat.then(toStats);
}
/**
* Handle fs:statSync
*/
const handleRequestFsStatSync = RequestFsStatSync.createRequestHandler((req) => {
	const { params } = req;
	try {
		return createResponse(statSync(fileURLToPath(params.url)));
	} catch (e) {
		return createResponseFail(req, toError$1$1(e));
	}
}, void 0, "Node: fs.stat.");
/**
* Handle deflating gzip data
*/
const handleRequestFsStatHttp = RequestFsStat.createRequestHandler((req, next) => {
	const { url } = req.params;
	if (!(url.protocol in supportedFetchProtocols)) return next(req);
	return createResponse(getStatHttp(url));
}, void 0, "Node: http get stat");
/**
* Handle fs:writeFile
*/
const handleRequestFsWriteFile = RequestFsWriteFile.createRequestHandler(({ params }) => createResponse(writeFile$2(params, params.content)), void 0, "Node: fs.writeFile");
async function writeFile$2(fileRef, content) {
	const gz = isGZipped(content);
	const { url, encoding, baseFilename } = fileRef;
	const resultRef = {
		url,
		encoding,
		baseFilename,
		gz
	};
	await promises.writeFile(fileURLToPath(fileRef.url), encodeContent(fileRef, content));
	return resultRef;
}
/**
* Handle fs:writeFile
*/
const handleRequestFsWriteFileDataUrl = RequestFsWriteFile.createRequestHandler((req, next) => {
	const fileResource = req.params;
	const { url } = req.params;
	if (url.protocol !== "data:") return next(req);
	const gz = isGZipped(fileResource.content);
	const baseFilename = fileResource.baseFilename || "file.txt" + (gz ? ".gz" : "");
	const mt = guessMimeType(baseFilename);
	const mediaType = mt?.mimeType || "text/plain";
	const dataUrl = toDataUrl(fileResource.content, mediaType, [["filename", baseFilename]]);
	return createResponse(Promise.resolve({
		url: dataUrl,
		baseFilename,
		gz,
		encoding: mt?.encoding
	}));
}, void 0, "Node: fs.writeFile DataUrl");
/**
* Handle fs:writeFile compressed
*/
const handleRequestFsWriteFileGz = RequestFsWriteFile.createRequestHandler((req, next, dispatcher) => {
	const fileResource = req.params;
	if (!fileResource.gz && !isGzFile(fileResource.url) && (!fileResource.baseFilename || !isGzFile(fileResource.baseFilename))) return next(req);
	if (typeof fileResource.content !== "string" && isGZipped(fileResource.content)) return next(req);
	return createResponse(compressAndChainWriteRequest(dispatcher, fileResource, fileResource.content));
}, void 0, "Node: fs.writeFile compressed");
async function compressAndChainWriteRequest(dispatcher, fileRef, content) {
	const buf = await pGzip(encodeContent(fileRef, content));
	const res = dispatcher.dispatch(RequestFsWriteFile.create({
		...fileRef,
		content: buf
	}));
	assert$1(isServiceResponseSuccess(res));
	return res.value;
}
function registerHandlers(serviceBus) {
	[
		handleRequestFsReadFile,
		handleRequestFsReadFileSync,
		handleRequestFsWriteFile,
		handleRequestFsWriteFileDataUrl,
		handleRequestFsWriteFileGz,
		handleRequestFsReadFileHttp,
		handleRequestFsReadFileData,
		handleRequestFsReadFileSyncData,
		handleRequestFsReadDirectory,
		handleRequestZlibInflate,
		handleRequestFsStatSync,
		handleRequestFsStat,
		handleRequestFsStatHttp
	].forEach((handler) => serviceBus.addHandler(handler));
}
function encodeContent(ref, content) {
	if (typeof content === "string") {
		if ([
			void 0,
			"utf8",
			"utf-8"
		].includes(ref.encoding)) return content;
		return arrayBufferViewToBuffer(encodeString$1(content, ref.encoding));
	}
	return arrayBufferViewToBuffer(content);
}
function mapperDirentToDirEntry(dir) {
	return (dirent) => direntToDirEntry(dir, dirent);
}
function direntToDirEntries(dir, dirent) {
	return dirent.map(mapperDirentToDirEntry(dir));
}
function direntToDirEntry(dir, dirent) {
	return {
		name: dirent.name,
		dir,
		fileType: toFileType(dirent)
	};
}
function toFileType(statLike) {
	const t = statLike.isFile() ? FileType.File : statLike.isDirectory() ? FileType.Directory : FileType.Unknown;
	return statLike.isSymbolicLink() ? t | FileType.SymbolicLink : t;
}
let defaultCSpellIONode = void 0;
var CSpellIONode = class {
	constructor(serviceBus = new ServiceBus()) {
		this.serviceBus = serviceBus;
		registerHandlers(serviceBus);
	}
	readFile(urlOrFilename, options) {
		const readOptions = toReadFileOptions(options);
		const ref = toFileResourceRequest(urlOrFilename, readOptions?.encoding, readOptions?.signal);
		const res = this.serviceBus.dispatch(RequestFsReadFile.create(ref));
		if (!isServiceResponseSuccess(res)) throw genError(res.error, "readFile");
		return res.value;
	}
	readDirectory(urlOrFilename) {
		const ref = toFileReference(urlOrFilename);
		const res = this.serviceBus.dispatch(RequestFsReadDirectory.create(ref));
		if (!isServiceResponseSuccess(res)) throw genError(res.error, "readDirectory");
		return res.value;
	}
	readFileSync(urlOrFilename, encoding) {
		const ref = toFileReference(urlOrFilename, encoding);
		const res = this.serviceBus.dispatch(RequestFsReadFileTextSync.create(ref));
		if (!isServiceResponseSuccess(res)) throw genError(res.error, "readFileSync");
		return res.value;
	}
	writeFile(urlOrFilename, content) {
		const ref = toFileReference(urlOrFilename);
		const fileResource = CFileResource.from(ref, content);
		const res = this.serviceBus.dispatch(RequestFsWriteFile.create(fileResource));
		if (!isServiceResponseSuccess(res)) throw genError(res.error, "writeFile");
		return res.value;
	}
	getStat(urlOrFilename) {
		const ref = toFileReference(urlOrFilename);
		const res = this.serviceBus.dispatch(RequestFsStat.create(ref));
		if (!isServiceResponseSuccess(res)) throw genError(res.error, "getStat");
		return res.value;
	}
	getStatSync(urlOrFilename) {
		const ref = toFileReference(urlOrFilename);
		const res = this.serviceBus.dispatch(RequestFsStatSync.create(ref));
		if (!isServiceResponseSuccess(res)) throw genError(res.error, "getStatSync");
		return res.value;
	}
	compareStats(left, right) {
		return compareStats(left, right);
	}
	toURL(urlOrFilename, relativeTo) {
		if (isFileReference(urlOrFilename)) return urlOrFilename.url;
		return toURL$2(urlOrFilename, relativeTo);
	}
	toFileURL(urlOrFilename, relativeTo) {
		if (isFileReference(urlOrFilename)) return urlOrFilename.url;
		return toFileURL(urlOrFilename, relativeTo);
	}
	urlBasename(urlOrFilename) {
		return urlBasename(this.toURL(urlOrFilename));
	}
	urlDirname(urlOrFilename) {
		return urlParent(this.toURL(urlOrFilename));
	}
};
function genError(err, alt) {
	return err || new ErrorNotImplemented(alt);
}
function getDefaultCSpellIO() {
	if (defaultCSpellIONode) return defaultCSpellIONode;
	const cspellIO = new CSpellIONode();
	defaultCSpellIONode = cspellIO;
	return cspellIO;
}
const debug = false;
async function findUpFromUrl$1(name, from, options) {
	const { type: entryType = "file", stopAt, fs } = options;
	let dir = new URL(".", from);
	const root = new URL("/", dir);
	const predicate = makePredicate$1(fs, name, entryType);
	const stopAtHrefs = new Set((Array.isArray(stopAt) ? stopAt : [stopAt || root]).map((p) => new URL(".", p).href));
	let last = "";
	while (dir.href !== last) {
		const found = await predicate(dir);
		if (found !== void 0) return found;
		last = dir.href;
		if (dir.href === root.href || stopAtHrefs.has(dir.href)) break;
		dir = new URL("..", dir);
	}
}
function makePredicate$1(fs, name, entryType) {
	if (typeof name === "function") return name;
	const checkStat = entryType === "file" || entryType === "!file" ? "isFile" : "isDirectory";
	const checkValue = entryType.startsWith("!") ? false : true;
	function checkName(dir, name) {
		const f = new URL(name, dir);
		return fs.stat(f).then((stats) => (stats.isUnknown() || stats[checkStat]() === checkValue) && f || void 0).catch(() => void 0);
	}
	if (!Array.isArray(name)) return (dir) => checkName(dir, name);
	return async (dir) => {
		const pending = name.map((n) => checkName(dir, n));
		for (const p of pending) {
			const found = await p;
			if (found) return found;
		}
	};
}
var CVFileSystem = class {
	#core;
	readFile;
	writeFile;
	stat;
	readDirectory;
	getCapabilities;
	constructor(core) {
		this.#core = core;
		this.readFile = this.#core.readFile.bind(this.#core);
		this.writeFile = this.#core.writeFile.bind(this.#core);
		this.stat = this.#core.stat.bind(this.#core);
		this.readDirectory = this.#core.readDirectory.bind(this.#core);
		this.getCapabilities = this.#core.getCapabilities.bind(this.#core);
	}
	get providerInfo() {
		return this.#core.providerInfo;
	}
	get hasProvider() {
		return this.#core.hasProvider;
	}
	findUp(name, from, options = {}) {
		return findUpFromUrl$1(name, from, {
			...options,
			fs: this.#core
		});
	}
};
let FSCapabilityFlags = /* @__PURE__ */ function(FSCapabilityFlags) {
	FSCapabilityFlags[FSCapabilityFlags["None"] = 0] = "None";
	FSCapabilityFlags[FSCapabilityFlags["Stat"] = 1] = "Stat";
	FSCapabilityFlags[FSCapabilityFlags["Read"] = 2] = "Read";
	FSCapabilityFlags[FSCapabilityFlags["Write"] = 4] = "Write";
	FSCapabilityFlags[FSCapabilityFlags["ReadWrite"] = 6] = "ReadWrite";
	FSCapabilityFlags[FSCapabilityFlags["ReadDir"] = 8] = "ReadDir";
	FSCapabilityFlags[FSCapabilityFlags["WriteDir"] = 16] = "WriteDir";
	FSCapabilityFlags[FSCapabilityFlags["ReadWriteDir"] = 24] = "ReadWriteDir";
	return FSCapabilityFlags;
}({});
function cspellIOToFsProvider(cspellIO) {
	const capabilities = FSCapabilityFlags.Stat | FSCapabilityFlags.ReadWrite | FSCapabilityFlags.ReadDir;
	const capabilitiesHttp = capabilities & ~FSCapabilityFlags.Write & ~FSCapabilityFlags.ReadDir;
	const capMap = {
		"file:": capabilities,
		"http:": capabilitiesHttp,
		"https:": capabilitiesHttp
	};
	const name = "CSpellIO";
	const supportedProtocols = new Set([
		"file:",
		"http:",
		"https:"
	]);
	const fs = {
		providerInfo: { name },
		stat: (url) => cspellIO.getStat(url),
		readFile: (url, options) => cspellIO.readFile(url, options),
		readDirectory: (url) => cspellIO.readDirectory(url),
		writeFile: (file) => cspellIO.writeFile(file.url, file.content),
		dispose: () => void 0,
		capabilities,
		getCapabilities(url) {
			return fsCapabilities(capMap[url.protocol] || FSCapabilityFlags.None);
		}
	};
	return {
		name,
		getFileSystem: (url, _next) => {
			return supportedProtocols.has(url.protocol) ? fs : void 0;
		}
	};
}
function wrapError(e) {
	if (e instanceof VFSError) return e;
	return e;
}
var VFSError = class extends Error {
	constructor(message, options) {
		super(message, options);
	}
};
var VFSErrorUnsupportedRequest = class extends VFSError {
	url;
	constructor(request, url, parameters) {
		super(`Unsupported request: ${request}`);
		this.request = request;
		this.parameters = parameters;
		this.url = url?.toString();
	}
};
var CFsCapabilities = class {
	constructor(flags) {
		this.flags = flags;
	}
	get readFile() {
		return !!(this.flags & FSCapabilityFlags.Read);
	}
	get writeFile() {
		return !!(this.flags & FSCapabilityFlags.Write);
	}
	get readDirectory() {
		return !!(this.flags & FSCapabilityFlags.ReadDir);
	}
	get writeDirectory() {
		return !!(this.flags & FSCapabilityFlags.WriteDir);
	}
	get stat() {
		return !!(this.flags & FSCapabilityFlags.Stat);
	}
};
function fsCapabilities(flags) {
	return new CFsCapabilities(flags);
}
var WrappedProviderFs = class WrappedProviderFs {
	hasProvider;
	capabilities;
	providerInfo;
	_capabilities;
	constructor(fs, eventLogger) {
		this.fs = fs;
		this.eventLogger = eventLogger;
		this.hasProvider = !!fs;
		this.capabilities = fs?.capabilities || FSCapabilityFlags.None;
		this._capabilities = fsCapabilities(this.capabilities);
		this.providerInfo = fs?.providerInfo || { name: "unknown" };
	}
	logEvent(method, event, traceID, url, message) {
		this.eventLogger({
			method,
			event,
			url,
			traceID,
			ts: performance.now(),
			message
		});
	}
	getCapabilities(url) {
		if (this.fs?.getCapabilities) return this.fs.getCapabilities(url);
		return this._capabilities;
	}
	async stat(urlRef) {
		const traceID = performance.now();
		const url = urlOrReferenceToUrl(urlRef);
		this.logEvent("stat", "start", traceID, url);
		try {
			checkCapabilityOrThrow(this.fs, this.capabilities, FSCapabilityFlags.Stat, "stat", url);
			return new CVfsStat(await this.fs.stat(urlRef));
		} catch (e) {
			this.logEvent("stat", "error", traceID, url, e instanceof Error ? e.message : "");
			throw wrapError(e);
		} finally {
			this.logEvent("stat", "end", traceID, url);
		}
	}
	async readFile(urlRef, optionsOrEncoding) {
		const traceID = performance.now();
		const url = urlOrReferenceToUrl(urlRef);
		this.logEvent("readFile", "start", traceID, url);
		try {
			checkCapabilityOrThrow(this.fs, this.capabilities, FSCapabilityFlags.Read, "readFile", url);
			const readOptions = toOptions(optionsOrEncoding);
			return fromFileResource(await this.fs.readFile(urlRef, readOptions), readOptions?.encoding);
		} catch (e) {
			this.logEvent("readFile", "error", traceID, url, e instanceof Error ? e.message : "");
			throw wrapError(e);
		} finally {
			this.logEvent("readFile", "end", traceID, url);
		}
	}
	async readDirectory(url) {
		const traceID = performance.now();
		this.logEvent("readDir", "start", traceID, url);
		try {
			checkCapabilityOrThrow(this.fs, this.capabilities, FSCapabilityFlags.ReadDir, "readDirectory", url);
			return (await this.fs.readDirectory(url)).map((e) => new CVfsDirEntry(e));
		} catch (e) {
			this.logEvent("readDir", "error", traceID, url, e instanceof Error ? e.message : "");
			throw wrapError(e);
		} finally {
			this.logEvent("readDir", "end", traceID, url);
		}
	}
	async writeFile(file) {
		const traceID = performance.now();
		const url = file.url;
		this.logEvent("writeFile", "start", traceID, url);
		try {
			checkCapabilityOrThrow(this.fs, this.capabilities, FSCapabilityFlags.Write, "writeFile", file.url);
			return await this.fs.writeFile(file);
		} catch (e) {
			this.logEvent("writeFile", "error", traceID, url, e instanceof Error ? e.message : "");
			throw wrapError(e);
		} finally {
			this.logEvent("writeFile", "end", traceID, url);
		}
	}
	static disposeOf(fs) {
		fs instanceof WrappedProviderFs && fs.fs?.dispose();
	}
};
function checkCapabilityOrThrow(fs, capabilities, flag, name, url) {
	if (!(capabilities & flag)) throw new VFSErrorUnsupportedRequest(name, url);
}
var CFileType = class {
	constructor(fileType) {
		this.fileType = fileType;
	}
	isFile() {
		return this.fileType === FileType.File;
	}
	isDirectory() {
		return this.fileType === FileType.Directory;
	}
	isUnknown() {
		return !this.fileType;
	}
	isSymbolicLink() {
		return !!(this.fileType & FileType.SymbolicLink);
	}
};
var CVfsStat = class extends CFileType {
	constructor(stat) {
		super(stat.fileType || FileType.Unknown);
		this.stat = stat;
	}
	get size() {
		return this.stat.size;
	}
	get mtimeMs() {
		return this.stat.mtimeMs;
	}
	get eTag() {
		return this.stat.eTag;
	}
};
var CVfsDirEntry = class extends CFileType {
	_url;
	constructor(entry) {
		super(entry.fileType);
		this.entry = entry;
	}
	get name() {
		return this.entry.name;
	}
	get dir() {
		return this.entry.dir;
	}
	get url() {
		if (this._url) return this._url;
		this._url = new URL(this.entry.name, this.entry.dir);
		return this._url;
	}
	toJSON() {
		return {
			name: this.name,
			dir: this.dir,
			fileType: this.fileType
		};
	}
};
function chopUrl(url) {
	if (!url) return "";
	const href = url.href;
	const parts = href.split("/");
	const n = parts.indexOf("node_modules");
	if (n > 0) {
		const tail = parts.slice(Math.max(parts.length - 3, n + 1));
		return parts.slice(0, n + 1).join("/") + "//" + tail.join("/");
	}
	return href;
}
function rPad(str, len, ch = " ") {
	return str.padEnd(len, ch);
}
function toOptions(val) {
	return typeof val === "string" ? { encoding: val } : val;
}
var CVirtualFS = class {
	providers = /* @__PURE__ */ new Set();
	cachedFs = /* @__PURE__ */ new Map();
	revCacheFs = /* @__PURE__ */ new Map();
	fsc;
	fs;
	loggingEnabled = debug;
	constructor() {
		this.fsc = fsPassThroughCore((url) => this._getFS(url));
		this.fs = new CVFileSystem(this.fsc);
	}
	enableLogging(value) {
		this.loggingEnabled = value ?? true;
	}
	log = console.log;
	logEvent = (event) => {
		if (this.loggingEnabled) {
			const id = event.traceID.toFixed(13).replaceAll(/\d{4}(?=\d)/g, "$&.");
			const msg = event.message ? `\n\t\t${event.message}` : "";
			const method = rPad(`${event.method}-${event.event}`, 16);
			this.log(`${method} ID:${id} ts:${event.ts.toFixed(13)} ${chopUrl(event.url)}${msg}`);
		}
	};
	registerFileSystemProvider(...providers) {
		providers.forEach((provider) => this.providers.add(provider));
		this.reset();
		return { dispose: () => {
			for (const provider of providers) {
				for (const key of this.revCacheFs.get(provider) || []) this.cachedFs.delete(key);
				this.providers.delete(provider);
			}
			this.reset();
		} };
	}
	getFS(url) {
		return new CVFileSystem(this._getFS(url));
	}
	_getFS(url) {
		const key = `${url.protocol}${url.hostname}`;
		const cached = this.cachedFs.get(key);
		if (cached) return cached;
		const fnNext = (provider, next) => {
			return (url) => {
				let calledNext = false;
				const fs = provider.getFileSystem(url, (_url) => {
					calledNext = calledNext || url === _url;
					return next(_url);
				});
				if (fs) {
					const s = this.revCacheFs.get(provider) || /* @__PURE__ */ new Set();
					s.add(key);
					this.revCacheFs.set(provider, s);
					return fs;
				}
				if (!calledNext) return next(url);
			};
		};
		let next = (_url) => void 0;
		for (const provider of this.providers) next = fnNext(provider, next);
		const fs = new WrappedProviderFs(next(url), this.logEvent);
		this.cachedFs.set(key, fs);
		return fs;
	}
	reset() {
		this.disposeOfCachedFs();
	}
	disposeOfCachedFs() {
		for (const [key, fs] of [...this.cachedFs].reverse()) {
			try {
				WrappedProviderFs.disposeOf(fs);
			} catch {}
			this.cachedFs.delete(key);
		}
		this.cachedFs.clear();
		this.revCacheFs.clear();
	}
	dispose() {
		this.disposeOfCachedFs();
		const providers = [...this.providers].reverse();
		for (const provider of providers) try {
			provider.dispose?.();
		} catch {}
	}
};
function fsPassThroughCore(fs) {
	function gfs(ur, name) {
		const url = urlOrReferenceToUrl(ur);
		const f = fs(url);
		if (!f.hasProvider) throw new VFSErrorUnsupportedRequest(name, url, ur instanceof URL ? void 0 : {
			url: ur.url.toString(),
			encoding: ur.encoding
		});
		return f;
	}
	return {
		providerInfo: { name: "default" },
		hasProvider: true,
		stat: async (url) => gfs(url, "stat").stat(url),
		readFile: async (url, options) => gfs(url, "readFile").readFile(url, options),
		writeFile: async (file) => gfs(file, "writeFile").writeFile(file),
		readDirectory: async (url) => gfs(url, "readDirectory").readDirectory(url).then((entries) => entries.map((e) => new CVfsDirEntry(e))),
		getCapabilities: (url) => gfs(url, "getCapabilities").getCapabilities(url)
	};
}
function createVirtualFS(cspellIO) {
	const cspell = cspellIO || getDefaultCSpellIO();
	const vfs = new CVirtualFS();
	vfs.registerFileSystemProvider(cspellIOToFsProvider(cspell));
	return vfs;
}
let defaultVirtualFs = void 0;
function getDefaultVirtualFs() {
	if (!defaultVirtualFs) defaultVirtualFs = createVirtualFS();
	return defaultVirtualFs;
}
const pipeline = promisify(Stream.pipeline);
async function readFileText(filename, encoding) {
	return (await getDefaultCSpellIO().readFile(filename, encoding)).getText();
}
async function getStat(filenameOrUri) {
	try {
		return await getDefaultCSpellIO().getStat(filenameOrUri);
	} catch (e) {
		return toError$1$1(e);
	}
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/fileSystem.js
function getVirtualFS() {
	return getDefaultVirtualFs();
}
function getFileSystem() {
	return getVirtualFS().fs;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/templates.js
function replaceTemplate(template, replacements) {
	const templateStart = "${";
	const tLen = 2;
	const templateEnd = "}";
	const parts = [];
	let lastPos = 0;
	let p = template.indexOf(templateStart, lastPos);
	if (p < 0) return template;
	while (p >= 0) {
		parts.push(template.substring(lastPos, p));
		lastPos = p;
		const end = template.indexOf(templateEnd, p);
		if (end < 0) break;
		const name = template.substring(p + tLen, end);
		if (name in replacements) parts.push(replacements[name] || "");
		else parts.push(template.substring(p, end + 1));
		lastPos = end + 1;
		p = template.indexOf(templateStart, lastPos);
	}
	parts.push(template.substring(lastPos));
	return parts.join("");
}
function envToTemplateVars(env) {
	const vars = {};
	for (const [key, value] of Object.entries(env)) vars[`env:${key}`] = value || "";
	return vars;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/resolveFile.js
var import_resolve_from = /* @__PURE__ */ __toESM(require_resolve_from$1(), 1);
const regExpStartsWidthNodeModules = /^node_modules[/\\]/;
var FileResolver = class {
	fs;
	templateReplacements;
	constructor(fs, templateReplacements) {
		this.fs = fs;
		this.templateReplacements = templateReplacements;
	}
	/**
	* Resolve filename to absolute paths.
	* - Replaces `${env:NAME}` with the value of the environment variable `NAME`.
	* - Replaces `~` with the user's home directory.
	* It tries to look for local files as well as node_modules
	* @param filename an absolute path, relative path, `~` path, a node_module, or URL.
	* @param relativeTo absolute path
	*/
	async resolveFile(filename, relativeTo) {
		if (filename instanceof URL) return {
			filename: toFilePathOrHref(filename),
			relativeTo: relativeTo.toString(),
			found: await this.doesExist(filename),
			method: "url"
		};
		const result = await this._resolveFile(filename, relativeTo);
		const match = filename.match(regExpStartsWidthNodeModules);
		if (match) result.warning ??= `Import of '${filename}' should not start with '${match[0]}' in '${toFilePathOrHref(relativeTo)}'. Use '${filename.replace(regExpStartsWidthNodeModules, "")}' or a relative path instead.`;
		return result;
	}
	async _resolveFile(filename, relativeTo) {
		filename = patchFilename(filename, this.templateReplacements);
		const steps = [
			{
				filename,
				fn: this.tryUrlRel
			},
			{
				filename,
				fn: this.tryCreateRequire
			},
			{
				filename,
				fn: this.tryNodeRequireResolve
			},
			{
				filename,
				fn: this.tryImportResolve
			},
			{
				filename,
				fn: this.tryResolveExists
			},
			{
				filename,
				fn: this.tryNodeResolveDefaultPaths
			},
			{
				filename,
				fn: this.tryResolveFrom
			},
			{
				filename,
				fn: this.tryResolveGlobal
			},
			{
				filename,
				fn: this.tryLegacyResolve
			}
		];
		for (const step of steps) {
			const r = await step.fn(step.filename, relativeTo);
			if (r?.found) return r;
		}
		return await this.tryUrl(filename, relativeTo) || {
			filename: isRelative(filename) ? joinWith(filename, relativeTo) : filename.toString(),
			relativeTo: relativeTo.toString(),
			found: false,
			method: "not found"
		};
	}
	async doesExist(file) {
		try {
			const s = await this.fs.stat(file);
			return s.isFile() || s.isUnknown();
		} catch {
			return false;
		}
	}
	/**
	* Check to see if it is a URL.
	* Note: URLs are absolute!
	* If relativeTo is a non-file URL, then it will try to resolve the filename relative to it.
	* @param filename - url string
	* @returns ResolveFileResult
	*/
	tryUrlRel = async (filename, relativeToURL) => {
		if (isUrlLike(filename)) {
			const fileURL = toURL$2(filename);
			return {
				filename: toFilePathOrHref(fileURL),
				relativeTo: void 0,
				found: await this.doesExist(fileURL),
				method: "tryUrl"
			};
		}
		if (isRelative(filename) && isUrlLike(relativeToURL) && !isDataURL(relativeToURL)) {
			const relToURL = toURL$2(relativeToURL);
			const url = toFileURL(filename, relToURL);
			return {
				filename: toFilePathOrHref(url),
				relativeTo: toFilePathOrHref(relToURL),
				found: await this.doesExist(url),
				method: "tryUrl"
			};
		}
	};
	/**
	* Check to see if it is a URL.
	* Note: URLs are absolute!
	* If relativeTo is a non-file URL, then it will try to resolve the filename relative to it.
	* @param filename - url string
	* @returns ResolveFileResult
	*/
	tryUrl = async (filename, relativeToURL) => {
		if (isUrlLike(relativeToURL) && !isDataURL(relativeToURL)) {
			const relToURL = toURL$2(relativeToURL);
			const url = toFileURL(filename, relToURL);
			return {
				filename: toFilePathOrHref(url),
				relativeTo: toFilePathOrHref(relToURL),
				found: await this.doesExist(url),
				method: "tryUrl"
			};
		}
	};
	tryCreateRequire = (filename, relativeTo) => {
		if (filename instanceof URL) return void 0;
		const rel = !isUrlLike(relativeTo) || isFileURL(relativeTo) ? relativeTo : toFileDirURL("./");
		try {
			return {
				filename: createRequire(rel).resolve(filename),
				relativeTo: rel.toString(),
				found: true,
				method: "tryCreateRequire"
			};
		} catch (error) {
			return;
		}
	};
	tryNodeResolveDefaultPaths = (filename) => {
		try {
			return {
				filename: __require$1.resolve(filename),
				relativeTo: void 0,
				found: true,
				method: "tryNodeResolveDefaultPaths"
			};
		} catch {
			return;
		}
	};
	tryNodeRequireResolve = (filenameOrURL, relativeTo) => {
		if (isUrlLike(relativeTo) && !isFileURL(relativeTo)) return void 0;
		const filename = fileURLOrPathToPath(filenameOrURL);
		const relativeToPath = pathFromRelativeTo(relativeTo);
		const home = os$2.homedir();
		function calcPaths(p) {
			const paths = [p];
			if (isRelative(filename)) return paths;
			for (; p && Path.dirname(p) !== p && p !== home; p = Path.dirname(p)) paths.push(p);
			return paths;
		}
		const paths = calcPaths(Path.resolve(relativeToPath));
		try {
			return {
				filename: __require$1.resolve(filename, { paths }),
				relativeTo: relativeToPath,
				found: true,
				method: "tryNodeRequireResolve"
			};
		} catch {
			return;
		}
	};
	tryImportResolve = (filename, relativeTo) => {
		try {
			return {
				filename: fileURLToPath(importResolveModuleName(filename, isRelative(filename) ? [relativeTo] : [relativeTo, srcDirectory])),
				relativeTo: relativeTo.toString(),
				found: true,
				method: "tryImportResolve"
			};
		} catch {
			return;
		}
	};
	tryResolveGlobal = (filename) => {
		const r = resolveGlobal(filename);
		return r && {
			filename: r,
			relativeTo: void 0,
			found: true,
			method: "tryResolveGlobal"
		} || void 0;
	};
	tryResolveExists = async (filename, relativeTo) => {
		if (filename instanceof URL || isUrlLike(filename) || isUrlLike(relativeTo) && !isFileURL(relativeTo)) return;
		relativeTo = pathFromRelativeTo(relativeTo);
		const toTry = [{ filename }, {
			filename: Path.resolve(relativeTo, filename),
			relativeTo
		}];
		for (const { filename, relativeTo } of toTry) {
			const found = Path.isAbsolute(filename) && await this.doesExist(toFileUrl(filename));
			if (found) return {
				filename,
				relativeTo: relativeTo?.toString(),
				found,
				method: "tryResolveExists"
			};
		}
		filename = Path.resolve(filename);
		return {
			filename,
			relativeTo: Path.resolve("."),
			found: await this.doesExist(toFileUrl(filename)),
			method: "tryResolveExists"
		};
	};
	tryResolveFrom = (filename, relativeTo) => {
		if (relativeTo instanceof URL) return void 0;
		try {
			return {
				filename: (0, import_resolve_from.default)(pathFromRelativeTo(relativeTo), filename),
				relativeTo,
				found: true,
				method: "tryResolveFrom"
			};
		} catch {
			return;
		}
	};
	tryLegacyResolve = (filename, relativeTo) => {
		if (filename instanceof URL || isUrlLike(filename) || isUrlLike(relativeTo) && !isFileURL(relativeTo)) return;
		const relativeToPath = isUrlLike(relativeTo) ? fileURLToPath(new URL("./", relativeTo)) : relativeTo.toString();
		if (filename.match(regExpStartsWidthNodeModules)) {
			const fixedFilename = filename.replace(regExpStartsWidthNodeModules, "");
			const found = this.tryImportResolve(fixedFilename, relativeToPath) || this.tryResolveFrom(fixedFilename, relativeToPath);
			if (found?.found) {
				found.method = "tryLegacyResolve";
				return found;
			}
		}
	};
};
function patchFilename(filename, templateReplacements) {
	const defaultReplacements = {
		cwd: process.cwd(),
		pathSeparator: Path.sep,
		userHome: os$2.homedir()
	};
	filename = filename.replace(/^~(?=[/\\])/, defaultReplacements.userHome);
	filename = replaceTemplate(filename, {
		...defaultReplacements,
		...templateReplacements
	});
	return filename;
}
/**
* Resolve filename to a URL
* - Replaces `${env:NAME}` with the value of the environment variable `NAME`.
* - Replaces `~` with the user's home directory.
* It will not resolve Node modules.
* @param filename - a filename, path, relative path, or URL.
* @param relativeTo - a path, or URL.
* @param env - environment variables used to patch the filename.
* @returns a URL
*/
function resolveRelativeTo(filename, relativeTo, templateReplacements = envToTemplateVars(process.env)) {
	if (filename instanceof URL) return filename;
	filename = patchFilename(filename, templateReplacements);
	const relativeToUrl = toFileUrl(relativeTo);
	return toFileURL(filename, relativeToUrl);
}
function isRelative(filename) {
	if (filename instanceof URL) return false;
	if (isUrlLike(filename)) return false;
	if (filename.startsWith("./")) return true;
	if (filename.startsWith("../")) return true;
	if (filename.startsWith("." + Path.sep)) return true;
	if (filename.startsWith(".." + Path.sep)) return true;
	return false;
}
function joinWith(filename, relativeTo) {
	return relativeTo instanceof URL || isUrlLike(relativeTo) ? toFilePathOrHref(new URL(filename, relativeTo)) : Path.resolve(relativeTo, filename);
}
function pathFromRelativeTo(relativeTo) {
	return relativeTo instanceof URL || isUrlLike(relativeTo) ? fileURLToPath(new URL("./", relativeTo)) : relativeTo;
}
const loaderCache = /* @__PURE__ */ new WeakMap();
function createFileResolver(fs, templateVariables = envToTemplateVars(process.env)) {
	let loader = loaderCache.get(fs);
	if (!loader) {
		loader = new FileResolver(fs, templateVariables);
		loaderCache.set(fs, loader);
	}
	return loader;
}
async function resolveFile(filename, relativeTo, fs = getFileSystem()) {
	return createFileResolver(fs).resolveFile(filename, relativeTo);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/DictionaryReferenceCollection.js
/**
* Create a collection of dictionary references to be able to easily determine if a dictionary is enabled or blocked.
* @param dictionaries - list of dictionary references
* @returns DictionaryReferenceCollection
*/
function createDictionaryReferenceCollection(dictionaries) {
	return new _DictionaryReferenceCollection(dictionaries);
}
var _DictionaryReferenceCollection = class {
	dictionaries;
	collection;
	constructor(dictionaries) {
		this.dictionaries = dictionaries;
		this.collection = collect(dictionaries);
	}
	isEnabled(name) {
		const entry = this.collection[name];
		return entry === void 0 ? void 0 : !!(entry & 1);
	}
	isBlocked(name) {
		const entry = this.collection[name];
		return entry === void 0 ? void 0 : !(entry & 1);
	}
	enabled() {
		return this.dictionaryIds.filter((n) => this.isEnabled(n));
	}
	blocked() {
		return this.dictionaryIds.filter((n) => this.isBlocked(n));
	}
	get dictionaryIds() {
		return Object.keys(this.collection);
	}
};
function collect(dictionaries) {
	const refs = dictionaries.map(normalizeName).map(mapReference);
	const col = {};
	for (const ref of refs) col[ref.name] = Math.max(ref.weight, col[ref.name] || 0);
	return col;
}
function normalizeName(entry) {
	return entry.normalize().trim();
}
function mapReference(ref) {
	const name = ref.replace(/^!+/, "");
	const weight = ref.length - name.length + 1;
	return {
		name: name.trim(),
		weight
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/internal/InternalDictionaryDef.js
function isDictionaryDefinitionInlineInternal(def) {
	if (def.path) return false;
	const defInline = def;
	return !!(defInline.words || defInline.flagWords || defInline.ignoreWords || defInline.suggestWords);
}
function isDictionaryFileDefinitionInternal(def) {
	return !!(def.path || def.file);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/internal/DictionarySettings.js
/**
* Combines the list of desired dictionaries with the list of dictionary
* definitions. Order does not matter, but the number of leading `!` does.
*
* Excluding dictionaries.
* - Adding `!` to a dictId will remove the dictionary.
* - Adding `!!` will add it back.
*
* @param dictRefCol - dictionaries desired
* @param defs - dictionary definitions
* @returns map from dictIds to definitions
*/
function filterDictDefsToLoad(dictRefCol, defs) {
	const allActiveDefs = defs.filter(({ name }) => dictRefCol.isEnabled(name)).map(fixPath);
	return [...new Map(allActiveDefs.map((d) => [d.name, d])).values()];
}
function fixPath(def) {
	if (def instanceof _DictionaryDefinitionInternalWithSource) return def;
	const newPath = fixDicPath(def.path, def.file);
	const newBTriePath = def.btrie ? fixDicPath(def.btrie, def.file) : void 0;
	return {
		...def,
		file: void 0,
		path: newPath,
		btrie: newBTriePath
	};
}
function fixDicPath(defPath, defFile) {
	const parts = [defPath || "", defFile || ""].filter((p) => !!p);
	return parts.length > 1 ? Path.join(...parts) : parts[0] || "";
}
function mapDictDefsToInternal(defs, pathToSettingsFile) {
	return defs?.map((def) => mapDictDefToInternal(def, pathToSettingsFile));
}
const internalDefs = createAutoResolveWeakWeakCache();
function mapDictDefToInternal(def, pathToSettingsFile) {
	return internalDefs.get(def, (def) => _mapDictDefToInternal(def, pathToSettingsFile));
}
function _mapDictDefToInternal(def, pathToSettingsFile) {
	if (isDictionaryDefinitionWithSource(def)) return def;
	const source = pathToSettingsFile.href;
	if (isDictionaryDefinitionInlineInternal(def)) return {
		...def,
		__source: source
	};
	return new _DictionaryDefinitionInternalWithSource(def, pathToSettingsFile);
}
function determineName(filename, options) {
	return options.name || Path.basename(filename);
}
function calcDictionaryDefsToLoad(settings) {
	const { dictionaries = [], dictionaryDefinitions = [], noSuggestDictionaries = [] } = settings;
	const colNoSug = createDictionaryReferenceCollection(noSuggestDictionaries);
	return filterDictDefsToLoad(createDictionaryReferenceCollection([...dictionaries, ...colNoSug.enabled()]), dictionaryDefinitions.map((def) => {
		const enabled = colNoSug.isEnabled(def.name);
		if (enabled === void 0) return def;
		return {
			...def,
			noSuggest: enabled
		};
	}));
}
function isDictionaryDefinitionWithSource(d) {
	return isDictionaryFileDefinitionInternalWithSource(d) || isDictionaryDefinitionInlineInternalWithSource(d);
}
function isDictionaryFileDefinitionInternalWithSource(def) {
	return def instanceof _DictionaryDefinitionInternalWithSource;
}
function isDictionaryDefinitionInlineInternalWithSource(def) {
	return isDictionaryDefinitionInlineInternal(def) && !!def.__source;
}
var _DictionaryDefinitionInternalWithSource = class {
	sourceURL;
	_weightMap;
	name;
	path;
	addWords;
	description;
	dictionaryInformation;
	type;
	file;
	repMap;
	useCompounds;
	noSuggest;
	ignoreForbiddenWords;
	scope;
	__source;
	#ddi;
	#def;
	constructor(def, sourceURL) {
		this.sourceURL = sourceURL;
		this.#def = def;
		this.__source = sourceURL.href;
		const { path: relPath = "", file = "", btrie, addWords, description, dictionaryInformation, type, repMap, noSuggest, ignoreForbiddenWords, scope, supportNonStrictSearches, useCompounds } = def;
		const defaultPath = sourceURL;
		const filePath = fixDicPath(relPath, file);
		const name = determineName(filePath, def);
		const resolvedPath = toFilePathOrHref(resolveRelativeTo(filePath, defaultPath));
		let bTriePath = btrie ? fixDicPath(btrie, file) : void 0;
		bTriePath = bTriePath ? toFilePathOrHref(resolveRelativeTo(bTriePath, defaultPath)) : void 0;
		const ddi = {
			name,
			file: void 0,
			path: resolvedPath,
			btrie: bTriePath,
			addWords,
			description,
			dictionaryInformation,
			type,
			repMap,
			noSuggest,
			ignoreForbiddenWords,
			supportNonStrictSearches,
			scope,
			useCompounds
		};
		Object.assign(this, clean$1(ddi));
		this.#ddi = ddi;
		this.name = ddi.name;
		this.file = ddi.file;
		this.path = ddi.path;
		this._weightMap = this.dictionaryInformation ? mapDictionaryInformationToWeightMap(this.dictionaryInformation) : void 0;
	}
	get weightMap() {
		return this._weightMap;
	}
	toJSON() {
		return this.#ddi;
	}
	__getOriginalDefinition() {
		return this.#def;
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/mergeCache.js
var CalcLeftRightResultWeakCache = class {
	map = new AutoResolveWeakCache();
	_toDispose;
	constructor() {
		this._toDispose = onClearCache(() => {
			this.clear();
		});
	}
	get(left, right, calc) {
		return this.map.get(left, () => new AutoResolveWeakCache()).get(right, () => calc(left, right));
	}
	clear() {
		this.map.clear();
	}
	dispose() {
		this.map.dispose();
		this._toDispose?.dispose();
		this._toDispose = void 0;
	}
	stats() {
		return this.map.stats();
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/mergeList.js
const cacheMergeListUnique = new CalcLeftRightResultWeakCache();
const cacheMergeLists = new CalcLeftRightResultWeakCache();
function mergeListUnique(left, right) {
	if (!Array.isArray(left)) return Array.isArray(right) ? right : void 0;
	if (!Array.isArray(right)) return left;
	if (!right.length) return left;
	if (!left.length) return right;
	const result = cacheMergeListUnique.get(left, right, (left, right) => [...new Set([...left, ...right])]);
	Object.freeze(left);
	Object.freeze(right);
	Object.freeze(result);
	return result;
}
function mergeList$1(left, right) {
	if (!Array.isArray(left)) return Array.isArray(right) ? right : void 0;
	if (!Array.isArray(right)) return left;
	if (!left.length) return right;
	if (!right.length) return left;
	const result = cacheMergeLists.get(left, right, (left, right) => [...left, ...right]);
	Object.freeze(left);
	Object.freeze(right);
	Object.freeze(result);
	return result;
}
function stats() {
	return {
		cacheMergeListUnique: cacheMergeListUnique.stats(),
		cacheMergeLists: cacheMergeLists.stats()
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/textRegex.js
const regExSplitWords = /(\p{Ll}\p{M}?)(\p{Lu})/gu;
const regExSplitWords2 = /(\p{Lu}\p{M}?)((\p{Lu}\p{M}?)\p{Ll})/gu;
const regExpCamelCaseWordBreaksWithEnglishSuffix = /(?<=\p{Ll}\p{M}?)(?=\p{Lu})|(?<=\p{Lu}\p{M}?)(?=\p{Lu}\p{M}?\p{Ll})(?!\p{Lu}\p{M}?(?:s|ing|ies|es|ings|ed|ning)(?!\p{Ll}))/gu;
const regExWords = /\p{L}\p{M}?(?:(?:\\?['])?\p{L}\p{M}?)*/gu;
const regExWordsAndDigits = /[\p{L}\w'`.+-](?:(?:\\(?=[']))?[\p{L}\p{M}\w'`.+-])*/gu;
const regExIgnoreCharacters = /[\p{sc=Hiragana}\p{sc=Han}\p{sc=Katakana}\u30A0-\u30FF\p{sc=Hangul}]/gu;
const regExPossibleWordBreaks = /[-+_'`.\s]/g;
const regExMatchRegExParts = /^\s*\/([\s\S]*?)\/([gimuxy]*)\s*$/;
const regExEscapeCharacters$1 = /(?<=\\)[anrvtbf]/gi;
/** Matches against leading `'` or `{single letter}'` */
const regExDanglingQuote = /(?<=(?:^|(?!\p{M})\P{L})(?:\p{L}\p{M}?)?)[']/gu;
/** Match tailing endings after CAPS words */
const regExTrailingEndings = /(?<=(?:\p{Lu}\p{M}?){2})[']?(?:s|d|ings?|ies|e[ds]?|ning|th|nth)(?!\p{Ll})/gu;
const regExNumericLiteral = /^[-+]?(?:\d+(?:\.\d*)?|\.\d+)(?:[eE][-+]?\d+)?$/;
function stringToRegExp(pattern, defaultFlags = "gimu", forceFlags = "g") {
	if (pattern instanceof RegExp) return pattern;
	try {
		const [, pat, flag] = [...pattern.match(regExMatchRegExParts) || [
			"",
			pattern.trim(),
			defaultFlags
		], forceFlags];
		if (pat) {
			const regPattern = flag.includes("x") ? removeVerboseFromRegExp(pat) : pat;
			const flags = [...new Set(forceFlags + flag)].join("").replaceAll(/[^gimuy]/g, "");
			return new RegExp(regPattern, flags);
		}
	} catch {}
}
const SPACES = {
	" ": true,
	"\n": true,
	"\r": true,
	"	": true
};
/**
* Remove all whitespace and comments from a regexp string. The format follows Pythons Verbose.
* Note: this is a best attempt. Special cases for comments: `#` and spaces should be proceeded with a `\`
*
* All space must be proceeded by a `\` or in a character class `[]`
*
* @param pattern - the pattern to clean
*/
function removeVerboseFromRegExp(pattern) {
	function escape(acc) {
		if (pattern[acc.idx] !== "\\") return void 0;
		const next = pattern[++acc.idx];
		acc.idx++;
		if (next === "#") {
			acc.result += "#";
			return acc;
		}
		if (!(next in SPACES)) {
			acc.result += "\\" + next;
			return acc;
		}
		acc.result += next;
		if (next === "\r" && pattern[acc.idx] === "\n") {
			acc.result += "\n";
			acc.idx++;
		}
		return acc;
	}
	function braces(acc) {
		const char = pattern[acc.idx];
		if (char !== "[") return void 0;
		acc.result += char;
		acc.idx++;
		let escCount = 0;
		while (acc.idx < pattern.length) {
			const char = pattern[acc.idx];
			acc.result += char;
			acc.idx++;
			if (char === "]" && !(escCount & 1)) break;
			escCount = char === "\\" ? escCount + 1 : 0;
		}
		return acc;
	}
	function spaces(acc) {
		if (!(pattern[acc.idx] in SPACES)) return void 0;
		acc.idx++;
		return acc;
	}
	function comments(acc) {
		if (pattern[acc.idx] !== "#") return void 0;
		while (acc.idx < pattern.length && pattern[acc.idx] !== "\n") acc.idx++;
		return acc;
	}
	function copy(acc) {
		const char = pattern[acc.idx++];
		acc.result += char;
		return acc;
	}
	const reducers = [
		escape,
		braces,
		spaces,
		comments,
		copy
	];
	const result = {
		idx: 0,
		result: ""
	};
	while (result.idx < pattern.length) for (const r of reducers) if (r(result)) break;
	return result.result;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/patterns.js
const emptyRegExpList = [];
const emptyPatternDefinitions = [];
const cache = new CalcLeftRightResultWeakCache();
function resolvePatterns(regExpList = emptyRegExpList, patternDefinitions = emptyPatternDefinitions) {
	return cache.get(regExpList, patternDefinitions, _resolvePatterns);
}
function _resolvePatterns(regExpList, patternDefinitions) {
	const patternMap = new Map(patternDefinitions.map((def) => [def.name.toLowerCase(), def.pattern]));
	const resolved = /* @__PURE__ */ new Set();
	function resolvePattern(p) {
		if (resolved.has(p)) return void 0;
		resolved.add(p);
		return patternMap.get(p.toString().toLowerCase()) || p;
	}
	function* flatten(patterns) {
		for (const pattern of patterns) if (Array.isArray(pattern)) yield* flatten(pattern.map(resolvePattern).filter(isDefined$2));
		else yield pattern;
	}
	const result = [...flatten(regExpList.map(resolvePattern).filter(isDefined$2))].map(toRegExp).filter(isDefined$2);
	Object.freeze(regExpList);
	Object.freeze(patternDefinitions);
	Object.freeze(result);
	return result;
}
function toRegExp(pattern) {
	return pattern instanceof RegExp ? new RegExp(pattern) : stringToRegExp(pattern, "gim", "g");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/resolveCwd.js
var CwdUrlResolver = class {
	#lastPath;
	#lastUrl;
	#cwd;
	#cwdUrl;
	constructor() {
		this.#cwd = process.cwd();
		this.#cwdUrl = toFileDirURL(this.#cwd);
		this.#lastPath = this.#cwd;
		this.#lastUrl = this.#cwdUrl;
	}
	resolveUrl(path) {
		path = path || this.#cwd;
		if (path === this.#lastPath) return this.#lastUrl;
		if (path === this.#cwd) return this.#cwdUrl;
		this.#lastPath = path;
		this.#lastUrl = toFileURL(path);
		return this.#lastUrl;
	}
	reset(cwd = process.cwd()) {
		this.#cwd = cwd;
		this.#cwdUrl = toFileDirURL(this.#cwd);
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/CSpellSettingsServer.js
const emptyWords$1 = [];
Object.freeze(emptyWords$1);
const cachedMerges = new AutoResolveWeakCache();
const mergeCache = new AutoResolveWeakCache();
const cacheInternalSettings = new AutoResolveWeakCache();
const parserCache = new AutoResolveWeakCache();
const emptyParserMap = /* @__PURE__ */ new Map();
const cwdResolver = new CwdUrlResolver();
let envCSpellGlobRoot = process.env[ENV_CSPELL_GLOB_ROOT];
onClearCache(() => {
	parserCache.clear();
	emptyParserMap.clear();
	cachedMerges.clear();
	mergeCache.clear();
	cacheInternalSettings.clear();
	cwdResolver.reset();
	envCSpellGlobRoot = process.env[ENV_CSPELL_GLOB_ROOT];
});
function _mergeWordsCached(left, right) {
	return autoResolveWeak(autoResolveWeak(cachedMerges, left, () => /* @__PURE__ */ new WeakMap()), right, () => [...left, ...right]);
}
function mergeWordsCached(left, right) {
	if (!Array.isArray(left) || !left.length) return Array.isArray(right) ? right.length ? right : emptyWords$1 : void 0;
	if (!Array.isArray(right) || !right.length) return left;
	return _mergeWordsCached(left, right);
}
function mergeObjects(left, right) {
	if (!left || typeof left !== "object") return !right || typeof right !== "object" ? void 0 : right;
	if (!right || typeof right !== "object") return left;
	return {
		...left,
		...right
	};
}
function replaceIfNotEmpty(left = [], right = []) {
	const filtered = right.filter((a) => !!a);
	if (filtered.length) return filtered;
	return left;
}
function mergeSettings(left, ...settings) {
	const rawSettings = settings.filter(isDefined$2).reduce(merge$2, toInternalSettings(left));
	return clean$1(rawSettings);
}
function isEmpty(obj) {
	return !obj || Object.keys(obj).length === 0;
}
function merge$2(left, right) {
	return autoResolveWeak(mergeCache.get(left, () => /* @__PURE__ */ new WeakMap()), right, () => _merge(left, right));
}
function _merge(left, right) {
	const _left = toInternalSettings(left);
	const _right = toInternalSettings(right);
	if (left === right) return _left;
	if (isEmpty(right)) return _left;
	if (isEmpty(left)) return _right;
	if (isLeftAncestorOfRight(_left, _right)) return _right;
	if (doesLeftHaveRightAncestor(_left, _right)) return _left;
	const includeRegExpList = takeRightOtherwiseLeft(_left.includeRegExpList, _right.includeRegExpList);
	const optionals = includeRegExpList?.length ? { includeRegExpList } : {};
	const version = max(_left.version, _right.version);
	const valuesToClear = {
		name: void 0,
		id: void 0,
		description: void 0,
		globRoot: void 0,
		import: void 0,
		__importRef: void 0
	};
	return cleanCSpellSettingsInternal({
		..._left,
		..._right,
		...optionals,
		...valuesToClear,
		version,
		words: mergeWordsCached(_left.words, _right.words),
		userWords: mergeWordsCached(_left.userWords, _right.userWords),
		flagWords: mergeWordsCached(_left.flagWords, _right.flagWords),
		ignoreWords: mergeWordsCached(_left.ignoreWords, _right.ignoreWords),
		suggestWords: mergeWordsCached(_left.suggestWords, _right.suggestWords),
		enabledLanguageIds: replaceIfNotEmpty(_left.enabledLanguageIds, _right.enabledLanguageIds),
		enableFiletypes: mergeList$1(_left.enableFiletypes, _right.enableFiletypes),
		enabledFileTypes: mergeObjects(_left.enabledFileTypes, _right.enabledFileTypes),
		ignoreRegExpList: mergeListUnique(_left.ignoreRegExpList, _right.ignoreRegExpList),
		patterns: mergeListUnique(_left.patterns, _right.patterns),
		dictionaryDefinitions: mergeListUnique(_left.dictionaryDefinitions, _right.dictionaryDefinitions),
		dictionaries: mergeListUnique(_left.dictionaries, _right.dictionaries),
		noSuggestDictionaries: mergeListUnique(_left.noSuggestDictionaries, _right.noSuggestDictionaries),
		languageSettings: mergeList$1(_left.languageSettings, _right.languageSettings),
		enabled: _right.enabled !== void 0 ? _right.enabled : _left.enabled,
		files: mergeListUnique(_left.files, _right.files),
		ignorePaths: versionBasedMergeList(_left.ignorePaths, _right.ignorePaths, version),
		overrides: versionBasedMergeList(_left.overrides, _right.overrides, version),
		features: mergeObjects(_left.features, _right.features),
		source: mergeSources(_left, _right),
		plugins: mergeList$1(_left.plugins, _right.plugins),
		__imports: mergeImportRefs$1(_left, _right)
	});
}
function versionBasedMergeList(left, right, version) {
	if (version === configSettingsFileVersion0_1) return takeRightOtherwiseLeft(left, right);
	return mergeListUnique(left, right);
}
/**
* Check to see if left is a left ancestor of right.
* If that is the case, merging is not necessary:
* @param left - setting on the left side of a merge
* @param right - setting on the right side of a merge
*/
function isLeftAncestorOfRight(left, right) {
	return hasAncestor(right, left, 0);
}
/**
* Check to see if left has right as an ancestor to the right.
* If that is the case, merging is not necessary:
* @param left - setting on the left side of a merge
* @param right - setting on the right side of a merge
*/
function doesLeftHaveRightAncestor(left, right) {
	return hasAncestor(left, right, 1);
}
function hasAncestor(s, ancestor, side) {
	const sources = s.source?.sources;
	if (!sources) return false;
	const src = sources[side ? sources.length - 1 : 0];
	return src === ancestor || src && hasAncestor(src, ancestor, side) || false;
}
function takeRightOtherwiseLeft(left, right) {
	if (right?.length) return right;
	return left || right;
}
/**
*
* @param settings - settings to finalize
* @returns settings where all globs and file paths have been resolved.
*/
function finalizeSettings(settings) {
	return _finalizeSettings(toInternalSettings(settings));
}
function _finalizeSettings(settings) {
	const finalized = {
		...settings,
		finalized: true,
		ignoreRegExpList: resolvePatterns(settings.ignoreRegExpList, settings.patterns),
		includeRegExpList: resolvePatterns(settings.includeRegExpList, settings.patterns),
		parserFn: resolveParser(settings)
	};
	finalized.name = "Finalized " + (finalized.name || "");
	finalized.source = {
		name: settings.name || "src",
		sources: [settings]
	};
	return finalized;
}
function toInternalSettings(settings) {
	if (settings === void 0) return void 0;
	if (isCSpellSettingsInternal(settings)) return settings;
	return cacheInternalSettings.get(settings, _toInternalSettings);
}
function _toInternalSettings(settings) {
	const { dictionaryDefinitions: defs, ...rest } = settings;
	const dictionaryDefinitions = defs && mapDictDefsToInternal(defs, settings.source?.filename && toFileUrl(settings.source?.filename) || resolveCwd());
	return cleanCSpellSettingsInternal(dictionaryDefinitions ? {
		...rest,
		dictionaryDefinitions
	} : rest);
}
function mergeSources(left, right) {
	return {
		name: "merged",
		sources: [left, right]
	};
}
function max(a, b) {
	if (a === void 0 || a === null) return b;
	if (b === void 0 || b === null) return a;
	return a > b ? a : b;
}
/**
* Return a list of Setting Sources used to create this Setting.
* @param settings the settings to search
*/
function getSources(settings) {
	const visited = /* @__PURE__ */ new Set();
	const sources = [];
	function _walkSourcesTree(settings) {
		if (!settings || visited.has(settings)) return;
		visited.add(settings);
		if (!settings.source?.sources?.length) {
			sources.push(settings);
			return;
		}
		settings.source.sources.forEach(_walkSourcesTree);
	}
	_walkSourcesTree(settings);
	return sources;
}
function mergeImportRefs$1(left, right = {}) {
	const imports = new Map(left.__imports || []);
	if (left.__importRef) imports.set(left.__importRef.filename, left.__importRef);
	if (right.__importRef) imports.set(right.__importRef.filename, right.__importRef);
	const rightImports = right.__imports?.values() || [];
	for (const ref of rightImports) imports.set(ref.filename, ref);
	return imports.size ? imports : void 0;
}
function extractDependencies(settings) {
	const settingsI = toInternalSettings(settings);
	return {
		configFiles: [...mergeImportRefs$1(settingsI) || []].map(([filename]) => filename),
		dictionaryFiles: calcDictionaryDefsToLoad(settingsI).map((dict) => dict.path).filter((file) => !!file)
	};
}
function resolveCwd() {
	return cwdResolver.resolveUrl(envCSpellGlobRoot);
}
function resolveParser(settings) {
	if (!settings.parser) return void 0;
	if (typeof settings.parser === "function") return settings.parser;
	const parserName = settings.parser;
	assert(typeof parserName === "string");
	const parser = extractParsers(settings.plugins).get(parserName);
	assert(parser, `Parser "${parserName}" not found.`);
	return parser;
}
function* parsers$1(plugins) {
	for (const plugin of plugins) {
		if (!plugin.parsers) continue;
		for (const parser of plugin.parsers) yield [parser.name, parser];
	}
}
function mapPlugins(plugins) {
	return new Map(parsers$1(plugins));
}
function extractParsers(plugins) {
	if (!plugins || !plugins.length) return emptyParserMap;
	return parserCache.get(plugins, mapPlugins);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/calcOverrideSettings.js
function calcOverrideSettings(settings, filename) {
	const _settings = toInternalSettings(settings);
	return (_settings.overrides || []).filter((override) => checkFilenameMatchesExcludeGlob(filename, override.filename)).reduce((settings, override) => mergeSettings(settings, override), _settings);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile.js
var CSpellConfigFile = class {
	url;
	constructor(url) {
		this.url = url;
	}
	get readonly() {
		return this.settings.readonly || this.url.protocol !== "file:";
	}
	get virtual() {
		return false;
	}
	get remote() {
		return this.url.protocol !== "file:";
	}
};
var MutableCSpellConfigFile = class extends CSpellConfigFile {};
var ImplCSpellConfigFile = class extends CSpellConfigFile {
	url;
	settings;
	constructor(url, settings) {
		super(url);
		this.url = url;
		this.settings = settings;
	}
	setSchema(_schema) {
		return this;
	}
	removeAllComments() {
		if (this.readonly) throw new Error(`Config file is readonly: ${this.url.href}`);
		return this;
	}
	addWords(words) {
		if (this.readonly) throw new Error(`Config file is readonly: ${this.url.href}`);
		const w = this.settings.words || [];
		this.settings.words = w;
		addUniqueWordsToListAndSort(w, words);
		return this;
	}
	setComment(_key, _comment, _inline) {
		if (this.readonly) throw new Error(`Config file is readonly: ${this.url.href}`);
		return this;
	}
	setValue(key, value) {
		if (this.readonly) throw new Error(`Config file is readonly: ${this.url.href}`);
		this.settings[key] = value;
		return this;
	}
};
/**
* Adds words to a list, sorts the list and makes sure it is unique.
* Note: this method is used to try and preserve comments in the config file.
* @param list - list to be modified
* @param toAdd - words to add
*/
function addUniqueWordsToListAndSort(list, toAdd) {
	list.push(...toAdd);
	list.sort();
	for (let i = 1; i < list.length; ++i) if (list[i] === list[i - 1]) {
		list.splice(i, 1);
		--i;
	}
}
function satisfiesCSpellConfigFile(obj) {
	return obj instanceof CSpellConfigFile || !!obj && typeof obj === "object" && "url" in obj && obj.url instanceof URL && "settings" in obj && !!obj.settings && typeof obj.settings === "object";
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFileInMemory.js
var CSpellConfigFileInMemory = class CSpellConfigFileInMemory extends ImplCSpellConfigFile {
	url;
	settings;
	constructor(url, settings) {
		super(url, settings);
		this.url = url;
		this.settings = settings;
	}
	setSchema(schema) {
		this.settings.$schema = schema;
		return this;
	}
	get virtual() {
		return true;
	}
	static from(url, settings, _indent) {
		return new CSpellConfigFileInMemory(url, settings);
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFileJavaScript.js
var CSpellConfigFileJavaScript = class extends ImplCSpellConfigFile {
	url;
	settings;
	get readonly() {
		return true;
	}
	constructor(url, settings) {
		super(url, settings);
		this.url = url;
		this.settings = settings;
	}
	addWords(_words) {
		throw new Error("Unable to add words to a JavaScript config file.");
	}
};

//#endregion
//#region ../node_modules/.pnpm/esprima@4.0.1/node_modules/esprima/dist/esprima.js
var require_esprima = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	(function webpackUniversalModuleDefinition(root, factory) {
		/* istanbul ignore next */
		if (typeof exports === "object" && typeof module === "object") module.exports = factory();
		else if (typeof define === "function" && define.amd) define([], factory);
		else if (typeof exports === "object") exports["esprima"] = factory();
		else root["esprima"] = factory();
	})(exports, function() {
		return (function(modules) {
			var installedModules = {};
			function __webpack_require__(moduleId) {
				/* istanbul ignore if */
				if (installedModules[moduleId]) return installedModules[moduleId].exports;
				var module$1 = installedModules[moduleId] = {
					exports: {},
					id: moduleId,
					loaded: false
				};
				modules[moduleId].call(module$1.exports, module$1, module$1.exports, __webpack_require__);
				module$1.loaded = true;
				return module$1.exports;
			}
			__webpack_require__.m = modules;
			__webpack_require__.c = installedModules;
			__webpack_require__.p = "";
			return __webpack_require__(0);
		})([
			function(module$2, exports$1, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$1, "__esModule", { value: true });
				var comment_handler_1 = __webpack_require__(1);
				var jsx_parser_1 = __webpack_require__(3);
				var parser_1 = __webpack_require__(8);
				var tokenizer_1 = __webpack_require__(15);
				function parse(code, options, delegate) {
					var commentHandler = null;
					var proxyDelegate = function(node, metadata) {
						if (delegate) delegate(node, metadata);
						if (commentHandler) commentHandler.visit(node, metadata);
					};
					var parserDelegate = typeof delegate === "function" ? proxyDelegate : null;
					var collectComment = false;
					if (options) {
						collectComment = typeof options.comment === "boolean" && options.comment;
						var attachComment = typeof options.attachComment === "boolean" && options.attachComment;
						if (collectComment || attachComment) {
							commentHandler = new comment_handler_1.CommentHandler();
							commentHandler.attach = attachComment;
							options.comment = true;
							parserDelegate = proxyDelegate;
						}
					}
					var isModule = false;
					if (options && typeof options.sourceType === "string") isModule = options.sourceType === "module";
					var parser;
					if (options && typeof options.jsx === "boolean" && options.jsx) parser = new jsx_parser_1.JSXParser(code, options, parserDelegate);
					else parser = new parser_1.Parser(code, options, parserDelegate);
					var ast = isModule ? parser.parseModule() : parser.parseScript();
					if (collectComment && commentHandler) ast.comments = commentHandler.comments;
					if (parser.config.tokens) ast.tokens = parser.tokens;
					if (parser.config.tolerant) ast.errors = parser.errorHandler.errors;
					return ast;
				}
				exports$1.parse = parse;
				function parseModule(code, options, delegate) {
					var parsingOptions = options || {};
					parsingOptions.sourceType = "module";
					return parse(code, parsingOptions, delegate);
				}
				exports$1.parseModule = parseModule;
				function parseScript(code, options, delegate) {
					var parsingOptions = options || {};
					parsingOptions.sourceType = "script";
					return parse(code, parsingOptions, delegate);
				}
				exports$1.parseScript = parseScript;
				function tokenize(code, options, delegate) {
					var tokenizer = new tokenizer_1.Tokenizer(code, options);
					var tokens = [];
					try {
						while (true) {
							var token = tokenizer.getNextToken();
							if (!token) break;
							if (delegate) token = delegate(token);
							tokens.push(token);
						}
					} catch (e) {
						tokenizer.errorHandler.tolerate(e);
					}
					if (tokenizer.errorHandler.tolerant) tokens.errors = tokenizer.errors();
					return tokens;
				}
				exports$1.tokenize = tokenize;
				exports$1.Syntax = __webpack_require__(2).Syntax;
				exports$1.version = "4.0.1";
			},
			function(module$3, exports$2, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$2, "__esModule", { value: true });
				var syntax_1 = __webpack_require__(2);
				exports$2.CommentHandler = function() {
					function CommentHandler() {
						this.attach = false;
						this.comments = [];
						this.stack = [];
						this.leading = [];
						this.trailing = [];
					}
					CommentHandler.prototype.insertInnerComments = function(node, metadata) {
						if (node.type === syntax_1.Syntax.BlockStatement && node.body.length === 0) {
							var innerComments = [];
							for (var i = this.leading.length - 1; i >= 0; --i) {
								var entry = this.leading[i];
								if (metadata.end.offset >= entry.start) {
									innerComments.unshift(entry.comment);
									this.leading.splice(i, 1);
									this.trailing.splice(i, 1);
								}
							}
							if (innerComments.length) node.innerComments = innerComments;
						}
					};
					CommentHandler.prototype.findTrailingComments = function(metadata) {
						var trailingComments = [];
						if (this.trailing.length > 0) {
							for (var i = this.trailing.length - 1; i >= 0; --i) {
								var entry_1 = this.trailing[i];
								if (entry_1.start >= metadata.end.offset) trailingComments.unshift(entry_1.comment);
							}
							this.trailing.length = 0;
							return trailingComments;
						}
						var entry = this.stack[this.stack.length - 1];
						if (entry && entry.node.trailingComments) {
							var firstComment = entry.node.trailingComments[0];
							if (firstComment && firstComment.range[0] >= metadata.end.offset) {
								trailingComments = entry.node.trailingComments;
								delete entry.node.trailingComments;
							}
						}
						return trailingComments;
					};
					CommentHandler.prototype.findLeadingComments = function(metadata) {
						var leadingComments = [];
						var target;
						while (this.stack.length > 0) {
							var entry = this.stack[this.stack.length - 1];
							if (entry && entry.start >= metadata.start.offset) {
								target = entry.node;
								this.stack.pop();
							} else break;
						}
						if (target) {
							for (var i = (target.leadingComments ? target.leadingComments.length : 0) - 1; i >= 0; --i) {
								var comment = target.leadingComments[i];
								if (comment.range[1] <= metadata.start.offset) {
									leadingComments.unshift(comment);
									target.leadingComments.splice(i, 1);
								}
							}
							if (target.leadingComments && target.leadingComments.length === 0) delete target.leadingComments;
							return leadingComments;
						}
						for (var i = this.leading.length - 1; i >= 0; --i) {
							var entry = this.leading[i];
							if (entry.start <= metadata.start.offset) {
								leadingComments.unshift(entry.comment);
								this.leading.splice(i, 1);
							}
						}
						return leadingComments;
					};
					CommentHandler.prototype.visitNode = function(node, metadata) {
						if (node.type === syntax_1.Syntax.Program && node.body.length > 0) return;
						this.insertInnerComments(node, metadata);
						var trailingComments = this.findTrailingComments(metadata);
						var leadingComments = this.findLeadingComments(metadata);
						if (leadingComments.length > 0) node.leadingComments = leadingComments;
						if (trailingComments.length > 0) node.trailingComments = trailingComments;
						this.stack.push({
							node,
							start: metadata.start.offset
						});
					};
					CommentHandler.prototype.visitComment = function(node, metadata) {
						var type = node.type[0] === "L" ? "Line" : "Block";
						var comment = {
							type,
							value: node.value
						};
						if (node.range) comment.range = node.range;
						if (node.loc) comment.loc = node.loc;
						this.comments.push(comment);
						if (this.attach) {
							var entry = {
								comment: {
									type,
									value: node.value,
									range: [metadata.start.offset, metadata.end.offset]
								},
								start: metadata.start.offset
							};
							if (node.loc) entry.comment.loc = node.loc;
							node.type = type;
							this.leading.push(entry);
							this.trailing.push(entry);
						}
					};
					CommentHandler.prototype.visit = function(node, metadata) {
						if (node.type === "LineComment") this.visitComment(node, metadata);
						else if (node.type === "BlockComment") this.visitComment(node, metadata);
						else if (this.attach) this.visitNode(node, metadata);
					};
					return CommentHandler;
				}();
			},
			function(module$4, exports$3) {
				"use strict";
				Object.defineProperty(exports$3, "__esModule", { value: true });
				exports$3.Syntax = {
					AssignmentExpression: "AssignmentExpression",
					AssignmentPattern: "AssignmentPattern",
					ArrayExpression: "ArrayExpression",
					ArrayPattern: "ArrayPattern",
					ArrowFunctionExpression: "ArrowFunctionExpression",
					AwaitExpression: "AwaitExpression",
					BlockStatement: "BlockStatement",
					BinaryExpression: "BinaryExpression",
					BreakStatement: "BreakStatement",
					CallExpression: "CallExpression",
					CatchClause: "CatchClause",
					ClassBody: "ClassBody",
					ClassDeclaration: "ClassDeclaration",
					ClassExpression: "ClassExpression",
					ConditionalExpression: "ConditionalExpression",
					ContinueStatement: "ContinueStatement",
					DoWhileStatement: "DoWhileStatement",
					DebuggerStatement: "DebuggerStatement",
					EmptyStatement: "EmptyStatement",
					ExportAllDeclaration: "ExportAllDeclaration",
					ExportDefaultDeclaration: "ExportDefaultDeclaration",
					ExportNamedDeclaration: "ExportNamedDeclaration",
					ExportSpecifier: "ExportSpecifier",
					ExpressionStatement: "ExpressionStatement",
					ForStatement: "ForStatement",
					ForOfStatement: "ForOfStatement",
					ForInStatement: "ForInStatement",
					FunctionDeclaration: "FunctionDeclaration",
					FunctionExpression: "FunctionExpression",
					Identifier: "Identifier",
					IfStatement: "IfStatement",
					ImportDeclaration: "ImportDeclaration",
					ImportDefaultSpecifier: "ImportDefaultSpecifier",
					ImportNamespaceSpecifier: "ImportNamespaceSpecifier",
					ImportSpecifier: "ImportSpecifier",
					Literal: "Literal",
					LabeledStatement: "LabeledStatement",
					LogicalExpression: "LogicalExpression",
					MemberExpression: "MemberExpression",
					MetaProperty: "MetaProperty",
					MethodDefinition: "MethodDefinition",
					NewExpression: "NewExpression",
					ObjectExpression: "ObjectExpression",
					ObjectPattern: "ObjectPattern",
					Program: "Program",
					Property: "Property",
					RestElement: "RestElement",
					ReturnStatement: "ReturnStatement",
					SequenceExpression: "SequenceExpression",
					SpreadElement: "SpreadElement",
					Super: "Super",
					SwitchCase: "SwitchCase",
					SwitchStatement: "SwitchStatement",
					TaggedTemplateExpression: "TaggedTemplateExpression",
					TemplateElement: "TemplateElement",
					TemplateLiteral: "TemplateLiteral",
					ThisExpression: "ThisExpression",
					ThrowStatement: "ThrowStatement",
					TryStatement: "TryStatement",
					UnaryExpression: "UnaryExpression",
					UpdateExpression: "UpdateExpression",
					VariableDeclaration: "VariableDeclaration",
					VariableDeclarator: "VariableDeclarator",
					WhileStatement: "WhileStatement",
					WithStatement: "WithStatement",
					YieldExpression: "YieldExpression"
				};
			},
			function(module$5, exports$4, __webpack_require__) {
				"use strict";
				/* istanbul ignore next */
				var __extends = this && this.__extends || (function() {
					var extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d, b) {
						d.__proto__ = b;
					} || function(d, b) {
						for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];
					};
					return function(d, b) {
						extendStatics(d, b);
						function __() {
							this.constructor = d;
						}
						d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
					};
				})();
				Object.defineProperty(exports$4, "__esModule", { value: true });
				var character_1 = __webpack_require__(4);
				var JSXNode = __webpack_require__(5);
				var jsx_syntax_1 = __webpack_require__(6);
				var Node = __webpack_require__(7);
				var parser_1 = __webpack_require__(8);
				var token_1 = __webpack_require__(13);
				var xhtml_entities_1 = __webpack_require__(14);
				token_1.TokenName[100] = "JSXIdentifier";
				token_1.TokenName[101] = "JSXText";
				function getQualifiedElementName(elementName) {
					var qualifiedName;
					switch (elementName.type) {
						case jsx_syntax_1.JSXSyntax.JSXIdentifier:
							qualifiedName = elementName.name;
							break;
						case jsx_syntax_1.JSXSyntax.JSXNamespacedName:
							var ns = elementName;
							qualifiedName = getQualifiedElementName(ns.namespace) + ":" + getQualifiedElementName(ns.name);
							break;
						case jsx_syntax_1.JSXSyntax.JSXMemberExpression:
							var expr = elementName;
							qualifiedName = getQualifiedElementName(expr.object) + "." + getQualifiedElementName(expr.property);
							break;
						default: break;
					}
					return qualifiedName;
				}
				exports$4.JSXParser = function(_super) {
					__extends(JSXParser, _super);
					function JSXParser(code, options, delegate) {
						return _super.call(this, code, options, delegate) || this;
					}
					JSXParser.prototype.parsePrimaryExpression = function() {
						return this.match("<") ? this.parseJSXRoot() : _super.prototype.parsePrimaryExpression.call(this);
					};
					JSXParser.prototype.startJSX = function() {
						this.scanner.index = this.startMarker.index;
						this.scanner.lineNumber = this.startMarker.line;
						this.scanner.lineStart = this.startMarker.index - this.startMarker.column;
					};
					JSXParser.prototype.finishJSX = function() {
						this.nextToken();
					};
					JSXParser.prototype.reenterJSX = function() {
						this.startJSX();
						this.expectJSX("}");
						if (this.config.tokens) this.tokens.pop();
					};
					JSXParser.prototype.createJSXNode = function() {
						this.collectComments();
						return {
							index: this.scanner.index,
							line: this.scanner.lineNumber,
							column: this.scanner.index - this.scanner.lineStart
						};
					};
					JSXParser.prototype.createJSXChildNode = function() {
						return {
							index: this.scanner.index,
							line: this.scanner.lineNumber,
							column: this.scanner.index - this.scanner.lineStart
						};
					};
					JSXParser.prototype.scanXHTMLEntity = function(quote) {
						var result = "&";
						var valid = true;
						var terminated = false;
						var numeric = false;
						var hex = false;
						while (!this.scanner.eof() && valid && !terminated) {
							var ch = this.scanner.source[this.scanner.index];
							if (ch === quote) break;
							terminated = ch === ";";
							result += ch;
							++this.scanner.index;
							if (!terminated) switch (result.length) {
								case 2:
									numeric = ch === "#";
									break;
								case 3:
									if (numeric) {
										hex = ch === "x";
										valid = hex || character_1.Character.isDecimalDigit(ch.charCodeAt(0));
										numeric = numeric && !hex;
									}
									break;
								default:
									valid = valid && !(numeric && !character_1.Character.isDecimalDigit(ch.charCodeAt(0)));
									valid = valid && !(hex && !character_1.Character.isHexDigit(ch.charCodeAt(0)));
									break;
							}
						}
						if (valid && terminated && result.length > 2) {
							var str = result.substr(1, result.length - 2);
							if (numeric && str.length > 1) result = String.fromCharCode(parseInt(str.substr(1), 10));
							else if (hex && str.length > 2) result = String.fromCharCode(parseInt("0" + str.substr(1), 16));
							else if (!numeric && !hex && xhtml_entities_1.XHTMLEntities[str]) result = xhtml_entities_1.XHTMLEntities[str];
						}
						return result;
					};
					JSXParser.prototype.lexJSX = function() {
						var cp = this.scanner.source.charCodeAt(this.scanner.index);
						if (cp === 60 || cp === 62 || cp === 47 || cp === 58 || cp === 61 || cp === 123 || cp === 125) {
							var value = this.scanner.source[this.scanner.index++];
							return {
								type: 7,
								value,
								lineNumber: this.scanner.lineNumber,
								lineStart: this.scanner.lineStart,
								start: this.scanner.index - 1,
								end: this.scanner.index
							};
						}
						if (cp === 34 || cp === 39) {
							var start = this.scanner.index;
							var quote = this.scanner.source[this.scanner.index++];
							var str = "";
							while (!this.scanner.eof()) {
								var ch = this.scanner.source[this.scanner.index++];
								if (ch === quote) break;
								else if (ch === "&") str += this.scanXHTMLEntity(quote);
								else str += ch;
							}
							return {
								type: 8,
								value: str,
								lineNumber: this.scanner.lineNumber,
								lineStart: this.scanner.lineStart,
								start,
								end: this.scanner.index
							};
						}
						if (cp === 46) {
							var n1 = this.scanner.source.charCodeAt(this.scanner.index + 1);
							var n2 = this.scanner.source.charCodeAt(this.scanner.index + 2);
							var value = n1 === 46 && n2 === 46 ? "..." : ".";
							var start = this.scanner.index;
							this.scanner.index += value.length;
							return {
								type: 7,
								value,
								lineNumber: this.scanner.lineNumber,
								lineStart: this.scanner.lineStart,
								start,
								end: this.scanner.index
							};
						}
						if (cp === 96) return {
							type: 10,
							value: "",
							lineNumber: this.scanner.lineNumber,
							lineStart: this.scanner.lineStart,
							start: this.scanner.index,
							end: this.scanner.index
						};
						if (character_1.Character.isIdentifierStart(cp) && cp !== 92) {
							var start = this.scanner.index;
							++this.scanner.index;
							while (!this.scanner.eof()) {
								var ch = this.scanner.source.charCodeAt(this.scanner.index);
								if (character_1.Character.isIdentifierPart(ch) && ch !== 92) ++this.scanner.index;
								else if (ch === 45) ++this.scanner.index;
								else break;
							}
							return {
								type: 100,
								value: this.scanner.source.slice(start, this.scanner.index),
								lineNumber: this.scanner.lineNumber,
								lineStart: this.scanner.lineStart,
								start,
								end: this.scanner.index
							};
						}
						return this.scanner.lex();
					};
					JSXParser.prototype.nextJSXToken = function() {
						this.collectComments();
						this.startMarker.index = this.scanner.index;
						this.startMarker.line = this.scanner.lineNumber;
						this.startMarker.column = this.scanner.index - this.scanner.lineStart;
						var token = this.lexJSX();
						this.lastMarker.index = this.scanner.index;
						this.lastMarker.line = this.scanner.lineNumber;
						this.lastMarker.column = this.scanner.index - this.scanner.lineStart;
						if (this.config.tokens) this.tokens.push(this.convertToken(token));
						return token;
					};
					JSXParser.prototype.nextJSXText = function() {
						this.startMarker.index = this.scanner.index;
						this.startMarker.line = this.scanner.lineNumber;
						this.startMarker.column = this.scanner.index - this.scanner.lineStart;
						var start = this.scanner.index;
						var text = "";
						while (!this.scanner.eof()) {
							var ch = this.scanner.source[this.scanner.index];
							if (ch === "{" || ch === "<") break;
							++this.scanner.index;
							text += ch;
							if (character_1.Character.isLineTerminator(ch.charCodeAt(0))) {
								++this.scanner.lineNumber;
								if (ch === "\r" && this.scanner.source[this.scanner.index] === "\n") ++this.scanner.index;
								this.scanner.lineStart = this.scanner.index;
							}
						}
						this.lastMarker.index = this.scanner.index;
						this.lastMarker.line = this.scanner.lineNumber;
						this.lastMarker.column = this.scanner.index - this.scanner.lineStart;
						var token = {
							type: 101,
							value: text,
							lineNumber: this.scanner.lineNumber,
							lineStart: this.scanner.lineStart,
							start,
							end: this.scanner.index
						};
						if (text.length > 0 && this.config.tokens) this.tokens.push(this.convertToken(token));
						return token;
					};
					JSXParser.prototype.peekJSXToken = function() {
						var state = this.scanner.saveState();
						this.scanner.scanComments();
						var next = this.lexJSX();
						this.scanner.restoreState(state);
						return next;
					};
					JSXParser.prototype.expectJSX = function(value) {
						var token = this.nextJSXToken();
						if (token.type !== 7 || token.value !== value) this.throwUnexpectedToken(token);
					};
					JSXParser.prototype.matchJSX = function(value) {
						var next = this.peekJSXToken();
						return next.type === 7 && next.value === value;
					};
					JSXParser.prototype.parseJSXIdentifier = function() {
						var node = this.createJSXNode();
						var token = this.nextJSXToken();
						if (token.type !== 100) this.throwUnexpectedToken(token);
						return this.finalize(node, new JSXNode.JSXIdentifier(token.value));
					};
					JSXParser.prototype.parseJSXElementName = function() {
						var node = this.createJSXNode();
						var elementName = this.parseJSXIdentifier();
						if (this.matchJSX(":")) {
							var namespace = elementName;
							this.expectJSX(":");
							var name_1 = this.parseJSXIdentifier();
							elementName = this.finalize(node, new JSXNode.JSXNamespacedName(namespace, name_1));
						} else if (this.matchJSX(".")) while (this.matchJSX(".")) {
							var object = elementName;
							this.expectJSX(".");
							var property = this.parseJSXIdentifier();
							elementName = this.finalize(node, new JSXNode.JSXMemberExpression(object, property));
						}
						return elementName;
					};
					JSXParser.prototype.parseJSXAttributeName = function() {
						var node = this.createJSXNode();
						var attributeName;
						var identifier = this.parseJSXIdentifier();
						if (this.matchJSX(":")) {
							var namespace = identifier;
							this.expectJSX(":");
							var name_2 = this.parseJSXIdentifier();
							attributeName = this.finalize(node, new JSXNode.JSXNamespacedName(namespace, name_2));
						} else attributeName = identifier;
						return attributeName;
					};
					JSXParser.prototype.parseJSXStringLiteralAttribute = function() {
						var node = this.createJSXNode();
						var token = this.nextJSXToken();
						if (token.type !== 8) this.throwUnexpectedToken(token);
						var raw = this.getTokenRaw(token);
						return this.finalize(node, new Node.Literal(token.value, raw));
					};
					JSXParser.prototype.parseJSXExpressionAttribute = function() {
						var node = this.createJSXNode();
						this.expectJSX("{");
						this.finishJSX();
						if (this.match("}")) this.tolerateError("JSX attributes must only be assigned a non-empty expression");
						var expression = this.parseAssignmentExpression();
						this.reenterJSX();
						return this.finalize(node, new JSXNode.JSXExpressionContainer(expression));
					};
					JSXParser.prototype.parseJSXAttributeValue = function() {
						return this.matchJSX("{") ? this.parseJSXExpressionAttribute() : this.matchJSX("<") ? this.parseJSXElement() : this.parseJSXStringLiteralAttribute();
					};
					JSXParser.prototype.parseJSXNameValueAttribute = function() {
						var node = this.createJSXNode();
						var name = this.parseJSXAttributeName();
						var value = null;
						if (this.matchJSX("=")) {
							this.expectJSX("=");
							value = this.parseJSXAttributeValue();
						}
						return this.finalize(node, new JSXNode.JSXAttribute(name, value));
					};
					JSXParser.prototype.parseJSXSpreadAttribute = function() {
						var node = this.createJSXNode();
						this.expectJSX("{");
						this.expectJSX("...");
						this.finishJSX();
						var argument = this.parseAssignmentExpression();
						this.reenterJSX();
						return this.finalize(node, new JSXNode.JSXSpreadAttribute(argument));
					};
					JSXParser.prototype.parseJSXAttributes = function() {
						var attributes = [];
						while (!this.matchJSX("/") && !this.matchJSX(">")) {
							var attribute = this.matchJSX("{") ? this.parseJSXSpreadAttribute() : this.parseJSXNameValueAttribute();
							attributes.push(attribute);
						}
						return attributes;
					};
					JSXParser.prototype.parseJSXOpeningElement = function() {
						var node = this.createJSXNode();
						this.expectJSX("<");
						var name = this.parseJSXElementName();
						var attributes = this.parseJSXAttributes();
						var selfClosing = this.matchJSX("/");
						if (selfClosing) this.expectJSX("/");
						this.expectJSX(">");
						return this.finalize(node, new JSXNode.JSXOpeningElement(name, selfClosing, attributes));
					};
					JSXParser.prototype.parseJSXBoundaryElement = function() {
						var node = this.createJSXNode();
						this.expectJSX("<");
						if (this.matchJSX("/")) {
							this.expectJSX("/");
							var name_3 = this.parseJSXElementName();
							this.expectJSX(">");
							return this.finalize(node, new JSXNode.JSXClosingElement(name_3));
						}
						var name = this.parseJSXElementName();
						var attributes = this.parseJSXAttributes();
						var selfClosing = this.matchJSX("/");
						if (selfClosing) this.expectJSX("/");
						this.expectJSX(">");
						return this.finalize(node, new JSXNode.JSXOpeningElement(name, selfClosing, attributes));
					};
					JSXParser.prototype.parseJSXEmptyExpression = function() {
						var node = this.createJSXChildNode();
						this.collectComments();
						this.lastMarker.index = this.scanner.index;
						this.lastMarker.line = this.scanner.lineNumber;
						this.lastMarker.column = this.scanner.index - this.scanner.lineStart;
						return this.finalize(node, new JSXNode.JSXEmptyExpression());
					};
					JSXParser.prototype.parseJSXExpressionContainer = function() {
						var node = this.createJSXNode();
						this.expectJSX("{");
						var expression;
						if (this.matchJSX("}")) {
							expression = this.parseJSXEmptyExpression();
							this.expectJSX("}");
						} else {
							this.finishJSX();
							expression = this.parseAssignmentExpression();
							this.reenterJSX();
						}
						return this.finalize(node, new JSXNode.JSXExpressionContainer(expression));
					};
					JSXParser.prototype.parseJSXChildren = function() {
						var children = [];
						while (!this.scanner.eof()) {
							var node = this.createJSXChildNode();
							var token = this.nextJSXText();
							if (token.start < token.end) {
								var raw = this.getTokenRaw(token);
								var child = this.finalize(node, new JSXNode.JSXText(token.value, raw));
								children.push(child);
							}
							if (this.scanner.source[this.scanner.index] === "{") {
								var container = this.parseJSXExpressionContainer();
								children.push(container);
							} else break;
						}
						return children;
					};
					JSXParser.prototype.parseComplexJSXElement = function(el) {
						var stack = [];
						while (!this.scanner.eof()) {
							el.children = el.children.concat(this.parseJSXChildren());
							var node = this.createJSXChildNode();
							var element = this.parseJSXBoundaryElement();
							if (element.type === jsx_syntax_1.JSXSyntax.JSXOpeningElement) {
								var opening = element;
								if (opening.selfClosing) {
									var child = this.finalize(node, new JSXNode.JSXElement(opening, [], null));
									el.children.push(child);
								} else {
									stack.push(el);
									el = {
										node,
										opening,
										closing: null,
										children: []
									};
								}
							}
							if (element.type === jsx_syntax_1.JSXSyntax.JSXClosingElement) {
								el.closing = element;
								var open_1 = getQualifiedElementName(el.opening.name);
								if (open_1 !== getQualifiedElementName(el.closing.name)) this.tolerateError("Expected corresponding JSX closing tag for %0", open_1);
								if (stack.length > 0) {
									var child = this.finalize(el.node, new JSXNode.JSXElement(el.opening, el.children, el.closing));
									el = stack[stack.length - 1];
									el.children.push(child);
									stack.pop();
								} else break;
							}
						}
						return el;
					};
					JSXParser.prototype.parseJSXElement = function() {
						var node = this.createJSXNode();
						var opening = this.parseJSXOpeningElement();
						var children = [];
						var closing = null;
						if (!opening.selfClosing) {
							var el = this.parseComplexJSXElement({
								node,
								opening,
								closing,
								children
							});
							children = el.children;
							closing = el.closing;
						}
						return this.finalize(node, new JSXNode.JSXElement(opening, children, closing));
					};
					JSXParser.prototype.parseJSXRoot = function() {
						if (this.config.tokens) this.tokens.pop();
						this.startJSX();
						var element = this.parseJSXElement();
						this.finishJSX();
						return element;
					};
					JSXParser.prototype.isStartOfExpression = function() {
						return _super.prototype.isStartOfExpression.call(this) || this.match("<");
					};
					return JSXParser;
				}(parser_1.Parser);
			},
			function(module$6, exports$5) {
				"use strict";
				Object.defineProperty(exports$5, "__esModule", { value: true });
				var Regex = {
					NonAsciiIdentifierStart: /[\xAA\xB5\xBA\xC0-\xD6\xD8-\xF6\xF8-\u02C1\u02C6-\u02D1\u02E0-\u02E4\u02EC\u02EE\u0370-\u0374\u0376\u0377\u037A-\u037D\u037F\u0386\u0388-\u038A\u038C\u038E-\u03A1\u03A3-\u03F5\u03F7-\u0481\u048A-\u052F\u0531-\u0556\u0559\u0561-\u0587\u05D0-\u05EA\u05F0-\u05F2\u0620-\u064A\u066E\u066F\u0671-\u06D3\u06D5\u06E5\u06E6\u06EE\u06EF\u06FA-\u06FC\u06FF\u0710\u0712-\u072F\u074D-\u07A5\u07B1\u07CA-\u07EA\u07F4\u07F5\u07FA\u0800-\u0815\u081A\u0824\u0828\u0840-\u0858\u08A0-\u08B4\u0904-\u0939\u093D\u0950\u0958-\u0961\u0971-\u0980\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BD\u09CE\u09DC\u09DD\u09DF-\u09E1\u09F0\u09F1\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A59-\u0A5C\u0A5E\u0A72-\u0A74\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABD\u0AD0\u0AE0\u0AE1\u0AF9\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3D\u0B5C\u0B5D\u0B5F-\u0B61\u0B71\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BD0\u0C05-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3D\u0C58-\u0C5A\u0C60\u0C61\u0C85-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBD\u0CDE\u0CE0\u0CE1\u0CF1\u0CF2\u0D05-\u0D0C\u0D0E-\u0D10\u0D12-\u0D3A\u0D3D\u0D4E\u0D5F-\u0D61\u0D7A-\u0D7F\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0E01-\u0E30\u0E32\u0E33\u0E40-\u0E46\u0E81\u0E82\u0E84\u0E87\u0E88\u0E8A\u0E8D\u0E94-\u0E97\u0E99-\u0E9F\u0EA1-\u0EA3\u0EA5\u0EA7\u0EAA\u0EAB\u0EAD-\u0EB0\u0EB2\u0EB3\u0EBD\u0EC0-\u0EC4\u0EC6\u0EDC-\u0EDF\u0F00\u0F40-\u0F47\u0F49-\u0F6C\u0F88-\u0F8C\u1000-\u102A\u103F\u1050-\u1055\u105A-\u105D\u1061\u1065\u1066\u106E-\u1070\u1075-\u1081\u108E\u10A0-\u10C5\u10C7\u10CD\u10D0-\u10FA\u10FC-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u1380-\u138F\u13A0-\u13F5\u13F8-\u13FD\u1401-\u166C\u166F-\u167F\u1681-\u169A\u16A0-\u16EA\u16EE-\u16F8\u1700-\u170C\u170E-\u1711\u1720-\u1731\u1740-\u1751\u1760-\u176C\u176E-\u1770\u1780-\u17B3\u17D7\u17DC\u1820-\u1877\u1880-\u18A8\u18AA\u18B0-\u18F5\u1900-\u191E\u1950-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u1A00-\u1A16\u1A20-\u1A54\u1AA7\u1B05-\u1B33\u1B45-\u1B4B\u1B83-\u1BA0\u1BAE\u1BAF\u1BBA-\u1BE5\u1C00-\u1C23\u1C4D-\u1C4F\u1C5A-\u1C7D\u1CE9-\u1CEC\u1CEE-\u1CF1\u1CF5\u1CF6\u1D00-\u1DBF\u1E00-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FBC\u1FBE\u1FC2-\u1FC4\u1FC6-\u1FCC\u1FD0-\u1FD3\u1FD6-\u1FDB\u1FE0-\u1FEC\u1FF2-\u1FF4\u1FF6-\u1FFC\u2071\u207F\u2090-\u209C\u2102\u2107\u210A-\u2113\u2115\u2118-\u211D\u2124\u2126\u2128\u212A-\u2139\u213C-\u213F\u2145-\u2149\u214E\u2160-\u2188\u2C00-\u2C2E\u2C30-\u2C5E\u2C60-\u2CE4\u2CEB-\u2CEE\u2CF2\u2CF3\u2D00-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D80-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u3005-\u3007\u3021-\u3029\u3031-\u3035\u3038-\u303C\u3041-\u3096\u309B-\u309F\u30A1-\u30FA\u30FC-\u30FF\u3105-\u312D\u3131-\u318E\u31A0-\u31BA\u31F0-\u31FF\u3400-\u4DB5\u4E00-\u9FD5\uA000-\uA48C\uA4D0-\uA4FD\uA500-\uA60C\uA610-\uA61F\uA62A\uA62B\uA640-\uA66E\uA67F-\uA69D\uA6A0-\uA6EF\uA717-\uA71F\uA722-\uA788\uA78B-\uA7AD\uA7B0-\uA7B7\uA7F7-\uA801\uA803-\uA805\uA807-\uA80A\uA80C-\uA822\uA840-\uA873\uA882-\uA8B3\uA8F2-\uA8F7\uA8FB\uA8FD\uA90A-\uA925\uA930-\uA946\uA960-\uA97C\uA984-\uA9B2\uA9CF\uA9E0-\uA9E4\uA9E6-\uA9EF\uA9FA-\uA9FE\uAA00-\uAA28\uAA40-\uAA42\uAA44-\uAA4B\uAA60-\uAA76\uAA7A\uAA7E-\uAAAF\uAAB1\uAAB5\uAAB6\uAAB9-\uAABD\uAAC0\uAAC2\uAADB-\uAADD\uAAE0-\uAAEA\uAAF2-\uAAF4\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB5A\uAB5C-\uAB65\uAB70-\uABE2\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uF900-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFB1D\uFB1F-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBB1\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFB\uFE70-\uFE74\uFE76-\uFEFC\uFF21-\uFF3A\uFF41-\uFF5A\uFF66-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC]|\uD800[\uDC00-\uDC0B\uDC0D-\uDC26\uDC28-\uDC3A\uDC3C\uDC3D\uDC3F-\uDC4D\uDC50-\uDC5D\uDC80-\uDCFA\uDD40-\uDD74\uDE80-\uDE9C\uDEA0-\uDED0\uDF00-\uDF1F\uDF30-\uDF4A\uDF50-\uDF75\uDF80-\uDF9D\uDFA0-\uDFC3\uDFC8-\uDFCF\uDFD1-\uDFD5]|\uD801[\uDC00-\uDC9D\uDD00-\uDD27\uDD30-\uDD63\uDE00-\uDF36\uDF40-\uDF55\uDF60-\uDF67]|\uD802[\uDC00-\uDC05\uDC08\uDC0A-\uDC35\uDC37\uDC38\uDC3C\uDC3F-\uDC55\uDC60-\uDC76\uDC80-\uDC9E\uDCE0-\uDCF2\uDCF4\uDCF5\uDD00-\uDD15\uDD20-\uDD39\uDD80-\uDDB7\uDDBE\uDDBF\uDE00\uDE10-\uDE13\uDE15-\uDE17\uDE19-\uDE33\uDE60-\uDE7C\uDE80-\uDE9C\uDEC0-\uDEC7\uDEC9-\uDEE4\uDF00-\uDF35\uDF40-\uDF55\uDF60-\uDF72\uDF80-\uDF91]|\uD803[\uDC00-\uDC48\uDC80-\uDCB2\uDCC0-\uDCF2]|\uD804[\uDC03-\uDC37\uDC83-\uDCAF\uDCD0-\uDCE8\uDD03-\uDD26\uDD50-\uDD72\uDD76\uDD83-\uDDB2\uDDC1-\uDDC4\uDDDA\uDDDC\uDE00-\uDE11\uDE13-\uDE2B\uDE80-\uDE86\uDE88\uDE8A-\uDE8D\uDE8F-\uDE9D\uDE9F-\uDEA8\uDEB0-\uDEDE\uDF05-\uDF0C\uDF0F\uDF10\uDF13-\uDF28\uDF2A-\uDF30\uDF32\uDF33\uDF35-\uDF39\uDF3D\uDF50\uDF5D-\uDF61]|\uD805[\uDC80-\uDCAF\uDCC4\uDCC5\uDCC7\uDD80-\uDDAE\uDDD8-\uDDDB\uDE00-\uDE2F\uDE44\uDE80-\uDEAA\uDF00-\uDF19]|\uD806[\uDCA0-\uDCDF\uDCFF\uDEC0-\uDEF8]|\uD808[\uDC00-\uDF99]|\uD809[\uDC00-\uDC6E\uDC80-\uDD43]|[\uD80C\uD840-\uD868\uD86A-\uD86C\uD86F-\uD872][\uDC00-\uDFFF]|\uD80D[\uDC00-\uDC2E]|\uD811[\uDC00-\uDE46]|\uD81A[\uDC00-\uDE38\uDE40-\uDE5E\uDED0-\uDEED\uDF00-\uDF2F\uDF40-\uDF43\uDF63-\uDF77\uDF7D-\uDF8F]|\uD81B[\uDF00-\uDF44\uDF50\uDF93-\uDF9F]|\uD82C[\uDC00\uDC01]|\uD82F[\uDC00-\uDC6A\uDC70-\uDC7C\uDC80-\uDC88\uDC90-\uDC99]|\uD835[\uDC00-\uDC54\uDC56-\uDC9C\uDC9E\uDC9F\uDCA2\uDCA5\uDCA6\uDCA9-\uDCAC\uDCAE-\uDCB9\uDCBB\uDCBD-\uDCC3\uDCC5-\uDD05\uDD07-\uDD0A\uDD0D-\uDD14\uDD16-\uDD1C\uDD1E-\uDD39\uDD3B-\uDD3E\uDD40-\uDD44\uDD46\uDD4A-\uDD50\uDD52-\uDEA5\uDEA8-\uDEC0\uDEC2-\uDEDA\uDEDC-\uDEFA\uDEFC-\uDF14\uDF16-\uDF34\uDF36-\uDF4E\uDF50-\uDF6E\uDF70-\uDF88\uDF8A-\uDFA8\uDFAA-\uDFC2\uDFC4-\uDFCB]|\uD83A[\uDC00-\uDCC4]|\uD83B[\uDE00-\uDE03\uDE05-\uDE1F\uDE21\uDE22\uDE24\uDE27\uDE29-\uDE32\uDE34-\uDE37\uDE39\uDE3B\uDE42\uDE47\uDE49\uDE4B\uDE4D-\uDE4F\uDE51\uDE52\uDE54\uDE57\uDE59\uDE5B\uDE5D\uDE5F\uDE61\uDE62\uDE64\uDE67-\uDE6A\uDE6C-\uDE72\uDE74-\uDE77\uDE79-\uDE7C\uDE7E\uDE80-\uDE89\uDE8B-\uDE9B\uDEA1-\uDEA3\uDEA5-\uDEA9\uDEAB-\uDEBB]|\uD869[\uDC00-\uDED6\uDF00-\uDFFF]|\uD86D[\uDC00-\uDF34\uDF40-\uDFFF]|\uD86E[\uDC00-\uDC1D\uDC20-\uDFFF]|\uD873[\uDC00-\uDEA1]|\uD87E[\uDC00-\uDE1D]/,
					NonAsciiIdentifierPart: /[\xAA\xB5\xB7\xBA\xC0-\xD6\xD8-\xF6\xF8-\u02C1\u02C6-\u02D1\u02E0-\u02E4\u02EC\u02EE\u0300-\u0374\u0376\u0377\u037A-\u037D\u037F\u0386-\u038A\u038C\u038E-\u03A1\u03A3-\u03F5\u03F7-\u0481\u0483-\u0487\u048A-\u052F\u0531-\u0556\u0559\u0561-\u0587\u0591-\u05BD\u05BF\u05C1\u05C2\u05C4\u05C5\u05C7\u05D0-\u05EA\u05F0-\u05F2\u0610-\u061A\u0620-\u0669\u066E-\u06D3\u06D5-\u06DC\u06DF-\u06E8\u06EA-\u06FC\u06FF\u0710-\u074A\u074D-\u07B1\u07C0-\u07F5\u07FA\u0800-\u082D\u0840-\u085B\u08A0-\u08B4\u08E3-\u0963\u0966-\u096F\u0971-\u0983\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BC-\u09C4\u09C7\u09C8\u09CB-\u09CE\u09D7\u09DC\u09DD\u09DF-\u09E3\u09E6-\u09F1\u0A01-\u0A03\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A3C\u0A3E-\u0A42\u0A47\u0A48\u0A4B-\u0A4D\u0A51\u0A59-\u0A5C\u0A5E\u0A66-\u0A75\u0A81-\u0A83\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABC-\u0AC5\u0AC7-\u0AC9\u0ACB-\u0ACD\u0AD0\u0AE0-\u0AE3\u0AE6-\u0AEF\u0AF9\u0B01-\u0B03\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3C-\u0B44\u0B47\u0B48\u0B4B-\u0B4D\u0B56\u0B57\u0B5C\u0B5D\u0B5F-\u0B63\u0B66-\u0B6F\u0B71\u0B82\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BBE-\u0BC2\u0BC6-\u0BC8\u0BCA-\u0BCD\u0BD0\u0BD7\u0BE6-\u0BEF\u0C00-\u0C03\u0C05-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3D-\u0C44\u0C46-\u0C48\u0C4A-\u0C4D\u0C55\u0C56\u0C58-\u0C5A\u0C60-\u0C63\u0C66-\u0C6F\u0C81-\u0C83\u0C85-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBC-\u0CC4\u0CC6-\u0CC8\u0CCA-\u0CCD\u0CD5\u0CD6\u0CDE\u0CE0-\u0CE3\u0CE6-\u0CEF\u0CF1\u0CF2\u0D01-\u0D03\u0D05-\u0D0C\u0D0E-\u0D10\u0D12-\u0D3A\u0D3D-\u0D44\u0D46-\u0D48\u0D4A-\u0D4E\u0D57\u0D5F-\u0D63\u0D66-\u0D6F\u0D7A-\u0D7F\u0D82\u0D83\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0DCA\u0DCF-\u0DD4\u0DD6\u0DD8-\u0DDF\u0DE6-\u0DEF\u0DF2\u0DF3\u0E01-\u0E3A\u0E40-\u0E4E\u0E50-\u0E59\u0E81\u0E82\u0E84\u0E87\u0E88\u0E8A\u0E8D\u0E94-\u0E97\u0E99-\u0E9F\u0EA1-\u0EA3\u0EA5\u0EA7\u0EAA\u0EAB\u0EAD-\u0EB9\u0EBB-\u0EBD\u0EC0-\u0EC4\u0EC6\u0EC8-\u0ECD\u0ED0-\u0ED9\u0EDC-\u0EDF\u0F00\u0F18\u0F19\u0F20-\u0F29\u0F35\u0F37\u0F39\u0F3E-\u0F47\u0F49-\u0F6C\u0F71-\u0F84\u0F86-\u0F97\u0F99-\u0FBC\u0FC6\u1000-\u1049\u1050-\u109D\u10A0-\u10C5\u10C7\u10CD\u10D0-\u10FA\u10FC-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u135D-\u135F\u1369-\u1371\u1380-\u138F\u13A0-\u13F5\u13F8-\u13FD\u1401-\u166C\u166F-\u167F\u1681-\u169A\u16A0-\u16EA\u16EE-\u16F8\u1700-\u170C\u170E-\u1714\u1720-\u1734\u1740-\u1753\u1760-\u176C\u176E-\u1770\u1772\u1773\u1780-\u17D3\u17D7\u17DC\u17DD\u17E0-\u17E9\u180B-\u180D\u1810-\u1819\u1820-\u1877\u1880-\u18AA\u18B0-\u18F5\u1900-\u191E\u1920-\u192B\u1930-\u193B\u1946-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u19D0-\u19DA\u1A00-\u1A1B\u1A20-\u1A5E\u1A60-\u1A7C\u1A7F-\u1A89\u1A90-\u1A99\u1AA7\u1AB0-\u1ABD\u1B00-\u1B4B\u1B50-\u1B59\u1B6B-\u1B73\u1B80-\u1BF3\u1C00-\u1C37\u1C40-\u1C49\u1C4D-\u1C7D\u1CD0-\u1CD2\u1CD4-\u1CF6\u1CF8\u1CF9\u1D00-\u1DF5\u1DFC-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FBC\u1FBE\u1FC2-\u1FC4\u1FC6-\u1FCC\u1FD0-\u1FD3\u1FD6-\u1FDB\u1FE0-\u1FEC\u1FF2-\u1FF4\u1FF6-\u1FFC\u200C\u200D\u203F\u2040\u2054\u2071\u207F\u2090-\u209C\u20D0-\u20DC\u20E1\u20E5-\u20F0\u2102\u2107\u210A-\u2113\u2115\u2118-\u211D\u2124\u2126\u2128\u212A-\u2139\u213C-\u213F\u2145-\u2149\u214E\u2160-\u2188\u2C00-\u2C2E\u2C30-\u2C5E\u2C60-\u2CE4\u2CEB-\u2CF3\u2D00-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D7F-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u2DE0-\u2DFF\u3005-\u3007\u3021-\u302F\u3031-\u3035\u3038-\u303C\u3041-\u3096\u3099-\u309F\u30A1-\u30FA\u30FC-\u30FF\u3105-\u312D\u3131-\u318E\u31A0-\u31BA\u31F0-\u31FF\u3400-\u4DB5\u4E00-\u9FD5\uA000-\uA48C\uA4D0-\uA4FD\uA500-\uA60C\uA610-\uA62B\uA640-\uA66F\uA674-\uA67D\uA67F-\uA6F1\uA717-\uA71F\uA722-\uA788\uA78B-\uA7AD\uA7B0-\uA7B7\uA7F7-\uA827\uA840-\uA873\uA880-\uA8C4\uA8D0-\uA8D9\uA8E0-\uA8F7\uA8FB\uA8FD\uA900-\uA92D\uA930-\uA953\uA960-\uA97C\uA980-\uA9C0\uA9CF-\uA9D9\uA9E0-\uA9FE\uAA00-\uAA36\uAA40-\uAA4D\uAA50-\uAA59\uAA60-\uAA76\uAA7A-\uAAC2\uAADB-\uAADD\uAAE0-\uAAEF\uAAF2-\uAAF6\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB5A\uAB5C-\uAB65\uAB70-\uABEA\uABEC\uABED\uABF0-\uABF9\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uF900-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFB1D-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBB1\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFB\uFE00-\uFE0F\uFE20-\uFE2F\uFE33\uFE34\uFE4D-\uFE4F\uFE70-\uFE74\uFE76-\uFEFC\uFF10-\uFF19\uFF21-\uFF3A\uFF3F\uFF41-\uFF5A\uFF66-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC]|\uD800[\uDC00-\uDC0B\uDC0D-\uDC26\uDC28-\uDC3A\uDC3C\uDC3D\uDC3F-\uDC4D\uDC50-\uDC5D\uDC80-\uDCFA\uDD40-\uDD74\uDDFD\uDE80-\uDE9C\uDEA0-\uDED0\uDEE0\uDF00-\uDF1F\uDF30-\uDF4A\uDF50-\uDF7A\uDF80-\uDF9D\uDFA0-\uDFC3\uDFC8-\uDFCF\uDFD1-\uDFD5]|\uD801[\uDC00-\uDC9D\uDCA0-\uDCA9\uDD00-\uDD27\uDD30-\uDD63\uDE00-\uDF36\uDF40-\uDF55\uDF60-\uDF67]|\uD802[\uDC00-\uDC05\uDC08\uDC0A-\uDC35\uDC37\uDC38\uDC3C\uDC3F-\uDC55\uDC60-\uDC76\uDC80-\uDC9E\uDCE0-\uDCF2\uDCF4\uDCF5\uDD00-\uDD15\uDD20-\uDD39\uDD80-\uDDB7\uDDBE\uDDBF\uDE00-\uDE03\uDE05\uDE06\uDE0C-\uDE13\uDE15-\uDE17\uDE19-\uDE33\uDE38-\uDE3A\uDE3F\uDE60-\uDE7C\uDE80-\uDE9C\uDEC0-\uDEC7\uDEC9-\uDEE6\uDF00-\uDF35\uDF40-\uDF55\uDF60-\uDF72\uDF80-\uDF91]|\uD803[\uDC00-\uDC48\uDC80-\uDCB2\uDCC0-\uDCF2]|\uD804[\uDC00-\uDC46\uDC66-\uDC6F\uDC7F-\uDCBA\uDCD0-\uDCE8\uDCF0-\uDCF9\uDD00-\uDD34\uDD36-\uDD3F\uDD50-\uDD73\uDD76\uDD80-\uDDC4\uDDCA-\uDDCC\uDDD0-\uDDDA\uDDDC\uDE00-\uDE11\uDE13-\uDE37\uDE80-\uDE86\uDE88\uDE8A-\uDE8D\uDE8F-\uDE9D\uDE9F-\uDEA8\uDEB0-\uDEEA\uDEF0-\uDEF9\uDF00-\uDF03\uDF05-\uDF0C\uDF0F\uDF10\uDF13-\uDF28\uDF2A-\uDF30\uDF32\uDF33\uDF35-\uDF39\uDF3C-\uDF44\uDF47\uDF48\uDF4B-\uDF4D\uDF50\uDF57\uDF5D-\uDF63\uDF66-\uDF6C\uDF70-\uDF74]|\uD805[\uDC80-\uDCC5\uDCC7\uDCD0-\uDCD9\uDD80-\uDDB5\uDDB8-\uDDC0\uDDD8-\uDDDD\uDE00-\uDE40\uDE44\uDE50-\uDE59\uDE80-\uDEB7\uDEC0-\uDEC9\uDF00-\uDF19\uDF1D-\uDF2B\uDF30-\uDF39]|\uD806[\uDCA0-\uDCE9\uDCFF\uDEC0-\uDEF8]|\uD808[\uDC00-\uDF99]|\uD809[\uDC00-\uDC6E\uDC80-\uDD43]|[\uD80C\uD840-\uD868\uD86A-\uD86C\uD86F-\uD872][\uDC00-\uDFFF]|\uD80D[\uDC00-\uDC2E]|\uD811[\uDC00-\uDE46]|\uD81A[\uDC00-\uDE38\uDE40-\uDE5E\uDE60-\uDE69\uDED0-\uDEED\uDEF0-\uDEF4\uDF00-\uDF36\uDF40-\uDF43\uDF50-\uDF59\uDF63-\uDF77\uDF7D-\uDF8F]|\uD81B[\uDF00-\uDF44\uDF50-\uDF7E\uDF8F-\uDF9F]|\uD82C[\uDC00\uDC01]|\uD82F[\uDC00-\uDC6A\uDC70-\uDC7C\uDC80-\uDC88\uDC90-\uDC99\uDC9D\uDC9E]|\uD834[\uDD65-\uDD69\uDD6D-\uDD72\uDD7B-\uDD82\uDD85-\uDD8B\uDDAA-\uDDAD\uDE42-\uDE44]|\uD835[\uDC00-\uDC54\uDC56-\uDC9C\uDC9E\uDC9F\uDCA2\uDCA5\uDCA6\uDCA9-\uDCAC\uDCAE-\uDCB9\uDCBB\uDCBD-\uDCC3\uDCC5-\uDD05\uDD07-\uDD0A\uDD0D-\uDD14\uDD16-\uDD1C\uDD1E-\uDD39\uDD3B-\uDD3E\uDD40-\uDD44\uDD46\uDD4A-\uDD50\uDD52-\uDEA5\uDEA8-\uDEC0\uDEC2-\uDEDA\uDEDC-\uDEFA\uDEFC-\uDF14\uDF16-\uDF34\uDF36-\uDF4E\uDF50-\uDF6E\uDF70-\uDF88\uDF8A-\uDFA8\uDFAA-\uDFC2\uDFC4-\uDFCB\uDFCE-\uDFFF]|\uD836[\uDE00-\uDE36\uDE3B-\uDE6C\uDE75\uDE84\uDE9B-\uDE9F\uDEA1-\uDEAF]|\uD83A[\uDC00-\uDCC4\uDCD0-\uDCD6]|\uD83B[\uDE00-\uDE03\uDE05-\uDE1F\uDE21\uDE22\uDE24\uDE27\uDE29-\uDE32\uDE34-\uDE37\uDE39\uDE3B\uDE42\uDE47\uDE49\uDE4B\uDE4D-\uDE4F\uDE51\uDE52\uDE54\uDE57\uDE59\uDE5B\uDE5D\uDE5F\uDE61\uDE62\uDE64\uDE67-\uDE6A\uDE6C-\uDE72\uDE74-\uDE77\uDE79-\uDE7C\uDE7E\uDE80-\uDE89\uDE8B-\uDE9B\uDEA1-\uDEA3\uDEA5-\uDEA9\uDEAB-\uDEBB]|\uD869[\uDC00-\uDED6\uDF00-\uDFFF]|\uD86D[\uDC00-\uDF34\uDF40-\uDFFF]|\uD86E[\uDC00-\uDC1D\uDC20-\uDFFF]|\uD873[\uDC00-\uDEA1]|\uD87E[\uDC00-\uDE1D]|\uDB40[\uDD00-\uDDEF]/
				};
				exports$5.Character = {
					fromCodePoint: function(cp) {
						return cp < 65536 ? String.fromCharCode(cp) : String.fromCharCode(55296 + (cp - 65536 >> 10)) + String.fromCharCode(56320 + (cp - 65536 & 1023));
					},
					isWhiteSpace: function(cp) {
						return cp === 32 || cp === 9 || cp === 11 || cp === 12 || cp === 160 || cp >= 5760 && [
							5760,
							8192,
							8193,
							8194,
							8195,
							8196,
							8197,
							8198,
							8199,
							8200,
							8201,
							8202,
							8239,
							8287,
							12288,
							65279
						].indexOf(cp) >= 0;
					},
					isLineTerminator: function(cp) {
						return cp === 10 || cp === 13 || cp === 8232 || cp === 8233;
					},
					isIdentifierStart: function(cp) {
						return cp === 36 || cp === 95 || cp >= 65 && cp <= 90 || cp >= 97 && cp <= 122 || cp === 92 || cp >= 128 && Regex.NonAsciiIdentifierStart.test(exports$5.Character.fromCodePoint(cp));
					},
					isIdentifierPart: function(cp) {
						return cp === 36 || cp === 95 || cp >= 65 && cp <= 90 || cp >= 97 && cp <= 122 || cp >= 48 && cp <= 57 || cp === 92 || cp >= 128 && Regex.NonAsciiIdentifierPart.test(exports$5.Character.fromCodePoint(cp));
					},
					isDecimalDigit: function(cp) {
						return cp >= 48 && cp <= 57;
					},
					isHexDigit: function(cp) {
						return cp >= 48 && cp <= 57 || cp >= 65 && cp <= 70 || cp >= 97 && cp <= 102;
					},
					isOctalDigit: function(cp) {
						return cp >= 48 && cp <= 55;
					}
				};
			},
			function(module$7, exports$6, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$6, "__esModule", { value: true });
				var jsx_syntax_1 = __webpack_require__(6);
				exports$6.JSXClosingElement = function() {
					function JSXClosingElement(name) {
						this.type = jsx_syntax_1.JSXSyntax.JSXClosingElement;
						this.name = name;
					}
					return JSXClosingElement;
				}();
				exports$6.JSXElement = function() {
					function JSXElement(openingElement, children, closingElement) {
						this.type = jsx_syntax_1.JSXSyntax.JSXElement;
						this.openingElement = openingElement;
						this.children = children;
						this.closingElement = closingElement;
					}
					return JSXElement;
				}();
				exports$6.JSXEmptyExpression = function() {
					function JSXEmptyExpression() {
						this.type = jsx_syntax_1.JSXSyntax.JSXEmptyExpression;
					}
					return JSXEmptyExpression;
				}();
				exports$6.JSXExpressionContainer = function() {
					function JSXExpressionContainer(expression) {
						this.type = jsx_syntax_1.JSXSyntax.JSXExpressionContainer;
						this.expression = expression;
					}
					return JSXExpressionContainer;
				}();
				exports$6.JSXIdentifier = function() {
					function JSXIdentifier(name) {
						this.type = jsx_syntax_1.JSXSyntax.JSXIdentifier;
						this.name = name;
					}
					return JSXIdentifier;
				}();
				exports$6.JSXMemberExpression = function() {
					function JSXMemberExpression(object, property) {
						this.type = jsx_syntax_1.JSXSyntax.JSXMemberExpression;
						this.object = object;
						this.property = property;
					}
					return JSXMemberExpression;
				}();
				exports$6.JSXAttribute = function() {
					function JSXAttribute(name, value) {
						this.type = jsx_syntax_1.JSXSyntax.JSXAttribute;
						this.name = name;
						this.value = value;
					}
					return JSXAttribute;
				}();
				exports$6.JSXNamespacedName = function() {
					function JSXNamespacedName(namespace, name) {
						this.type = jsx_syntax_1.JSXSyntax.JSXNamespacedName;
						this.namespace = namespace;
						this.name = name;
					}
					return JSXNamespacedName;
				}();
				exports$6.JSXOpeningElement = function() {
					function JSXOpeningElement(name, selfClosing, attributes) {
						this.type = jsx_syntax_1.JSXSyntax.JSXOpeningElement;
						this.name = name;
						this.selfClosing = selfClosing;
						this.attributes = attributes;
					}
					return JSXOpeningElement;
				}();
				exports$6.JSXSpreadAttribute = function() {
					function JSXSpreadAttribute(argument) {
						this.type = jsx_syntax_1.JSXSyntax.JSXSpreadAttribute;
						this.argument = argument;
					}
					return JSXSpreadAttribute;
				}();
				exports$6.JSXText = function() {
					function JSXText(value, raw) {
						this.type = jsx_syntax_1.JSXSyntax.JSXText;
						this.value = value;
						this.raw = raw;
					}
					return JSXText;
				}();
			},
			function(module$8, exports$7) {
				"use strict";
				Object.defineProperty(exports$7, "__esModule", { value: true });
				exports$7.JSXSyntax = {
					JSXAttribute: "JSXAttribute",
					JSXClosingElement: "JSXClosingElement",
					JSXElement: "JSXElement",
					JSXEmptyExpression: "JSXEmptyExpression",
					JSXExpressionContainer: "JSXExpressionContainer",
					JSXIdentifier: "JSXIdentifier",
					JSXMemberExpression: "JSXMemberExpression",
					JSXNamespacedName: "JSXNamespacedName",
					JSXOpeningElement: "JSXOpeningElement",
					JSXSpreadAttribute: "JSXSpreadAttribute",
					JSXText: "JSXText"
				};
			},
			function(module$9, exports$8, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$8, "__esModule", { value: true });
				var syntax_1 = __webpack_require__(2);
				exports$8.ArrayExpression = function() {
					function ArrayExpression(elements) {
						this.type = syntax_1.Syntax.ArrayExpression;
						this.elements = elements;
					}
					return ArrayExpression;
				}();
				exports$8.ArrayPattern = function() {
					function ArrayPattern(elements) {
						this.type = syntax_1.Syntax.ArrayPattern;
						this.elements = elements;
					}
					return ArrayPattern;
				}();
				exports$8.ArrowFunctionExpression = function() {
					function ArrowFunctionExpression(params, body, expression) {
						this.type = syntax_1.Syntax.ArrowFunctionExpression;
						this.id = null;
						this.params = params;
						this.body = body;
						this.generator = false;
						this.expression = expression;
						this.async = false;
					}
					return ArrowFunctionExpression;
				}();
				exports$8.AssignmentExpression = function() {
					function AssignmentExpression(operator, left, right) {
						this.type = syntax_1.Syntax.AssignmentExpression;
						this.operator = operator;
						this.left = left;
						this.right = right;
					}
					return AssignmentExpression;
				}();
				exports$8.AssignmentPattern = function() {
					function AssignmentPattern(left, right) {
						this.type = syntax_1.Syntax.AssignmentPattern;
						this.left = left;
						this.right = right;
					}
					return AssignmentPattern;
				}();
				exports$8.AsyncArrowFunctionExpression = function() {
					function AsyncArrowFunctionExpression(params, body, expression) {
						this.type = syntax_1.Syntax.ArrowFunctionExpression;
						this.id = null;
						this.params = params;
						this.body = body;
						this.generator = false;
						this.expression = expression;
						this.async = true;
					}
					return AsyncArrowFunctionExpression;
				}();
				exports$8.AsyncFunctionDeclaration = function() {
					function AsyncFunctionDeclaration(id, params, body) {
						this.type = syntax_1.Syntax.FunctionDeclaration;
						this.id = id;
						this.params = params;
						this.body = body;
						this.generator = false;
						this.expression = false;
						this.async = true;
					}
					return AsyncFunctionDeclaration;
				}();
				exports$8.AsyncFunctionExpression = function() {
					function AsyncFunctionExpression(id, params, body) {
						this.type = syntax_1.Syntax.FunctionExpression;
						this.id = id;
						this.params = params;
						this.body = body;
						this.generator = false;
						this.expression = false;
						this.async = true;
					}
					return AsyncFunctionExpression;
				}();
				exports$8.AwaitExpression = function() {
					function AwaitExpression(argument) {
						this.type = syntax_1.Syntax.AwaitExpression;
						this.argument = argument;
					}
					return AwaitExpression;
				}();
				exports$8.BinaryExpression = function() {
					function BinaryExpression(operator, left, right) {
						this.type = operator === "||" || operator === "&&" ? syntax_1.Syntax.LogicalExpression : syntax_1.Syntax.BinaryExpression;
						this.operator = operator;
						this.left = left;
						this.right = right;
					}
					return BinaryExpression;
				}();
				exports$8.BlockStatement = function() {
					function BlockStatement(body) {
						this.type = syntax_1.Syntax.BlockStatement;
						this.body = body;
					}
					return BlockStatement;
				}();
				exports$8.BreakStatement = function() {
					function BreakStatement(label) {
						this.type = syntax_1.Syntax.BreakStatement;
						this.label = label;
					}
					return BreakStatement;
				}();
				exports$8.CallExpression = function() {
					function CallExpression(callee, args) {
						this.type = syntax_1.Syntax.CallExpression;
						this.callee = callee;
						this.arguments = args;
					}
					return CallExpression;
				}();
				exports$8.CatchClause = function() {
					function CatchClause(param, body) {
						this.type = syntax_1.Syntax.CatchClause;
						this.param = param;
						this.body = body;
					}
					return CatchClause;
				}();
				exports$8.ClassBody = function() {
					function ClassBody(body) {
						this.type = syntax_1.Syntax.ClassBody;
						this.body = body;
					}
					return ClassBody;
				}();
				exports$8.ClassDeclaration = function() {
					function ClassDeclaration(id, superClass, body) {
						this.type = syntax_1.Syntax.ClassDeclaration;
						this.id = id;
						this.superClass = superClass;
						this.body = body;
					}
					return ClassDeclaration;
				}();
				exports$8.ClassExpression = function() {
					function ClassExpression(id, superClass, body) {
						this.type = syntax_1.Syntax.ClassExpression;
						this.id = id;
						this.superClass = superClass;
						this.body = body;
					}
					return ClassExpression;
				}();
				exports$8.ComputedMemberExpression = function() {
					function ComputedMemberExpression(object, property) {
						this.type = syntax_1.Syntax.MemberExpression;
						this.computed = true;
						this.object = object;
						this.property = property;
					}
					return ComputedMemberExpression;
				}();
				exports$8.ConditionalExpression = function() {
					function ConditionalExpression(test, consequent, alternate) {
						this.type = syntax_1.Syntax.ConditionalExpression;
						this.test = test;
						this.consequent = consequent;
						this.alternate = alternate;
					}
					return ConditionalExpression;
				}();
				exports$8.ContinueStatement = function() {
					function ContinueStatement(label) {
						this.type = syntax_1.Syntax.ContinueStatement;
						this.label = label;
					}
					return ContinueStatement;
				}();
				exports$8.DebuggerStatement = function() {
					function DebuggerStatement() {
						this.type = syntax_1.Syntax.DebuggerStatement;
					}
					return DebuggerStatement;
				}();
				exports$8.Directive = function() {
					function Directive(expression, directive) {
						this.type = syntax_1.Syntax.ExpressionStatement;
						this.expression = expression;
						this.directive = directive;
					}
					return Directive;
				}();
				exports$8.DoWhileStatement = function() {
					function DoWhileStatement(body, test) {
						this.type = syntax_1.Syntax.DoWhileStatement;
						this.body = body;
						this.test = test;
					}
					return DoWhileStatement;
				}();
				exports$8.EmptyStatement = function() {
					function EmptyStatement() {
						this.type = syntax_1.Syntax.EmptyStatement;
					}
					return EmptyStatement;
				}();
				exports$8.ExportAllDeclaration = function() {
					function ExportAllDeclaration(source) {
						this.type = syntax_1.Syntax.ExportAllDeclaration;
						this.source = source;
					}
					return ExportAllDeclaration;
				}();
				exports$8.ExportDefaultDeclaration = function() {
					function ExportDefaultDeclaration(declaration) {
						this.type = syntax_1.Syntax.ExportDefaultDeclaration;
						this.declaration = declaration;
					}
					return ExportDefaultDeclaration;
				}();
				exports$8.ExportNamedDeclaration = function() {
					function ExportNamedDeclaration(declaration, specifiers, source) {
						this.type = syntax_1.Syntax.ExportNamedDeclaration;
						this.declaration = declaration;
						this.specifiers = specifiers;
						this.source = source;
					}
					return ExportNamedDeclaration;
				}();
				exports$8.ExportSpecifier = function() {
					function ExportSpecifier(local, exported) {
						this.type = syntax_1.Syntax.ExportSpecifier;
						this.exported = exported;
						this.local = local;
					}
					return ExportSpecifier;
				}();
				exports$8.ExpressionStatement = function() {
					function ExpressionStatement(expression) {
						this.type = syntax_1.Syntax.ExpressionStatement;
						this.expression = expression;
					}
					return ExpressionStatement;
				}();
				exports$8.ForInStatement = function() {
					function ForInStatement(left, right, body) {
						this.type = syntax_1.Syntax.ForInStatement;
						this.left = left;
						this.right = right;
						this.body = body;
						this.each = false;
					}
					return ForInStatement;
				}();
				exports$8.ForOfStatement = function() {
					function ForOfStatement(left, right, body) {
						this.type = syntax_1.Syntax.ForOfStatement;
						this.left = left;
						this.right = right;
						this.body = body;
					}
					return ForOfStatement;
				}();
				exports$8.ForStatement = function() {
					function ForStatement(init, test, update, body) {
						this.type = syntax_1.Syntax.ForStatement;
						this.init = init;
						this.test = test;
						this.update = update;
						this.body = body;
					}
					return ForStatement;
				}();
				exports$8.FunctionDeclaration = function() {
					function FunctionDeclaration(id, params, body, generator) {
						this.type = syntax_1.Syntax.FunctionDeclaration;
						this.id = id;
						this.params = params;
						this.body = body;
						this.generator = generator;
						this.expression = false;
						this.async = false;
					}
					return FunctionDeclaration;
				}();
				exports$8.FunctionExpression = function() {
					function FunctionExpression(id, params, body, generator) {
						this.type = syntax_1.Syntax.FunctionExpression;
						this.id = id;
						this.params = params;
						this.body = body;
						this.generator = generator;
						this.expression = false;
						this.async = false;
					}
					return FunctionExpression;
				}();
				exports$8.Identifier = function() {
					function Identifier(name) {
						this.type = syntax_1.Syntax.Identifier;
						this.name = name;
					}
					return Identifier;
				}();
				exports$8.IfStatement = function() {
					function IfStatement(test, consequent, alternate) {
						this.type = syntax_1.Syntax.IfStatement;
						this.test = test;
						this.consequent = consequent;
						this.alternate = alternate;
					}
					return IfStatement;
				}();
				exports$8.ImportDeclaration = function() {
					function ImportDeclaration(specifiers, source) {
						this.type = syntax_1.Syntax.ImportDeclaration;
						this.specifiers = specifiers;
						this.source = source;
					}
					return ImportDeclaration;
				}();
				exports$8.ImportDefaultSpecifier = function() {
					function ImportDefaultSpecifier(local) {
						this.type = syntax_1.Syntax.ImportDefaultSpecifier;
						this.local = local;
					}
					return ImportDefaultSpecifier;
				}();
				exports$8.ImportNamespaceSpecifier = function() {
					function ImportNamespaceSpecifier(local) {
						this.type = syntax_1.Syntax.ImportNamespaceSpecifier;
						this.local = local;
					}
					return ImportNamespaceSpecifier;
				}();
				exports$8.ImportSpecifier = function() {
					function ImportSpecifier(local, imported) {
						this.type = syntax_1.Syntax.ImportSpecifier;
						this.local = local;
						this.imported = imported;
					}
					return ImportSpecifier;
				}();
				exports$8.LabeledStatement = function() {
					function LabeledStatement(label, body) {
						this.type = syntax_1.Syntax.LabeledStatement;
						this.label = label;
						this.body = body;
					}
					return LabeledStatement;
				}();
				exports$8.Literal = function() {
					function Literal(value, raw) {
						this.type = syntax_1.Syntax.Literal;
						this.value = value;
						this.raw = raw;
					}
					return Literal;
				}();
				exports$8.MetaProperty = function() {
					function MetaProperty(meta, property) {
						this.type = syntax_1.Syntax.MetaProperty;
						this.meta = meta;
						this.property = property;
					}
					return MetaProperty;
				}();
				exports$8.MethodDefinition = function() {
					function MethodDefinition(key, computed, value, kind, isStatic) {
						this.type = syntax_1.Syntax.MethodDefinition;
						this.key = key;
						this.computed = computed;
						this.value = value;
						this.kind = kind;
						this.static = isStatic;
					}
					return MethodDefinition;
				}();
				exports$8.Module = function() {
					function Module(body) {
						this.type = syntax_1.Syntax.Program;
						this.body = body;
						this.sourceType = "module";
					}
					return Module;
				}();
				exports$8.NewExpression = function() {
					function NewExpression(callee, args) {
						this.type = syntax_1.Syntax.NewExpression;
						this.callee = callee;
						this.arguments = args;
					}
					return NewExpression;
				}();
				exports$8.ObjectExpression = function() {
					function ObjectExpression(properties) {
						this.type = syntax_1.Syntax.ObjectExpression;
						this.properties = properties;
					}
					return ObjectExpression;
				}();
				exports$8.ObjectPattern = function() {
					function ObjectPattern(properties) {
						this.type = syntax_1.Syntax.ObjectPattern;
						this.properties = properties;
					}
					return ObjectPattern;
				}();
				exports$8.Property = function() {
					function Property(kind, key, computed, value, method, shorthand) {
						this.type = syntax_1.Syntax.Property;
						this.key = key;
						this.computed = computed;
						this.value = value;
						this.kind = kind;
						this.method = method;
						this.shorthand = shorthand;
					}
					return Property;
				}();
				exports$8.RegexLiteral = function() {
					function RegexLiteral(value, raw, pattern, flags) {
						this.type = syntax_1.Syntax.Literal;
						this.value = value;
						this.raw = raw;
						this.regex = {
							pattern,
							flags
						};
					}
					return RegexLiteral;
				}();
				exports$8.RestElement = function() {
					function RestElement(argument) {
						this.type = syntax_1.Syntax.RestElement;
						this.argument = argument;
					}
					return RestElement;
				}();
				exports$8.ReturnStatement = function() {
					function ReturnStatement(argument) {
						this.type = syntax_1.Syntax.ReturnStatement;
						this.argument = argument;
					}
					return ReturnStatement;
				}();
				exports$8.Script = function() {
					function Script(body) {
						this.type = syntax_1.Syntax.Program;
						this.body = body;
						this.sourceType = "script";
					}
					return Script;
				}();
				exports$8.SequenceExpression = function() {
					function SequenceExpression(expressions) {
						this.type = syntax_1.Syntax.SequenceExpression;
						this.expressions = expressions;
					}
					return SequenceExpression;
				}();
				exports$8.SpreadElement = function() {
					function SpreadElement(argument) {
						this.type = syntax_1.Syntax.SpreadElement;
						this.argument = argument;
					}
					return SpreadElement;
				}();
				exports$8.StaticMemberExpression = function() {
					function StaticMemberExpression(object, property) {
						this.type = syntax_1.Syntax.MemberExpression;
						this.computed = false;
						this.object = object;
						this.property = property;
					}
					return StaticMemberExpression;
				}();
				exports$8.Super = function() {
					function Super() {
						this.type = syntax_1.Syntax.Super;
					}
					return Super;
				}();
				exports$8.SwitchCase = function() {
					function SwitchCase(test, consequent) {
						this.type = syntax_1.Syntax.SwitchCase;
						this.test = test;
						this.consequent = consequent;
					}
					return SwitchCase;
				}();
				exports$8.SwitchStatement = function() {
					function SwitchStatement(discriminant, cases) {
						this.type = syntax_1.Syntax.SwitchStatement;
						this.discriminant = discriminant;
						this.cases = cases;
					}
					return SwitchStatement;
				}();
				exports$8.TaggedTemplateExpression = function() {
					function TaggedTemplateExpression(tag, quasi) {
						this.type = syntax_1.Syntax.TaggedTemplateExpression;
						this.tag = tag;
						this.quasi = quasi;
					}
					return TaggedTemplateExpression;
				}();
				exports$8.TemplateElement = function() {
					function TemplateElement(value, tail) {
						this.type = syntax_1.Syntax.TemplateElement;
						this.value = value;
						this.tail = tail;
					}
					return TemplateElement;
				}();
				exports$8.TemplateLiteral = function() {
					function TemplateLiteral(quasis, expressions) {
						this.type = syntax_1.Syntax.TemplateLiteral;
						this.quasis = quasis;
						this.expressions = expressions;
					}
					return TemplateLiteral;
				}();
				exports$8.ThisExpression = function() {
					function ThisExpression() {
						this.type = syntax_1.Syntax.ThisExpression;
					}
					return ThisExpression;
				}();
				exports$8.ThrowStatement = function() {
					function ThrowStatement(argument) {
						this.type = syntax_1.Syntax.ThrowStatement;
						this.argument = argument;
					}
					return ThrowStatement;
				}();
				exports$8.TryStatement = function() {
					function TryStatement(block, handler, finalizer) {
						this.type = syntax_1.Syntax.TryStatement;
						this.block = block;
						this.handler = handler;
						this.finalizer = finalizer;
					}
					return TryStatement;
				}();
				exports$8.UnaryExpression = function() {
					function UnaryExpression(operator, argument) {
						this.type = syntax_1.Syntax.UnaryExpression;
						this.operator = operator;
						this.argument = argument;
						this.prefix = true;
					}
					return UnaryExpression;
				}();
				exports$8.UpdateExpression = function() {
					function UpdateExpression(operator, argument, prefix) {
						this.type = syntax_1.Syntax.UpdateExpression;
						this.operator = operator;
						this.argument = argument;
						this.prefix = prefix;
					}
					return UpdateExpression;
				}();
				exports$8.VariableDeclaration = function() {
					function VariableDeclaration(declarations, kind) {
						this.type = syntax_1.Syntax.VariableDeclaration;
						this.declarations = declarations;
						this.kind = kind;
					}
					return VariableDeclaration;
				}();
				exports$8.VariableDeclarator = function() {
					function VariableDeclarator(id, init) {
						this.type = syntax_1.Syntax.VariableDeclarator;
						this.id = id;
						this.init = init;
					}
					return VariableDeclarator;
				}();
				exports$8.WhileStatement = function() {
					function WhileStatement(test, body) {
						this.type = syntax_1.Syntax.WhileStatement;
						this.test = test;
						this.body = body;
					}
					return WhileStatement;
				}();
				exports$8.WithStatement = function() {
					function WithStatement(object, body) {
						this.type = syntax_1.Syntax.WithStatement;
						this.object = object;
						this.body = body;
					}
					return WithStatement;
				}();
				exports$8.YieldExpression = function() {
					function YieldExpression(argument, delegate) {
						this.type = syntax_1.Syntax.YieldExpression;
						this.argument = argument;
						this.delegate = delegate;
					}
					return YieldExpression;
				}();
			},
			function(module$10, exports$9, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$9, "__esModule", { value: true });
				var assert_1 = __webpack_require__(9);
				var error_handler_1 = __webpack_require__(10);
				var messages_1 = __webpack_require__(11);
				var Node = __webpack_require__(7);
				var scanner_1 = __webpack_require__(12);
				var syntax_1 = __webpack_require__(2);
				var token_1 = __webpack_require__(13);
				var ArrowParameterPlaceHolder = "ArrowParameterPlaceHolder";
				exports$9.Parser = function() {
					function Parser(code, options, delegate) {
						if (options === void 0) options = {};
						this.config = {
							range: typeof options.range === "boolean" && options.range,
							loc: typeof options.loc === "boolean" && options.loc,
							source: null,
							tokens: typeof options.tokens === "boolean" && options.tokens,
							comment: typeof options.comment === "boolean" && options.comment,
							tolerant: typeof options.tolerant === "boolean" && options.tolerant
						};
						if (this.config.loc && options.source && options.source !== null) this.config.source = String(options.source);
						this.delegate = delegate;
						this.errorHandler = new error_handler_1.ErrorHandler();
						this.errorHandler.tolerant = this.config.tolerant;
						this.scanner = new scanner_1.Scanner(code, this.errorHandler);
						this.scanner.trackComment = this.config.comment;
						this.operatorPrecedence = {
							")": 0,
							";": 0,
							",": 0,
							"=": 0,
							"]": 0,
							"||": 1,
							"&&": 2,
							"|": 3,
							"^": 4,
							"&": 5,
							"==": 6,
							"!=": 6,
							"===": 6,
							"!==": 6,
							"<": 7,
							">": 7,
							"<=": 7,
							">=": 7,
							"<<": 8,
							">>": 8,
							">>>": 8,
							"+": 9,
							"-": 9,
							"*": 11,
							"/": 11,
							"%": 11
						};
						this.lookahead = {
							type: 2,
							value: "",
							lineNumber: this.scanner.lineNumber,
							lineStart: 0,
							start: 0,
							end: 0
						};
						this.hasLineTerminator = false;
						this.context = {
							isModule: false,
							await: false,
							allowIn: true,
							allowStrictDirective: true,
							allowYield: true,
							firstCoverInitializedNameError: null,
							isAssignmentTarget: false,
							isBindingElement: false,
							inFunctionBody: false,
							inIteration: false,
							inSwitch: false,
							labelSet: {},
							strict: false
						};
						this.tokens = [];
						this.startMarker = {
							index: 0,
							line: this.scanner.lineNumber,
							column: 0
						};
						this.lastMarker = {
							index: 0,
							line: this.scanner.lineNumber,
							column: 0
						};
						this.nextToken();
						this.lastMarker = {
							index: this.scanner.index,
							line: this.scanner.lineNumber,
							column: this.scanner.index - this.scanner.lineStart
						};
					}
					Parser.prototype.throwError = function(messageFormat) {
						var values = [];
						for (var _i = 1; _i < arguments.length; _i++) values[_i - 1] = arguments[_i];
						var args = Array.prototype.slice.call(arguments, 1);
						var msg = messageFormat.replace(/%(\d)/g, function(whole, idx) {
							assert_1.assert(idx < args.length, "Message reference must be in range");
							return args[idx];
						});
						var index = this.lastMarker.index;
						var line = this.lastMarker.line;
						var column = this.lastMarker.column + 1;
						throw this.errorHandler.createError(index, line, column, msg);
					};
					Parser.prototype.tolerateError = function(messageFormat) {
						var values = [];
						for (var _i = 1; _i < arguments.length; _i++) values[_i - 1] = arguments[_i];
						var args = Array.prototype.slice.call(arguments, 1);
						var msg = messageFormat.replace(/%(\d)/g, function(whole, idx) {
							assert_1.assert(idx < args.length, "Message reference must be in range");
							return args[idx];
						});
						var index = this.lastMarker.index;
						var line = this.scanner.lineNumber;
						var column = this.lastMarker.column + 1;
						this.errorHandler.tolerateError(index, line, column, msg);
					};
					Parser.prototype.unexpectedTokenError = function(token, message) {
						var msg = message || messages_1.Messages.UnexpectedToken;
						var value;
						if (token) {
							if (!message) {
								msg = token.type === 2 ? messages_1.Messages.UnexpectedEOS : token.type === 3 ? messages_1.Messages.UnexpectedIdentifier : token.type === 6 ? messages_1.Messages.UnexpectedNumber : token.type === 8 ? messages_1.Messages.UnexpectedString : token.type === 10 ? messages_1.Messages.UnexpectedTemplate : messages_1.Messages.UnexpectedToken;
								if (token.type === 4) {
									if (this.scanner.isFutureReservedWord(token.value)) msg = messages_1.Messages.UnexpectedReserved;
									else if (this.context.strict && this.scanner.isStrictModeReservedWord(token.value)) msg = messages_1.Messages.StrictReservedWord;
								}
							}
							value = token.value;
						} else value = "ILLEGAL";
						msg = msg.replace("%0", value);
						if (token && typeof token.lineNumber === "number") {
							var index = token.start;
							var line = token.lineNumber;
							var lastMarkerLineStart = this.lastMarker.index - this.lastMarker.column;
							var column = token.start - lastMarkerLineStart + 1;
							return this.errorHandler.createError(index, line, column, msg);
						} else {
							var index = this.lastMarker.index;
							var line = this.lastMarker.line;
							var column = this.lastMarker.column + 1;
							return this.errorHandler.createError(index, line, column, msg);
						}
					};
					Parser.prototype.throwUnexpectedToken = function(token, message) {
						throw this.unexpectedTokenError(token, message);
					};
					Parser.prototype.tolerateUnexpectedToken = function(token, message) {
						this.errorHandler.tolerate(this.unexpectedTokenError(token, message));
					};
					Parser.prototype.collectComments = function() {
						if (!this.config.comment) this.scanner.scanComments();
						else {
							var comments = this.scanner.scanComments();
							if (comments.length > 0 && this.delegate) for (var i = 0; i < comments.length; ++i) {
								var e = comments[i];
								var node = void 0;
								node = {
									type: e.multiLine ? "BlockComment" : "LineComment",
									value: this.scanner.source.slice(e.slice[0], e.slice[1])
								};
								if (this.config.range) node.range = e.range;
								if (this.config.loc) node.loc = e.loc;
								var metadata = {
									start: {
										line: e.loc.start.line,
										column: e.loc.start.column,
										offset: e.range[0]
									},
									end: {
										line: e.loc.end.line,
										column: e.loc.end.column,
										offset: e.range[1]
									}
								};
								this.delegate(node, metadata);
							}
						}
					};
					Parser.prototype.getTokenRaw = function(token) {
						return this.scanner.source.slice(token.start, token.end);
					};
					Parser.prototype.convertToken = function(token) {
						var t = {
							type: token_1.TokenName[token.type],
							value: this.getTokenRaw(token)
						};
						if (this.config.range) t.range = [token.start, token.end];
						if (this.config.loc) t.loc = {
							start: {
								line: this.startMarker.line,
								column: this.startMarker.column
							},
							end: {
								line: this.scanner.lineNumber,
								column: this.scanner.index - this.scanner.lineStart
							}
						};
						if (token.type === 9) t.regex = {
							pattern: token.pattern,
							flags: token.flags
						};
						return t;
					};
					Parser.prototype.nextToken = function() {
						var token = this.lookahead;
						this.lastMarker.index = this.scanner.index;
						this.lastMarker.line = this.scanner.lineNumber;
						this.lastMarker.column = this.scanner.index - this.scanner.lineStart;
						this.collectComments();
						if (this.scanner.index !== this.startMarker.index) {
							this.startMarker.index = this.scanner.index;
							this.startMarker.line = this.scanner.lineNumber;
							this.startMarker.column = this.scanner.index - this.scanner.lineStart;
						}
						var next = this.scanner.lex();
						this.hasLineTerminator = token.lineNumber !== next.lineNumber;
						if (next && this.context.strict && next.type === 3) {
							if (this.scanner.isStrictModeReservedWord(next.value)) next.type = 4;
						}
						this.lookahead = next;
						if (this.config.tokens && next.type !== 2) this.tokens.push(this.convertToken(next));
						return token;
					};
					Parser.prototype.nextRegexToken = function() {
						this.collectComments();
						var token = this.scanner.scanRegExp();
						if (this.config.tokens) {
							this.tokens.pop();
							this.tokens.push(this.convertToken(token));
						}
						this.lookahead = token;
						this.nextToken();
						return token;
					};
					Parser.prototype.createNode = function() {
						return {
							index: this.startMarker.index,
							line: this.startMarker.line,
							column: this.startMarker.column
						};
					};
					Parser.prototype.startNode = function(token, lastLineStart) {
						if (lastLineStart === void 0) lastLineStart = 0;
						var column = token.start - token.lineStart;
						var line = token.lineNumber;
						if (column < 0) {
							column += lastLineStart;
							line--;
						}
						return {
							index: token.start,
							line,
							column
						};
					};
					Parser.prototype.finalize = function(marker, node) {
						if (this.config.range) node.range = [marker.index, this.lastMarker.index];
						if (this.config.loc) {
							node.loc = {
								start: {
									line: marker.line,
									column: marker.column
								},
								end: {
									line: this.lastMarker.line,
									column: this.lastMarker.column
								}
							};
							if (this.config.source) node.loc.source = this.config.source;
						}
						if (this.delegate) {
							var metadata = {
								start: {
									line: marker.line,
									column: marker.column,
									offset: marker.index
								},
								end: {
									line: this.lastMarker.line,
									column: this.lastMarker.column,
									offset: this.lastMarker.index
								}
							};
							this.delegate(node, metadata);
						}
						return node;
					};
					Parser.prototype.expect = function(value) {
						var token = this.nextToken();
						if (token.type !== 7 || token.value !== value) this.throwUnexpectedToken(token);
					};
					Parser.prototype.expectCommaSeparator = function() {
						if (this.config.tolerant) {
							var token = this.lookahead;
							if (token.type === 7 && token.value === ",") this.nextToken();
							else if (token.type === 7 && token.value === ";") {
								this.nextToken();
								this.tolerateUnexpectedToken(token);
							} else this.tolerateUnexpectedToken(token, messages_1.Messages.UnexpectedToken);
						} else this.expect(",");
					};
					Parser.prototype.expectKeyword = function(keyword) {
						var token = this.nextToken();
						if (token.type !== 4 || token.value !== keyword) this.throwUnexpectedToken(token);
					};
					Parser.prototype.match = function(value) {
						return this.lookahead.type === 7 && this.lookahead.value === value;
					};
					Parser.prototype.matchKeyword = function(keyword) {
						return this.lookahead.type === 4 && this.lookahead.value === keyword;
					};
					Parser.prototype.matchContextualKeyword = function(keyword) {
						return this.lookahead.type === 3 && this.lookahead.value === keyword;
					};
					Parser.prototype.matchAssign = function() {
						if (this.lookahead.type !== 7) return false;
						var op = this.lookahead.value;
						return op === "=" || op === "*=" || op === "**=" || op === "/=" || op === "%=" || op === "+=" || op === "-=" || op === "<<=" || op === ">>=" || op === ">>>=" || op === "&=" || op === "^=" || op === "|=";
					};
					Parser.prototype.isolateCoverGrammar = function(parseFunction) {
						var previousIsBindingElement = this.context.isBindingElement;
						var previousIsAssignmentTarget = this.context.isAssignmentTarget;
						var previousFirstCoverInitializedNameError = this.context.firstCoverInitializedNameError;
						this.context.isBindingElement = true;
						this.context.isAssignmentTarget = true;
						this.context.firstCoverInitializedNameError = null;
						var result = parseFunction.call(this);
						if (this.context.firstCoverInitializedNameError !== null) this.throwUnexpectedToken(this.context.firstCoverInitializedNameError);
						this.context.isBindingElement = previousIsBindingElement;
						this.context.isAssignmentTarget = previousIsAssignmentTarget;
						this.context.firstCoverInitializedNameError = previousFirstCoverInitializedNameError;
						return result;
					};
					Parser.prototype.inheritCoverGrammar = function(parseFunction) {
						var previousIsBindingElement = this.context.isBindingElement;
						var previousIsAssignmentTarget = this.context.isAssignmentTarget;
						var previousFirstCoverInitializedNameError = this.context.firstCoverInitializedNameError;
						this.context.isBindingElement = true;
						this.context.isAssignmentTarget = true;
						this.context.firstCoverInitializedNameError = null;
						var result = parseFunction.call(this);
						this.context.isBindingElement = this.context.isBindingElement && previousIsBindingElement;
						this.context.isAssignmentTarget = this.context.isAssignmentTarget && previousIsAssignmentTarget;
						this.context.firstCoverInitializedNameError = previousFirstCoverInitializedNameError || this.context.firstCoverInitializedNameError;
						return result;
					};
					Parser.prototype.consumeSemicolon = function() {
						if (this.match(";")) this.nextToken();
						else if (!this.hasLineTerminator) {
							if (this.lookahead.type !== 2 && !this.match("}")) this.throwUnexpectedToken(this.lookahead);
							this.lastMarker.index = this.startMarker.index;
							this.lastMarker.line = this.startMarker.line;
							this.lastMarker.column = this.startMarker.column;
						}
					};
					Parser.prototype.parsePrimaryExpression = function() {
						var node = this.createNode();
						var expr;
						var token, raw;
						switch (this.lookahead.type) {
							case 3:
								if ((this.context.isModule || this.context.await) && this.lookahead.value === "await") this.tolerateUnexpectedToken(this.lookahead);
								expr = this.matchAsyncFunction() ? this.parseFunctionExpression() : this.finalize(node, new Node.Identifier(this.nextToken().value));
								break;
							case 6:
							case 8:
								if (this.context.strict && this.lookahead.octal) this.tolerateUnexpectedToken(this.lookahead, messages_1.Messages.StrictOctalLiteral);
								this.context.isAssignmentTarget = false;
								this.context.isBindingElement = false;
								token = this.nextToken();
								raw = this.getTokenRaw(token);
								expr = this.finalize(node, new Node.Literal(token.value, raw));
								break;
							case 1:
								this.context.isAssignmentTarget = false;
								this.context.isBindingElement = false;
								token = this.nextToken();
								raw = this.getTokenRaw(token);
								expr = this.finalize(node, new Node.Literal(token.value === "true", raw));
								break;
							case 5:
								this.context.isAssignmentTarget = false;
								this.context.isBindingElement = false;
								token = this.nextToken();
								raw = this.getTokenRaw(token);
								expr = this.finalize(node, new Node.Literal(null, raw));
								break;
							case 10:
								expr = this.parseTemplateLiteral();
								break;
							case 7:
								switch (this.lookahead.value) {
									case "(":
										this.context.isBindingElement = false;
										expr = this.inheritCoverGrammar(this.parseGroupExpression);
										break;
									case "[":
										expr = this.inheritCoverGrammar(this.parseArrayInitializer);
										break;
									case "{":
										expr = this.inheritCoverGrammar(this.parseObjectInitializer);
										break;
									case "/":
									case "/=":
										this.context.isAssignmentTarget = false;
										this.context.isBindingElement = false;
										this.scanner.index = this.startMarker.index;
										token = this.nextRegexToken();
										raw = this.getTokenRaw(token);
										expr = this.finalize(node, new Node.RegexLiteral(token.regex, raw, token.pattern, token.flags));
										break;
									default: expr = this.throwUnexpectedToken(this.nextToken());
								}
								break;
							case 4:
								if (!this.context.strict && this.context.allowYield && this.matchKeyword("yield")) expr = this.parseIdentifierName();
								else if (!this.context.strict && this.matchKeyword("let")) expr = this.finalize(node, new Node.Identifier(this.nextToken().value));
								else {
									this.context.isAssignmentTarget = false;
									this.context.isBindingElement = false;
									if (this.matchKeyword("function")) expr = this.parseFunctionExpression();
									else if (this.matchKeyword("this")) {
										this.nextToken();
										expr = this.finalize(node, new Node.ThisExpression());
									} else if (this.matchKeyword("class")) expr = this.parseClassExpression();
									else expr = this.throwUnexpectedToken(this.nextToken());
								}
								break;
							default: expr = this.throwUnexpectedToken(this.nextToken());
						}
						return expr;
					};
					Parser.prototype.parseSpreadElement = function() {
						var node = this.createNode();
						this.expect("...");
						var arg = this.inheritCoverGrammar(this.parseAssignmentExpression);
						return this.finalize(node, new Node.SpreadElement(arg));
					};
					Parser.prototype.parseArrayInitializer = function() {
						var node = this.createNode();
						var elements = [];
						this.expect("[");
						while (!this.match("]")) if (this.match(",")) {
							this.nextToken();
							elements.push(null);
						} else if (this.match("...")) {
							var element = this.parseSpreadElement();
							if (!this.match("]")) {
								this.context.isAssignmentTarget = false;
								this.context.isBindingElement = false;
								this.expect(",");
							}
							elements.push(element);
						} else {
							elements.push(this.inheritCoverGrammar(this.parseAssignmentExpression));
							if (!this.match("]")) this.expect(",");
						}
						this.expect("]");
						return this.finalize(node, new Node.ArrayExpression(elements));
					};
					Parser.prototype.parsePropertyMethod = function(params) {
						this.context.isAssignmentTarget = false;
						this.context.isBindingElement = false;
						var previousStrict = this.context.strict;
						var previousAllowStrictDirective = this.context.allowStrictDirective;
						this.context.allowStrictDirective = params.simple;
						var body = this.isolateCoverGrammar(this.parseFunctionSourceElements);
						if (this.context.strict && params.firstRestricted) this.tolerateUnexpectedToken(params.firstRestricted, params.message);
						if (this.context.strict && params.stricted) this.tolerateUnexpectedToken(params.stricted, params.message);
						this.context.strict = previousStrict;
						this.context.allowStrictDirective = previousAllowStrictDirective;
						return body;
					};
					Parser.prototype.parsePropertyMethodFunction = function() {
						var isGenerator = false;
						var node = this.createNode();
						var previousAllowYield = this.context.allowYield;
						this.context.allowYield = true;
						var params = this.parseFormalParameters();
						var method = this.parsePropertyMethod(params);
						this.context.allowYield = previousAllowYield;
						return this.finalize(node, new Node.FunctionExpression(null, params.params, method, isGenerator));
					};
					Parser.prototype.parsePropertyMethodAsyncFunction = function() {
						var node = this.createNode();
						var previousAllowYield = this.context.allowYield;
						var previousAwait = this.context.await;
						this.context.allowYield = false;
						this.context.await = true;
						var params = this.parseFormalParameters();
						var method = this.parsePropertyMethod(params);
						this.context.allowYield = previousAllowYield;
						this.context.await = previousAwait;
						return this.finalize(node, new Node.AsyncFunctionExpression(null, params.params, method));
					};
					Parser.prototype.parseObjectPropertyKey = function() {
						var node = this.createNode();
						var token = this.nextToken();
						var key;
						switch (token.type) {
							case 8:
							case 6:
								if (this.context.strict && token.octal) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictOctalLiteral);
								var raw = this.getTokenRaw(token);
								key = this.finalize(node, new Node.Literal(token.value, raw));
								break;
							case 3:
							case 1:
							case 5:
							case 4:
								key = this.finalize(node, new Node.Identifier(token.value));
								break;
							case 7:
								if (token.value === "[") {
									key = this.isolateCoverGrammar(this.parseAssignmentExpression);
									this.expect("]");
								} else key = this.throwUnexpectedToken(token);
								break;
							default: key = this.throwUnexpectedToken(token);
						}
						return key;
					};
					Parser.prototype.isPropertyKey = function(key, value) {
						return key.type === syntax_1.Syntax.Identifier && key.name === value || key.type === syntax_1.Syntax.Literal && key.value === value;
					};
					Parser.prototype.parseObjectProperty = function(hasProto) {
						var node = this.createNode();
						var token = this.lookahead;
						var kind;
						var key = null;
						var value = null;
						var computed = false;
						var method = false;
						var shorthand = false;
						var isAsync = false;
						if (token.type === 3) {
							var id = token.value;
							this.nextToken();
							computed = this.match("[");
							isAsync = !this.hasLineTerminator && id === "async" && !this.match(":") && !this.match("(") && !this.match("*") && !this.match(",");
							key = isAsync ? this.parseObjectPropertyKey() : this.finalize(node, new Node.Identifier(id));
						} else if (this.match("*")) this.nextToken();
						else {
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
						}
						var lookaheadPropertyKey = this.qualifiedPropertyName(this.lookahead);
						if (token.type === 3 && !isAsync && token.value === "get" && lookaheadPropertyKey) {
							kind = "get";
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
							this.context.allowYield = false;
							value = this.parseGetterMethod();
						} else if (token.type === 3 && !isAsync && token.value === "set" && lookaheadPropertyKey) {
							kind = "set";
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
							value = this.parseSetterMethod();
						} else if (token.type === 7 && token.value === "*" && lookaheadPropertyKey) {
							kind = "init";
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
							value = this.parseGeneratorMethod();
							method = true;
						} else {
							if (!key) this.throwUnexpectedToken(this.lookahead);
							kind = "init";
							if (this.match(":") && !isAsync) {
								if (!computed && this.isPropertyKey(key, "__proto__")) {
									if (hasProto.value) this.tolerateError(messages_1.Messages.DuplicateProtoProperty);
									hasProto.value = true;
								}
								this.nextToken();
								value = this.inheritCoverGrammar(this.parseAssignmentExpression);
							} else if (this.match("(")) {
								value = isAsync ? this.parsePropertyMethodAsyncFunction() : this.parsePropertyMethodFunction();
								method = true;
							} else if (token.type === 3) {
								var id = this.finalize(node, new Node.Identifier(token.value));
								if (this.match("=")) {
									this.context.firstCoverInitializedNameError = this.lookahead;
									this.nextToken();
									shorthand = true;
									var init = this.isolateCoverGrammar(this.parseAssignmentExpression);
									value = this.finalize(node, new Node.AssignmentPattern(id, init));
								} else {
									shorthand = true;
									value = id;
								}
							} else this.throwUnexpectedToken(this.nextToken());
						}
						return this.finalize(node, new Node.Property(kind, key, computed, value, method, shorthand));
					};
					Parser.prototype.parseObjectInitializer = function() {
						var node = this.createNode();
						this.expect("{");
						var properties = [];
						var hasProto = { value: false };
						while (!this.match("}")) {
							properties.push(this.parseObjectProperty(hasProto));
							if (!this.match("}")) this.expectCommaSeparator();
						}
						this.expect("}");
						return this.finalize(node, new Node.ObjectExpression(properties));
					};
					Parser.prototype.parseTemplateHead = function() {
						assert_1.assert(this.lookahead.head, "Template literal must start with a template head");
						var node = this.createNode();
						var token = this.nextToken();
						var raw = token.value;
						var cooked = token.cooked;
						return this.finalize(node, new Node.TemplateElement({
							raw,
							cooked
						}, token.tail));
					};
					Parser.prototype.parseTemplateElement = function() {
						if (this.lookahead.type !== 10) this.throwUnexpectedToken();
						var node = this.createNode();
						var token = this.nextToken();
						var raw = token.value;
						var cooked = token.cooked;
						return this.finalize(node, new Node.TemplateElement({
							raw,
							cooked
						}, token.tail));
					};
					Parser.prototype.parseTemplateLiteral = function() {
						var node = this.createNode();
						var expressions = [];
						var quasis = [];
						var quasi = this.parseTemplateHead();
						quasis.push(quasi);
						while (!quasi.tail) {
							expressions.push(this.parseExpression());
							quasi = this.parseTemplateElement();
							quasis.push(quasi);
						}
						return this.finalize(node, new Node.TemplateLiteral(quasis, expressions));
					};
					Parser.prototype.reinterpretExpressionAsPattern = function(expr) {
						switch (expr.type) {
							case syntax_1.Syntax.Identifier:
							case syntax_1.Syntax.MemberExpression:
							case syntax_1.Syntax.RestElement:
							case syntax_1.Syntax.AssignmentPattern: break;
							case syntax_1.Syntax.SpreadElement:
								expr.type = syntax_1.Syntax.RestElement;
								this.reinterpretExpressionAsPattern(expr.argument);
								break;
							case syntax_1.Syntax.ArrayExpression:
								expr.type = syntax_1.Syntax.ArrayPattern;
								for (var i = 0; i < expr.elements.length; i++) if (expr.elements[i] !== null) this.reinterpretExpressionAsPattern(expr.elements[i]);
								break;
							case syntax_1.Syntax.ObjectExpression:
								expr.type = syntax_1.Syntax.ObjectPattern;
								for (var i = 0; i < expr.properties.length; i++) this.reinterpretExpressionAsPattern(expr.properties[i].value);
								break;
							case syntax_1.Syntax.AssignmentExpression:
								expr.type = syntax_1.Syntax.AssignmentPattern;
								delete expr.operator;
								this.reinterpretExpressionAsPattern(expr.left);
								break;
							default: break;
						}
					};
					Parser.prototype.parseGroupExpression = function() {
						var expr;
						this.expect("(");
						if (this.match(")")) {
							this.nextToken();
							if (!this.match("=>")) this.expect("=>");
							expr = {
								type: ArrowParameterPlaceHolder,
								params: [],
								async: false
							};
						} else {
							var startToken = this.lookahead;
							var params = [];
							if (this.match("...")) {
								expr = this.parseRestElement(params);
								this.expect(")");
								if (!this.match("=>")) this.expect("=>");
								expr = {
									type: ArrowParameterPlaceHolder,
									params: [expr],
									async: false
								};
							} else {
								var arrow = false;
								this.context.isBindingElement = true;
								expr = this.inheritCoverGrammar(this.parseAssignmentExpression);
								if (this.match(",")) {
									var expressions = [];
									this.context.isAssignmentTarget = false;
									expressions.push(expr);
									while (this.lookahead.type !== 2) {
										if (!this.match(",")) break;
										this.nextToken();
										if (this.match(")")) {
											this.nextToken();
											for (var i = 0; i < expressions.length; i++) this.reinterpretExpressionAsPattern(expressions[i]);
											arrow = true;
											expr = {
												type: ArrowParameterPlaceHolder,
												params: expressions,
												async: false
											};
										} else if (this.match("...")) {
											if (!this.context.isBindingElement) this.throwUnexpectedToken(this.lookahead);
											expressions.push(this.parseRestElement(params));
											this.expect(")");
											if (!this.match("=>")) this.expect("=>");
											this.context.isBindingElement = false;
											for (var i = 0; i < expressions.length; i++) this.reinterpretExpressionAsPattern(expressions[i]);
											arrow = true;
											expr = {
												type: ArrowParameterPlaceHolder,
												params: expressions,
												async: false
											};
										} else expressions.push(this.inheritCoverGrammar(this.parseAssignmentExpression));
										if (arrow) break;
									}
									if (!arrow) expr = this.finalize(this.startNode(startToken), new Node.SequenceExpression(expressions));
								}
								if (!arrow) {
									this.expect(")");
									if (this.match("=>")) {
										if (expr.type === syntax_1.Syntax.Identifier && expr.name === "yield") {
											arrow = true;
											expr = {
												type: ArrowParameterPlaceHolder,
												params: [expr],
												async: false
											};
										}
										if (!arrow) {
											if (!this.context.isBindingElement) this.throwUnexpectedToken(this.lookahead);
											if (expr.type === syntax_1.Syntax.SequenceExpression) for (var i = 0; i < expr.expressions.length; i++) this.reinterpretExpressionAsPattern(expr.expressions[i]);
											else this.reinterpretExpressionAsPattern(expr);
											expr = {
												type: ArrowParameterPlaceHolder,
												params: expr.type === syntax_1.Syntax.SequenceExpression ? expr.expressions : [expr],
												async: false
											};
										}
									}
									this.context.isBindingElement = false;
								}
							}
						}
						return expr;
					};
					Parser.prototype.parseArguments = function() {
						this.expect("(");
						var args = [];
						if (!this.match(")")) while (true) {
							var expr = this.match("...") ? this.parseSpreadElement() : this.isolateCoverGrammar(this.parseAssignmentExpression);
							args.push(expr);
							if (this.match(")")) break;
							this.expectCommaSeparator();
							if (this.match(")")) break;
						}
						this.expect(")");
						return args;
					};
					Parser.prototype.isIdentifierName = function(token) {
						return token.type === 3 || token.type === 4 || token.type === 1 || token.type === 5;
					};
					Parser.prototype.parseIdentifierName = function() {
						var node = this.createNode();
						var token = this.nextToken();
						if (!this.isIdentifierName(token)) this.throwUnexpectedToken(token);
						return this.finalize(node, new Node.Identifier(token.value));
					};
					Parser.prototype.parseNewExpression = function() {
						var node = this.createNode();
						var id = this.parseIdentifierName();
						assert_1.assert(id.name === "new", "New expression must start with `new`");
						var expr;
						if (this.match(".")) {
							this.nextToken();
							if (this.lookahead.type === 3 && this.context.inFunctionBody && this.lookahead.value === "target") {
								var property = this.parseIdentifierName();
								expr = new Node.MetaProperty(id, property);
							} else this.throwUnexpectedToken(this.lookahead);
						} else {
							var callee = this.isolateCoverGrammar(this.parseLeftHandSideExpression);
							var args = this.match("(") ? this.parseArguments() : [];
							expr = new Node.NewExpression(callee, args);
							this.context.isAssignmentTarget = false;
							this.context.isBindingElement = false;
						}
						return this.finalize(node, expr);
					};
					Parser.prototype.parseAsyncArgument = function() {
						var arg = this.parseAssignmentExpression();
						this.context.firstCoverInitializedNameError = null;
						return arg;
					};
					Parser.prototype.parseAsyncArguments = function() {
						this.expect("(");
						var args = [];
						if (!this.match(")")) while (true) {
							var expr = this.match("...") ? this.parseSpreadElement() : this.isolateCoverGrammar(this.parseAsyncArgument);
							args.push(expr);
							if (this.match(")")) break;
							this.expectCommaSeparator();
							if (this.match(")")) break;
						}
						this.expect(")");
						return args;
					};
					Parser.prototype.parseLeftHandSideExpressionAllowCall = function() {
						var startToken = this.lookahead;
						var maybeAsync = this.matchContextualKeyword("async");
						var previousAllowIn = this.context.allowIn;
						this.context.allowIn = true;
						var expr;
						if (this.matchKeyword("super") && this.context.inFunctionBody) {
							expr = this.createNode();
							this.nextToken();
							expr = this.finalize(expr, new Node.Super());
							if (!this.match("(") && !this.match(".") && !this.match("[")) this.throwUnexpectedToken(this.lookahead);
						} else expr = this.inheritCoverGrammar(this.matchKeyword("new") ? this.parseNewExpression : this.parsePrimaryExpression);
						while (true) if (this.match(".")) {
							this.context.isBindingElement = false;
							this.context.isAssignmentTarget = true;
							this.expect(".");
							var property = this.parseIdentifierName();
							expr = this.finalize(this.startNode(startToken), new Node.StaticMemberExpression(expr, property));
						} else if (this.match("(")) {
							var asyncArrow = maybeAsync && startToken.lineNumber === this.lookahead.lineNumber;
							this.context.isBindingElement = false;
							this.context.isAssignmentTarget = false;
							var args = asyncArrow ? this.parseAsyncArguments() : this.parseArguments();
							expr = this.finalize(this.startNode(startToken), new Node.CallExpression(expr, args));
							if (asyncArrow && this.match("=>")) {
								for (var i = 0; i < args.length; ++i) this.reinterpretExpressionAsPattern(args[i]);
								expr = {
									type: ArrowParameterPlaceHolder,
									params: args,
									async: true
								};
							}
						} else if (this.match("[")) {
							this.context.isBindingElement = false;
							this.context.isAssignmentTarget = true;
							this.expect("[");
							var property = this.isolateCoverGrammar(this.parseExpression);
							this.expect("]");
							expr = this.finalize(this.startNode(startToken), new Node.ComputedMemberExpression(expr, property));
						} else if (this.lookahead.type === 10 && this.lookahead.head) {
							var quasi = this.parseTemplateLiteral();
							expr = this.finalize(this.startNode(startToken), new Node.TaggedTemplateExpression(expr, quasi));
						} else break;
						this.context.allowIn = previousAllowIn;
						return expr;
					};
					Parser.prototype.parseSuper = function() {
						var node = this.createNode();
						this.expectKeyword("super");
						if (!this.match("[") && !this.match(".")) this.throwUnexpectedToken(this.lookahead);
						return this.finalize(node, new Node.Super());
					};
					Parser.prototype.parseLeftHandSideExpression = function() {
						assert_1.assert(this.context.allowIn, "callee of new expression always allow in keyword.");
						var node = this.startNode(this.lookahead);
						var expr = this.matchKeyword("super") && this.context.inFunctionBody ? this.parseSuper() : this.inheritCoverGrammar(this.matchKeyword("new") ? this.parseNewExpression : this.parsePrimaryExpression);
						while (true) if (this.match("[")) {
							this.context.isBindingElement = false;
							this.context.isAssignmentTarget = true;
							this.expect("[");
							var property = this.isolateCoverGrammar(this.parseExpression);
							this.expect("]");
							expr = this.finalize(node, new Node.ComputedMemberExpression(expr, property));
						} else if (this.match(".")) {
							this.context.isBindingElement = false;
							this.context.isAssignmentTarget = true;
							this.expect(".");
							var property = this.parseIdentifierName();
							expr = this.finalize(node, new Node.StaticMemberExpression(expr, property));
						} else if (this.lookahead.type === 10 && this.lookahead.head) {
							var quasi = this.parseTemplateLiteral();
							expr = this.finalize(node, new Node.TaggedTemplateExpression(expr, quasi));
						} else break;
						return expr;
					};
					Parser.prototype.parseUpdateExpression = function() {
						var expr;
						var startToken = this.lookahead;
						if (this.match("++") || this.match("--")) {
							var node = this.startNode(startToken);
							var token = this.nextToken();
							expr = this.inheritCoverGrammar(this.parseUnaryExpression);
							if (this.context.strict && expr.type === syntax_1.Syntax.Identifier && this.scanner.isRestrictedWord(expr.name)) this.tolerateError(messages_1.Messages.StrictLHSPrefix);
							if (!this.context.isAssignmentTarget) this.tolerateError(messages_1.Messages.InvalidLHSInAssignment);
							var prefix = true;
							expr = this.finalize(node, new Node.UpdateExpression(token.value, expr, prefix));
							this.context.isAssignmentTarget = false;
							this.context.isBindingElement = false;
						} else {
							expr = this.inheritCoverGrammar(this.parseLeftHandSideExpressionAllowCall);
							if (!this.hasLineTerminator && this.lookahead.type === 7) {
								if (this.match("++") || this.match("--")) {
									if (this.context.strict && expr.type === syntax_1.Syntax.Identifier && this.scanner.isRestrictedWord(expr.name)) this.tolerateError(messages_1.Messages.StrictLHSPostfix);
									if (!this.context.isAssignmentTarget) this.tolerateError(messages_1.Messages.InvalidLHSInAssignment);
									this.context.isAssignmentTarget = false;
									this.context.isBindingElement = false;
									var operator = this.nextToken().value;
									var prefix = false;
									expr = this.finalize(this.startNode(startToken), new Node.UpdateExpression(operator, expr, prefix));
								}
							}
						}
						return expr;
					};
					Parser.prototype.parseAwaitExpression = function() {
						var node = this.createNode();
						this.nextToken();
						var argument = this.parseUnaryExpression();
						return this.finalize(node, new Node.AwaitExpression(argument));
					};
					Parser.prototype.parseUnaryExpression = function() {
						var expr;
						if (this.match("+") || this.match("-") || this.match("~") || this.match("!") || this.matchKeyword("delete") || this.matchKeyword("void") || this.matchKeyword("typeof")) {
							var node = this.startNode(this.lookahead);
							var token = this.nextToken();
							expr = this.inheritCoverGrammar(this.parseUnaryExpression);
							expr = this.finalize(node, new Node.UnaryExpression(token.value, expr));
							if (this.context.strict && expr.operator === "delete" && expr.argument.type === syntax_1.Syntax.Identifier) this.tolerateError(messages_1.Messages.StrictDelete);
							this.context.isAssignmentTarget = false;
							this.context.isBindingElement = false;
						} else if (this.context.await && this.matchContextualKeyword("await")) expr = this.parseAwaitExpression();
						else expr = this.parseUpdateExpression();
						return expr;
					};
					Parser.prototype.parseExponentiationExpression = function() {
						var startToken = this.lookahead;
						var expr = this.inheritCoverGrammar(this.parseUnaryExpression);
						if (expr.type !== syntax_1.Syntax.UnaryExpression && this.match("**")) {
							this.nextToken();
							this.context.isAssignmentTarget = false;
							this.context.isBindingElement = false;
							var left = expr;
							var right = this.isolateCoverGrammar(this.parseExponentiationExpression);
							expr = this.finalize(this.startNode(startToken), new Node.BinaryExpression("**", left, right));
						}
						return expr;
					};
					Parser.prototype.binaryPrecedence = function(token) {
						var op = token.value;
						var precedence;
						if (token.type === 7) precedence = this.operatorPrecedence[op] || 0;
						else if (token.type === 4) precedence = op === "instanceof" || this.context.allowIn && op === "in" ? 7 : 0;
						else precedence = 0;
						return precedence;
					};
					Parser.prototype.parseBinaryExpression = function() {
						var startToken = this.lookahead;
						var expr = this.inheritCoverGrammar(this.parseExponentiationExpression);
						var token = this.lookahead;
						var prec = this.binaryPrecedence(token);
						if (prec > 0) {
							this.nextToken();
							this.context.isAssignmentTarget = false;
							this.context.isBindingElement = false;
							var markers = [startToken, this.lookahead];
							var left = expr;
							var right = this.isolateCoverGrammar(this.parseExponentiationExpression);
							var stack = [
								left,
								token.value,
								right
							];
							var precedences = [prec];
							while (true) {
								prec = this.binaryPrecedence(this.lookahead);
								if (prec <= 0) break;
								while (stack.length > 2 && prec <= precedences[precedences.length - 1]) {
									right = stack.pop();
									var operator = stack.pop();
									precedences.pop();
									left = stack.pop();
									markers.pop();
									var node = this.startNode(markers[markers.length - 1]);
									stack.push(this.finalize(node, new Node.BinaryExpression(operator, left, right)));
								}
								stack.push(this.nextToken().value);
								precedences.push(prec);
								markers.push(this.lookahead);
								stack.push(this.isolateCoverGrammar(this.parseExponentiationExpression));
							}
							var i = stack.length - 1;
							expr = stack[i];
							var lastMarker = markers.pop();
							while (i > 1) {
								var marker = markers.pop();
								var lastLineStart = lastMarker && lastMarker.lineStart;
								var node = this.startNode(marker, lastLineStart);
								var operator = stack[i - 1];
								expr = this.finalize(node, new Node.BinaryExpression(operator, stack[i - 2], expr));
								i -= 2;
								lastMarker = marker;
							}
						}
						return expr;
					};
					Parser.prototype.parseConditionalExpression = function() {
						var startToken = this.lookahead;
						var expr = this.inheritCoverGrammar(this.parseBinaryExpression);
						if (this.match("?")) {
							this.nextToken();
							var previousAllowIn = this.context.allowIn;
							this.context.allowIn = true;
							var consequent = this.isolateCoverGrammar(this.parseAssignmentExpression);
							this.context.allowIn = previousAllowIn;
							this.expect(":");
							var alternate = this.isolateCoverGrammar(this.parseAssignmentExpression);
							expr = this.finalize(this.startNode(startToken), new Node.ConditionalExpression(expr, consequent, alternate));
							this.context.isAssignmentTarget = false;
							this.context.isBindingElement = false;
						}
						return expr;
					};
					Parser.prototype.checkPatternParam = function(options, param) {
						switch (param.type) {
							case syntax_1.Syntax.Identifier:
								this.validateParam(options, param, param.name);
								break;
							case syntax_1.Syntax.RestElement:
								this.checkPatternParam(options, param.argument);
								break;
							case syntax_1.Syntax.AssignmentPattern:
								this.checkPatternParam(options, param.left);
								break;
							case syntax_1.Syntax.ArrayPattern:
								for (var i = 0; i < param.elements.length; i++) if (param.elements[i] !== null) this.checkPatternParam(options, param.elements[i]);
								break;
							case syntax_1.Syntax.ObjectPattern:
								for (var i = 0; i < param.properties.length; i++) this.checkPatternParam(options, param.properties[i].value);
								break;
							default: break;
						}
						options.simple = options.simple && param instanceof Node.Identifier;
					};
					Parser.prototype.reinterpretAsCoverFormalsList = function(expr) {
						var params = [expr];
						var options;
						var asyncArrow = false;
						switch (expr.type) {
							case syntax_1.Syntax.Identifier: break;
							case ArrowParameterPlaceHolder:
								params = expr.params;
								asyncArrow = expr.async;
								break;
							default: return null;
						}
						options = {
							simple: true,
							paramSet: {}
						};
						for (var i = 0; i < params.length; ++i) {
							var param = params[i];
							if (param.type === syntax_1.Syntax.AssignmentPattern) {
								if (param.right.type === syntax_1.Syntax.YieldExpression) {
									if (param.right.argument) this.throwUnexpectedToken(this.lookahead);
									param.right.type = syntax_1.Syntax.Identifier;
									param.right.name = "yield";
									delete param.right.argument;
									delete param.right.delegate;
								}
							} else if (asyncArrow && param.type === syntax_1.Syntax.Identifier && param.name === "await") this.throwUnexpectedToken(this.lookahead);
							this.checkPatternParam(options, param);
							params[i] = param;
						}
						if (this.context.strict || !this.context.allowYield) for (var i = 0; i < params.length; ++i) {
							var param = params[i];
							if (param.type === syntax_1.Syntax.YieldExpression) this.throwUnexpectedToken(this.lookahead);
						}
						if (options.message === messages_1.Messages.StrictParamDupe) {
							var token = this.context.strict ? options.stricted : options.firstRestricted;
							this.throwUnexpectedToken(token, options.message);
						}
						return {
							simple: options.simple,
							params,
							stricted: options.stricted,
							firstRestricted: options.firstRestricted,
							message: options.message
						};
					};
					Parser.prototype.parseAssignmentExpression = function() {
						var expr;
						if (!this.context.allowYield && this.matchKeyword("yield")) expr = this.parseYieldExpression();
						else {
							var startToken = this.lookahead;
							var token = startToken;
							expr = this.parseConditionalExpression();
							if (token.type === 3 && token.lineNumber === this.lookahead.lineNumber && token.value === "async") {
								if (this.lookahead.type === 3 || this.matchKeyword("yield")) {
									var arg = this.parsePrimaryExpression();
									this.reinterpretExpressionAsPattern(arg);
									expr = {
										type: ArrowParameterPlaceHolder,
										params: [arg],
										async: true
									};
								}
							}
							if (expr.type === ArrowParameterPlaceHolder || this.match("=>")) {
								this.context.isAssignmentTarget = false;
								this.context.isBindingElement = false;
								var isAsync = expr.async;
								var list = this.reinterpretAsCoverFormalsList(expr);
								if (list) {
									if (this.hasLineTerminator) this.tolerateUnexpectedToken(this.lookahead);
									this.context.firstCoverInitializedNameError = null;
									var previousStrict = this.context.strict;
									var previousAllowStrictDirective = this.context.allowStrictDirective;
									this.context.allowStrictDirective = list.simple;
									var previousAllowYield = this.context.allowYield;
									var previousAwait = this.context.await;
									this.context.allowYield = true;
									this.context.await = isAsync;
									var node = this.startNode(startToken);
									this.expect("=>");
									var body = void 0;
									if (this.match("{")) {
										var previousAllowIn = this.context.allowIn;
										this.context.allowIn = true;
										body = this.parseFunctionSourceElements();
										this.context.allowIn = previousAllowIn;
									} else body = this.isolateCoverGrammar(this.parseAssignmentExpression);
									var expression = body.type !== syntax_1.Syntax.BlockStatement;
									if (this.context.strict && list.firstRestricted) this.throwUnexpectedToken(list.firstRestricted, list.message);
									if (this.context.strict && list.stricted) this.tolerateUnexpectedToken(list.stricted, list.message);
									expr = isAsync ? this.finalize(node, new Node.AsyncArrowFunctionExpression(list.params, body, expression)) : this.finalize(node, new Node.ArrowFunctionExpression(list.params, body, expression));
									this.context.strict = previousStrict;
									this.context.allowStrictDirective = previousAllowStrictDirective;
									this.context.allowYield = previousAllowYield;
									this.context.await = previousAwait;
								}
							} else if (this.matchAssign()) {
								if (!this.context.isAssignmentTarget) this.tolerateError(messages_1.Messages.InvalidLHSInAssignment);
								if (this.context.strict && expr.type === syntax_1.Syntax.Identifier) {
									var id = expr;
									if (this.scanner.isRestrictedWord(id.name)) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictLHSAssignment);
									if (this.scanner.isStrictModeReservedWord(id.name)) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictReservedWord);
								}
								if (!this.match("=")) {
									this.context.isAssignmentTarget = false;
									this.context.isBindingElement = false;
								} else this.reinterpretExpressionAsPattern(expr);
								token = this.nextToken();
								var operator = token.value;
								var right = this.isolateCoverGrammar(this.parseAssignmentExpression);
								expr = this.finalize(this.startNode(startToken), new Node.AssignmentExpression(operator, expr, right));
								this.context.firstCoverInitializedNameError = null;
							}
						}
						return expr;
					};
					Parser.prototype.parseExpression = function() {
						var startToken = this.lookahead;
						var expr = this.isolateCoverGrammar(this.parseAssignmentExpression);
						if (this.match(",")) {
							var expressions = [];
							expressions.push(expr);
							while (this.lookahead.type !== 2) {
								if (!this.match(",")) break;
								this.nextToken();
								expressions.push(this.isolateCoverGrammar(this.parseAssignmentExpression));
							}
							expr = this.finalize(this.startNode(startToken), new Node.SequenceExpression(expressions));
						}
						return expr;
					};
					Parser.prototype.parseStatementListItem = function() {
						var statement;
						this.context.isAssignmentTarget = true;
						this.context.isBindingElement = true;
						if (this.lookahead.type === 4) switch (this.lookahead.value) {
							case "export":
								if (!this.context.isModule) this.tolerateUnexpectedToken(this.lookahead, messages_1.Messages.IllegalExportDeclaration);
								statement = this.parseExportDeclaration();
								break;
							case "import":
								if (!this.context.isModule) this.tolerateUnexpectedToken(this.lookahead, messages_1.Messages.IllegalImportDeclaration);
								statement = this.parseImportDeclaration();
								break;
							case "const":
								statement = this.parseLexicalDeclaration({ inFor: false });
								break;
							case "function":
								statement = this.parseFunctionDeclaration();
								break;
							case "class":
								statement = this.parseClassDeclaration();
								break;
							case "let":
								statement = this.isLexicalDeclaration() ? this.parseLexicalDeclaration({ inFor: false }) : this.parseStatement();
								break;
							default:
								statement = this.parseStatement();
								break;
						}
						else statement = this.parseStatement();
						return statement;
					};
					Parser.prototype.parseBlock = function() {
						var node = this.createNode();
						this.expect("{");
						var block = [];
						while (true) {
							if (this.match("}")) break;
							block.push(this.parseStatementListItem());
						}
						this.expect("}");
						return this.finalize(node, new Node.BlockStatement(block));
					};
					Parser.prototype.parseLexicalBinding = function(kind, options) {
						var node = this.createNode();
						var id = this.parsePattern([], kind);
						if (this.context.strict && id.type === syntax_1.Syntax.Identifier) {
							if (this.scanner.isRestrictedWord(id.name)) this.tolerateError(messages_1.Messages.StrictVarName);
						}
						var init = null;
						if (kind === "const") {
							if (!this.matchKeyword("in") && !this.matchContextualKeyword("of")) if (this.match("=")) {
								this.nextToken();
								init = this.isolateCoverGrammar(this.parseAssignmentExpression);
							} else this.throwError(messages_1.Messages.DeclarationMissingInitializer, "const");
						} else if (!options.inFor && id.type !== syntax_1.Syntax.Identifier || this.match("=")) {
							this.expect("=");
							init = this.isolateCoverGrammar(this.parseAssignmentExpression);
						}
						return this.finalize(node, new Node.VariableDeclarator(id, init));
					};
					Parser.prototype.parseBindingList = function(kind, options) {
						var list = [this.parseLexicalBinding(kind, options)];
						while (this.match(",")) {
							this.nextToken();
							list.push(this.parseLexicalBinding(kind, options));
						}
						return list;
					};
					Parser.prototype.isLexicalDeclaration = function() {
						var state = this.scanner.saveState();
						this.scanner.scanComments();
						var next = this.scanner.lex();
						this.scanner.restoreState(state);
						return next.type === 3 || next.type === 7 && next.value === "[" || next.type === 7 && next.value === "{" || next.type === 4 && next.value === "let" || next.type === 4 && next.value === "yield";
					};
					Parser.prototype.parseLexicalDeclaration = function(options) {
						var node = this.createNode();
						var kind = this.nextToken().value;
						assert_1.assert(kind === "let" || kind === "const", "Lexical declaration must be either let or const");
						var declarations = this.parseBindingList(kind, options);
						this.consumeSemicolon();
						return this.finalize(node, new Node.VariableDeclaration(declarations, kind));
					};
					Parser.prototype.parseBindingRestElement = function(params, kind) {
						var node = this.createNode();
						this.expect("...");
						var arg = this.parsePattern(params, kind);
						return this.finalize(node, new Node.RestElement(arg));
					};
					Parser.prototype.parseArrayPattern = function(params, kind) {
						var node = this.createNode();
						this.expect("[");
						var elements = [];
						while (!this.match("]")) if (this.match(",")) {
							this.nextToken();
							elements.push(null);
						} else {
							if (this.match("...")) {
								elements.push(this.parseBindingRestElement(params, kind));
								break;
							} else elements.push(this.parsePatternWithDefault(params, kind));
							if (!this.match("]")) this.expect(",");
						}
						this.expect("]");
						return this.finalize(node, new Node.ArrayPattern(elements));
					};
					Parser.prototype.parsePropertyPattern = function(params, kind) {
						var node = this.createNode();
						var computed = false;
						var shorthand = false;
						var method = false;
						var key;
						var value;
						if (this.lookahead.type === 3) {
							var keyToken = this.lookahead;
							key = this.parseVariableIdentifier();
							var init = this.finalize(node, new Node.Identifier(keyToken.value));
							if (this.match("=")) {
								params.push(keyToken);
								shorthand = true;
								this.nextToken();
								var expr = this.parseAssignmentExpression();
								value = this.finalize(this.startNode(keyToken), new Node.AssignmentPattern(init, expr));
							} else if (!this.match(":")) {
								params.push(keyToken);
								shorthand = true;
								value = init;
							} else {
								this.expect(":");
								value = this.parsePatternWithDefault(params, kind);
							}
						} else {
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
							this.expect(":");
							value = this.parsePatternWithDefault(params, kind);
						}
						return this.finalize(node, new Node.Property("init", key, computed, value, method, shorthand));
					};
					Parser.prototype.parseObjectPattern = function(params, kind) {
						var node = this.createNode();
						var properties = [];
						this.expect("{");
						while (!this.match("}")) {
							properties.push(this.parsePropertyPattern(params, kind));
							if (!this.match("}")) this.expect(",");
						}
						this.expect("}");
						return this.finalize(node, new Node.ObjectPattern(properties));
					};
					Parser.prototype.parsePattern = function(params, kind) {
						var pattern;
						if (this.match("[")) pattern = this.parseArrayPattern(params, kind);
						else if (this.match("{")) pattern = this.parseObjectPattern(params, kind);
						else {
							if (this.matchKeyword("let") && (kind === "const" || kind === "let")) this.tolerateUnexpectedToken(this.lookahead, messages_1.Messages.LetInLexicalBinding);
							params.push(this.lookahead);
							pattern = this.parseVariableIdentifier(kind);
						}
						return pattern;
					};
					Parser.prototype.parsePatternWithDefault = function(params, kind) {
						var startToken = this.lookahead;
						var pattern = this.parsePattern(params, kind);
						if (this.match("=")) {
							this.nextToken();
							var previousAllowYield = this.context.allowYield;
							this.context.allowYield = true;
							var right = this.isolateCoverGrammar(this.parseAssignmentExpression);
							this.context.allowYield = previousAllowYield;
							pattern = this.finalize(this.startNode(startToken), new Node.AssignmentPattern(pattern, right));
						}
						return pattern;
					};
					Parser.prototype.parseVariableIdentifier = function(kind) {
						var node = this.createNode();
						var token = this.nextToken();
						if (token.type === 4 && token.value === "yield") {
							if (this.context.strict) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictReservedWord);
							else if (!this.context.allowYield) this.throwUnexpectedToken(token);
						} else if (token.type !== 3) {
							if (this.context.strict && token.type === 4 && this.scanner.isStrictModeReservedWord(token.value)) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictReservedWord);
							else if (this.context.strict || token.value !== "let" || kind !== "var") this.throwUnexpectedToken(token);
						} else if ((this.context.isModule || this.context.await) && token.type === 3 && token.value === "await") this.tolerateUnexpectedToken(token);
						return this.finalize(node, new Node.Identifier(token.value));
					};
					Parser.prototype.parseVariableDeclaration = function(options) {
						var node = this.createNode();
						var id = this.parsePattern([], "var");
						if (this.context.strict && id.type === syntax_1.Syntax.Identifier) {
							if (this.scanner.isRestrictedWord(id.name)) this.tolerateError(messages_1.Messages.StrictVarName);
						}
						var init = null;
						if (this.match("=")) {
							this.nextToken();
							init = this.isolateCoverGrammar(this.parseAssignmentExpression);
						} else if (id.type !== syntax_1.Syntax.Identifier && !options.inFor) this.expect("=");
						return this.finalize(node, new Node.VariableDeclarator(id, init));
					};
					Parser.prototype.parseVariableDeclarationList = function(options) {
						var opt = { inFor: options.inFor };
						var list = [];
						list.push(this.parseVariableDeclaration(opt));
						while (this.match(",")) {
							this.nextToken();
							list.push(this.parseVariableDeclaration(opt));
						}
						return list;
					};
					Parser.prototype.parseVariableStatement = function() {
						var node = this.createNode();
						this.expectKeyword("var");
						var declarations = this.parseVariableDeclarationList({ inFor: false });
						this.consumeSemicolon();
						return this.finalize(node, new Node.VariableDeclaration(declarations, "var"));
					};
					Parser.prototype.parseEmptyStatement = function() {
						var node = this.createNode();
						this.expect(";");
						return this.finalize(node, new Node.EmptyStatement());
					};
					Parser.prototype.parseExpressionStatement = function() {
						var node = this.createNode();
						var expr = this.parseExpression();
						this.consumeSemicolon();
						return this.finalize(node, new Node.ExpressionStatement(expr));
					};
					Parser.prototype.parseIfClause = function() {
						if (this.context.strict && this.matchKeyword("function")) this.tolerateError(messages_1.Messages.StrictFunction);
						return this.parseStatement();
					};
					Parser.prototype.parseIfStatement = function() {
						var node = this.createNode();
						var consequent;
						var alternate = null;
						this.expectKeyword("if");
						this.expect("(");
						var test = this.parseExpression();
						if (!this.match(")") && this.config.tolerant) {
							this.tolerateUnexpectedToken(this.nextToken());
							consequent = this.finalize(this.createNode(), new Node.EmptyStatement());
						} else {
							this.expect(")");
							consequent = this.parseIfClause();
							if (this.matchKeyword("else")) {
								this.nextToken();
								alternate = this.parseIfClause();
							}
						}
						return this.finalize(node, new Node.IfStatement(test, consequent, alternate));
					};
					Parser.prototype.parseDoWhileStatement = function() {
						var node = this.createNode();
						this.expectKeyword("do");
						var previousInIteration = this.context.inIteration;
						this.context.inIteration = true;
						var body = this.parseStatement();
						this.context.inIteration = previousInIteration;
						this.expectKeyword("while");
						this.expect("(");
						var test = this.parseExpression();
						if (!this.match(")") && this.config.tolerant) this.tolerateUnexpectedToken(this.nextToken());
						else {
							this.expect(")");
							if (this.match(";")) this.nextToken();
						}
						return this.finalize(node, new Node.DoWhileStatement(body, test));
					};
					Parser.prototype.parseWhileStatement = function() {
						var node = this.createNode();
						var body;
						this.expectKeyword("while");
						this.expect("(");
						var test = this.parseExpression();
						if (!this.match(")") && this.config.tolerant) {
							this.tolerateUnexpectedToken(this.nextToken());
							body = this.finalize(this.createNode(), new Node.EmptyStatement());
						} else {
							this.expect(")");
							var previousInIteration = this.context.inIteration;
							this.context.inIteration = true;
							body = this.parseStatement();
							this.context.inIteration = previousInIteration;
						}
						return this.finalize(node, new Node.WhileStatement(test, body));
					};
					Parser.prototype.parseForStatement = function() {
						var init = null;
						var test = null;
						var update = null;
						var forIn = true;
						var left, right;
						var node = this.createNode();
						this.expectKeyword("for");
						this.expect("(");
						if (this.match(";")) this.nextToken();
						else if (this.matchKeyword("var")) {
							init = this.createNode();
							this.nextToken();
							var previousAllowIn = this.context.allowIn;
							this.context.allowIn = false;
							var declarations = this.parseVariableDeclarationList({ inFor: true });
							this.context.allowIn = previousAllowIn;
							if (declarations.length === 1 && this.matchKeyword("in")) {
								var decl = declarations[0];
								if (decl.init && (decl.id.type === syntax_1.Syntax.ArrayPattern || decl.id.type === syntax_1.Syntax.ObjectPattern || this.context.strict)) this.tolerateError(messages_1.Messages.ForInOfLoopInitializer, "for-in");
								init = this.finalize(init, new Node.VariableDeclaration(declarations, "var"));
								this.nextToken();
								left = init;
								right = this.parseExpression();
								init = null;
							} else if (declarations.length === 1 && declarations[0].init === null && this.matchContextualKeyword("of")) {
								init = this.finalize(init, new Node.VariableDeclaration(declarations, "var"));
								this.nextToken();
								left = init;
								right = this.parseAssignmentExpression();
								init = null;
								forIn = false;
							} else {
								init = this.finalize(init, new Node.VariableDeclaration(declarations, "var"));
								this.expect(";");
							}
						} else if (this.matchKeyword("const") || this.matchKeyword("let")) {
							init = this.createNode();
							var kind = this.nextToken().value;
							if (!this.context.strict && this.lookahead.value === "in") {
								init = this.finalize(init, new Node.Identifier(kind));
								this.nextToken();
								left = init;
								right = this.parseExpression();
								init = null;
							} else {
								var previousAllowIn = this.context.allowIn;
								this.context.allowIn = false;
								var declarations = this.parseBindingList(kind, { inFor: true });
								this.context.allowIn = previousAllowIn;
								if (declarations.length === 1 && declarations[0].init === null && this.matchKeyword("in")) {
									init = this.finalize(init, new Node.VariableDeclaration(declarations, kind));
									this.nextToken();
									left = init;
									right = this.parseExpression();
									init = null;
								} else if (declarations.length === 1 && declarations[0].init === null && this.matchContextualKeyword("of")) {
									init = this.finalize(init, new Node.VariableDeclaration(declarations, kind));
									this.nextToken();
									left = init;
									right = this.parseAssignmentExpression();
									init = null;
									forIn = false;
								} else {
									this.consumeSemicolon();
									init = this.finalize(init, new Node.VariableDeclaration(declarations, kind));
								}
							}
						} else {
							var initStartToken = this.lookahead;
							var previousAllowIn = this.context.allowIn;
							this.context.allowIn = false;
							init = this.inheritCoverGrammar(this.parseAssignmentExpression);
							this.context.allowIn = previousAllowIn;
							if (this.matchKeyword("in")) {
								if (!this.context.isAssignmentTarget || init.type === syntax_1.Syntax.AssignmentExpression) this.tolerateError(messages_1.Messages.InvalidLHSInForIn);
								this.nextToken();
								this.reinterpretExpressionAsPattern(init);
								left = init;
								right = this.parseExpression();
								init = null;
							} else if (this.matchContextualKeyword("of")) {
								if (!this.context.isAssignmentTarget || init.type === syntax_1.Syntax.AssignmentExpression) this.tolerateError(messages_1.Messages.InvalidLHSInForLoop);
								this.nextToken();
								this.reinterpretExpressionAsPattern(init);
								left = init;
								right = this.parseAssignmentExpression();
								init = null;
								forIn = false;
							} else {
								if (this.match(",")) {
									var initSeq = [init];
									while (this.match(",")) {
										this.nextToken();
										initSeq.push(this.isolateCoverGrammar(this.parseAssignmentExpression));
									}
									init = this.finalize(this.startNode(initStartToken), new Node.SequenceExpression(initSeq));
								}
								this.expect(";");
							}
						}
						if (typeof left === "undefined") {
							if (!this.match(";")) test = this.parseExpression();
							this.expect(";");
							if (!this.match(")")) update = this.parseExpression();
						}
						var body;
						if (!this.match(")") && this.config.tolerant) {
							this.tolerateUnexpectedToken(this.nextToken());
							body = this.finalize(this.createNode(), new Node.EmptyStatement());
						} else {
							this.expect(")");
							var previousInIteration = this.context.inIteration;
							this.context.inIteration = true;
							body = this.isolateCoverGrammar(this.parseStatement);
							this.context.inIteration = previousInIteration;
						}
						return typeof left === "undefined" ? this.finalize(node, new Node.ForStatement(init, test, update, body)) : forIn ? this.finalize(node, new Node.ForInStatement(left, right, body)) : this.finalize(node, new Node.ForOfStatement(left, right, body));
					};
					Parser.prototype.parseContinueStatement = function() {
						var node = this.createNode();
						this.expectKeyword("continue");
						var label = null;
						if (this.lookahead.type === 3 && !this.hasLineTerminator) {
							var id = this.parseVariableIdentifier();
							label = id;
							var key = "$" + id.name;
							if (!Object.prototype.hasOwnProperty.call(this.context.labelSet, key)) this.throwError(messages_1.Messages.UnknownLabel, id.name);
						}
						this.consumeSemicolon();
						if (label === null && !this.context.inIteration) this.throwError(messages_1.Messages.IllegalContinue);
						return this.finalize(node, new Node.ContinueStatement(label));
					};
					Parser.prototype.parseBreakStatement = function() {
						var node = this.createNode();
						this.expectKeyword("break");
						var label = null;
						if (this.lookahead.type === 3 && !this.hasLineTerminator) {
							var id = this.parseVariableIdentifier();
							var key = "$" + id.name;
							if (!Object.prototype.hasOwnProperty.call(this.context.labelSet, key)) this.throwError(messages_1.Messages.UnknownLabel, id.name);
							label = id;
						}
						this.consumeSemicolon();
						if (label === null && !this.context.inIteration && !this.context.inSwitch) this.throwError(messages_1.Messages.IllegalBreak);
						return this.finalize(node, new Node.BreakStatement(label));
					};
					Parser.prototype.parseReturnStatement = function() {
						if (!this.context.inFunctionBody) this.tolerateError(messages_1.Messages.IllegalReturn);
						var node = this.createNode();
						this.expectKeyword("return");
						var argument = !this.match(";") && !this.match("}") && !this.hasLineTerminator && this.lookahead.type !== 2 || this.lookahead.type === 8 || this.lookahead.type === 10 ? this.parseExpression() : null;
						this.consumeSemicolon();
						return this.finalize(node, new Node.ReturnStatement(argument));
					};
					Parser.prototype.parseWithStatement = function() {
						if (this.context.strict) this.tolerateError(messages_1.Messages.StrictModeWith);
						var node = this.createNode();
						var body;
						this.expectKeyword("with");
						this.expect("(");
						var object = this.parseExpression();
						if (!this.match(")") && this.config.tolerant) {
							this.tolerateUnexpectedToken(this.nextToken());
							body = this.finalize(this.createNode(), new Node.EmptyStatement());
						} else {
							this.expect(")");
							body = this.parseStatement();
						}
						return this.finalize(node, new Node.WithStatement(object, body));
					};
					Parser.prototype.parseSwitchCase = function() {
						var node = this.createNode();
						var test;
						if (this.matchKeyword("default")) {
							this.nextToken();
							test = null;
						} else {
							this.expectKeyword("case");
							test = this.parseExpression();
						}
						this.expect(":");
						var consequent = [];
						while (true) {
							if (this.match("}") || this.matchKeyword("default") || this.matchKeyword("case")) break;
							consequent.push(this.parseStatementListItem());
						}
						return this.finalize(node, new Node.SwitchCase(test, consequent));
					};
					Parser.prototype.parseSwitchStatement = function() {
						var node = this.createNode();
						this.expectKeyword("switch");
						this.expect("(");
						var discriminant = this.parseExpression();
						this.expect(")");
						var previousInSwitch = this.context.inSwitch;
						this.context.inSwitch = true;
						var cases = [];
						var defaultFound = false;
						this.expect("{");
						while (true) {
							if (this.match("}")) break;
							var clause = this.parseSwitchCase();
							if (clause.test === null) {
								if (defaultFound) this.throwError(messages_1.Messages.MultipleDefaultsInSwitch);
								defaultFound = true;
							}
							cases.push(clause);
						}
						this.expect("}");
						this.context.inSwitch = previousInSwitch;
						return this.finalize(node, new Node.SwitchStatement(discriminant, cases));
					};
					Parser.prototype.parseLabelledStatement = function() {
						var node = this.createNode();
						var expr = this.parseExpression();
						var statement;
						if (expr.type === syntax_1.Syntax.Identifier && this.match(":")) {
							this.nextToken();
							var id = expr;
							var key = "$" + id.name;
							if (Object.prototype.hasOwnProperty.call(this.context.labelSet, key)) this.throwError(messages_1.Messages.Redeclaration, "Label", id.name);
							this.context.labelSet[key] = true;
							var body = void 0;
							if (this.matchKeyword("class")) {
								this.tolerateUnexpectedToken(this.lookahead);
								body = this.parseClassDeclaration();
							} else if (this.matchKeyword("function")) {
								var token = this.lookahead;
								var declaration = this.parseFunctionDeclaration();
								if (this.context.strict) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictFunction);
								else if (declaration.generator) this.tolerateUnexpectedToken(token, messages_1.Messages.GeneratorInLegacyContext);
								body = declaration;
							} else body = this.parseStatement();
							delete this.context.labelSet[key];
							statement = new Node.LabeledStatement(id, body);
						} else {
							this.consumeSemicolon();
							statement = new Node.ExpressionStatement(expr);
						}
						return this.finalize(node, statement);
					};
					Parser.prototype.parseThrowStatement = function() {
						var node = this.createNode();
						this.expectKeyword("throw");
						if (this.hasLineTerminator) this.throwError(messages_1.Messages.NewlineAfterThrow);
						var argument = this.parseExpression();
						this.consumeSemicolon();
						return this.finalize(node, new Node.ThrowStatement(argument));
					};
					Parser.prototype.parseCatchClause = function() {
						var node = this.createNode();
						this.expectKeyword("catch");
						this.expect("(");
						if (this.match(")")) this.throwUnexpectedToken(this.lookahead);
						var params = [];
						var param = this.parsePattern(params);
						var paramMap = {};
						for (var i = 0; i < params.length; i++) {
							var key = "$" + params[i].value;
							if (Object.prototype.hasOwnProperty.call(paramMap, key)) this.tolerateError(messages_1.Messages.DuplicateBinding, params[i].value);
							paramMap[key] = true;
						}
						if (this.context.strict && param.type === syntax_1.Syntax.Identifier) {
							if (this.scanner.isRestrictedWord(param.name)) this.tolerateError(messages_1.Messages.StrictCatchVariable);
						}
						this.expect(")");
						var body = this.parseBlock();
						return this.finalize(node, new Node.CatchClause(param, body));
					};
					Parser.prototype.parseFinallyClause = function() {
						this.expectKeyword("finally");
						return this.parseBlock();
					};
					Parser.prototype.parseTryStatement = function() {
						var node = this.createNode();
						this.expectKeyword("try");
						var block = this.parseBlock();
						var handler = this.matchKeyword("catch") ? this.parseCatchClause() : null;
						var finalizer = this.matchKeyword("finally") ? this.parseFinallyClause() : null;
						if (!handler && !finalizer) this.throwError(messages_1.Messages.NoCatchOrFinally);
						return this.finalize(node, new Node.TryStatement(block, handler, finalizer));
					};
					Parser.prototype.parseDebuggerStatement = function() {
						var node = this.createNode();
						this.expectKeyword("debugger");
						this.consumeSemicolon();
						return this.finalize(node, new Node.DebuggerStatement());
					};
					Parser.prototype.parseStatement = function() {
						var statement;
						switch (this.lookahead.type) {
							case 1:
							case 5:
							case 6:
							case 8:
							case 10:
							case 9:
								statement = this.parseExpressionStatement();
								break;
							case 7:
								var value = this.lookahead.value;
								if (value === "{") statement = this.parseBlock();
								else if (value === "(") statement = this.parseExpressionStatement();
								else if (value === ";") statement = this.parseEmptyStatement();
								else statement = this.parseExpressionStatement();
								break;
							case 3:
								statement = this.matchAsyncFunction() ? this.parseFunctionDeclaration() : this.parseLabelledStatement();
								break;
							case 4:
								switch (this.lookahead.value) {
									case "break":
										statement = this.parseBreakStatement();
										break;
									case "continue":
										statement = this.parseContinueStatement();
										break;
									case "debugger":
										statement = this.parseDebuggerStatement();
										break;
									case "do":
										statement = this.parseDoWhileStatement();
										break;
									case "for":
										statement = this.parseForStatement();
										break;
									case "function":
										statement = this.parseFunctionDeclaration();
										break;
									case "if":
										statement = this.parseIfStatement();
										break;
									case "return":
										statement = this.parseReturnStatement();
										break;
									case "switch":
										statement = this.parseSwitchStatement();
										break;
									case "throw":
										statement = this.parseThrowStatement();
										break;
									case "try":
										statement = this.parseTryStatement();
										break;
									case "var":
										statement = this.parseVariableStatement();
										break;
									case "while":
										statement = this.parseWhileStatement();
										break;
									case "with":
										statement = this.parseWithStatement();
										break;
									default:
										statement = this.parseExpressionStatement();
										break;
								}
								break;
							default: statement = this.throwUnexpectedToken(this.lookahead);
						}
						return statement;
					};
					Parser.prototype.parseFunctionSourceElements = function() {
						var node = this.createNode();
						this.expect("{");
						var body = this.parseDirectivePrologues();
						var previousLabelSet = this.context.labelSet;
						var previousInIteration = this.context.inIteration;
						var previousInSwitch = this.context.inSwitch;
						var previousInFunctionBody = this.context.inFunctionBody;
						this.context.labelSet = {};
						this.context.inIteration = false;
						this.context.inSwitch = false;
						this.context.inFunctionBody = true;
						while (this.lookahead.type !== 2) {
							if (this.match("}")) break;
							body.push(this.parseStatementListItem());
						}
						this.expect("}");
						this.context.labelSet = previousLabelSet;
						this.context.inIteration = previousInIteration;
						this.context.inSwitch = previousInSwitch;
						this.context.inFunctionBody = previousInFunctionBody;
						return this.finalize(node, new Node.BlockStatement(body));
					};
					Parser.prototype.validateParam = function(options, param, name) {
						var key = "$" + name;
						if (this.context.strict) {
							if (this.scanner.isRestrictedWord(name)) {
								options.stricted = param;
								options.message = messages_1.Messages.StrictParamName;
							}
							if (Object.prototype.hasOwnProperty.call(options.paramSet, key)) {
								options.stricted = param;
								options.message = messages_1.Messages.StrictParamDupe;
							}
						} else if (!options.firstRestricted) {
							if (this.scanner.isRestrictedWord(name)) {
								options.firstRestricted = param;
								options.message = messages_1.Messages.StrictParamName;
							} else if (this.scanner.isStrictModeReservedWord(name)) {
								options.firstRestricted = param;
								options.message = messages_1.Messages.StrictReservedWord;
							} else if (Object.prototype.hasOwnProperty.call(options.paramSet, key)) {
								options.stricted = param;
								options.message = messages_1.Messages.StrictParamDupe;
							}
						}
						/* istanbul ignore next */
						if (typeof Object.defineProperty === "function") Object.defineProperty(options.paramSet, key, {
							value: true,
							enumerable: true,
							writable: true,
							configurable: true
						});
						else options.paramSet[key] = true;
					};
					Parser.prototype.parseRestElement = function(params) {
						var node = this.createNode();
						this.expect("...");
						var arg = this.parsePattern(params);
						if (this.match("=")) this.throwError(messages_1.Messages.DefaultRestParameter);
						if (!this.match(")")) this.throwError(messages_1.Messages.ParameterAfterRestParameter);
						return this.finalize(node, new Node.RestElement(arg));
					};
					Parser.prototype.parseFormalParameter = function(options) {
						var params = [];
						var param = this.match("...") ? this.parseRestElement(params) : this.parsePatternWithDefault(params);
						for (var i = 0; i < params.length; i++) this.validateParam(options, params[i], params[i].value);
						options.simple = options.simple && param instanceof Node.Identifier;
						options.params.push(param);
					};
					Parser.prototype.parseFormalParameters = function(firstRestricted) {
						var options = {
							simple: true,
							params: [],
							firstRestricted
						};
						this.expect("(");
						if (!this.match(")")) {
							options.paramSet = {};
							while (this.lookahead.type !== 2) {
								this.parseFormalParameter(options);
								if (this.match(")")) break;
								this.expect(",");
								if (this.match(")")) break;
							}
						}
						this.expect(")");
						return {
							simple: options.simple,
							params: options.params,
							stricted: options.stricted,
							firstRestricted: options.firstRestricted,
							message: options.message
						};
					};
					Parser.prototype.matchAsyncFunction = function() {
						var match = this.matchContextualKeyword("async");
						if (match) {
							var state = this.scanner.saveState();
							this.scanner.scanComments();
							var next = this.scanner.lex();
							this.scanner.restoreState(state);
							match = state.lineNumber === next.lineNumber && next.type === 4 && next.value === "function";
						}
						return match;
					};
					Parser.prototype.parseFunctionDeclaration = function(identifierIsOptional) {
						var node = this.createNode();
						var isAsync = this.matchContextualKeyword("async");
						if (isAsync) this.nextToken();
						this.expectKeyword("function");
						var isGenerator = isAsync ? false : this.match("*");
						if (isGenerator) this.nextToken();
						var message;
						var id = null;
						var firstRestricted = null;
						if (!identifierIsOptional || !this.match("(")) {
							var token = this.lookahead;
							id = this.parseVariableIdentifier();
							if (this.context.strict) {
								if (this.scanner.isRestrictedWord(token.value)) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictFunctionName);
							} else if (this.scanner.isRestrictedWord(token.value)) {
								firstRestricted = token;
								message = messages_1.Messages.StrictFunctionName;
							} else if (this.scanner.isStrictModeReservedWord(token.value)) {
								firstRestricted = token;
								message = messages_1.Messages.StrictReservedWord;
							}
						}
						var previousAllowAwait = this.context.await;
						var previousAllowYield = this.context.allowYield;
						this.context.await = isAsync;
						this.context.allowYield = !isGenerator;
						var formalParameters = this.parseFormalParameters(firstRestricted);
						var params = formalParameters.params;
						var stricted = formalParameters.stricted;
						firstRestricted = formalParameters.firstRestricted;
						if (formalParameters.message) message = formalParameters.message;
						var previousStrict = this.context.strict;
						var previousAllowStrictDirective = this.context.allowStrictDirective;
						this.context.allowStrictDirective = formalParameters.simple;
						var body = this.parseFunctionSourceElements();
						if (this.context.strict && firstRestricted) this.throwUnexpectedToken(firstRestricted, message);
						if (this.context.strict && stricted) this.tolerateUnexpectedToken(stricted, message);
						this.context.strict = previousStrict;
						this.context.allowStrictDirective = previousAllowStrictDirective;
						this.context.await = previousAllowAwait;
						this.context.allowYield = previousAllowYield;
						return isAsync ? this.finalize(node, new Node.AsyncFunctionDeclaration(id, params, body)) : this.finalize(node, new Node.FunctionDeclaration(id, params, body, isGenerator));
					};
					Parser.prototype.parseFunctionExpression = function() {
						var node = this.createNode();
						var isAsync = this.matchContextualKeyword("async");
						if (isAsync) this.nextToken();
						this.expectKeyword("function");
						var isGenerator = isAsync ? false : this.match("*");
						if (isGenerator) this.nextToken();
						var message;
						var id = null;
						var firstRestricted;
						var previousAllowAwait = this.context.await;
						var previousAllowYield = this.context.allowYield;
						this.context.await = isAsync;
						this.context.allowYield = !isGenerator;
						if (!this.match("(")) {
							var token = this.lookahead;
							id = !this.context.strict && !isGenerator && this.matchKeyword("yield") ? this.parseIdentifierName() : this.parseVariableIdentifier();
							if (this.context.strict) {
								if (this.scanner.isRestrictedWord(token.value)) this.tolerateUnexpectedToken(token, messages_1.Messages.StrictFunctionName);
							} else if (this.scanner.isRestrictedWord(token.value)) {
								firstRestricted = token;
								message = messages_1.Messages.StrictFunctionName;
							} else if (this.scanner.isStrictModeReservedWord(token.value)) {
								firstRestricted = token;
								message = messages_1.Messages.StrictReservedWord;
							}
						}
						var formalParameters = this.parseFormalParameters(firstRestricted);
						var params = formalParameters.params;
						var stricted = formalParameters.stricted;
						firstRestricted = formalParameters.firstRestricted;
						if (formalParameters.message) message = formalParameters.message;
						var previousStrict = this.context.strict;
						var previousAllowStrictDirective = this.context.allowStrictDirective;
						this.context.allowStrictDirective = formalParameters.simple;
						var body = this.parseFunctionSourceElements();
						if (this.context.strict && firstRestricted) this.throwUnexpectedToken(firstRestricted, message);
						if (this.context.strict && stricted) this.tolerateUnexpectedToken(stricted, message);
						this.context.strict = previousStrict;
						this.context.allowStrictDirective = previousAllowStrictDirective;
						this.context.await = previousAllowAwait;
						this.context.allowYield = previousAllowYield;
						return isAsync ? this.finalize(node, new Node.AsyncFunctionExpression(id, params, body)) : this.finalize(node, new Node.FunctionExpression(id, params, body, isGenerator));
					};
					Parser.prototype.parseDirective = function() {
						var token = this.lookahead;
						var node = this.createNode();
						var expr = this.parseExpression();
						var directive = expr.type === syntax_1.Syntax.Literal ? this.getTokenRaw(token).slice(1, -1) : null;
						this.consumeSemicolon();
						return this.finalize(node, directive ? new Node.Directive(expr, directive) : new Node.ExpressionStatement(expr));
					};
					Parser.prototype.parseDirectivePrologues = function() {
						var firstRestricted = null;
						var body = [];
						while (true) {
							var token = this.lookahead;
							if (token.type !== 8) break;
							var statement = this.parseDirective();
							body.push(statement);
							var directive = statement.directive;
							if (typeof directive !== "string") break;
							if (directive === "use strict") {
								this.context.strict = true;
								if (firstRestricted) this.tolerateUnexpectedToken(firstRestricted, messages_1.Messages.StrictOctalLiteral);
								if (!this.context.allowStrictDirective) this.tolerateUnexpectedToken(token, messages_1.Messages.IllegalLanguageModeDirective);
							} else if (!firstRestricted && token.octal) firstRestricted = token;
						}
						return body;
					};
					Parser.prototype.qualifiedPropertyName = function(token) {
						switch (token.type) {
							case 3:
							case 8:
							case 1:
							case 5:
							case 6:
							case 4: return true;
							case 7: return token.value === "[";
							default: break;
						}
						return false;
					};
					Parser.prototype.parseGetterMethod = function() {
						var node = this.createNode();
						var isGenerator = false;
						var previousAllowYield = this.context.allowYield;
						this.context.allowYield = !isGenerator;
						var formalParameters = this.parseFormalParameters();
						if (formalParameters.params.length > 0) this.tolerateError(messages_1.Messages.BadGetterArity);
						var method = this.parsePropertyMethod(formalParameters);
						this.context.allowYield = previousAllowYield;
						return this.finalize(node, new Node.FunctionExpression(null, formalParameters.params, method, isGenerator));
					};
					Parser.prototype.parseSetterMethod = function() {
						var node = this.createNode();
						var isGenerator = false;
						var previousAllowYield = this.context.allowYield;
						this.context.allowYield = !isGenerator;
						var formalParameters = this.parseFormalParameters();
						if (formalParameters.params.length !== 1) this.tolerateError(messages_1.Messages.BadSetterArity);
						else if (formalParameters.params[0] instanceof Node.RestElement) this.tolerateError(messages_1.Messages.BadSetterRestParameter);
						var method = this.parsePropertyMethod(formalParameters);
						this.context.allowYield = previousAllowYield;
						return this.finalize(node, new Node.FunctionExpression(null, formalParameters.params, method, isGenerator));
					};
					Parser.prototype.parseGeneratorMethod = function() {
						var node = this.createNode();
						var isGenerator = true;
						var previousAllowYield = this.context.allowYield;
						this.context.allowYield = true;
						var params = this.parseFormalParameters();
						this.context.allowYield = false;
						var method = this.parsePropertyMethod(params);
						this.context.allowYield = previousAllowYield;
						return this.finalize(node, new Node.FunctionExpression(null, params.params, method, isGenerator));
					};
					Parser.prototype.isStartOfExpression = function() {
						var start = true;
						var value = this.lookahead.value;
						switch (this.lookahead.type) {
							case 7:
								start = value === "[" || value === "(" || value === "{" || value === "+" || value === "-" || value === "!" || value === "~" || value === "++" || value === "--" || value === "/" || value === "/=";
								break;
							case 4:
								start = value === "class" || value === "delete" || value === "function" || value === "let" || value === "new" || value === "super" || value === "this" || value === "typeof" || value === "void" || value === "yield";
								break;
							default: break;
						}
						return start;
					};
					Parser.prototype.parseYieldExpression = function() {
						var node = this.createNode();
						this.expectKeyword("yield");
						var argument = null;
						var delegate = false;
						if (!this.hasLineTerminator) {
							var previousAllowYield = this.context.allowYield;
							this.context.allowYield = false;
							delegate = this.match("*");
							if (delegate) {
								this.nextToken();
								argument = this.parseAssignmentExpression();
							} else if (this.isStartOfExpression()) argument = this.parseAssignmentExpression();
							this.context.allowYield = previousAllowYield;
						}
						return this.finalize(node, new Node.YieldExpression(argument, delegate));
					};
					Parser.prototype.parseClassElement = function(hasConstructor) {
						var token = this.lookahead;
						var node = this.createNode();
						var kind = "";
						var key = null;
						var value = null;
						var computed = false;
						var method = false;
						var isStatic = false;
						var isAsync = false;
						if (this.match("*")) this.nextToken();
						else {
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
							if (key.name === "static" && (this.qualifiedPropertyName(this.lookahead) || this.match("*"))) {
								token = this.lookahead;
								isStatic = true;
								computed = this.match("[");
								if (this.match("*")) this.nextToken();
								else key = this.parseObjectPropertyKey();
							}
							if (token.type === 3 && !this.hasLineTerminator && token.value === "async") {
								var punctuator = this.lookahead.value;
								if (punctuator !== ":" && punctuator !== "(" && punctuator !== "*") {
									isAsync = true;
									token = this.lookahead;
									key = this.parseObjectPropertyKey();
									if (token.type === 3 && token.value === "constructor") this.tolerateUnexpectedToken(token, messages_1.Messages.ConstructorIsAsync);
								}
							}
						}
						var lookaheadPropertyKey = this.qualifiedPropertyName(this.lookahead);
						if (token.type === 3) {
							if (token.value === "get" && lookaheadPropertyKey) {
								kind = "get";
								computed = this.match("[");
								key = this.parseObjectPropertyKey();
								this.context.allowYield = false;
								value = this.parseGetterMethod();
							} else if (token.value === "set" && lookaheadPropertyKey) {
								kind = "set";
								computed = this.match("[");
								key = this.parseObjectPropertyKey();
								value = this.parseSetterMethod();
							}
						} else if (token.type === 7 && token.value === "*" && lookaheadPropertyKey) {
							kind = "init";
							computed = this.match("[");
							key = this.parseObjectPropertyKey();
							value = this.parseGeneratorMethod();
							method = true;
						}
						if (!kind && key && this.match("(")) {
							kind = "init";
							value = isAsync ? this.parsePropertyMethodAsyncFunction() : this.parsePropertyMethodFunction();
							method = true;
						}
						if (!kind) this.throwUnexpectedToken(this.lookahead);
						if (kind === "init") kind = "method";
						if (!computed) {
							if (isStatic && this.isPropertyKey(key, "prototype")) this.throwUnexpectedToken(token, messages_1.Messages.StaticPrototype);
							if (!isStatic && this.isPropertyKey(key, "constructor")) {
								if (kind !== "method" || !method || value && value.generator) this.throwUnexpectedToken(token, messages_1.Messages.ConstructorSpecialMethod);
								if (hasConstructor.value) this.throwUnexpectedToken(token, messages_1.Messages.DuplicateConstructor);
								else hasConstructor.value = true;
								kind = "constructor";
							}
						}
						return this.finalize(node, new Node.MethodDefinition(key, computed, value, kind, isStatic));
					};
					Parser.prototype.parseClassElementList = function() {
						var body = [];
						var hasConstructor = { value: false };
						this.expect("{");
						while (!this.match("}")) if (this.match(";")) this.nextToken();
						else body.push(this.parseClassElement(hasConstructor));
						this.expect("}");
						return body;
					};
					Parser.prototype.parseClassBody = function() {
						var node = this.createNode();
						var elementList = this.parseClassElementList();
						return this.finalize(node, new Node.ClassBody(elementList));
					};
					Parser.prototype.parseClassDeclaration = function(identifierIsOptional) {
						var node = this.createNode();
						var previousStrict = this.context.strict;
						this.context.strict = true;
						this.expectKeyword("class");
						var id = identifierIsOptional && this.lookahead.type !== 3 ? null : this.parseVariableIdentifier();
						var superClass = null;
						if (this.matchKeyword("extends")) {
							this.nextToken();
							superClass = this.isolateCoverGrammar(this.parseLeftHandSideExpressionAllowCall);
						}
						var classBody = this.parseClassBody();
						this.context.strict = previousStrict;
						return this.finalize(node, new Node.ClassDeclaration(id, superClass, classBody));
					};
					Parser.prototype.parseClassExpression = function() {
						var node = this.createNode();
						var previousStrict = this.context.strict;
						this.context.strict = true;
						this.expectKeyword("class");
						var id = this.lookahead.type === 3 ? this.parseVariableIdentifier() : null;
						var superClass = null;
						if (this.matchKeyword("extends")) {
							this.nextToken();
							superClass = this.isolateCoverGrammar(this.parseLeftHandSideExpressionAllowCall);
						}
						var classBody = this.parseClassBody();
						this.context.strict = previousStrict;
						return this.finalize(node, new Node.ClassExpression(id, superClass, classBody));
					};
					Parser.prototype.parseModule = function() {
						this.context.strict = true;
						this.context.isModule = true;
						this.scanner.isModule = true;
						var node = this.createNode();
						var body = this.parseDirectivePrologues();
						while (this.lookahead.type !== 2) body.push(this.parseStatementListItem());
						return this.finalize(node, new Node.Module(body));
					};
					Parser.prototype.parseScript = function() {
						var node = this.createNode();
						var body = this.parseDirectivePrologues();
						while (this.lookahead.type !== 2) body.push(this.parseStatementListItem());
						return this.finalize(node, new Node.Script(body));
					};
					Parser.prototype.parseModuleSpecifier = function() {
						var node = this.createNode();
						if (this.lookahead.type !== 8) this.throwError(messages_1.Messages.InvalidModuleSpecifier);
						var token = this.nextToken();
						var raw = this.getTokenRaw(token);
						return this.finalize(node, new Node.Literal(token.value, raw));
					};
					Parser.prototype.parseImportSpecifier = function() {
						var node = this.createNode();
						var imported;
						var local;
						if (this.lookahead.type === 3) {
							imported = this.parseVariableIdentifier();
							local = imported;
							if (this.matchContextualKeyword("as")) {
								this.nextToken();
								local = this.parseVariableIdentifier();
							}
						} else {
							imported = this.parseIdentifierName();
							local = imported;
							if (this.matchContextualKeyword("as")) {
								this.nextToken();
								local = this.parseVariableIdentifier();
							} else this.throwUnexpectedToken(this.nextToken());
						}
						return this.finalize(node, new Node.ImportSpecifier(local, imported));
					};
					Parser.prototype.parseNamedImports = function() {
						this.expect("{");
						var specifiers = [];
						while (!this.match("}")) {
							specifiers.push(this.parseImportSpecifier());
							if (!this.match("}")) this.expect(",");
						}
						this.expect("}");
						return specifiers;
					};
					Parser.prototype.parseImportDefaultSpecifier = function() {
						var node = this.createNode();
						var local = this.parseIdentifierName();
						return this.finalize(node, new Node.ImportDefaultSpecifier(local));
					};
					Parser.prototype.parseImportNamespaceSpecifier = function() {
						var node = this.createNode();
						this.expect("*");
						if (!this.matchContextualKeyword("as")) this.throwError(messages_1.Messages.NoAsAfterImportNamespace);
						this.nextToken();
						var local = this.parseIdentifierName();
						return this.finalize(node, new Node.ImportNamespaceSpecifier(local));
					};
					Parser.prototype.parseImportDeclaration = function() {
						if (this.context.inFunctionBody) this.throwError(messages_1.Messages.IllegalImportDeclaration);
						var node = this.createNode();
						this.expectKeyword("import");
						var src;
						var specifiers = [];
						if (this.lookahead.type === 8) src = this.parseModuleSpecifier();
						else {
							if (this.match("{")) specifiers = specifiers.concat(this.parseNamedImports());
							else if (this.match("*")) specifiers.push(this.parseImportNamespaceSpecifier());
							else if (this.isIdentifierName(this.lookahead) && !this.matchKeyword("default")) {
								specifiers.push(this.parseImportDefaultSpecifier());
								if (this.match(",")) {
									this.nextToken();
									if (this.match("*")) specifiers.push(this.parseImportNamespaceSpecifier());
									else if (this.match("{")) specifiers = specifiers.concat(this.parseNamedImports());
									else this.throwUnexpectedToken(this.lookahead);
								}
							} else this.throwUnexpectedToken(this.nextToken());
							if (!this.matchContextualKeyword("from")) {
								var message = this.lookahead.value ? messages_1.Messages.UnexpectedToken : messages_1.Messages.MissingFromClause;
								this.throwError(message, this.lookahead.value);
							}
							this.nextToken();
							src = this.parseModuleSpecifier();
						}
						this.consumeSemicolon();
						return this.finalize(node, new Node.ImportDeclaration(specifiers, src));
					};
					Parser.prototype.parseExportSpecifier = function() {
						var node = this.createNode();
						var local = this.parseIdentifierName();
						var exported = local;
						if (this.matchContextualKeyword("as")) {
							this.nextToken();
							exported = this.parseIdentifierName();
						}
						return this.finalize(node, new Node.ExportSpecifier(local, exported));
					};
					Parser.prototype.parseExportDeclaration = function() {
						if (this.context.inFunctionBody) this.throwError(messages_1.Messages.IllegalExportDeclaration);
						var node = this.createNode();
						this.expectKeyword("export");
						var exportDeclaration;
						if (this.matchKeyword("default")) {
							this.nextToken();
							if (this.matchKeyword("function")) {
								var declaration = this.parseFunctionDeclaration(true);
								exportDeclaration = this.finalize(node, new Node.ExportDefaultDeclaration(declaration));
							} else if (this.matchKeyword("class")) {
								var declaration = this.parseClassDeclaration(true);
								exportDeclaration = this.finalize(node, new Node.ExportDefaultDeclaration(declaration));
							} else if (this.matchContextualKeyword("async")) {
								var declaration = this.matchAsyncFunction() ? this.parseFunctionDeclaration(true) : this.parseAssignmentExpression();
								exportDeclaration = this.finalize(node, new Node.ExportDefaultDeclaration(declaration));
							} else {
								if (this.matchContextualKeyword("from")) this.throwError(messages_1.Messages.UnexpectedToken, this.lookahead.value);
								var declaration = this.match("{") ? this.parseObjectInitializer() : this.match("[") ? this.parseArrayInitializer() : this.parseAssignmentExpression();
								this.consumeSemicolon();
								exportDeclaration = this.finalize(node, new Node.ExportDefaultDeclaration(declaration));
							}
						} else if (this.match("*")) {
							this.nextToken();
							if (!this.matchContextualKeyword("from")) {
								var message = this.lookahead.value ? messages_1.Messages.UnexpectedToken : messages_1.Messages.MissingFromClause;
								this.throwError(message, this.lookahead.value);
							}
							this.nextToken();
							var src = this.parseModuleSpecifier();
							this.consumeSemicolon();
							exportDeclaration = this.finalize(node, new Node.ExportAllDeclaration(src));
						} else if (this.lookahead.type === 4) {
							var declaration = void 0;
							switch (this.lookahead.value) {
								case "let":
								case "const":
									declaration = this.parseLexicalDeclaration({ inFor: false });
									break;
								case "var":
								case "class":
								case "function":
									declaration = this.parseStatementListItem();
									break;
								default: this.throwUnexpectedToken(this.lookahead);
							}
							exportDeclaration = this.finalize(node, new Node.ExportNamedDeclaration(declaration, [], null));
						} else if (this.matchAsyncFunction()) {
							var declaration = this.parseFunctionDeclaration();
							exportDeclaration = this.finalize(node, new Node.ExportNamedDeclaration(declaration, [], null));
						} else {
							var specifiers = [];
							var source = null;
							var isExportFromIdentifier = false;
							this.expect("{");
							while (!this.match("}")) {
								isExportFromIdentifier = isExportFromIdentifier || this.matchKeyword("default");
								specifiers.push(this.parseExportSpecifier());
								if (!this.match("}")) this.expect(",");
							}
							this.expect("}");
							if (this.matchContextualKeyword("from")) {
								this.nextToken();
								source = this.parseModuleSpecifier();
								this.consumeSemicolon();
							} else if (isExportFromIdentifier) {
								var message = this.lookahead.value ? messages_1.Messages.UnexpectedToken : messages_1.Messages.MissingFromClause;
								this.throwError(message, this.lookahead.value);
							} else this.consumeSemicolon();
							exportDeclaration = this.finalize(node, new Node.ExportNamedDeclaration(null, specifiers, source));
						}
						return exportDeclaration;
					};
					return Parser;
				}();
			},
			function(module$11, exports$10) {
				"use strict";
				Object.defineProperty(exports$10, "__esModule", { value: true });
				function assert(condition, message) {
					/* istanbul ignore if */
					if (!condition) throw new Error("ASSERT: " + message);
				}
				exports$10.assert = assert;
			},
			function(module$12, exports$11) {
				"use strict";
				Object.defineProperty(exports$11, "__esModule", { value: true });
				exports$11.ErrorHandler = function() {
					function ErrorHandler() {
						this.errors = [];
						this.tolerant = false;
					}
					ErrorHandler.prototype.recordError = function(error) {
						this.errors.push(error);
					};
					ErrorHandler.prototype.tolerate = function(error) {
						if (this.tolerant) this.recordError(error);
						else throw error;
					};
					ErrorHandler.prototype.constructError = function(msg, column) {
						var error = new Error(msg);
						try {
							throw error;
						} catch (base) {
							/* istanbul ignore else */
							if (Object.create && Object.defineProperty) {
								error = Object.create(base);
								Object.defineProperty(error, "column", { value: column });
							}
						}
						/* istanbul ignore next */
						return error;
					};
					ErrorHandler.prototype.createError = function(index, line, col, description) {
						var msg = "Line " + line + ": " + description;
						var error = this.constructError(msg, col);
						error.index = index;
						error.lineNumber = line;
						error.description = description;
						return error;
					};
					ErrorHandler.prototype.throwError = function(index, line, col, description) {
						throw this.createError(index, line, col, description);
					};
					ErrorHandler.prototype.tolerateError = function(index, line, col, description) {
						var error = this.createError(index, line, col, description);
						if (this.tolerant) this.recordError(error);
						else throw error;
					};
					return ErrorHandler;
				}();
			},
			function(module$13, exports$12) {
				"use strict";
				Object.defineProperty(exports$12, "__esModule", { value: true });
				exports$12.Messages = {
					BadGetterArity: "Getter must not have any formal parameters",
					BadSetterArity: "Setter must have exactly one formal parameter",
					BadSetterRestParameter: "Setter function argument must not be a rest parameter",
					ConstructorIsAsync: "Class constructor may not be an async method",
					ConstructorSpecialMethod: "Class constructor may not be an accessor",
					DeclarationMissingInitializer: "Missing initializer in %0 declaration",
					DefaultRestParameter: "Unexpected token =",
					DuplicateBinding: "Duplicate binding %0",
					DuplicateConstructor: "A class may only have one constructor",
					DuplicateProtoProperty: "Duplicate __proto__ fields are not allowed in object literals",
					ForInOfLoopInitializer: "%0 loop variable declaration may not have an initializer",
					GeneratorInLegacyContext: "Generator declarations are not allowed in legacy contexts",
					IllegalBreak: "Illegal break statement",
					IllegalContinue: "Illegal continue statement",
					IllegalExportDeclaration: "Unexpected token",
					IllegalImportDeclaration: "Unexpected token",
					IllegalLanguageModeDirective: "Illegal 'use strict' directive in function with non-simple parameter list",
					IllegalReturn: "Illegal return statement",
					InvalidEscapedReservedWord: "Keyword must not contain escaped characters",
					InvalidHexEscapeSequence: "Invalid hexadecimal escape sequence",
					InvalidLHSInAssignment: "Invalid left-hand side in assignment",
					InvalidLHSInForIn: "Invalid left-hand side in for-in",
					InvalidLHSInForLoop: "Invalid left-hand side in for-loop",
					InvalidModuleSpecifier: "Unexpected token",
					InvalidRegExp: "Invalid regular expression",
					LetInLexicalBinding: "let is disallowed as a lexically bound name",
					MissingFromClause: "Unexpected token",
					MultipleDefaultsInSwitch: "More than one default clause in switch statement",
					NewlineAfterThrow: "Illegal newline after throw",
					NoAsAfterImportNamespace: "Unexpected token",
					NoCatchOrFinally: "Missing catch or finally after try",
					ParameterAfterRestParameter: "Rest parameter must be last formal parameter",
					Redeclaration: "%0 '%1' has already been declared",
					StaticPrototype: "Classes may not have static property named prototype",
					StrictCatchVariable: "Catch variable may not be eval or arguments in strict mode",
					StrictDelete: "Delete of an unqualified identifier in strict mode.",
					StrictFunction: "In strict mode code, functions can only be declared at top level or inside a block",
					StrictFunctionName: "Function name may not be eval or arguments in strict mode",
					StrictLHSAssignment: "Assignment to eval or arguments is not allowed in strict mode",
					StrictLHSPostfix: "Postfix increment/decrement may not have eval or arguments operand in strict mode",
					StrictLHSPrefix: "Prefix increment/decrement may not have eval or arguments operand in strict mode",
					StrictModeWith: "Strict mode code may not include a with statement",
					StrictOctalLiteral: "Octal literals are not allowed in strict mode.",
					StrictParamDupe: "Strict mode function may not have duplicate parameter names",
					StrictParamName: "Parameter name eval or arguments is not allowed in strict mode",
					StrictReservedWord: "Use of future reserved word in strict mode",
					StrictVarName: "Variable name may not be eval or arguments in strict mode",
					TemplateOctalLiteral: "Octal literals are not allowed in template strings.",
					UnexpectedEOS: "Unexpected end of input",
					UnexpectedIdentifier: "Unexpected identifier",
					UnexpectedNumber: "Unexpected number",
					UnexpectedReserved: "Unexpected reserved word",
					UnexpectedString: "Unexpected string",
					UnexpectedTemplate: "Unexpected quasi %0",
					UnexpectedToken: "Unexpected token %0",
					UnexpectedTokenIllegal: "Unexpected token ILLEGAL",
					UnknownLabel: "Undefined label '%0'",
					UnterminatedRegExp: "Invalid regular expression: missing /"
				};
			},
			function(module$14, exports$13, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$13, "__esModule", { value: true });
				var assert_1 = __webpack_require__(9);
				var character_1 = __webpack_require__(4);
				var messages_1 = __webpack_require__(11);
				function hexValue(ch) {
					return "0123456789abcdef".indexOf(ch.toLowerCase());
				}
				function octalValue(ch) {
					return "01234567".indexOf(ch);
				}
				exports$13.Scanner = function() {
					function Scanner(code, handler) {
						this.source = code;
						this.errorHandler = handler;
						this.trackComment = false;
						this.isModule = false;
						this.length = code.length;
						this.index = 0;
						this.lineNumber = code.length > 0 ? 1 : 0;
						this.lineStart = 0;
						this.curlyStack = [];
					}
					Scanner.prototype.saveState = function() {
						return {
							index: this.index,
							lineNumber: this.lineNumber,
							lineStart: this.lineStart
						};
					};
					Scanner.prototype.restoreState = function(state) {
						this.index = state.index;
						this.lineNumber = state.lineNumber;
						this.lineStart = state.lineStart;
					};
					Scanner.prototype.eof = function() {
						return this.index >= this.length;
					};
					Scanner.prototype.throwUnexpectedToken = function(message) {
						if (message === void 0) message = messages_1.Messages.UnexpectedTokenIllegal;
						return this.errorHandler.throwError(this.index, this.lineNumber, this.index - this.lineStart + 1, message);
					};
					Scanner.prototype.tolerateUnexpectedToken = function(message) {
						if (message === void 0) message = messages_1.Messages.UnexpectedTokenIllegal;
						this.errorHandler.tolerateError(this.index, this.lineNumber, this.index - this.lineStart + 1, message);
					};
					Scanner.prototype.skipSingleLineComment = function(offset) {
						var comments = [];
						var start, loc;
						if (this.trackComment) {
							comments = [];
							start = this.index - offset;
							loc = {
								start: {
									line: this.lineNumber,
									column: this.index - this.lineStart - offset
								},
								end: {}
							};
						}
						while (!this.eof()) {
							var ch = this.source.charCodeAt(this.index);
							++this.index;
							if (character_1.Character.isLineTerminator(ch)) {
								if (this.trackComment) {
									loc.end = {
										line: this.lineNumber,
										column: this.index - this.lineStart - 1
									};
									var entry = {
										multiLine: false,
										slice: [start + offset, this.index - 1],
										range: [start, this.index - 1],
										loc
									};
									comments.push(entry);
								}
								if (ch === 13 && this.source.charCodeAt(this.index) === 10) ++this.index;
								++this.lineNumber;
								this.lineStart = this.index;
								return comments;
							}
						}
						if (this.trackComment) {
							loc.end = {
								line: this.lineNumber,
								column: this.index - this.lineStart
							};
							var entry = {
								multiLine: false,
								slice: [start + offset, this.index],
								range: [start, this.index],
								loc
							};
							comments.push(entry);
						}
						return comments;
					};
					Scanner.prototype.skipMultiLineComment = function() {
						var comments = [];
						var start, loc;
						if (this.trackComment) {
							comments = [];
							start = this.index - 2;
							loc = {
								start: {
									line: this.lineNumber,
									column: this.index - this.lineStart - 2
								},
								end: {}
							};
						}
						while (!this.eof()) {
							var ch = this.source.charCodeAt(this.index);
							if (character_1.Character.isLineTerminator(ch)) {
								if (ch === 13 && this.source.charCodeAt(this.index + 1) === 10) ++this.index;
								++this.lineNumber;
								++this.index;
								this.lineStart = this.index;
							} else if (ch === 42) {
								if (this.source.charCodeAt(this.index + 1) === 47) {
									this.index += 2;
									if (this.trackComment) {
										loc.end = {
											line: this.lineNumber,
											column: this.index - this.lineStart
										};
										var entry = {
											multiLine: true,
											slice: [start + 2, this.index - 2],
											range: [start, this.index],
											loc
										};
										comments.push(entry);
									}
									return comments;
								}
								++this.index;
							} else ++this.index;
						}
						if (this.trackComment) {
							loc.end = {
								line: this.lineNumber,
								column: this.index - this.lineStart
							};
							var entry = {
								multiLine: true,
								slice: [start + 2, this.index],
								range: [start, this.index],
								loc
							};
							comments.push(entry);
						}
						this.tolerateUnexpectedToken();
						return comments;
					};
					Scanner.prototype.scanComments = function() {
						var comments;
						if (this.trackComment) comments = [];
						var start = this.index === 0;
						while (!this.eof()) {
							var ch = this.source.charCodeAt(this.index);
							if (character_1.Character.isWhiteSpace(ch)) ++this.index;
							else if (character_1.Character.isLineTerminator(ch)) {
								++this.index;
								if (ch === 13 && this.source.charCodeAt(this.index) === 10) ++this.index;
								++this.lineNumber;
								this.lineStart = this.index;
								start = true;
							} else if (ch === 47) {
								ch = this.source.charCodeAt(this.index + 1);
								if (ch === 47) {
									this.index += 2;
									var comment = this.skipSingleLineComment(2);
									if (this.trackComment) comments = comments.concat(comment);
									start = true;
								} else if (ch === 42) {
									this.index += 2;
									var comment = this.skipMultiLineComment();
									if (this.trackComment) comments = comments.concat(comment);
								} else break;
							} else if (start && ch === 45) if (this.source.charCodeAt(this.index + 1) === 45 && this.source.charCodeAt(this.index + 2) === 62) {
								this.index += 3;
								var comment = this.skipSingleLineComment(3);
								if (this.trackComment) comments = comments.concat(comment);
							} else break;
							else if (ch === 60 && !this.isModule) if (this.source.slice(this.index + 1, this.index + 4) === "!--") {
								this.index += 4;
								var comment = this.skipSingleLineComment(4);
								if (this.trackComment) comments = comments.concat(comment);
							} else break;
							else break;
						}
						return comments;
					};
					Scanner.prototype.isFutureReservedWord = function(id) {
						switch (id) {
							case "enum":
							case "export":
							case "import":
							case "super": return true;
							default: return false;
						}
					};
					Scanner.prototype.isStrictModeReservedWord = function(id) {
						switch (id) {
							case "implements":
							case "interface":
							case "package":
							case "private":
							case "protected":
							case "public":
							case "static":
							case "yield":
							case "let": return true;
							default: return false;
						}
					};
					Scanner.prototype.isRestrictedWord = function(id) {
						return id === "eval" || id === "arguments";
					};
					Scanner.prototype.isKeyword = function(id) {
						switch (id.length) {
							case 2: return id === "if" || id === "in" || id === "do";
							case 3: return id === "var" || id === "for" || id === "new" || id === "try" || id === "let";
							case 4: return id === "this" || id === "else" || id === "case" || id === "void" || id === "with" || id === "enum";
							case 5: return id === "while" || id === "break" || id === "catch" || id === "throw" || id === "const" || id === "yield" || id === "class" || id === "super";
							case 6: return id === "return" || id === "typeof" || id === "delete" || id === "switch" || id === "export" || id === "import";
							case 7: return id === "default" || id === "finally" || id === "extends";
							case 8: return id === "function" || id === "continue" || id === "debugger";
							case 10: return id === "instanceof";
							default: return false;
						}
					};
					Scanner.prototype.codePointAt = function(i) {
						var cp = this.source.charCodeAt(i);
						if (cp >= 55296 && cp <= 56319) {
							var second = this.source.charCodeAt(i + 1);
							if (second >= 56320 && second <= 57343) cp = (cp - 55296) * 1024 + second - 56320 + 65536;
						}
						return cp;
					};
					Scanner.prototype.scanHexEscape = function(prefix) {
						var len = prefix === "u" ? 4 : 2;
						var code = 0;
						for (var i = 0; i < len; ++i) if (!this.eof() && character_1.Character.isHexDigit(this.source.charCodeAt(this.index))) code = code * 16 + hexValue(this.source[this.index++]);
						else return null;
						return String.fromCharCode(code);
					};
					Scanner.prototype.scanUnicodeCodePointEscape = function() {
						var ch = this.source[this.index];
						var code = 0;
						if (ch === "}") this.throwUnexpectedToken();
						while (!this.eof()) {
							ch = this.source[this.index++];
							if (!character_1.Character.isHexDigit(ch.charCodeAt(0))) break;
							code = code * 16 + hexValue(ch);
						}
						if (code > 1114111 || ch !== "}") this.throwUnexpectedToken();
						return character_1.Character.fromCodePoint(code);
					};
					Scanner.prototype.getIdentifier = function() {
						var start = this.index++;
						while (!this.eof()) {
							var ch = this.source.charCodeAt(this.index);
							if (ch === 92) {
								this.index = start;
								return this.getComplexIdentifier();
							} else if (ch >= 55296 && ch < 57343) {
								this.index = start;
								return this.getComplexIdentifier();
							}
							if (character_1.Character.isIdentifierPart(ch)) ++this.index;
							else break;
						}
						return this.source.slice(start, this.index);
					};
					Scanner.prototype.getComplexIdentifier = function() {
						var cp = this.codePointAt(this.index);
						var id = character_1.Character.fromCodePoint(cp);
						this.index += id.length;
						var ch;
						if (cp === 92) {
							if (this.source.charCodeAt(this.index) !== 117) this.throwUnexpectedToken();
							++this.index;
							if (this.source[this.index] === "{") {
								++this.index;
								ch = this.scanUnicodeCodePointEscape();
							} else {
								ch = this.scanHexEscape("u");
								if (ch === null || ch === "\\" || !character_1.Character.isIdentifierStart(ch.charCodeAt(0))) this.throwUnexpectedToken();
							}
							id = ch;
						}
						while (!this.eof()) {
							cp = this.codePointAt(this.index);
							if (!character_1.Character.isIdentifierPart(cp)) break;
							ch = character_1.Character.fromCodePoint(cp);
							id += ch;
							this.index += ch.length;
							if (cp === 92) {
								id = id.substr(0, id.length - 1);
								if (this.source.charCodeAt(this.index) !== 117) this.throwUnexpectedToken();
								++this.index;
								if (this.source[this.index] === "{") {
									++this.index;
									ch = this.scanUnicodeCodePointEscape();
								} else {
									ch = this.scanHexEscape("u");
									if (ch === null || ch === "\\" || !character_1.Character.isIdentifierPart(ch.charCodeAt(0))) this.throwUnexpectedToken();
								}
								id += ch;
							}
						}
						return id;
					};
					Scanner.prototype.octalToDecimal = function(ch) {
						var octal = ch !== "0";
						var code = octalValue(ch);
						if (!this.eof() && character_1.Character.isOctalDigit(this.source.charCodeAt(this.index))) {
							octal = true;
							code = code * 8 + octalValue(this.source[this.index++]);
							if ("0123".indexOf(ch) >= 0 && !this.eof() && character_1.Character.isOctalDigit(this.source.charCodeAt(this.index))) code = code * 8 + octalValue(this.source[this.index++]);
						}
						return {
							code,
							octal
						};
					};
					Scanner.prototype.scanIdentifier = function() {
						var type;
						var start = this.index;
						var id = this.source.charCodeAt(start) === 92 ? this.getComplexIdentifier() : this.getIdentifier();
						if (id.length === 1) type = 3;
						else if (this.isKeyword(id)) type = 4;
						else if (id === "null") type = 5;
						else if (id === "true" || id === "false") type = 1;
						else type = 3;
						if (type !== 3 && start + id.length !== this.index) {
							var restore = this.index;
							this.index = start;
							this.tolerateUnexpectedToken(messages_1.Messages.InvalidEscapedReservedWord);
							this.index = restore;
						}
						return {
							type,
							value: id,
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.scanPunctuator = function() {
						var start = this.index;
						var str = this.source[this.index];
						switch (str) {
							case "(":
							case "{":
								if (str === "{") this.curlyStack.push("{");
								++this.index;
								break;
							case ".":
								++this.index;
								if (this.source[this.index] === "." && this.source[this.index + 1] === ".") {
									this.index += 2;
									str = "...";
								}
								break;
							case "}":
								++this.index;
								this.curlyStack.pop();
								break;
							case ")":
							case ";":
							case ",":
							case "[":
							case "]":
							case ":":
							case "?":
							case "~":
								++this.index;
								break;
							default:
								str = this.source.substr(this.index, 4);
								if (str === ">>>=") this.index += 4;
								else {
									str = str.substr(0, 3);
									if (str === "===" || str === "!==" || str === ">>>" || str === "<<=" || str === ">>=" || str === "**=") this.index += 3;
									else {
										str = str.substr(0, 2);
										if (str === "&&" || str === "||" || str === "==" || str === "!=" || str === "+=" || str === "-=" || str === "*=" || str === "/=" || str === "++" || str === "--" || str === "<<" || str === ">>" || str === "&=" || str === "|=" || str === "^=" || str === "%=" || str === "<=" || str === ">=" || str === "=>" || str === "**") this.index += 2;
										else {
											str = this.source[this.index];
											if ("<>=!+-*%&|^/".indexOf(str) >= 0) ++this.index;
										}
									}
								}
						}
						if (this.index === start) this.throwUnexpectedToken();
						return {
							type: 7,
							value: str,
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.scanHexLiteral = function(start) {
						var num = "";
						while (!this.eof()) {
							if (!character_1.Character.isHexDigit(this.source.charCodeAt(this.index))) break;
							num += this.source[this.index++];
						}
						if (num.length === 0) this.throwUnexpectedToken();
						if (character_1.Character.isIdentifierStart(this.source.charCodeAt(this.index))) this.throwUnexpectedToken();
						return {
							type: 6,
							value: parseInt("0x" + num, 16),
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.scanBinaryLiteral = function(start) {
						var num = "";
						var ch;
						while (!this.eof()) {
							ch = this.source[this.index];
							if (ch !== "0" && ch !== "1") break;
							num += this.source[this.index++];
						}
						if (num.length === 0) this.throwUnexpectedToken();
						if (!this.eof()) {
							ch = this.source.charCodeAt(this.index);
							/* istanbul ignore else */
							if (character_1.Character.isIdentifierStart(ch) || character_1.Character.isDecimalDigit(ch)) this.throwUnexpectedToken();
						}
						return {
							type: 6,
							value: parseInt(num, 2),
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.scanOctalLiteral = function(prefix, start) {
						var num = "";
						var octal = false;
						if (character_1.Character.isOctalDigit(prefix.charCodeAt(0))) {
							octal = true;
							num = "0" + this.source[this.index++];
						} else ++this.index;
						while (!this.eof()) {
							if (!character_1.Character.isOctalDigit(this.source.charCodeAt(this.index))) break;
							num += this.source[this.index++];
						}
						if (!octal && num.length === 0) this.throwUnexpectedToken();
						if (character_1.Character.isIdentifierStart(this.source.charCodeAt(this.index)) || character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index))) this.throwUnexpectedToken();
						return {
							type: 6,
							value: parseInt(num, 8),
							octal,
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.isImplicitOctalLiteral = function() {
						for (var i = this.index + 1; i < this.length; ++i) {
							var ch = this.source[i];
							if (ch === "8" || ch === "9") return false;
							if (!character_1.Character.isOctalDigit(ch.charCodeAt(0))) return true;
						}
						return true;
					};
					Scanner.prototype.scanNumericLiteral = function() {
						var start = this.index;
						var ch = this.source[start];
						assert_1.assert(character_1.Character.isDecimalDigit(ch.charCodeAt(0)) || ch === ".", "Numeric literal must start with a decimal digit or a decimal point");
						var num = "";
						if (ch !== ".") {
							num = this.source[this.index++];
							ch = this.source[this.index];
							if (num === "0") {
								if (ch === "x" || ch === "X") {
									++this.index;
									return this.scanHexLiteral(start);
								}
								if (ch === "b" || ch === "B") {
									++this.index;
									return this.scanBinaryLiteral(start);
								}
								if (ch === "o" || ch === "O") return this.scanOctalLiteral(ch, start);
								if (ch && character_1.Character.isOctalDigit(ch.charCodeAt(0))) {
									if (this.isImplicitOctalLiteral()) return this.scanOctalLiteral(ch, start);
								}
							}
							while (character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index))) num += this.source[this.index++];
							ch = this.source[this.index];
						}
						if (ch === ".") {
							num += this.source[this.index++];
							while (character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index))) num += this.source[this.index++];
							ch = this.source[this.index];
						}
						if (ch === "e" || ch === "E") {
							num += this.source[this.index++];
							ch = this.source[this.index];
							if (ch === "+" || ch === "-") num += this.source[this.index++];
							if (character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index))) while (character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index))) num += this.source[this.index++];
							else this.throwUnexpectedToken();
						}
						if (character_1.Character.isIdentifierStart(this.source.charCodeAt(this.index))) this.throwUnexpectedToken();
						return {
							type: 6,
							value: parseFloat(num),
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.scanStringLiteral = function() {
						var start = this.index;
						var quote = this.source[start];
						assert_1.assert(quote === "'" || quote === "\"", "String literal must starts with a quote");
						++this.index;
						var octal = false;
						var str = "";
						while (!this.eof()) {
							var ch = this.source[this.index++];
							if (ch === quote) {
								quote = "";
								break;
							} else if (ch === "\\") {
								ch = this.source[this.index++];
								if (!ch || !character_1.Character.isLineTerminator(ch.charCodeAt(0))) switch (ch) {
									case "u":
										if (this.source[this.index] === "{") {
											++this.index;
											str += this.scanUnicodeCodePointEscape();
										} else {
											var unescaped_1 = this.scanHexEscape(ch);
											if (unescaped_1 === null) this.throwUnexpectedToken();
											str += unescaped_1;
										}
										break;
									case "x":
										var unescaped = this.scanHexEscape(ch);
										if (unescaped === null) this.throwUnexpectedToken(messages_1.Messages.InvalidHexEscapeSequence);
										str += unescaped;
										break;
									case "n":
										str += "\n";
										break;
									case "r":
										str += "\r";
										break;
									case "t":
										str += "	";
										break;
									case "b":
										str += "\b";
										break;
									case "f":
										str += "\f";
										break;
									case "v":
										str += "\v";
										break;
									case "8":
									case "9":
										str += ch;
										this.tolerateUnexpectedToken();
										break;
									default:
										if (ch && character_1.Character.isOctalDigit(ch.charCodeAt(0))) {
											var octToDec = this.octalToDecimal(ch);
											octal = octToDec.octal || octal;
											str += String.fromCharCode(octToDec.code);
										} else str += ch;
										break;
								}
								else {
									++this.lineNumber;
									if (ch === "\r" && this.source[this.index] === "\n") ++this.index;
									this.lineStart = this.index;
								}
							} else if (character_1.Character.isLineTerminator(ch.charCodeAt(0))) break;
							else str += ch;
						}
						if (quote !== "") {
							this.index = start;
							this.throwUnexpectedToken();
						}
						return {
							type: 8,
							value: str,
							octal,
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.scanTemplate = function() {
						var cooked = "";
						var terminated = false;
						var start = this.index;
						var head = this.source[start] === "`";
						var tail = false;
						var rawOffset = 2;
						++this.index;
						while (!this.eof()) {
							var ch = this.source[this.index++];
							if (ch === "`") {
								rawOffset = 1;
								tail = true;
								terminated = true;
								break;
							} else if (ch === "$") {
								if (this.source[this.index] === "{") {
									this.curlyStack.push("${");
									++this.index;
									terminated = true;
									break;
								}
								cooked += ch;
							} else if (ch === "\\") {
								ch = this.source[this.index++];
								if (!character_1.Character.isLineTerminator(ch.charCodeAt(0))) switch (ch) {
									case "n":
										cooked += "\n";
										break;
									case "r":
										cooked += "\r";
										break;
									case "t":
										cooked += "	";
										break;
									case "u":
										if (this.source[this.index] === "{") {
											++this.index;
											cooked += this.scanUnicodeCodePointEscape();
										} else {
											var restore = this.index;
											var unescaped_2 = this.scanHexEscape(ch);
											if (unescaped_2 !== null) cooked += unescaped_2;
											else {
												this.index = restore;
												cooked += ch;
											}
										}
										break;
									case "x":
										var unescaped = this.scanHexEscape(ch);
										if (unescaped === null) this.throwUnexpectedToken(messages_1.Messages.InvalidHexEscapeSequence);
										cooked += unescaped;
										break;
									case "b":
										cooked += "\b";
										break;
									case "f":
										cooked += "\f";
										break;
									case "v":
										cooked += "\v";
										break;
									default:
										if (ch === "0") {
											if (character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index))) this.throwUnexpectedToken(messages_1.Messages.TemplateOctalLiteral);
											cooked += "\0";
										} else if (character_1.Character.isOctalDigit(ch.charCodeAt(0))) this.throwUnexpectedToken(messages_1.Messages.TemplateOctalLiteral);
										else cooked += ch;
										break;
								}
								else {
									++this.lineNumber;
									if (ch === "\r" && this.source[this.index] === "\n") ++this.index;
									this.lineStart = this.index;
								}
							} else if (character_1.Character.isLineTerminator(ch.charCodeAt(0))) {
								++this.lineNumber;
								if (ch === "\r" && this.source[this.index] === "\n") ++this.index;
								this.lineStart = this.index;
								cooked += "\n";
							} else cooked += ch;
						}
						if (!terminated) this.throwUnexpectedToken();
						if (!head) this.curlyStack.pop();
						return {
							type: 10,
							value: this.source.slice(start + 1, this.index - rawOffset),
							cooked,
							head,
							tail,
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.testRegExp = function(pattern, flags) {
						var astralSubstitute = "";
						var tmp = pattern;
						var self = this;
						if (flags.indexOf("u") >= 0) tmp = tmp.replace(/\\u\{([0-9a-fA-F]+)\}|\\u([a-fA-F0-9]{4})/g, function($0, $1, $2) {
							var codePoint = parseInt($1 || $2, 16);
							if (codePoint > 1114111) self.throwUnexpectedToken(messages_1.Messages.InvalidRegExp);
							if (codePoint <= 65535) return String.fromCharCode(codePoint);
							return astralSubstitute;
						}).replace(/[\uD800-\uDBFF][\uDC00-\uDFFF]/g, astralSubstitute);
						try {
							RegExp(tmp);
						} catch (e) {
							this.throwUnexpectedToken(messages_1.Messages.InvalidRegExp);
						}
						try {
							return new RegExp(pattern, flags);
						} catch (exception) {
							/* istanbul ignore next */
							return null;
						}
					};
					Scanner.prototype.scanRegExpBody = function() {
						var ch = this.source[this.index];
						assert_1.assert(ch === "/", "Regular expression literal must start with a slash");
						var str = this.source[this.index++];
						var classMarker = false;
						var terminated = false;
						while (!this.eof()) {
							ch = this.source[this.index++];
							str += ch;
							if (ch === "\\") {
								ch = this.source[this.index++];
								if (character_1.Character.isLineTerminator(ch.charCodeAt(0))) this.throwUnexpectedToken(messages_1.Messages.UnterminatedRegExp);
								str += ch;
							} else if (character_1.Character.isLineTerminator(ch.charCodeAt(0))) this.throwUnexpectedToken(messages_1.Messages.UnterminatedRegExp);
							else if (classMarker) {
								if (ch === "]") classMarker = false;
							} else if (ch === "/") {
								terminated = true;
								break;
							} else if (ch === "[") classMarker = true;
						}
						if (!terminated) this.throwUnexpectedToken(messages_1.Messages.UnterminatedRegExp);
						return str.substr(1, str.length - 2);
					};
					Scanner.prototype.scanRegExpFlags = function() {
						var str = "";
						var flags = "";
						while (!this.eof()) {
							var ch = this.source[this.index];
							if (!character_1.Character.isIdentifierPart(ch.charCodeAt(0))) break;
							++this.index;
							if (ch === "\\" && !this.eof()) {
								ch = this.source[this.index];
								if (ch === "u") {
									++this.index;
									var restore = this.index;
									var char = this.scanHexEscape("u");
									if (char !== null) {
										flags += char;
										for (str += "\\u"; restore < this.index; ++restore) str += this.source[restore];
									} else {
										this.index = restore;
										flags += "u";
										str += "\\u";
									}
									this.tolerateUnexpectedToken();
								} else {
									str += "\\";
									this.tolerateUnexpectedToken();
								}
							} else {
								flags += ch;
								str += ch;
							}
						}
						return flags;
					};
					Scanner.prototype.scanRegExp = function() {
						var start = this.index;
						var pattern = this.scanRegExpBody();
						var flags = this.scanRegExpFlags();
						return {
							type: 9,
							value: "",
							pattern,
							flags,
							regex: this.testRegExp(pattern, flags),
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start,
							end: this.index
						};
					};
					Scanner.prototype.lex = function() {
						if (this.eof()) return {
							type: 2,
							value: "",
							lineNumber: this.lineNumber,
							lineStart: this.lineStart,
							start: this.index,
							end: this.index
						};
						var cp = this.source.charCodeAt(this.index);
						if (character_1.Character.isIdentifierStart(cp)) return this.scanIdentifier();
						if (cp === 40 || cp === 41 || cp === 59) return this.scanPunctuator();
						if (cp === 39 || cp === 34) return this.scanStringLiteral();
						if (cp === 46) {
							if (character_1.Character.isDecimalDigit(this.source.charCodeAt(this.index + 1))) return this.scanNumericLiteral();
							return this.scanPunctuator();
						}
						if (character_1.Character.isDecimalDigit(cp)) return this.scanNumericLiteral();
						if (cp === 96 || cp === 125 && this.curlyStack[this.curlyStack.length - 1] === "${") return this.scanTemplate();
						if (cp >= 55296 && cp < 57343) {
							if (character_1.Character.isIdentifierStart(this.codePointAt(this.index))) return this.scanIdentifier();
						}
						return this.scanPunctuator();
					};
					return Scanner;
				}();
			},
			function(module$15, exports$14) {
				"use strict";
				Object.defineProperty(exports$14, "__esModule", { value: true });
				exports$14.TokenName = {};
				exports$14.TokenName[1] = "Boolean";
				exports$14.TokenName[2] = "<end>";
				exports$14.TokenName[3] = "Identifier";
				exports$14.TokenName[4] = "Keyword";
				exports$14.TokenName[5] = "Null";
				exports$14.TokenName[6] = "Numeric";
				exports$14.TokenName[7] = "Punctuator";
				exports$14.TokenName[8] = "String";
				exports$14.TokenName[9] = "RegularExpression";
				exports$14.TokenName[10] = "Template";
			},
			function(module$16, exports$15) {
				"use strict";
				Object.defineProperty(exports$15, "__esModule", { value: true });
				exports$15.XHTMLEntities = {
					quot: "\"",
					amp: "&",
					apos: "'",
					gt: ">",
					nbsp: "\xA0",
					iexcl: "",
					cent: "",
					pound: "",
					curren: "",
					yen: "",
					brvbar: "",
					sect: "",
					uml: "",
					copy: "",
					ordf: "",
					laquo: "",
					not: "",
					shy: "",
					reg: "",
					macr: "",
					deg: "",
					plusmn: "",
					sup2: "",
					sup3: "",
					acute: "",
					micro: "",
					para: "",
					middot: "",
					cedil: "",
					sup1: "",
					ordm: "",
					raquo: "",
					frac14: "",
					frac12: "",
					frac34: "",
					iquest: "",
					Agrave: "",
					Aacute: "",
					Acirc: "",
					Atilde: "",
					Auml: "",
					Aring: "",
					AElig: "",
					Ccedil: "",
					Egrave: "",
					Eacute: "",
					Ecirc: "",
					Euml: "",
					Igrave: "",
					Iacute: "",
					Icirc: "",
					Iuml: "",
					ETH: "",
					Ntilde: "",
					Ograve: "",
					Oacute: "",
					Ocirc: "",
					Otilde: "",
					Ouml: "",
					times: "",
					Oslash: "",
					Ugrave: "",
					Uacute: "",
					Ucirc: "",
					Uuml: "",
					Yacute: "",
					THORN: "",
					szlig: "",
					agrave: "",
					aacute: "",
					acirc: "",
					atilde: "",
					auml: "",
					aring: "",
					aelig: "",
					ccedil: "",
					egrave: "",
					eacute: "",
					ecirc: "",
					euml: "",
					igrave: "",
					iacute: "",
					icirc: "",
					iuml: "",
					eth: "",
					ntilde: "",
					ograve: "",
					oacute: "",
					ocirc: "",
					otilde: "",
					ouml: "",
					divide: "",
					oslash: "",
					ugrave: "",
					uacute: "",
					ucirc: "",
					uuml: "",
					yacute: "",
					thorn: "",
					yuml: "",
					OElig: "",
					oelig: "",
					Scaron: "",
					scaron: "",
					Yuml: "",
					fnof: "",
					circ: "",
					tilde: "",
					Alpha: "",
					Beta: "",
					Gamma: "",
					Delta: "",
					Epsilon: "",
					Zeta: "",
					Eta: "",
					Theta: "",
					Iota: "",
					Kappa: "",
					Lambda: "",
					Mu: "",
					Nu: "",
					Xi: "",
					Omicron: "",
					Pi: "",
					Rho: "",
					Sigma: "",
					Tau: "",
					Upsilon: "",
					Phi: "",
					Chi: "",
					Psi: "",
					Omega: "",
					alpha: "",
					beta: "",
					gamma: "",
					delta: "",
					epsilon: "",
					zeta: "",
					eta: "",
					theta: "",
					iota: "",
					kappa: "",
					lambda: "",
					mu: "",
					nu: "",
					xi: "",
					omicron: "",
					pi: "",
					rho: "",
					sigmaf: "",
					sigma: "",
					tau: "",
					upsilon: "",
					phi: "",
					chi: "",
					psi: "",
					omega: "",
					thetasym: "",
					upsih: "",
					piv: "",
					ensp: "",
					emsp: "",
					thinsp: "",
					zwnj: "",
					zwj: "",
					lrm: "",
					rlm: "",
					ndash: "",
					mdash: "",
					lsquo: "",
					rsquo: "",
					sbquo: "",
					ldquo: "",
					rdquo: "",
					bdquo: "",
					dagger: "",
					Dagger: "",
					bull: "",
					hellip: "",
					permil: "",
					prime: "",
					Prime: "",
					lsaquo: "",
					rsaquo: "",
					oline: "",
					frasl: "",
					euro: "",
					image: "",
					weierp: "",
					real: "",
					trade: "",
					alefsym: "",
					larr: "",
					uarr: "",
					rarr: "",
					darr: "",
					harr: "",
					crarr: "",
					lArr: "",
					uArr: "",
					rArr: "",
					dArr: "",
					hArr: "",
					forall: "",
					part: "",
					exist: "",
					empty: "",
					nabla: "",
					isin: "",
					notin: "",
					ni: "",
					prod: "",
					sum: "",
					minus: "",
					lowast: "",
					radic: "",
					prop: "",
					infin: "",
					ang: "",
					and: "",
					or: "",
					cap: "",
					cup: "",
					int: "",
					there4: "",
					sim: "",
					cong: "",
					asymp: "",
					ne: "",
					equiv: "",
					le: "",
					ge: "",
					sub: "",
					sup: "",
					nsub: "",
					sube: "",
					supe: "",
					oplus: "",
					otimes: "",
					perp: "",
					sdot: "",
					lceil: "",
					rceil: "",
					lfloor: "",
					rfloor: "",
					loz: "",
					spades: "",
					clubs: "",
					hearts: "",
					diams: "",
					lang: "",
					rang: ""
				};
			},
			function(module$17, exports$16, __webpack_require__) {
				"use strict";
				Object.defineProperty(exports$16, "__esModule", { value: true });
				var error_handler_1 = __webpack_require__(10);
				var scanner_1 = __webpack_require__(12);
				var token_1 = __webpack_require__(13);
				var Reader = function() {
					function Reader() {
						this.values = [];
						this.curly = this.paren = -1;
					}
					Reader.prototype.beforeFunctionExpression = function(t) {
						return [
							"(",
							"{",
							"[",
							"in",
							"typeof",
							"instanceof",
							"new",
							"return",
							"case",
							"delete",
							"throw",
							"void",
							"=",
							"+=",
							"-=",
							"*=",
							"**=",
							"/=",
							"%=",
							"<<=",
							">>=",
							">>>=",
							"&=",
							"|=",
							"^=",
							",",
							"+",
							"-",
							"*",
							"**",
							"/",
							"%",
							"++",
							"--",
							"<<",
							">>",
							">>>",
							"&",
							"|",
							"^",
							"!",
							"~",
							"&&",
							"||",
							"?",
							":",
							"===",
							"==",
							">=",
							"<=",
							"<",
							">",
							"!=",
							"!=="
						].indexOf(t) >= 0;
					};
					Reader.prototype.isRegexStart = function() {
						var previous = this.values[this.values.length - 1];
						var regex = previous !== null;
						switch (previous) {
							case "this":
							case "]":
								regex = false;
								break;
							case ")":
								var keyword = this.values[this.paren - 1];
								regex = keyword === "if" || keyword === "while" || keyword === "for" || keyword === "with";
								break;
							case "}":
								regex = false;
								if (this.values[this.curly - 3] === "function") {
									var check = this.values[this.curly - 4];
									regex = check ? !this.beforeFunctionExpression(check) : false;
								} else if (this.values[this.curly - 4] === "function") {
									var check = this.values[this.curly - 5];
									regex = check ? !this.beforeFunctionExpression(check) : true;
								}
								break;
							default: break;
						}
						return regex;
					};
					Reader.prototype.push = function(token) {
						if (token.type === 7 || token.type === 4) {
							if (token.value === "{") this.curly = this.values.length;
							else if (token.value === "(") this.paren = this.values.length;
							this.values.push(token.value);
						} else this.values.push(null);
					};
					return Reader;
				}();
				exports$16.Tokenizer = function() {
					function Tokenizer(code, config) {
						this.errorHandler = new error_handler_1.ErrorHandler();
						this.errorHandler.tolerant = config ? typeof config.tolerant === "boolean" && config.tolerant : false;
						this.scanner = new scanner_1.Scanner(code, this.errorHandler);
						this.scanner.trackComment = config ? typeof config.comment === "boolean" && config.comment : false;
						this.trackRange = config ? typeof config.range === "boolean" && config.range : false;
						this.trackLoc = config ? typeof config.loc === "boolean" && config.loc : false;
						this.buffer = [];
						this.reader = new Reader();
					}
					Tokenizer.prototype.errors = function() {
						return this.errorHandler.errors;
					};
					Tokenizer.prototype.getNextToken = function() {
						if (this.buffer.length === 0) {
							var comments = this.scanner.scanComments();
							if (this.scanner.trackComment) for (var i = 0; i < comments.length; ++i) {
								var e = comments[i];
								var value = this.scanner.source.slice(e.slice[0], e.slice[1]);
								var comment = {
									type: e.multiLine ? "BlockComment" : "LineComment",
									value
								};
								if (this.trackRange) comment.range = e.range;
								if (this.trackLoc) comment.loc = e.loc;
								this.buffer.push(comment);
							}
							if (!this.scanner.eof()) {
								var loc = void 0;
								if (this.trackLoc) loc = {
									start: {
										line: this.scanner.lineNumber,
										column: this.scanner.index - this.scanner.lineStart
									},
									end: {}
								};
								var token = this.scanner.source[this.scanner.index] === "/" && this.reader.isRegexStart() ? this.scanner.scanRegExp() : this.scanner.lex();
								this.reader.push(token);
								var entry = {
									type: token_1.TokenName[token.type],
									value: this.scanner.source.slice(token.start, token.end)
								};
								if (this.trackRange) entry.range = [token.start, token.end];
								if (this.trackLoc) {
									loc.end = {
										line: this.scanner.lineNumber,
										column: this.scanner.index - this.scanner.lineStart
									};
									entry.loc = loc;
								}
								if (token.type === 9) entry.regex = {
									pattern: token.pattern,
									flags: token.flags
								};
								this.buffer.push(entry);
							}
						}
						return this.buffer.shift();
					};
					return Tokenizer;
				}();
			}
		]);
	});
}));

//#endregion
//#region ../node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js
var require_util = /* @__PURE__ */ __commonJSMin(((exports) => {
	function isArray(arg) {
		if (Array.isArray) return Array.isArray(arg);
		return objectToString(arg) === "[object Array]";
	}
	exports.isArray = isArray;
	function isBoolean(arg) {
		return typeof arg === "boolean";
	}
	exports.isBoolean = isBoolean;
	function isNull(arg) {
		return arg === null;
	}
	exports.isNull = isNull;
	function isNullOrUndefined(arg) {
		return arg == null;
	}
	exports.isNullOrUndefined = isNullOrUndefined;
	function isNumber(arg) {
		return typeof arg === "number";
	}
	exports.isNumber = isNumber;
	function isString(arg) {
		return typeof arg === "string";
	}
	exports.isString = isString;
	function isSymbol(arg) {
		return typeof arg === "symbol";
	}
	exports.isSymbol = isSymbol;
	function isUndefined(arg) {
		return arg === void 0;
	}
	exports.isUndefined = isUndefined;
	function isRegExp(re) {
		return objectToString(re) === "[object RegExp]";
	}
	exports.isRegExp = isRegExp;
	function isObject(arg) {
		return typeof arg === "object" && arg !== null;
	}
	exports.isObject = isObject;
	function isDate(d) {
		return objectToString(d) === "[object Date]";
	}
	exports.isDate = isDate;
	function isError(e) {
		return objectToString(e) === "[object Error]" || e instanceof Error;
	}
	exports.isError = isError;
	function isFunction(arg) {
		return typeof arg === "function";
	}
	exports.isFunction = isFunction;
	function isPrimitive(arg) {
		return arg === null || typeof arg === "boolean" || typeof arg === "number" || typeof arg === "string" || typeof arg === "symbol" || typeof arg === "undefined";
	}
	exports.isPrimitive = isPrimitive;
	exports.isBuffer = __require$1("buffer").Buffer.isBuffer;
	function objectToString(o) {
		return Object.prototype.toString.call(o);
	}
}));

//#endregion
//#region ../node_modules/.pnpm/array-timsort@1.0.3/node_modules/array-timsort/src/index.js
var require_src$1 = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	/**
	* Default minimum size of a run.
	*/
	const DEFAULT_MIN_MERGE = 32;
	/**
	* Minimum ordered subsequece required to do galloping.
	*/
	const DEFAULT_MIN_GALLOPING = 7;
	/**
	* Default tmp storage length. Can increase depending on the size of the
	* smallest run to merge.
	*/
	const DEFAULT_TMP_STORAGE_LENGTH = 256;
	/**
	* Pre-computed powers of 10 for efficient lexicographic comparison of
	* small integers.
	*/
	const POWERS_OF_TEN = [
		1,
		10,
		100,
		1e3,
		1e4,
		1e5,
		1e6,
		1e7,
		1e8,
		1e9
	];
	let results;
	/**
	* Estimate the logarithm base 10 of a small integer.
	*
	* @param {number} x - The integer to estimate the logarithm of.
	* @return {number} - The estimated logarithm of the integer.
	*/
	const log10 = (x) => x < 1e5 ? x < 100 ? x < 10 ? 0 : 1 : x < 1e4 ? x < 1e3 ? 2 : 3 : 4 : x < 1e7 ? x < 1e6 ? 5 : 6 : x < 1e9 ? x < 1e8 ? 7 : 8 : 9;
	/**
	* Default alphabetical comparison of items.
	*
	* @param {string|object|number} a - First element to compare.
	* @param {string|object|number} b - Second element to compare.
	* @return {number} - A positive number if a.toString() > b.toString(), a
	* negative number if .toString() < b.toString(), 0 otherwise.
	*/
	function alphabeticalCompare(a, b) {
		if (a === b) return 0;
		if (~~a === a && ~~b === b) {
			if (a === 0 || b === 0) return a < b ? -1 : 1;
			if (a < 0 || b < 0) {
				if (b >= 0) return -1;
				if (a >= 0) return 1;
				a = -a;
				b = -b;
			}
			const al = log10(a);
			const bl = log10(b);
			let t = 0;
			if (al < bl) {
				a *= POWERS_OF_TEN[bl - al - 1];
				b /= 10;
				t = -1;
			} else if (al > bl) {
				b *= POWERS_OF_TEN[al - bl - 1];
				a /= 10;
				t = 1;
			}
			if (a === b) return t;
			return a < b ? -1 : 1;
		}
		const aStr = String(a);
		const bStr = String(b);
		if (aStr === bStr) return 0;
		return aStr < bStr ? -1 : 1;
	}
	/**
	* Compute minimum run length for TimSort
	*
	* @param {number} n - The size of the array to sort.
	*/
	function minRunLength(n) {
		let r = 0;
		while (n >= DEFAULT_MIN_MERGE) {
			r |= n & 1;
			n >>= 1;
		}
		return n + r;
	}
	/**
	* Counts the length of a monotonically ascending or strictly monotonically
	* descending sequence (run) starting at array[lo] in the range [lo, hi). If
	* the run is descending it is made ascending.
	*
	* @param {array} array - The array to reverse.
	* @param {number} lo - First element in the range (inclusive).
	* @param {number} hi - Last element in the range.
	* @param {function} compare - Item comparison function.
	* @return {number} - The length of the run.
	*/
	function makeAscendingRun(array, lo, hi, compare) {
		let runHi = lo + 1;
		if (runHi === hi) return 1;
		if (compare(array[runHi++], array[lo]) < 0) {
			while (runHi < hi && compare(array[runHi], array[runHi - 1]) < 0) runHi++;
			reverseRun(array, lo, runHi);
			reverseRun(results, lo, runHi);
		} else while (runHi < hi && compare(array[runHi], array[runHi - 1]) >= 0) runHi++;
		return runHi - lo;
	}
	/**
	* Reverse an array in the range [lo, hi).
	*
	* @param {array} array - The array to reverse.
	* @param {number} lo - First element in the range (inclusive).
	* @param {number} hi - Last element in the range.
	*/
	function reverseRun(array, lo, hi) {
		hi--;
		while (lo < hi) {
			const t = array[lo];
			array[lo++] = array[hi];
			array[hi--] = t;
		}
	}
	/**
	* Perform the binary sort of the array in the range [lo, hi) where start is
	* the first element possibly out of order.
	*
	* @param {array} array - The array to sort.
	* @param {number} lo - First element in the range (inclusive).
	* @param {number} hi - Last element in the range.
	* @param {number} start - First element possibly out of order.
	* @param {function} compare - Item comparison function.
	*/
	function binaryInsertionSort(array, lo, hi, start, compare) {
		if (start === lo) start++;
		for (; start < hi; start++) {
			const pivot = array[start];
			const pivotIndex = results[start];
			let left = lo;
			let right = start;
			while (left < right) {
				const mid = left + right >>> 1;
				if (compare(pivot, array[mid]) < 0) right = mid;
				else left = mid + 1;
			}
			let n = start - left;
			switch (n) {
				case 3:
					array[left + 3] = array[left + 2];
					results[left + 3] = results[left + 2];
				case 2:
					array[left + 2] = array[left + 1];
					results[left + 2] = results[left + 1];
				case 1:
					array[left + 1] = array[left];
					results[left + 1] = results[left];
					break;
				default: while (n > 0) {
					array[left + n] = array[left + n - 1];
					results[left + n] = results[left + n - 1];
					n--;
				}
			}
			array[left] = pivot;
			results[left] = pivotIndex;
		}
	}
	/**
	* Find the position at which to insert a value in a sorted range. If the range
	* contains elements equal to the value the leftmost element index is returned
	* (for stability).
	*
	* @param {number} value - Value to insert.
	* @param {array} array - The array in which to insert value.
	* @param {number} start - First element in the range.
	* @param {number} length - Length of the range.
	* @param {number} hint - The index at which to begin the search.
	* @param {function} compare - Item comparison function.
	* @return {number} - The index where to insert value.
	*/
	function gallopLeft(value, array, start, length, hint, compare) {
		let lastOffset = 0;
		let maxOffset = 0;
		let offset = 1;
		if (compare(value, array[start + hint]) > 0) {
			maxOffset = length - hint;
			while (offset < maxOffset && compare(value, array[start + hint + offset]) > 0) {
				lastOffset = offset;
				offset = (offset << 1) + 1;
				if (offset <= 0) offset = maxOffset;
			}
			if (offset > maxOffset) offset = maxOffset;
			lastOffset += hint;
			offset += hint;
		} else {
			maxOffset = hint + 1;
			while (offset < maxOffset && compare(value, array[start + hint - offset]) <= 0) {
				lastOffset = offset;
				offset = (offset << 1) + 1;
				if (offset <= 0) offset = maxOffset;
			}
			if (offset > maxOffset) offset = maxOffset;
			const tmp = lastOffset;
			lastOffset = hint - offset;
			offset = hint - tmp;
		}
		lastOffset++;
		while (lastOffset < offset) {
			const m = lastOffset + (offset - lastOffset >>> 1);
			if (compare(value, array[start + m]) > 0) lastOffset = m + 1;
			else offset = m;
		}
		return offset;
	}
	/**
	* Find the position at which to insert a value in a sorted range. If the range
	* contains elements equal to the value the rightmost element index is returned
	* (for stability).
	*
	* @param {number} value - Value to insert.
	* @param {array} array - The array in which to insert value.
	* @param {number} start - First element in the range.
	* @param {number} length - Length of the range.
	* @param {number} hint - The index at which to begin the search.
	* @param {function} compare - Item comparison function.
	* @return {number} - The index where to insert value.
	*/
	function gallopRight(value, array, start, length, hint, compare) {
		let lastOffset = 0;
		let maxOffset = 0;
		let offset = 1;
		if (compare(value, array[start + hint]) < 0) {
			maxOffset = hint + 1;
			while (offset < maxOffset && compare(value, array[start + hint - offset]) < 0) {
				lastOffset = offset;
				offset = (offset << 1) + 1;
				if (offset <= 0) offset = maxOffset;
			}
			if (offset > maxOffset) offset = maxOffset;
			const tmp = lastOffset;
			lastOffset = hint - offset;
			offset = hint - tmp;
		} else {
			maxOffset = length - hint;
			while (offset < maxOffset && compare(value, array[start + hint + offset]) >= 0) {
				lastOffset = offset;
				offset = (offset << 1) + 1;
				if (offset <= 0) offset = maxOffset;
			}
			if (offset > maxOffset) offset = maxOffset;
			lastOffset += hint;
			offset += hint;
		}
		lastOffset++;
		while (lastOffset < offset) {
			const m = lastOffset + (offset - lastOffset >>> 1);
			if (compare(value, array[start + m]) < 0) offset = m;
			else lastOffset = m + 1;
		}
		return offset;
	}
	var TimSort = class {
		constructor(array, compare) {
			this.array = array;
			this.compare = compare;
			const { length } = array;
			this.length = length;
			this.minGallop = DEFAULT_MIN_GALLOPING;
			this.tmpStorageLength = length < 2 * DEFAULT_TMP_STORAGE_LENGTH ? length >>> 1 : DEFAULT_TMP_STORAGE_LENGTH;
			this.tmp = new Array(this.tmpStorageLength);
			this.tmpIndex = new Array(this.tmpStorageLength);
			this.stackLength = length < 120 ? 5 : length < 1542 ? 10 : length < 119151 ? 19 : 40;
			this.runStart = new Array(this.stackLength);
			this.runLength = new Array(this.stackLength);
			this.stackSize = 0;
		}
		/**
		* Push a new run on TimSort's stack.
		*
		* @param {number} runStart - Start index of the run in the original array.
		* @param {number} runLength - Length of the run;
		*/
		pushRun(runStart, runLength) {
			this.runStart[this.stackSize] = runStart;
			this.runLength[this.stackSize] = runLength;
			this.stackSize += 1;
		}
		/**
		* Merge runs on TimSort's stack so that the following holds for all i:
		* 1) runLength[i - 3] > runLength[i - 2] + runLength[i - 1]
		* 2) runLength[i - 2] > runLength[i - 1]
		*/
		mergeRuns() {
			while (this.stackSize > 1) {
				let n = this.stackSize - 2;
				if (n >= 1 && this.runLength[n - 1] <= this.runLength[n] + this.runLength[n + 1] || n >= 2 && this.runLength[n - 2] <= this.runLength[n] + this.runLength[n - 1]) {
					if (this.runLength[n - 1] < this.runLength[n + 1]) n--;
				} else if (this.runLength[n] > this.runLength[n + 1]) break;
				this.mergeAt(n);
			}
		}
		/**
		* Merge all runs on TimSort's stack until only one remains.
		*/
		forceMergeRuns() {
			while (this.stackSize > 1) {
				let n = this.stackSize - 2;
				if (n > 0 && this.runLength[n - 1] < this.runLength[n + 1]) n--;
				this.mergeAt(n);
			}
		}
		/**
		* Merge the runs on the stack at positions i and i+1. Must be always be called
		* with i=stackSize-2 or i=stackSize-3 (that is, we merge on top of the stack).
		*
		* @param {number} i - Index of the run to merge in TimSort's stack.
		*/
		mergeAt(i) {
			const { compare } = this;
			const { array } = this;
			let start1 = this.runStart[i];
			let length1 = this.runLength[i];
			const start2 = this.runStart[i + 1];
			let length2 = this.runLength[i + 1];
			this.runLength[i] = length1 + length2;
			if (i === this.stackSize - 3) {
				this.runStart[i + 1] = this.runStart[i + 2];
				this.runLength[i + 1] = this.runLength[i + 2];
			}
			this.stackSize--;
			const k = gallopRight(array[start2], array, start1, length1, 0, compare);
			start1 += k;
			length1 -= k;
			if (length1 === 0) return;
			length2 = gallopLeft(array[start1 + length1 - 1], array, start2, length2, length2 - 1, compare);
			if (length2 === 0) return;
			if (length1 <= length2) this.mergeLow(start1, length1, start2, length2);
			else this.mergeHigh(start1, length1, start2, length2);
		}
		/**
		* Merge two adjacent runs in a stable way. The runs must be such that the
		* first element of run1 is bigger than the first element in run2 and the
		* last element of run1 is greater than all the elements in run2.
		* The method should be called when run1.length <= run2.length as it uses
		* TimSort temporary array to store run1. Use mergeHigh if run1.length >
		* run2.length.
		*
		* @param {number} start1 - First element in run1.
		* @param {number} length1 - Length of run1.
		* @param {number} start2 - First element in run2.
		* @param {number} length2 - Length of run2.
		*/
		mergeLow(start1, length1, start2, length2) {
			const { compare } = this;
			const { array } = this;
			const { tmp } = this;
			const { tmpIndex } = this;
			let i = 0;
			for (i = 0; i < length1; i++) {
				tmp[i] = array[start1 + i];
				tmpIndex[i] = results[start1 + i];
			}
			let cursor1 = 0;
			let cursor2 = start2;
			let dest = start1;
			array[dest] = array[cursor2];
			results[dest] = results[cursor2];
			dest++;
			cursor2++;
			if (--length2 === 0) {
				for (i = 0; i < length1; i++) {
					array[dest + i] = tmp[cursor1 + i];
					results[dest + i] = tmpIndex[cursor1 + i];
				}
				return;
			}
			if (length1 === 1) {
				for (i = 0; i < length2; i++) {
					array[dest + i] = array[cursor2 + i];
					results[dest + i] = results[cursor2 + i];
				}
				array[dest + length2] = tmp[cursor1];
				results[dest + length2] = tmpIndex[cursor1];
				return;
			}
			let { minGallop } = this;
			while (true) {
				let count1 = 0;
				let count2 = 0;
				let exit = false;
				do
					if (compare(array[cursor2], tmp[cursor1]) < 0) {
						array[dest] = array[cursor2];
						results[dest] = results[cursor2];
						dest++;
						cursor2++;
						count2++;
						count1 = 0;
						if (--length2 === 0) {
							exit = true;
							break;
						}
					} else {
						array[dest] = tmp[cursor1];
						results[dest] = tmpIndex[cursor1];
						dest++;
						cursor1++;
						count1++;
						count2 = 0;
						if (--length1 === 1) {
							exit = true;
							break;
						}
					}
				while ((count1 | count2) < minGallop);
				if (exit) break;
				do {
					count1 = gallopRight(array[cursor2], tmp, cursor1, length1, 0, compare);
					if (count1 !== 0) {
						for (i = 0; i < count1; i++) {
							array[dest + i] = tmp[cursor1 + i];
							results[dest + i] = tmpIndex[cursor1 + i];
						}
						dest += count1;
						cursor1 += count1;
						length1 -= count1;
						if (length1 <= 1) {
							exit = true;
							break;
						}
					}
					array[dest] = array[cursor2];
					results[dest] = results[cursor2];
					dest++;
					cursor2++;
					if (--length2 === 0) {
						exit = true;
						break;
					}
					count2 = gallopLeft(tmp[cursor1], array, cursor2, length2, 0, compare);
					if (count2 !== 0) {
						for (i = 0; i < count2; i++) {
							array[dest + i] = array[cursor2 + i];
							results[dest + i] = results[cursor2 + i];
						}
						dest += count2;
						cursor2 += count2;
						length2 -= count2;
						if (length2 === 0) {
							exit = true;
							break;
						}
					}
					array[dest] = tmp[cursor1];
					results[dest] = tmpIndex[cursor1];
					dest++;
					cursor1++;
					if (--length1 === 1) {
						exit = true;
						break;
					}
					minGallop--;
				} while (count1 >= DEFAULT_MIN_GALLOPING || count2 >= DEFAULT_MIN_GALLOPING);
				if (exit) break;
				if (minGallop < 0) minGallop = 0;
				minGallop += 2;
			}
			this.minGallop = minGallop;
			if (minGallop < 1) this.minGallop = 1;
			if (length1 === 1) {
				for (i = 0; i < length2; i++) {
					array[dest + i] = array[cursor2 + i];
					results[dest + i] = results[cursor2 + i];
				}
				array[dest + length2] = tmp[cursor1];
				results[dest + length2] = tmpIndex[cursor1];
			} else if (length1 === 0) throw new Error("mergeLow preconditions were not respected");
			else for (i = 0; i < length1; i++) {
				array[dest + i] = tmp[cursor1 + i];
				results[dest + i] = tmpIndex[cursor1 + i];
			}
		}
		/**
		* Merge two adjacent runs in a stable way. The runs must be such that the
		* first element of run1 is bigger than the first element in run2 and the
		* last element of run1 is greater than all the elements in run2.
		* The method should be called when run1.length > run2.length as it uses
		* TimSort temporary array to store run2. Use mergeLow if run1.length <=
		* run2.length.
		*
		* @param {number} start1 - First element in run1.
		* @param {number} length1 - Length of run1.
		* @param {number} start2 - First element in run2.
		* @param {number} length2 - Length of run2.
		*/
		mergeHigh(start1, length1, start2, length2) {
			const { compare } = this;
			const { array } = this;
			const { tmp } = this;
			const { tmpIndex } = this;
			let i = 0;
			for (i = 0; i < length2; i++) {
				tmp[i] = array[start2 + i];
				tmpIndex[i] = results[start2 + i];
			}
			let cursor1 = start1 + length1 - 1;
			let cursor2 = length2 - 1;
			let dest = start2 + length2 - 1;
			let customCursor = 0;
			let customDest = 0;
			array[dest] = array[cursor1];
			results[dest] = results[cursor1];
			dest--;
			cursor1--;
			if (--length1 === 0) {
				customCursor = dest - (length2 - 1);
				for (i = 0; i < length2; i++) {
					array[customCursor + i] = tmp[i];
					results[customCursor + i] = tmpIndex[i];
				}
				return;
			}
			if (length2 === 1) {
				dest -= length1;
				cursor1 -= length1;
				customDest = dest + 1;
				customCursor = cursor1 + 1;
				for (i = length1 - 1; i >= 0; i--) {
					array[customDest + i] = array[customCursor + i];
					results[customDest + i] = results[customCursor + i];
				}
				array[dest] = tmp[cursor2];
				results[dest] = tmpIndex[cursor2];
				return;
			}
			let { minGallop } = this;
			while (true) {
				let count1 = 0;
				let count2 = 0;
				let exit = false;
				do
					if (compare(tmp[cursor2], array[cursor1]) < 0) {
						array[dest] = array[cursor1];
						results[dest] = results[cursor1];
						dest--;
						cursor1--;
						count1++;
						count2 = 0;
						if (--length1 === 0) {
							exit = true;
							break;
						}
					} else {
						array[dest] = tmp[cursor2];
						results[dest] = tmpIndex[cursor2];
						dest--;
						cursor2--;
						count2++;
						count1 = 0;
						if (--length2 === 1) {
							exit = true;
							break;
						}
					}
				while ((count1 | count2) < minGallop);
				if (exit) break;
				do {
					count1 = length1 - gallopRight(tmp[cursor2], array, start1, length1, length1 - 1, compare);
					if (count1 !== 0) {
						dest -= count1;
						cursor1 -= count1;
						length1 -= count1;
						customDest = dest + 1;
						customCursor = cursor1 + 1;
						for (i = count1 - 1; i >= 0; i--) {
							array[customDest + i] = array[customCursor + i];
							results[customDest + i] = results[customCursor + i];
						}
						if (length1 === 0) {
							exit = true;
							break;
						}
					}
					array[dest] = tmp[cursor2];
					results[dest] = tmpIndex[cursor2];
					dest--;
					cursor2--;
					if (--length2 === 1) {
						exit = true;
						break;
					}
					count2 = length2 - gallopLeft(array[cursor1], tmp, 0, length2, length2 - 1, compare);
					if (count2 !== 0) {
						dest -= count2;
						cursor2 -= count2;
						length2 -= count2;
						customDest = dest + 1;
						customCursor = cursor2 + 1;
						for (i = 0; i < count2; i++) {
							array[customDest + i] = tmp[customCursor + i];
							results[customDest + i] = tmpIndex[customCursor + i];
						}
						if (length2 <= 1) {
							exit = true;
							break;
						}
					}
					array[dest] = array[cursor1];
					results[dest] = results[cursor1];
					dest--;
					cursor1--;
					if (--length1 === 0) {
						exit = true;
						break;
					}
					minGallop--;
				} while (count1 >= DEFAULT_MIN_GALLOPING || count2 >= DEFAULT_MIN_GALLOPING);
				if (exit) break;
				if (minGallop < 0) minGallop = 0;
				minGallop += 2;
			}
			this.minGallop = minGallop;
			if (minGallop < 1) this.minGallop = 1;
			if (length2 === 1) {
				dest -= length1;
				cursor1 -= length1;
				customDest = dest + 1;
				customCursor = cursor1 + 1;
				for (i = length1 - 1; i >= 0; i--) {
					array[customDest + i] = array[customCursor + i];
					results[customDest + i] = results[customCursor + i];
				}
				array[dest] = tmp[cursor2];
				results[dest] = tmpIndex[cursor2];
			} else if (length2 === 0) throw new Error("mergeHigh preconditions were not respected");
			else {
				customCursor = dest - (length2 - 1);
				for (i = 0; i < length2; i++) {
					array[customCursor + i] = tmp[i];
					results[customCursor + i] = tmpIndex[i];
				}
			}
		}
	};
	/**
	* Sort an array in the range [lo, hi) using TimSort.
	*
	* @param {array} array - The array to sort.
	* @param {function=} compare - Item comparison function. Default is
	*     alphabetical
	* @param {number} lo - First element in the range (inclusive).
	* @param {number} hi - Last element in the range.
	*     comparator.
	*/
	function sort(array, compare, lo, hi) {
		if (!Array.isArray(array)) throw new TypeError(`The "array" argument must be an array. Received ${array}`);
		results = [];
		const { length } = array;
		let i = 0;
		while (i < length) results[i] = i++;
		if (!compare) compare = alphabeticalCompare;
		else if (typeof compare !== "function") {
			hi = lo;
			lo = compare;
			compare = alphabeticalCompare;
		}
		if (!lo) lo = 0;
		if (!hi) hi = length;
		let remaining = hi - lo;
		if (remaining < 2) return results;
		let runLength = 0;
		if (remaining < DEFAULT_MIN_MERGE) {
			runLength = makeAscendingRun(array, lo, hi, compare);
			binaryInsertionSort(array, lo, hi, lo + runLength, compare);
			return results;
		}
		const ts = new TimSort(array, compare);
		const minRun = minRunLength(remaining);
		do {
			runLength = makeAscendingRun(array, lo, hi, compare);
			if (runLength < minRun) {
				let force = remaining;
				if (force > minRun) force = minRun;
				binaryInsertionSort(array, lo, lo + force, lo + runLength, compare);
				runLength = force;
			}
			ts.pushRun(lo, runLength);
			ts.mergeRuns();
			remaining -= runLength;
			lo += runLength;
		} while (remaining !== 0);
		ts.forceMergeRuns();
		return results;
	}
	module.exports = { sort };
}));

//#endregion
//#region ../node_modules/.pnpm/comment-json@4.5.1/node_modules/comment-json/src/common.js
var require_common = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const { isObject, isArray, isString, isNumber, isFunction } = require_util();
	const PREFIX_BEFORE = "before";
	const PREFIX_AFTER_PROP = "after-prop";
	const PREFIX_AFTER_COLON = "after-colon";
	const PREFIX_AFTER_VALUE = "after-value";
	const PREFIX_AFTER = "after";
	const PREFIX_BEFORE_ALL = "before-all";
	const PREFIX_AFTER_ALL = "after-all";
	const BRACKET_OPEN = "[";
	const BRACKET_CLOSE = "]";
	const CURLY_BRACKET_OPEN = "{";
	const CURLY_BRACKET_CLOSE = "}";
	const COMMA = ",";
	const EMPTY = "";
	const MINUS = "-";
	const PROP_SYMBOL_PREFIXES = [
		PREFIX_BEFORE,
		PREFIX_AFTER_PROP,
		PREFIX_AFTER_COLON,
		PREFIX_AFTER_VALUE,
		PREFIX_AFTER
	];
	const NON_PROP_SYMBOL_PREFIXES = [
		PREFIX_BEFORE,
		PREFIX_AFTER,
		PREFIX_BEFORE_ALL,
		PREFIX_AFTER_ALL
	];
	const NON_PROP_SYMBOL_KEYS = NON_PROP_SYMBOL_PREFIXES.map(Symbol.for);
	const COLON = ":";
	const UNDEFINED = void 0;
	const symbol = (prefix, key) => Symbol.for(prefix + COLON + key);
	const symbol_checked = (prefix, key) => {
		if (key) {
			if (PROP_SYMBOL_PREFIXES.includes(prefix)) return symbol(prefix, key);
			throw new RangeError(`Unsupported comment position ${prefix} with key ${key}`);
		}
		if (NON_PROP_SYMBOL_PREFIXES.includes(prefix)) return Symbol.for(prefix);
		throw new RangeError(`Unsupported comment position ${prefix}`);
	};
	const define = (target, key, value) => Object.defineProperty(target, key, {
		value,
		writable: true,
		configurable: true
	});
	const copy_comments_by_kind = (target, source, target_key, source_key, prefix, remove_source) => {
		const source_prop = symbol(prefix, source_key);
		if (!Object.hasOwn(source, source_prop)) return;
		define(target, target_key === source_key ? source_prop : symbol(prefix, target_key), source[source_prop]);
		if (remove_source) delete source[source_prop];
	};
	const copy_comments = (target, source, target_key, source_key, remove_source) => {
		PROP_SYMBOL_PREFIXES.forEach((prefix) => {
			copy_comments_by_kind(target, source, target_key, source_key, prefix, remove_source);
		});
	};
	const swap_comments = (array, from, to) => {
		if (from === to) return;
		PROP_SYMBOL_PREFIXES.forEach((prefix) => {
			const target_prop = symbol(prefix, to);
			if (!Object.hasOwn(array, target_prop)) {
				copy_comments_by_kind(array, array, to, from, prefix, true);
				return;
			}
			const comments = array[target_prop];
			delete array[target_prop];
			copy_comments_by_kind(array, array, to, from, prefix, true);
			define(array, symbol(prefix, from), comments);
		});
	};
	const assign_non_prop_comments = (target, source) => {
		NON_PROP_SYMBOL_KEYS.forEach((key) => {
			const comments = source[key];
			if (comments) define(target, key, comments);
		});
	};
	const assign = (target, source, keys) => {
		keys.forEach((key) => {
			if (!isString(key) && !isNumber(key)) return;
			if (!Object.hasOwn(source, key)) return;
			target[key] = source[key];
			copy_comments(target, source, key, key);
		});
		return target;
	};
	const is_raw_json = isFunction(JSON.isRawJSON) ? JSON.isRawJSON : () => false;
	module.exports = {
		PROP_SYMBOL_PREFIXES,
		PREFIX_BEFORE,
		PREFIX_AFTER_PROP,
		PREFIX_AFTER_COLON,
		PREFIX_AFTER_VALUE,
		PREFIX_AFTER,
		PREFIX_BEFORE_ALL,
		PREFIX_AFTER_ALL,
		BRACKET_OPEN,
		BRACKET_CLOSE,
		CURLY_BRACKET_OPEN,
		CURLY_BRACKET_CLOSE,
		COLON,
		COMMA,
		MINUS,
		EMPTY,
		UNDEFINED,
		symbol,
		define,
		copy_comments,
		swap_comments,
		assign_non_prop_comments,
		is_raw_json,
		assign(target, source, keys) {
			if (!isObject(target)) throw new TypeError("Cannot convert undefined or null to object");
			if (!isObject(source)) return target;
			if (keys === UNDEFINED) {
				keys = Object.keys(source);
				assign_non_prop_comments(target, source);
			} else if (!isArray(keys)) throw new TypeError("keys must be array or undefined");
			else if (keys.length === 0) assign_non_prop_comments(target, source);
			return assign(target, source, keys);
		},
		moveComments(source, target, { where: from_where, key: from_key }, { where: to_where, key: to_key }, override = false) {
			if (!isObject(source)) throw new TypeError("source must be an object");
			if (!target) target = source;
			if (!isObject(target)) return;
			const from_prop = symbol_checked(from_where, from_key);
			const to_prop = symbol_checked(to_where, to_key);
			if (!Object.hasOwn(source, from_prop)) return;
			const source_comments = source[from_prop];
			delete source[from_prop];
			if (override || !Object.hasOwn(target, to_prop)) {
				define(target, to_prop, source_comments);
				return;
			}
			const target_comments = target[to_prop];
			if (target_comments) target_comments.push(...source_comments);
		},
		removeComments(target, { where, key }) {
			if (!isObject(target)) throw new TypeError("target must be an object");
			const prop = symbol_checked(where, key);
			if (!Object.hasOwn(target, prop)) return;
			delete target[prop];
		}
	};
}));

//#endregion
//#region ../node_modules/.pnpm/comment-json@4.5.1/node_modules/comment-json/src/array.js
var require_array = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const { isArray } = require_util();
	const { sort } = require_src$1();
	const { PROP_SYMBOL_PREFIXES, UNDEFINED, symbol, copy_comments, swap_comments } = require_common();
	const reverse_comments = (array) => {
		const { length } = array;
		let i = 0;
		const max = length / 2;
		for (; i < max; i++) swap_comments(array, i, length - i - 1);
	};
	const move_comment = (target, source, i, offset, remove) => {
		copy_comments(target, source, i + offset, i, remove);
	};
	const move_comments = (target, source, start, count, offset, remove) => {
		if (offset > 0) {
			let i = count;
			while (i-- > 0) move_comment(target, source, start + i, offset, remove);
			return;
		}
		let i = 0;
		while (i < count) move_comment(target, source, start + i++, offset, remove);
	};
	const remove_comments = (array, key) => {
		PROP_SYMBOL_PREFIXES.forEach((prefix) => {
			const prop = symbol(prefix, key);
			delete array[prop];
		});
	};
	const get_mapped = (map, key) => {
		let mapped = key;
		while (mapped in map) mapped = map[mapped];
		return mapped;
	};
	/**
	* An Array subclass that preserves comments when array operations are performed.
	*
	* CommentArray extends the native Array class and automatically handles comment
	* preservation during array mutations like splice, slice, push, pop, etc.
	* Comments are stored as symbol properties and are moved/copied appropriately
	* when the array structure changes.
	*
	* @extends Array
	*
	* @example
	* const arr = parse('[1, 2, 3]') // with comments
	* // arr is a CommentArray instance
	* arr.splice(1, 1) // Comments are preserved and repositioned correctly
	*/
	var CommentArray = class CommentArray extends Array {
		/**
		* Changes the contents of an array by removing or replacing existing
		*   elements and/or adding new elements in place.
		* Comments are automatically preserved and repositioned during the operation.
		*
		* @param {...*} args Arguments passed to Array.prototype.splice
		* @returns {CommentArray} A new CommentArray containing the deleted elements.
		*/
		splice(...args) {
			const { length } = this;
			const ret = super.splice(...args);
			let [begin, deleteCount, ...items] = args;
			if (begin < 0) begin += length;
			if (arguments.length === 1) deleteCount = length - begin;
			else deleteCount = Math.min(length - begin, deleteCount);
			const { length: item_length } = items;
			const offset = item_length - deleteCount;
			const start = begin + deleteCount;
			const count = length - start;
			move_comments(this, this, start, count, offset, true);
			return ret;
		}
		/**
		* Returns a shallow copy of a portion of an array into a new CommentArray object.
		* Comments are copied to the appropriate positions in the new array.
		*
		* @param {...*} args Arguments passed to Array.prototype.slice
		* @returns {CommentArray} A new CommentArray containing the extracted
		*   elements with their comments.
		*/
		slice(...args) {
			const { length } = this;
			const array = super.slice(...args);
			if (!array.length) return new CommentArray();
			let [begin, before] = args;
			if (before === UNDEFINED) before = length;
			else if (before < 0) before += length;
			if (begin < 0) begin += length;
			else if (begin === UNDEFINED) begin = 0;
			move_comments(array, this, begin, before - begin, -begin);
			return array;
		}
		unshift(...items) {
			const { length } = this;
			const ret = super.unshift(...items);
			const { length: items_length } = items;
			if (items_length > 0) move_comments(this, this, 0, length, items_length, true);
			return ret;
		}
		shift() {
			const ret = super.shift();
			const { length } = this;
			remove_comments(this, 0);
			move_comments(this, this, 1, length, -1, true);
			return ret;
		}
		reverse() {
			super.reverse();
			reverse_comments(this);
			return this;
		}
		pop() {
			const ret = super.pop();
			remove_comments(this, this.length);
			return ret;
		}
		concat(...items) {
			let { length } = this;
			const ret = super.concat(...items);
			if (!items.length) return ret;
			move_comments(ret, this, 0, this.length, 0);
			items.forEach((item) => {
				const prev = length;
				length += isArray(item) ? item.length : 1;
				if (!(item instanceof CommentArray)) return;
				move_comments(ret, item, 0, item.length, prev);
			});
			return ret;
		}
		sort(...args) {
			const result = sort(this, ...args.slice(0, 1));
			const map = Object.create(null);
			result.forEach((source_index, index) => {
				if (source_index === index) return;
				const real_source_index = get_mapped(map, source_index);
				if (real_source_index === index) return;
				map[index] = real_source_index;
				swap_comments(this, index, real_source_index);
			});
			return this;
		}
	};
	module.exports = { CommentArray };
}));

//#endregion
//#region ../node_modules/.pnpm/comment-json@4.5.1/node_modules/comment-json/src/parse.js
var require_parse = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const esprima = require_esprima();
	const { CommentArray } = require_array();
	const { PREFIX_BEFORE, PREFIX_AFTER_PROP, PREFIX_AFTER_COLON, PREFIX_AFTER_VALUE, PREFIX_AFTER, PREFIX_BEFORE_ALL, PREFIX_AFTER_ALL, BRACKET_OPEN, BRACKET_CLOSE, CURLY_BRACKET_OPEN, CURLY_BRACKET_CLOSE, COLON, COMMA, MINUS, EMPTY, UNDEFINED, define, assign_non_prop_comments } = require_common();
	/**
	* Tokenize JSON string with comments into an array of tokens.
	*
	* @param {string} code The JSON string with comments to tokenize.
	* @returns {Array} Array of token objects containing type, value, and location
	*   information.
	*
	* @example
	* const tokens = tokenize('{"a": 1 // comment}')
	* // Returns array of tokens including comment tokens
	*/
	const tokenize = (code) => esprima.tokenize(code, {
		comment: true,
		loc: true
	});
	let current_code;
	const previous_hosts = [];
	let comments_host = null;
	let unassigned_comments = null;
	const previous_props = [];
	let last_prop;
	let remove_comments = false;
	let inline = false;
	let tokens = null;
	let last = null;
	let current = null;
	let index;
	let reviver = null;
	const clean = () => {
		current_code = UNDEFINED;
		previous_props.length = previous_hosts.length = 0;
		last = null;
		last_prop = UNDEFINED;
	};
	const free = () => {
		clean();
		tokens.length = 0;
		unassigned_comments = comments_host = tokens = last = current = reviver = null;
		current_code = UNDEFINED;
	};
	const symbolFor = (prefix) => Symbol.for(last_prop !== UNDEFINED ? prefix + COLON + last_prop : prefix);
	const transform = (k, { value, context = {} }) => reviver ? reviver(k, value, context) : value;
	const unexpected = () => {
		const error = /* @__PURE__ */ new SyntaxError(`Unexpected token '${current.value.slice(0, 1)}', "${current_code}" is not valid JSON`);
		Object.assign(error, current.loc.start);
		free();
		throw error;
	};
	const unexpected_end = () => {
		const error = /* @__PURE__ */ new SyntaxError("Unexpected end of JSON input");
		Object.assign(error, last ? last.loc.end : {
			line: 1,
			column: 0
		});
		free();
		throw error;
	};
	const next = () => {
		const new_token = tokens[++index];
		inline = current && new_token && current.loc.end.line === new_token.loc.start.line || false;
		last = current;
		current = new_token;
	};
	const type = () => {
		if (!current) unexpected_end();
		return current.type === "Punctuator" ? current.value : current.type;
	};
	const is = (t) => type() === t;
	const expect = (a) => {
		if (!is(a)) unexpected();
	};
	const set_comments_host = (new_host) => {
		previous_hosts.push(comments_host);
		comments_host = new_host;
	};
	const restore_comments_host = () => {
		comments_host = previous_hosts.pop();
	};
	const assign_after_comments = () => {
		if (!unassigned_comments) return;
		const after_comments = [];
		for (const comment of unassigned_comments) if (comment.inline) after_comments.push(comment);
		else break;
		const { length } = after_comments;
		if (!length) return;
		if (length === unassigned_comments.length) unassigned_comments = null;
		else unassigned_comments.splice(0, length);
		define(comments_host, symbolFor(PREFIX_AFTER), after_comments);
	};
	const assign_comments = (prefix) => {
		if (!unassigned_comments) return;
		define(comments_host, symbolFor(prefix), unassigned_comments);
		unassigned_comments = null;
	};
	const parse_comments = (prefix) => {
		const comments = [];
		while (current && (is("LineComment") || is("BlockComment"))) {
			const comment = {
				...current,
				inline
			};
			comments.push(comment);
			next();
		}
		if (remove_comments) return;
		if (!comments.length) return;
		if (prefix) {
			define(comments_host, symbolFor(prefix), comments);
			return;
		}
		unassigned_comments = comments;
	};
	const set_prop = (prop, push) => {
		if (push) previous_props.push(last_prop);
		last_prop = prop;
	};
	const restore_prop = () => {
		last_prop = previous_props.pop();
	};
	const parse_object = () => {
		const obj = {};
		set_comments_host(obj);
		set_prop(UNDEFINED, true);
		let started = false;
		let name;
		parse_comments();
		while (!is(CURLY_BRACKET_CLOSE)) {
			if (started) {
				assign_comments(PREFIX_AFTER_VALUE);
				expect(COMMA);
				next();
				parse_comments();
				assign_after_comments();
				if (is(CURLY_BRACKET_CLOSE)) break;
			}
			started = true;
			expect("String");
			name = JSON.parse(current.value);
			set_prop(name);
			assign_comments(PREFIX_BEFORE);
			next();
			parse_comments(PREFIX_AFTER_PROP);
			expect(COLON);
			next();
			parse_comments(PREFIX_AFTER_COLON);
			obj[name] = transform(name, walk());
			parse_comments();
		}
		if (started) assign_comments(PREFIX_AFTER);
		next();
		last_prop = void 0;
		if (!started) assign_comments(PREFIX_BEFORE);
		restore_comments_host();
		restore_prop();
		return obj;
	};
	const parse_array = () => {
		const array = new CommentArray();
		set_comments_host(array);
		set_prop(UNDEFINED, true);
		let started = false;
		let i = 0;
		parse_comments();
		while (!is(BRACKET_CLOSE)) {
			if (started) {
				assign_comments(PREFIX_AFTER_VALUE);
				expect(COMMA);
				next();
				parse_comments();
				assign_after_comments();
				if (is(BRACKET_CLOSE)) break;
			}
			started = true;
			set_prop(i);
			assign_comments(PREFIX_BEFORE);
			array[i] = transform(i, walk());
			i++;
			parse_comments();
		}
		if (started) assign_comments(PREFIX_AFTER);
		next();
		last_prop = void 0;
		if (!started) assign_comments(PREFIX_BEFORE);
		restore_comments_host();
		restore_prop();
		return array;
	};
	function walk() {
		let tt = type();
		if (tt === CURLY_BRACKET_OPEN) {
			next();
			return { value: parse_object() };
		}
		if (tt === BRACKET_OPEN) {
			next();
			return { value: parse_array() };
		}
		let negative = EMPTY;
		if (tt === MINUS) {
			next();
			tt = type();
			negative = MINUS;
		}
		let v;
		let source;
		switch (tt) {
			case "String":
			case "Boolean":
			case "Null":
			case "Numeric":
				v = current.value;
				next();
				source = negative + v;
				return {
					value: JSON.parse(source),
					context: { source }
				};
			default: return {};
		}
	}
	const isObject = (subject) => Object(subject) === subject;
	/**
	* Converts a JavaScript Object Notation (JSON) string with comments into an
	* object.
	*
	* @param {string} code A valid JSON string with comments.
	* @param {function} [rev] A function that transforms the results. This function
	*   is called for each member of the object. If a member contains nested
	*   objects, the nested objects are transformed before the parent object is.
	* @param {boolean} [no_comments=false] If true, the comments won't be
	*   maintained, which is often used when we want to get a clean object.
	* @returns {*} The JavaScript object corresponding to the given JSON text with
	*   comments preserved as symbol properties.
	*
	* @example
	* const result = parse('{"a": 1 // This is a comment}')
	* // result.a === 1
	* // Comments are stored in symbol properties
	*
	* @example
	* // With reviver function
	* const result = parse('{"a": "1"}', (key, value) => {
	*   return typeof value === 'string' ? parseInt(value) : value
	* })
	*
	* @example
	* // Without comments
	* const clean = parse('{"a": 1 // comment}', null, true)
	* // Returns clean object without comment symbols
	*/
	const parse = (code, rev, no_comments) => {
		clean();
		current_code = code;
		tokens = tokenize(code);
		reviver = rev;
		remove_comments = no_comments;
		if (!tokens.length) unexpected_end();
		index = -1;
		next();
		set_comments_host({});
		parse_comments(PREFIX_BEFORE_ALL);
		const final = walk();
		parse_comments(PREFIX_AFTER_ALL);
		if (current) unexpected();
		let result = transform("", final);
		if (!no_comments && result !== null) {
			if (!isObject(result)) result = new Object(result);
			assign_non_prop_comments(result, comments_host);
		}
		restore_comments_host();
		free();
		return result;
	};
	module.exports = {
		parse,
		tokenize
	};
}));

//#endregion
//#region ../node_modules/.pnpm/comment-json@4.5.1/node_modules/comment-json/src/stringify.js
var require_stringify$1 = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const { isArray, isObject, isFunction, isNumber, isString } = require_util();
	const { PREFIX_BEFORE_ALL, PREFIX_BEFORE, PREFIX_AFTER_PROP, PREFIX_AFTER_COLON, PREFIX_AFTER_VALUE, PREFIX_AFTER, PREFIX_AFTER_ALL, BRACKET_OPEN, BRACKET_CLOSE, CURLY_BRACKET_OPEN, CURLY_BRACKET_CLOSE, COLON, COMMA, EMPTY, UNDEFINED, is_raw_json } = require_common();
	const ESCAPABLE = /[\\"\x00-\x1f\x7f-\x9f\u00ad\u0600-\u0604\u070f\u17b4\u17b5\u200c-\u200f\u2028-\u202f\u2060-\u206f\ufeff\ufff0-\uffff]/g;
	const SPACE = " ";
	const LF = "\n";
	const STR_NULL = "null";
	const BEFORE = (prop) => `${PREFIX_BEFORE}:${prop}`;
	const AFTER_PROP = (prop) => `${PREFIX_AFTER_PROP}:${prop}`;
	const AFTER_COLON = (prop) => `${PREFIX_AFTER_COLON}:${prop}`;
	const AFTER_VALUE = (prop) => `${PREFIX_AFTER_VALUE}:${prop}`;
	const AFTER = (prop) => `${PREFIX_AFTER}:${prop}`;
	const meta = {
		"\b": "\\b",
		"	": "\\t",
		"\n": "\\n",
		"\f": "\\f",
		"\r": "\\r",
		"\"": "\\\"",
		"\\": "\\\\"
	};
	const escape = (string) => {
		ESCAPABLE.lastIndex = 0;
		if (!ESCAPABLE.test(string)) return string;
		return string.replace(ESCAPABLE, (a) => {
			const c = meta[a];
			return typeof c === "string" ? c : a;
		});
	};
	const quote = (string) => `"${escape(string)}"`;
	const comment_stringify = (value, line) => line ? `//${value}` : `/*${value}*/`;
	const process_comments = (host, symbol_tag, deeper_gap, display_block) => {
		const comments = host[Symbol.for(symbol_tag)];
		if (!comments || !comments.length) return EMPTY;
		let is_line_comment = false;
		const str = comments.reduce((prev, { inline, type, value }) => {
			const delimiter = inline ? SPACE : LF + deeper_gap;
			is_line_comment = type === "LineComment";
			return prev + delimiter + comment_stringify(value, is_line_comment);
		}, EMPTY);
		return display_block || is_line_comment ? str + LF + deeper_gap : str;
	};
	let replacer = null;
	let indent = EMPTY;
	const clean = () => {
		replacer = null;
		indent = EMPTY;
	};
	const join = (one, two, gap) => one ? two ? one + two.trim() + LF + gap : one.trimRight() + LF + gap : two ? two.trimRight() + LF + gap : EMPTY;
	const join_content = (inside, value, gap) => {
		return join(process_comments(value, PREFIX_BEFORE, gap + indent, true), inside, gap);
	};
	const array_stringify = (value, gap) => {
		const deeper_gap = gap + indent;
		const { length } = value;
		let inside = EMPTY;
		let after_comma = EMPTY;
		for (let i = 0; i < length; i++) {
			if (i !== 0) inside += COMMA;
			const before = join(after_comma, process_comments(value, BEFORE(i), deeper_gap), deeper_gap);
			inside += before || LF + deeper_gap;
			inside += stringify(i, value, deeper_gap) || STR_NULL;
			inside += process_comments(value, AFTER_VALUE(i), deeper_gap);
			after_comma = process_comments(value, AFTER(i), deeper_gap);
		}
		inside += join(after_comma, process_comments(value, PREFIX_AFTER, deeper_gap), deeper_gap);
		return BRACKET_OPEN + join_content(inside, value, gap) + BRACKET_CLOSE;
	};
	const object_stringify = (value, gap) => {
		if (!value) return "null";
		const deeper_gap = gap + indent;
		let inside = EMPTY;
		let after_comma = EMPTY;
		let first = true;
		const keys = isArray(replacer) ? replacer : Object.keys(value);
		const iteratee = (key) => {
			const sv = stringify(key, value, deeper_gap);
			if (sv === UNDEFINED) return;
			if (!first) inside += COMMA;
			first = false;
			const before = join(after_comma, process_comments(value, BEFORE(key), deeper_gap), deeper_gap);
			inside += before || LF + deeper_gap;
			inside += quote(key) + process_comments(value, AFTER_PROP(key), deeper_gap) + COLON + process_comments(value, AFTER_COLON(key), deeper_gap) + SPACE + sv + process_comments(value, AFTER_VALUE(key), deeper_gap);
			after_comma = process_comments(value, AFTER(key), deeper_gap);
		};
		keys.forEach(iteratee);
		inside += join(after_comma, process_comments(value, PREFIX_AFTER, deeper_gap), deeper_gap);
		return CURLY_BRACKET_OPEN + join_content(inside, value, gap) + CURLY_BRACKET_CLOSE;
	};
	function stringify(key, holder, gap) {
		let value = holder[key];
		if (isObject(value) && isFunction(value.toJSON)) value = value.toJSON(key);
		if (isFunction(replacer)) value = replacer.call(holder, key, value);
		switch (typeof value) {
			case "string": return quote(value);
			case "number": return Number.isFinite(value) ? String(value) : STR_NULL;
			case "boolean":
			case "null": return String(value);
			case "object":
				if (is_raw_json(value)) return value.rawJSON;
				return isArray(value) ? array_stringify(value, gap) : object_stringify(value, gap);
			default:
		}
	}
	const get_indent = (space) => isString(space) ? space : isNumber(space) ? SPACE.repeat(space) : EMPTY;
	const { toString } = Object.prototype;
	const PRIMITIVE_OBJECT_TYPES = [
		"[object Number]",
		"[object String]",
		"[object Boolean]"
	];
	const is_primitive_object = (subject) => {
		if (typeof subject !== "object") return false;
		const str = toString.call(subject);
		return PRIMITIVE_OBJECT_TYPES.includes(str);
	};
	/**
	* Converts a JavaScript value to a JavaScript Object Notation (JSON) string
	* with comments preserved.
	*
	* @param {*} value A JavaScript value, usually an object or array, to be
	*   converted.
	* @param {function|Array|null} [replacer_] A function that transforms the
	*   results or an array of strings and numbers that acts as an approved list
	*   for selecting the object properties that will be stringified.
	* @param {string|number} [space] Adds indentation, white space, and line
	*   break characters to the return-value JSON text to make it easier to read.
	* @returns {string} A JSON string representing the given value with comments
	*   preserved.
	*
	* @example
	* const obj = parse('{"a": 1 // comment}')
	* stringify(obj, null, 2)
	* // Returns: '{\n  "a": 1 // comment\n}'
	*
	* @example
	* // With replacer function
	* stringify(obj, (key, value) => typeof value === 'number' ? value * 2 : value)
	*
	* @example
	* // With replacer array
	* stringify(obj, ['a', 'b']) // Only include 'a' and 'b' properties
	*/
	module.exports = (value, replacer_, space) => {
		const indent_ = get_indent(space);
		if (!indent_) return JSON.stringify(value, replacer_);
		if (!isFunction(replacer_) && !isArray(replacer_)) replacer_ = null;
		replacer = replacer_;
		indent = indent_;
		const str = is_primitive_object(value) ? JSON.stringify(value) : stringify("", { "": value }, EMPTY);
		clean();
		return isObject(value) ? process_comments(value, PREFIX_BEFORE_ALL, EMPTY, true).trimLeft() + str + process_comments(value, PREFIX_AFTER_ALL, EMPTY).trimRight() : str;
	};
}));

//#endregion
//#region ../node_modules/.pnpm/comment-json@4.5.1/node_modules/comment-json/src/index.js
var require_src = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const { parse, tokenize } = require_parse();
	const stringify = require_stringify$1();
	const { CommentArray } = require_array();
	const { PREFIX_BEFORE, PREFIX_AFTER_PROP, PREFIX_AFTER_COLON, PREFIX_AFTER_VALUE, PREFIX_AFTER, PREFIX_BEFORE_ALL, PREFIX_AFTER_ALL, assign, moveComments, removeComments } = require_common();
	module.exports = {
		PREFIX_BEFORE,
		PREFIX_AFTER_PROP,
		PREFIX_AFTER_COLON,
		PREFIX_AFTER_VALUE,
		PREFIX_AFTER,
		PREFIX_BEFORE_ALL,
		PREFIX_AFTER_ALL,
		parse,
		stringify,
		tokenize,
		CommentArray,
		assign,
		moveComments,
		removeComments
	};
}));

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/serializers/util.js
function detectIndent(content) {
	const m = content.match(/^[ \t]+/m);
	return m && m[0] || "  ";
}
function detectIndentAsNum(content) {
	return detectIndent(content).replaceAll("	", "    ").replaceAll(/[^ ]/g, "").length;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/Errors.js
var ParseError = class extends Error {
	url;
	constructor(url, message, options) {
		super(message || `Unable to parse ${url}`, options);
		this.url = url;
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFileJson.js
var import_src = require_src();
var CSpellConfigFileJson = class CSpellConfigFileJson extends ImplCSpellConfigFile {
	url;
	indent = 2;
	constructor(url, settings) {
		super(url, settings);
		this.url = url;
	}
	serialize() {
		return (0, import_src.stringify)(this.settings, void 0, this.indent) + "\n";
	}
	removeAllComments() {
		for (const key of Object.getOwnPropertySymbols(this.settings)) delete this.settings[key];
		Object.assign(this.settings, JSON.parse(JSON.stringify(this.settings)));
		return this;
	}
	setSchema(schema) {
		this.settings.$schema = schema;
		return this;
	}
	setComment(field, comment, inline) {
		const prefix = inline ? "after:" : "before:";
		const symbolKey = Symbol.for(prefix + field);
		const token = {
			type: "LineComment",
			value: comment,
			inline
		};
		const settings = this.settings;
		settings[symbolKey] = [token];
		return this;
	}
	static parse(file) {
		try {
			const cspell = parseJson(file.content);
			if (!isCSpellSettings$1(cspell)) throw new ParseError(file.url);
			const indent = detectIndent(file.content);
			const cfg = new CSpellConfigFileJson(file.url, cspell);
			cfg.indent = indent;
			return cfg;
		} catch (cause) {
			if (cause instanceof ParseError) throw cause;
			throw new ParseError(file.url, void 0, { cause });
		}
	}
	static from(url, settings, indent = 2) {
		const cfg = new CSpellConfigFileJson(url, settings);
		cfg.indent = indent;
		return cfg;
	}
};
function parseJson(content) {
	try {
		return JSON.parse(content);
	} catch {
		return (0, import_src.parse)(content);
	}
}
function parseCSpellConfigFileJson(file) {
	return CSpellConfigFileJson.parse(file);
}
function isCSpellSettings$1(cfg) {
	return !(!cfg || typeof cfg !== "object" || Array.isArray(cfg));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFilePackageJson.js
var CSpellConfigFilePackageJson = class extends ImplCSpellConfigFile {
	url;
	settings;
	serializer;
	constructor(url, settings, serializer) {
		super(url, settings);
		this.url = url;
		this.settings = settings;
		this.serializer = serializer;
	}
	serialize() {
		return this.serializer(this.settings);
	}
};
function parseCSpellConfigFilePackageJson(file) {
	const { url, content } = file;
	const packageJson = JSON.parse(content);
	if (!packageJson || typeof packageJson !== "object" || Array.isArray(packageJson)) throw new Error(`Unable to parse ${url}`);
	packageJson["cspell"] = packageJson["cspell"] || {};
	const cspell = packageJson["cspell"];
	if (typeof cspell !== "object" || Array.isArray(cspell)) throw new TypeError(`Unable to parse ${url}`);
	const indent = detectIndent(content);
	function serialize(settings) {
		packageJson["cspell"] = settings;
		return JSON.stringify(packageJson, void 0, indent) + "\n";
	}
	return new CSpellConfigFilePackageJson(url, cspell, serialize);
}

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/error.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
function getLineColFromPtr(string, ptr) {
	let lines = string.slice(0, ptr).split(/\r\n|\n|\r/g);
	return [lines.length, lines.pop().length + 1];
}
function makeCodeBlock(string, line, column) {
	let lines = string.split(/\r\n|\n|\r/g);
	let codeblock = "";
	let numberLen = (Math.log10(line + 1) | 0) + 1;
	for (let i = line - 1; i <= line + 1; i++) {
		let l = lines[i - 1];
		if (!l) continue;
		codeblock += i.toString().padEnd(numberLen, " ");
		codeblock += ":  ";
		codeblock += l;
		codeblock += "\n";
		if (i === line) {
			codeblock += " ".repeat(numberLen + column + 2);
			codeblock += "^\n";
		}
	}
	return codeblock;
}
var TomlError = class extends Error {
	line;
	column;
	codeblock;
	constructor(message, options) {
		const [line, column] = getLineColFromPtr(options.toml, options.ptr);
		const codeblock = makeCodeBlock(options.toml, line, column);
		super(`Invalid TOML document: ${message}\n\n${codeblock}`, options);
		this.line = line;
		this.column = column;
		this.codeblock = codeblock;
	}
};

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/util.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
function isEscaped(str, ptr) {
	let i = 0;
	while (str[ptr - ++i] === "\\");
	return --i && i % 2;
}
function indexOfNewline(str, start = 0, end = str.length) {
	let idx = str.indexOf("\n", start);
	if (str[idx - 1] === "\r") idx--;
	return idx <= end ? idx : -1;
}
function skipComment(str, ptr) {
	for (let i = ptr; i < str.length; i++) {
		let c = str[i];
		if (c === "\n") return i;
		if (c === "\r" && str[i + 1] === "\n") return i + 1;
		if (c < " " && c !== "	" || c === "") throw new TomlError("control characters are not allowed in comments", {
			toml: str,
			ptr
		});
	}
	return str.length;
}
function skipVoid(str, ptr, banNewLines, banComments) {
	let c;
	while ((c = str[ptr]) === " " || c === "	" || !banNewLines && (c === "\n" || c === "\r" && str[ptr + 1] === "\n")) ptr++;
	return banComments || c !== "#" ? ptr : skipVoid(str, skipComment(str, ptr), banNewLines);
}
function skipUntil(str, ptr, sep, end, banNewLines = false) {
	if (!end) {
		ptr = indexOfNewline(str, ptr);
		return ptr < 0 ? str.length : ptr;
	}
	for (let i = ptr; i < str.length; i++) {
		let c = str[i];
		if (c === "#") i = indexOfNewline(str, i);
		else if (c === sep) return i + 1;
		else if (c === end || banNewLines && (c === "\n" || c === "\r" && str[i + 1] === "\n")) return i;
	}
	throw new TomlError("cannot find end of structure", {
		toml: str,
		ptr
	});
}
function getStringEnd(str, seek) {
	let first = str[seek];
	let target = first === str[seek + 1] && str[seek + 1] === str[seek + 2] ? str.slice(seek, seek + 3) : first;
	seek += target.length - 1;
	do
		seek = str.indexOf(target, ++seek);
	while (seek > -1 && first !== "'" && isEscaped(str, seek));
	if (seek > -1) {
		seek += target.length;
		if (target.length > 1) {
			if (str[seek] === first) seek++;
			if (str[seek] === first) seek++;
		}
	}
	return seek;
}

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/date.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
let DATE_TIME_RE = /^(\d{4}-\d{2}-\d{2})?[T ]?(?:(\d{2}):\d{2}(?::\d{2}(?:\.\d+)?)?)?(Z|[-+]\d{2}:\d{2})?$/i;
var TomlDate = class TomlDate extends Date {
	#hasDate = false;
	#hasTime = false;
	#offset = null;
	constructor(date) {
		let hasDate = true;
		let hasTime = true;
		let offset = "Z";
		if (typeof date === "string") {
			let match = date.match(DATE_TIME_RE);
			if (match) {
				if (!match[1]) {
					hasDate = false;
					date = `0000-01-01T${date}`;
				}
				hasTime = !!match[2];
				hasTime && date[10] === " " && (date = date.replace(" ", "T"));
				if (match[2] && +match[2] > 23) date = "";
				else {
					offset = match[3] || null;
					date = date.toUpperCase();
					if (!offset && hasTime) date += "Z";
				}
			} else date = "";
		}
		super(date);
		if (!isNaN(this.getTime())) {
			this.#hasDate = hasDate;
			this.#hasTime = hasTime;
			this.#offset = offset;
		}
	}
	isDateTime() {
		return this.#hasDate && this.#hasTime;
	}
	isLocal() {
		return !this.#hasDate || !this.#hasTime || !this.#offset;
	}
	isDate() {
		return this.#hasDate && !this.#hasTime;
	}
	isTime() {
		return this.#hasTime && !this.#hasDate;
	}
	isValid() {
		return this.#hasDate || this.#hasTime;
	}
	toISOString() {
		let iso = super.toISOString();
		if (this.isDate()) return iso.slice(0, 10);
		if (this.isTime()) return iso.slice(11, 23);
		if (this.#offset === null) return iso.slice(0, -1);
		if (this.#offset === "Z") return iso;
		let offset = +this.#offset.slice(1, 3) * 60 + +this.#offset.slice(4, 6);
		offset = this.#offset[0] === "-" ? offset : -offset;
		return (/* @__PURE__ */ new Date(this.getTime() - offset * 6e4)).toISOString().slice(0, -1) + this.#offset;
	}
	static wrapAsOffsetDateTime(jsDate, offset = "Z") {
		let date = new TomlDate(jsDate);
		date.#offset = offset;
		return date;
	}
	static wrapAsLocalDateTime(jsDate) {
		let date = new TomlDate(jsDate);
		date.#offset = null;
		return date;
	}
	static wrapAsLocalDate(jsDate) {
		let date = new TomlDate(jsDate);
		date.#hasTime = false;
		date.#offset = null;
		return date;
	}
	static wrapAsLocalTime(jsDate) {
		let date = new TomlDate(jsDate);
		date.#hasDate = false;
		date.#offset = null;
		return date;
	}
};

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/primitive.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
let INT_REGEX = /^((0x[0-9a-fA-F](_?[0-9a-fA-F])*)|(([+-]|0[ob])?\d(_?\d)*))$/;
let FLOAT_REGEX = /^[+-]?\d(_?\d)*(\.\d(_?\d)*)?([eE][+-]?\d(_?\d)*)?$/;
let LEADING_ZERO = /^[+-]?0[0-9_]/;
let ESCAPE_REGEX$1 = /^[0-9a-f]{2,8}$/i;
let ESC_MAP = {
	b: "\b",
	t: "	",
	n: "\n",
	f: "\f",
	r: "\r",
	e: "\x1B",
	"\"": "\"",
	"\\": "\\"
};
function parseString(str, ptr = 0, endPtr = str.length) {
	let isLiteral = str[ptr] === "'";
	let isMultiline = str[ptr++] === str[ptr] && str[ptr] === str[ptr + 1];
	if (isMultiline) {
		endPtr -= 2;
		if (str[ptr += 2] === "\r") ptr++;
		if (str[ptr] === "\n") ptr++;
	}
	let tmp = 0;
	let isEscape;
	let parsed = "";
	let sliceStart = ptr;
	while (ptr < endPtr - 1) {
		let c = str[ptr++];
		if (c === "\n" || c === "\r" && str[ptr] === "\n") {
			if (!isMultiline) throw new TomlError("newlines are not allowed in strings", {
				toml: str,
				ptr: ptr - 1
			});
		} else if (c < " " && c !== "	" || c === "") throw new TomlError("control characters are not allowed in strings", {
			toml: str,
			ptr: ptr - 1
		});
		if (isEscape) {
			isEscape = false;
			if (c === "x" || c === "u" || c === "U") {
				let code = str.slice(ptr, ptr += c === "x" ? 2 : c === "u" ? 4 : 8);
				if (!ESCAPE_REGEX$1.test(code)) throw new TomlError("invalid unicode escape", {
					toml: str,
					ptr: tmp
				});
				try {
					parsed += String.fromCodePoint(parseInt(code, 16));
				} catch {
					throw new TomlError("invalid unicode escape", {
						toml: str,
						ptr: tmp
					});
				}
			} else if (isMultiline && (c === "\n" || c === " " || c === "	" || c === "\r")) {
				ptr = skipVoid(str, ptr - 1, true);
				if (str[ptr] !== "\n" && str[ptr] !== "\r") throw new TomlError("invalid escape: only line-ending whitespace may be escaped", {
					toml: str,
					ptr: tmp
				});
				ptr = skipVoid(str, ptr);
			} else if (c in ESC_MAP) parsed += ESC_MAP[c];
			else throw new TomlError("unrecognized escape sequence", {
				toml: str,
				ptr: tmp
			});
			sliceStart = ptr;
		} else if (!isLiteral && c === "\\") {
			tmp = ptr - 1;
			isEscape = true;
			parsed += str.slice(sliceStart, tmp);
		}
	}
	return parsed + str.slice(sliceStart, endPtr - 1);
}
function parseValue(value, toml, ptr, integersAsBigInt) {
	if (value === "true") return true;
	if (value === "false") return false;
	if (value === "-inf") return -Infinity;
	if (value === "inf" || value === "+inf") return Infinity;
	if (value === "nan" || value === "+nan" || value === "-nan") return NaN;
	if (value === "-0") return integersAsBigInt ? 0n : 0;
	let isInt = INT_REGEX.test(value);
	if (isInt || FLOAT_REGEX.test(value)) {
		if (LEADING_ZERO.test(value)) throw new TomlError("leading zeroes are not allowed", {
			toml,
			ptr
		});
		value = value.replace(/_/g, "");
		let numeric = +value;
		if (isNaN(numeric)) throw new TomlError("invalid number", {
			toml,
			ptr
		});
		if (isInt) {
			if ((isInt = !Number.isSafeInteger(numeric)) && !integersAsBigInt) throw new TomlError("integer value cannot be represented losslessly", {
				toml,
				ptr
			});
			if (isInt || integersAsBigInt === true) numeric = BigInt(value);
		}
		return numeric;
	}
	const date = new TomlDate(value);
	if (!date.isValid()) throw new TomlError("invalid value", {
		toml,
		ptr
	});
	return date;
}

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/extract.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
function sliceAndTrimEndOf(str, startPtr, endPtr) {
	let value = str.slice(startPtr, endPtr);
	let commentIdx = value.indexOf("#");
	if (commentIdx > -1) {
		skipComment(str, commentIdx);
		value = value.slice(0, commentIdx);
	}
	return [value.trimEnd(), commentIdx];
}
function extractValue(str, ptr, end, depth, integersAsBigInt) {
	if (depth === 0) throw new TomlError("document contains excessively nested structures. aborting.", {
		toml: str,
		ptr
	});
	let c = str[ptr];
	if (c === "[" || c === "{") {
		let [value, endPtr] = c === "[" ? parseArray(str, ptr, depth, integersAsBigInt) : parseInlineTable(str, ptr, depth, integersAsBigInt);
		if (end) {
			endPtr = skipVoid(str, endPtr);
			if (str[endPtr] === ",") endPtr++;
			else if (str[endPtr] !== end) throw new TomlError("expected comma or end of structure", {
				toml: str,
				ptr: endPtr
			});
		}
		return [value, endPtr];
	}
	let endPtr;
	if (c === "\"" || c === "'") {
		endPtr = getStringEnd(str, ptr);
		let parsed = parseString(str, ptr, endPtr);
		if (end) {
			endPtr = skipVoid(str, endPtr);
			if (str[endPtr] && str[endPtr] !== "," && str[endPtr] !== end && str[endPtr] !== "\n" && str[endPtr] !== "\r") throw new TomlError("unexpected character encountered", {
				toml: str,
				ptr: endPtr
			});
			endPtr += +(str[endPtr] === ",");
		}
		return [parsed, endPtr];
	}
	endPtr = skipUntil(str, ptr, ",", end);
	let slice = sliceAndTrimEndOf(str, ptr, endPtr - +(str[endPtr - 1] === ","));
	if (!slice[0]) throw new TomlError("incomplete key-value declaration: no value specified", {
		toml: str,
		ptr
	});
	if (end && slice[1] > -1) {
		endPtr = skipVoid(str, ptr + slice[1]);
		endPtr += +(str[endPtr] === ",");
	}
	return [parseValue(slice[0], str, ptr, integersAsBigInt), endPtr];
}

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/struct.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
let KEY_PART_RE = /^[a-zA-Z0-9-_]+[ \t]*$/;
function parseKey(str, ptr, end = "=") {
	let dot = ptr - 1;
	let parsed = [];
	let endPtr = str.indexOf(end, ptr);
	if (endPtr < 0) throw new TomlError("incomplete key-value: cannot find end of key", {
		toml: str,
		ptr
	});
	do {
		let c = str[ptr = ++dot];
		if (c !== " " && c !== "	") if (c === "\"" || c === "'") {
			if (c === str[ptr + 1] && c === str[ptr + 2]) throw new TomlError("multiline strings are not allowed in keys", {
				toml: str,
				ptr
			});
			let eos = getStringEnd(str, ptr);
			if (eos < 0) throw new TomlError("unfinished string encountered", {
				toml: str,
				ptr
			});
			dot = str.indexOf(".", eos);
			let strEnd = str.slice(eos, dot < 0 || dot > endPtr ? endPtr : dot);
			let newLine = indexOfNewline(strEnd);
			if (newLine > -1) throw new TomlError("newlines are not allowed in keys", {
				toml: str,
				ptr: ptr + dot + newLine
			});
			if (strEnd.trimStart()) throw new TomlError("found extra tokens after the string part", {
				toml: str,
				ptr: eos
			});
			if (endPtr < eos) {
				endPtr = str.indexOf(end, eos);
				if (endPtr < 0) throw new TomlError("incomplete key-value: cannot find end of key", {
					toml: str,
					ptr
				});
			}
			parsed.push(parseString(str, ptr, eos));
		} else {
			dot = str.indexOf(".", ptr);
			let part = str.slice(ptr, dot < 0 || dot > endPtr ? endPtr : dot);
			if (!KEY_PART_RE.test(part)) throw new TomlError("only letter, numbers, dashes and underscores are allowed in keys", {
				toml: str,
				ptr
			});
			parsed.push(part.trimEnd());
		}
	} while (dot + 1 && dot < endPtr);
	return [parsed, skipVoid(str, endPtr + 1, true, true)];
}
function parseInlineTable(str, ptr, depth, integersAsBigInt) {
	let res = {};
	let seen = /* @__PURE__ */ new Set();
	let c;
	ptr++;
	while ((c = str[ptr++]) !== "}" && c) if (c === ",") throw new TomlError("expected value, found comma", {
		toml: str,
		ptr: ptr - 1
	});
	else if (c === "#") ptr = skipComment(str, ptr);
	else if (c !== " " && c !== "	" && c !== "\n" && c !== "\r") {
		let k;
		let t = res;
		let hasOwn = false;
		let [key, keyEndPtr] = parseKey(str, ptr - 1);
		for (let i = 0; i < key.length; i++) {
			if (i) t = hasOwn ? t[k] : t[k] = {};
			k = key[i];
			if ((hasOwn = Object.hasOwn(t, k)) && (typeof t[k] !== "object" || seen.has(t[k]))) throw new TomlError("trying to redefine an already defined value", {
				toml: str,
				ptr
			});
			if (!hasOwn && k === "__proto__") Object.defineProperty(t, k, {
				enumerable: true,
				configurable: true,
				writable: true
			});
		}
		if (hasOwn) throw new TomlError("trying to redefine an already defined value", {
			toml: str,
			ptr
		});
		let [value, valueEndPtr] = extractValue(str, keyEndPtr, "}", depth - 1, integersAsBigInt);
		seen.add(value);
		t[k] = value;
		ptr = valueEndPtr;
	}
	if (!c) throw new TomlError("unfinished table encountered", {
		toml: str,
		ptr
	});
	return [res, ptr];
}
function parseArray(str, ptr, depth, integersAsBigInt) {
	let res = [];
	let c;
	ptr++;
	while ((c = str[ptr++]) !== "]" && c) if (c === ",") throw new TomlError("expected value, found comma", {
		toml: str,
		ptr: ptr - 1
	});
	else if (c === "#") ptr = skipComment(str, ptr);
	else if (c !== " " && c !== "	" && c !== "\n" && c !== "\r") {
		let e = extractValue(str, ptr - 1, "]", depth - 1, integersAsBigInt);
		res.push(e[0]);
		ptr = e[1];
	}
	if (!c) throw new TomlError("unfinished array encountered", {
		toml: str,
		ptr
	});
	return [res, ptr];
}

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/parse.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
function peekTable(key, table, meta, type) {
	let t = table;
	let m = meta;
	let k;
	let hasOwn = false;
	let state;
	for (let i = 0; i < key.length; i++) {
		if (i) {
			t = hasOwn ? t[k] : t[k] = {};
			m = (state = m[k]).c;
			if (type === 0 && (state.t === 1 || state.t === 2)) return null;
			if (state.t === 2) {
				let l = t.length - 1;
				t = t[l];
				m = m[l].c;
			}
		}
		k = key[i];
		if ((hasOwn = Object.hasOwn(t, k)) && m[k]?.t === 0 && m[k]?.d) return null;
		if (!hasOwn) {
			if (k === "__proto__") {
				Object.defineProperty(t, k, {
					enumerable: true,
					configurable: true,
					writable: true
				});
				Object.defineProperty(m, k, {
					enumerable: true,
					configurable: true,
					writable: true
				});
			}
			m[k] = {
				t: i < key.length - 1 && type === 2 ? 3 : type,
				d: false,
				i: 0,
				c: {}
			};
		}
	}
	state = m[k];
	if (state.t !== type && !(type === 1 && state.t === 3)) return null;
	if (type === 2) {
		if (!state.d) {
			state.d = true;
			t[k] = [];
		}
		t[k].push(t = {});
		state.c[state.i++] = state = {
			t: 1,
			d: false,
			i: 0,
			c: {}
		};
	}
	if (state.d) return null;
	state.d = true;
	if (type === 1) t = hasOwn ? t[k] : t[k] = {};
	else if (type === 0 && hasOwn) return null;
	return [
		k,
		t,
		state.c
	];
}
function parse$1(toml, { maxDepth = 1e3, integersAsBigInt } = {}) {
	let res = {};
	let meta = {};
	let tbl = res;
	let m = meta;
	for (let ptr = skipVoid(toml, 0); ptr < toml.length;) {
		if (toml[ptr] === "[") {
			let isTableArray = toml[++ptr] === "[";
			let k = parseKey(toml, ptr += +isTableArray, "]");
			if (isTableArray) {
				if (toml[k[1] - 1] !== "]") throw new TomlError("expected end of table declaration", {
					toml,
					ptr: k[1] - 1
				});
				k[1]++;
			}
			let p = peekTable(k[0], res, meta, isTableArray ? 2 : 1);
			if (!p) throw new TomlError("trying to redefine an already defined table or value", {
				toml,
				ptr
			});
			m = p[2];
			tbl = p[1];
			ptr = k[1];
		} else {
			let k = parseKey(toml, ptr);
			let p = peekTable(k[0], tbl, m, 0);
			if (!p) throw new TomlError("trying to redefine an already defined table or value", {
				toml,
				ptr
			});
			let v = extractValue(toml, k[1], void 0, maxDepth, integersAsBigInt);
			p[1][p[0]] = v[0];
			ptr = v[1];
		}
		ptr = skipVoid(toml, ptr, true);
		if (toml[ptr] && toml[ptr] !== "\n" && toml[ptr] !== "\r") throw new TomlError("each key-value declaration must be followed by an end-of-line", {
			toml,
			ptr
		});
		ptr = skipVoid(toml, ptr);
	}
	return res;
}

//#endregion
//#region ../node_modules/.pnpm/smol-toml@1.6.0/node_modules/smol-toml/dist/stringify.js
/*!
* Copyright (c) Squirrel Chat et al., All rights reserved.
* SPDX-License-Identifier: BSD-3-Clause
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions are met:
*
* 1. Redistributions of source code must retain the above copyright notice, this
*    list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice,
*    this list of conditions and the following disclaimer in the
*    documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors
*    may be used to endorse or promote products derived from this software without
*    specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
* ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
* WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
* DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
* FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
* DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
* SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
* OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
let BARE_KEY = /^[a-z0-9-_]+$/i;
function extendedTypeOf(obj) {
	let type = typeof obj;
	if (type === "object") {
		if (Array.isArray(obj)) return "array";
		if (obj instanceof Date) return "date";
	}
	return type;
}
function isArrayOfTables(obj) {
	for (let i = 0; i < obj.length; i++) if (extendedTypeOf(obj[i]) !== "object") return false;
	return obj.length != 0;
}
function formatString(s) {
	return JSON.stringify(s).replace(/\x7f/g, "\\u007f");
}
function stringifyValue(val, type, depth, numberAsFloat) {
	if (depth === 0) throw new Error("Could not stringify the object: maximum object depth exceeded");
	if (type === "number") {
		if (isNaN(val)) return "nan";
		if (val === Infinity) return "inf";
		if (val === -Infinity) return "-inf";
		if (numberAsFloat && Number.isInteger(val)) return val.toFixed(1);
		return val.toString();
	}
	if (type === "bigint" || type === "boolean") return val.toString();
	if (type === "string") return formatString(val);
	if (type === "date") {
		if (isNaN(val.getTime())) throw new TypeError("cannot serialize invalid date");
		return val.toISOString();
	}
	if (type === "object") return stringifyInlineTable(val, depth, numberAsFloat);
	if (type === "array") return stringifyArray(val, depth, numberAsFloat);
}
function stringifyInlineTable(obj, depth, numberAsFloat) {
	let keys = Object.keys(obj);
	if (keys.length === 0) return "{}";
	let res = "{ ";
	for (let i = 0; i < keys.length; i++) {
		let k = keys[i];
		if (i) res += ", ";
		res += BARE_KEY.test(k) ? k : formatString(k);
		res += " = ";
		res += stringifyValue(obj[k], extendedTypeOf(obj[k]), depth - 1, numberAsFloat);
	}
	return res + " }";
}
function stringifyArray(array, depth, numberAsFloat) {
	if (array.length === 0) return "[]";
	let res = "[ ";
	for (let i = 0; i < array.length; i++) {
		if (i) res += ", ";
		if (array[i] === null || array[i] === void 0) throw new TypeError("arrays cannot contain null or undefined values");
		res += stringifyValue(array[i], extendedTypeOf(array[i]), depth - 1, numberAsFloat);
	}
	return res + " ]";
}
function stringifyArrayTable(array, key, depth, numberAsFloat) {
	if (depth === 0) throw new Error("Could not stringify the object: maximum object depth exceeded");
	let res = "";
	for (let i = 0; i < array.length; i++) {
		res += `${res && "\n"}[[${key}]]\n`;
		res += stringifyTable(0, array[i], key, depth, numberAsFloat);
	}
	return res;
}
function stringifyTable(tableKey, obj, prefix, depth, numberAsFloat) {
	if (depth === 0) throw new Error("Could not stringify the object: maximum object depth exceeded");
	let preamble = "";
	let tables = "";
	let keys = Object.keys(obj);
	for (let i = 0; i < keys.length; i++) {
		let k = keys[i];
		if (obj[k] !== null && obj[k] !== void 0) {
			let type = extendedTypeOf(obj[k]);
			if (type === "symbol" || type === "function") throw new TypeError(`cannot serialize values of type '${type}'`);
			let key = BARE_KEY.test(k) ? k : formatString(k);
			if (type === "array" && isArrayOfTables(obj[k])) tables += (tables && "\n") + stringifyArrayTable(obj[k], prefix ? `${prefix}.${key}` : key, depth - 1, numberAsFloat);
			else if (type === "object") {
				let tblKey = prefix ? `${prefix}.${key}` : key;
				tables += (tables && "\n") + stringifyTable(tblKey, obj[k], tblKey, depth - 1, numberAsFloat);
			} else {
				preamble += key;
				preamble += " = ";
				preamble += stringifyValue(obj[k], type, depth, numberAsFloat);
				preamble += "\n";
			}
		}
	}
	if (tableKey && (preamble || !tables)) preamble = preamble ? `[${tableKey}]\n${preamble}` : `[${tableKey}]`;
	return preamble && tables ? `${preamble}\n${tables}` : preamble || tables;
}
function stringify$2(obj, { maxDepth = 1e3, numbersAsFloat = false } = {}) {
	if (extendedTypeOf(obj) !== "object") throw new TypeError("stringify can only be called with an object");
	let str = stringifyTable(0, obj, "", maxDepth, numbersAsFloat);
	if (str[str.length - 1] !== "\n") return str + "\n";
	return str;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFileToml.js
var CSpellConfigFileToml = class CSpellConfigFileToml extends ImplCSpellConfigFile {
	url;
	constructor(url, settings) {
		super(url, settings);
		this.url = url;
	}
	serialize() {
		return stringify$2(this.settings);
	}
	removeAllComments() {
		return this;
	}
	setSchema(schema) {
		this.settings.$schema = schema;
		return this;
	}
	setComment(_field, _comment, _inline) {
		return this;
	}
	static parse(file) {
		try {
			const cspell = parse$1(file.content);
			if (!isCSpellSettings(cspell)) throw new ParseError(file.url);
			return new CSpellConfigFileToml(file.url, cspell);
		} catch (cause) {
			if (cause instanceof ParseError) throw cause;
			throw new ParseError(file.url, void 0, { cause });
		}
	}
	static from(url, settings, _indent) {
		return new CSpellConfigFileToml(url, settings);
	}
};
function parseCSpellConfigFileToml(file) {
	return CSpellConfigFileToml.parse(file);
}
function isCSpellSettings(cfg) {
	return !(!cfg || typeof cfg !== "object" || Array.isArray(cfg));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFileWithErrors.js
/**
* A CSpell configuration file that had errors during loading.
*/
var CSpellConfigFileWithErrors = class extends ImplCSpellConfigFile {
	url;
	settings;
	error;
	constructor(url, settings, error) {
		super(url, settings);
		this.url = url;
		this.settings = settings;
		this.error = error;
	}
	get readonly() {
		return true;
	}
};

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/identity.js
var require_identity = /* @__PURE__ */ __commonJSMin(((exports) => {
	const ALIAS = Symbol.for("yaml.alias");
	const DOC = Symbol.for("yaml.document");
	const MAP = Symbol.for("yaml.map");
	const PAIR = Symbol.for("yaml.pair");
	const SCALAR = Symbol.for("yaml.scalar");
	const SEQ = Symbol.for("yaml.seq");
	const NODE_TYPE = Symbol.for("yaml.node.type");
	const isAlias = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === ALIAS;
	const isDocument = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === DOC;
	const isMap = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === MAP;
	const isPair = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === PAIR;
	const isScalar = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === SCALAR;
	const isSeq = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === SEQ;
	function isCollection(node) {
		if (node && typeof node === "object") switch (node[NODE_TYPE]) {
			case MAP:
			case SEQ: return true;
		}
		return false;
	}
	function isNode(node) {
		if (node && typeof node === "object") switch (node[NODE_TYPE]) {
			case ALIAS:
			case MAP:
			case SCALAR:
			case SEQ: return true;
		}
		return false;
	}
	const hasAnchor = (node) => (isScalar(node) || isCollection(node)) && !!node.anchor;
	exports.ALIAS = ALIAS;
	exports.DOC = DOC;
	exports.MAP = MAP;
	exports.NODE_TYPE = NODE_TYPE;
	exports.PAIR = PAIR;
	exports.SCALAR = SCALAR;
	exports.SEQ = SEQ;
	exports.hasAnchor = hasAnchor;
	exports.isAlias = isAlias;
	exports.isCollection = isCollection;
	exports.isDocument = isDocument;
	exports.isMap = isMap;
	exports.isNode = isNode;
	exports.isPair = isPair;
	exports.isScalar = isScalar;
	exports.isSeq = isSeq;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/visit.js
var require_visit = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	const BREAK = Symbol("break visit");
	const SKIP = Symbol("skip children");
	const REMOVE = Symbol("remove node");
	/**
	* Apply a visitor to an AST node or document.
	*
	* Walks through the tree (depth-first) starting from `node`, calling a
	* `visitor` function with three arguments:
	*   - `key`: For sequence values and map `Pair`, the node's index in the
	*     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.
	*     `null` for the root node.
	*   - `node`: The current node.
	*   - `path`: The ancestry of the current node.
	*
	* The return value of the visitor may be used to control the traversal:
	*   - `undefined` (default): Do nothing and continue
	*   - `visit.SKIP`: Do not visit the children of this node, continue with next
	*     sibling
	*   - `visit.BREAK`: Terminate traversal completely
	*   - `visit.REMOVE`: Remove the current node, then continue with the next one
	*   - `Node`: Replace the current node, then continue by visiting it
	*   - `number`: While iterating the items of a sequence or map, set the index
	*     of the next step. This is useful especially if the index of the current
	*     node has changed.
	*
	* If `visitor` is a single function, it will be called with all values
	* encountered in the tree, including e.g. `null` values. Alternatively,
	* separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,
	* `Alias` and `Scalar` node. To define the same visitor function for more than
	* one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)
	* and `Node` (alias, map, seq & scalar) targets. Of all these, only the most
	* specific defined one will be used for each node.
	*/
	function visit(node, visitor) {
		const visitor_ = initVisitor(visitor);
		if (identity.isDocument(node)) {
			if (visit_(null, node.contents, visitor_, Object.freeze([node])) === REMOVE) node.contents = null;
		} else visit_(null, node, visitor_, Object.freeze([]));
	}
	/** Terminate visit traversal completely */
	visit.BREAK = BREAK;
	/** Do not visit the children of the current node */
	visit.SKIP = SKIP;
	/** Remove the current node */
	visit.REMOVE = REMOVE;
	function visit_(key, node, visitor, path) {
		const ctrl = callVisitor(key, node, visitor, path);
		if (identity.isNode(ctrl) || identity.isPair(ctrl)) {
			replaceNode(key, path, ctrl);
			return visit_(key, ctrl, visitor, path);
		}
		if (typeof ctrl !== "symbol") {
			if (identity.isCollection(node)) {
				path = Object.freeze(path.concat(node));
				for (let i = 0; i < node.items.length; ++i) {
					const ci = visit_(i, node.items[i], visitor, path);
					if (typeof ci === "number") i = ci - 1;
					else if (ci === BREAK) return BREAK;
					else if (ci === REMOVE) {
						node.items.splice(i, 1);
						i -= 1;
					}
				}
			} else if (identity.isPair(node)) {
				path = Object.freeze(path.concat(node));
				const ck = visit_("key", node.key, visitor, path);
				if (ck === BREAK) return BREAK;
				else if (ck === REMOVE) node.key = null;
				const cv = visit_("value", node.value, visitor, path);
				if (cv === BREAK) return BREAK;
				else if (cv === REMOVE) node.value = null;
			}
		}
		return ctrl;
	}
	/**
	* Apply an async visitor to an AST node or document.
	*
	* Walks through the tree (depth-first) starting from `node`, calling a
	* `visitor` function with three arguments:
	*   - `key`: For sequence values and map `Pair`, the node's index in the
	*     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.
	*     `null` for the root node.
	*   - `node`: The current node.
	*   - `path`: The ancestry of the current node.
	*
	* The return value of the visitor may be used to control the traversal:
	*   - `Promise`: Must resolve to one of the following values
	*   - `undefined` (default): Do nothing and continue
	*   - `visit.SKIP`: Do not visit the children of this node, continue with next
	*     sibling
	*   - `visit.BREAK`: Terminate traversal completely
	*   - `visit.REMOVE`: Remove the current node, then continue with the next one
	*   - `Node`: Replace the current node, then continue by visiting it
	*   - `number`: While iterating the items of a sequence or map, set the index
	*     of the next step. This is useful especially if the index of the current
	*     node has changed.
	*
	* If `visitor` is a single function, it will be called with all values
	* encountered in the tree, including e.g. `null` values. Alternatively,
	* separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,
	* `Alias` and `Scalar` node. To define the same visitor function for more than
	* one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)
	* and `Node` (alias, map, seq & scalar) targets. Of all these, only the most
	* specific defined one will be used for each node.
	*/
	async function visitAsync(node, visitor) {
		const visitor_ = initVisitor(visitor);
		if (identity.isDocument(node)) {
			if (await visitAsync_(null, node.contents, visitor_, Object.freeze([node])) === REMOVE) node.contents = null;
		} else await visitAsync_(null, node, visitor_, Object.freeze([]));
	}
	/** Terminate visit traversal completely */
	visitAsync.BREAK = BREAK;
	/** Do not visit the children of the current node */
	visitAsync.SKIP = SKIP;
	/** Remove the current node */
	visitAsync.REMOVE = REMOVE;
	async function visitAsync_(key, node, visitor, path) {
		const ctrl = await callVisitor(key, node, visitor, path);
		if (identity.isNode(ctrl) || identity.isPair(ctrl)) {
			replaceNode(key, path, ctrl);
			return visitAsync_(key, ctrl, visitor, path);
		}
		if (typeof ctrl !== "symbol") {
			if (identity.isCollection(node)) {
				path = Object.freeze(path.concat(node));
				for (let i = 0; i < node.items.length; ++i) {
					const ci = await visitAsync_(i, node.items[i], visitor, path);
					if (typeof ci === "number") i = ci - 1;
					else if (ci === BREAK) return BREAK;
					else if (ci === REMOVE) {
						node.items.splice(i, 1);
						i -= 1;
					}
				}
			} else if (identity.isPair(node)) {
				path = Object.freeze(path.concat(node));
				const ck = await visitAsync_("key", node.key, visitor, path);
				if (ck === BREAK) return BREAK;
				else if (ck === REMOVE) node.key = null;
				const cv = await visitAsync_("value", node.value, visitor, path);
				if (cv === BREAK) return BREAK;
				else if (cv === REMOVE) node.value = null;
			}
		}
		return ctrl;
	}
	function initVisitor(visitor) {
		if (typeof visitor === "object" && (visitor.Collection || visitor.Node || visitor.Value)) return Object.assign({
			Alias: visitor.Node,
			Map: visitor.Node,
			Scalar: visitor.Node,
			Seq: visitor.Node
		}, visitor.Value && {
			Map: visitor.Value,
			Scalar: visitor.Value,
			Seq: visitor.Value
		}, visitor.Collection && {
			Map: visitor.Collection,
			Seq: visitor.Collection
		}, visitor);
		return visitor;
	}
	function callVisitor(key, node, visitor, path) {
		if (typeof visitor === "function") return visitor(key, node, path);
		if (identity.isMap(node)) return visitor.Map?.(key, node, path);
		if (identity.isSeq(node)) return visitor.Seq?.(key, node, path);
		if (identity.isPair(node)) return visitor.Pair?.(key, node, path);
		if (identity.isScalar(node)) return visitor.Scalar?.(key, node, path);
		if (identity.isAlias(node)) return visitor.Alias?.(key, node, path);
	}
	function replaceNode(key, path, node) {
		const parent = path[path.length - 1];
		if (identity.isCollection(parent)) parent.items[key] = node;
		else if (identity.isPair(parent)) if (key === "key") parent.key = node;
		else parent.value = node;
		else if (identity.isDocument(parent)) parent.contents = node;
		else {
			const pt = identity.isAlias(parent) ? "alias" : "scalar";
			throw new Error(`Cannot replace node with ${pt} parent`);
		}
	}
	exports.visit = visit;
	exports.visitAsync = visitAsync;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/directives.js
var require_directives = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var visit = require_visit();
	const escapeChars = {
		"!": "%21",
		",": "%2C",
		"[": "%5B",
		"]": "%5D",
		"{": "%7B",
		"}": "%7D"
	};
	const escapeTagName = (tn) => tn.replace(/[!,[\]{}]/g, (ch) => escapeChars[ch]);
	var Directives = class Directives {
		constructor(yaml, tags) {
			/**
			* The directives-end/doc-start marker `---`. If `null`, a marker may still be
			* included in the document's stringified representation.
			*/
			this.docStart = null;
			/** The doc-end marker `...`.  */
			this.docEnd = false;
			this.yaml = Object.assign({}, Directives.defaultYaml, yaml);
			this.tags = Object.assign({}, Directives.defaultTags, tags);
		}
		clone() {
			const copy = new Directives(this.yaml, this.tags);
			copy.docStart = this.docStart;
			return copy;
		}
		/**
		* During parsing, get a Directives instance for the current document and
		* update the stream state according to the current version's spec.
		*/
		atDocument() {
			const res = new Directives(this.yaml, this.tags);
			switch (this.yaml.version) {
				case "1.1":
					this.atNextDocument = true;
					break;
				case "1.2":
					this.atNextDocument = false;
					this.yaml = {
						explicit: Directives.defaultYaml.explicit,
						version: "1.2"
					};
					this.tags = Object.assign({}, Directives.defaultTags);
					break;
			}
			return res;
		}
		/**
		* @param onError - May be called even if the action was successful
		* @returns `true` on success
		*/
		add(line, onError) {
			if (this.atNextDocument) {
				this.yaml = {
					explicit: Directives.defaultYaml.explicit,
					version: "1.1"
				};
				this.tags = Object.assign({}, Directives.defaultTags);
				this.atNextDocument = false;
			}
			const parts = line.trim().split(/[ \t]+/);
			const name = parts.shift();
			switch (name) {
				case "%TAG": {
					if (parts.length !== 2) {
						onError(0, "%TAG directive should contain exactly two parts");
						if (parts.length < 2) return false;
					}
					const [handle, prefix] = parts;
					this.tags[handle] = prefix;
					return true;
				}
				case "%YAML": {
					this.yaml.explicit = true;
					if (parts.length !== 1) {
						onError(0, "%YAML directive should contain exactly one part");
						return false;
					}
					const [version] = parts;
					if (version === "1.1" || version === "1.2") {
						this.yaml.version = version;
						return true;
					} else {
						const isValid = /^\d+\.\d+$/.test(version);
						onError(6, `Unsupported YAML version ${version}`, isValid);
						return false;
					}
				}
				default:
					onError(0, `Unknown directive ${name}`, true);
					return false;
			}
		}
		/**
		* Resolves a tag, matching handles to those defined in %TAG directives.
		*
		* @returns Resolved tag, which may also be the non-specific tag `'!'` or a
		*   `'!local'` tag, or `null` if unresolvable.
		*/
		tagName(source, onError) {
			if (source === "!") return "!";
			if (source[0] !== "!") {
				onError(`Not a valid tag: ${source}`);
				return null;
			}
			if (source[1] === "<") {
				const verbatim = source.slice(2, -1);
				if (verbatim === "!" || verbatim === "!!") {
					onError(`Verbatim tags aren't resolved, so ${source} is invalid.`);
					return null;
				}
				if (source[source.length - 1] !== ">") onError("Verbatim tags must end with a >");
				return verbatim;
			}
			const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/s);
			if (!suffix) onError(`The ${source} tag has no suffix`);
			const prefix = this.tags[handle];
			if (prefix) try {
				return prefix + decodeURIComponent(suffix);
			} catch (error) {
				onError(String(error));
				return null;
			}
			if (handle === "!") return source;
			onError(`Could not resolve tag: ${source}`);
			return null;
		}
		/**
		* Given a fully resolved tag, returns its printable string form,
		* taking into account current tag prefixes and defaults.
		*/
		tagString(tag) {
			for (const [handle, prefix] of Object.entries(this.tags)) if (tag.startsWith(prefix)) return handle + escapeTagName(tag.substring(prefix.length));
			return tag[0] === "!" ? tag : `!<${tag}>`;
		}
		toString(doc) {
			const lines = this.yaml.explicit ? [`%YAML ${this.yaml.version || "1.2"}`] : [];
			const tagEntries = Object.entries(this.tags);
			let tagNames;
			if (doc && tagEntries.length > 0 && identity.isNode(doc.contents)) {
				const tags = {};
				visit.visit(doc.contents, (_key, node) => {
					if (identity.isNode(node) && node.tag) tags[node.tag] = true;
				});
				tagNames = Object.keys(tags);
			} else tagNames = [];
			for (const [handle, prefix] of tagEntries) {
				if (handle === "!!" && prefix === "tag:yaml.org,2002:") continue;
				if (!doc || tagNames.some((tn) => tn.startsWith(prefix))) lines.push(`%TAG ${handle} ${prefix}`);
			}
			return lines.join("\n");
		}
	};
	Directives.defaultYaml = {
		explicit: false,
		version: "1.2"
	};
	Directives.defaultTags = { "!!": "tag:yaml.org,2002:" };
	exports.Directives = Directives;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/anchors.js
var require_anchors = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var visit = require_visit();
	/**
	* Verify that the input string is a valid anchor.
	*
	* Will throw on errors.
	*/
	function anchorIsValid(anchor) {
		if (/[\x00-\x19\s,[\]{}]/.test(anchor)) {
			const msg = `Anchor must not contain whitespace or control characters: ${JSON.stringify(anchor)}`;
			throw new Error(msg);
		}
		return true;
	}
	function anchorNames(root) {
		const anchors = /* @__PURE__ */ new Set();
		visit.visit(root, { Value(_key, node) {
			if (node.anchor) anchors.add(node.anchor);
		} });
		return anchors;
	}
	/** Find a new anchor name with the given `prefix` and a one-indexed suffix. */
	function findNewAnchor(prefix, exclude) {
		for (let i = 1;; ++i) {
			const name = `${prefix}${i}`;
			if (!exclude.has(name)) return name;
		}
	}
	function createNodeAnchors(doc, prefix) {
		const aliasObjects = [];
		const sourceObjects = /* @__PURE__ */ new Map();
		let prevAnchors = null;
		return {
			onAnchor: (source) => {
				aliasObjects.push(source);
				prevAnchors ?? (prevAnchors = anchorNames(doc));
				const anchor = findNewAnchor(prefix, prevAnchors);
				prevAnchors.add(anchor);
				return anchor;
			},
			setAnchors: () => {
				for (const source of aliasObjects) {
					const ref = sourceObjects.get(source);
					if (typeof ref === "object" && ref.anchor && (identity.isScalar(ref.node) || identity.isCollection(ref.node))) ref.node.anchor = ref.anchor;
					else {
						const error = /* @__PURE__ */ new Error("Failed to resolve repeated object (this should not happen)");
						error.source = source;
						throw error;
					}
				}
			},
			sourceObjects
		};
	}
	exports.anchorIsValid = anchorIsValid;
	exports.anchorNames = anchorNames;
	exports.createNodeAnchors = createNodeAnchors;
	exports.findNewAnchor = findNewAnchor;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/applyReviver.js
var require_applyReviver = /* @__PURE__ */ __commonJSMin(((exports) => {
	/**
	* Applies the JSON.parse reviver algorithm as defined in the ECMA-262 spec,
	* in section 24.5.1.1 "Runtime Semantics: InternalizeJSONProperty" of the
	* 2021 edition: https://tc39.es/ecma262/#sec-json.parse
	*
	* Includes extensions for handling Map and Set objects.
	*/
	function applyReviver(reviver, obj, key, val) {
		if (val && typeof val === "object") if (Array.isArray(val)) for (let i = 0, len = val.length; i < len; ++i) {
			const v0 = val[i];
			const v1 = applyReviver(reviver, val, String(i), v0);
			if (v1 === void 0) delete val[i];
			else if (v1 !== v0) val[i] = v1;
		}
		else if (val instanceof Map) for (const k of Array.from(val.keys())) {
			const v0 = val.get(k);
			const v1 = applyReviver(reviver, val, k, v0);
			if (v1 === void 0) val.delete(k);
			else if (v1 !== v0) val.set(k, v1);
		}
		else if (val instanceof Set) for (const v0 of Array.from(val)) {
			const v1 = applyReviver(reviver, val, v0, v0);
			if (v1 === void 0) val.delete(v0);
			else if (v1 !== v0) {
				val.delete(v0);
				val.add(v1);
			}
		}
		else for (const [k, v0] of Object.entries(val)) {
			const v1 = applyReviver(reviver, val, k, v0);
			if (v1 === void 0) delete val[k];
			else if (v1 !== v0) val[k] = v1;
		}
		return reviver.call(obj, key, val);
	}
	exports.applyReviver = applyReviver;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/toJS.js
var require_toJS = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	/**
	* Recursively convert any node or its contents to native JavaScript
	*
	* @param value - The input value
	* @param arg - If `value` defines a `toJSON()` method, use this
	*   as its first argument
	* @param ctx - Conversion context, originally set in Document#toJS(). If
	*   `{ keep: true }` is not set, output should be suitable for JSON
	*   stringification.
	*/
	function toJS(value, arg, ctx) {
		if (Array.isArray(value)) return value.map((v, i) => toJS(v, String(i), ctx));
		if (value && typeof value.toJSON === "function") {
			if (!ctx || !identity.hasAnchor(value)) return value.toJSON(arg, ctx);
			const data = {
				aliasCount: 0,
				count: 1,
				res: void 0
			};
			ctx.anchors.set(value, data);
			ctx.onCreate = (res) => {
				data.res = res;
				delete ctx.onCreate;
			};
			const res = value.toJSON(arg, ctx);
			if (ctx.onCreate) ctx.onCreate(res);
			return res;
		}
		if (typeof value === "bigint" && !ctx?.keep) return Number(value);
		return value;
	}
	exports.toJS = toJS;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Node.js
var require_Node = /* @__PURE__ */ __commonJSMin(((exports) => {
	var applyReviver = require_applyReviver();
	var identity = require_identity();
	var toJS = require_toJS();
	var NodeBase = class {
		constructor(type) {
			Object.defineProperty(this, identity.NODE_TYPE, { value: type });
		}
		/** Create a copy of this node.  */
		clone() {
			const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));
			if (this.range) copy.range = this.range.slice();
			return copy;
		}
		/** A plain JavaScript representation of this node. */
		toJS(doc, { mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
			if (!identity.isDocument(doc)) throw new TypeError("A document argument is required");
			const ctx = {
				anchors: /* @__PURE__ */ new Map(),
				doc,
				keep: true,
				mapAsMap: mapAsMap === true,
				mapKeyWarned: false,
				maxAliasCount: typeof maxAliasCount === "number" ? maxAliasCount : 100
			};
			const res = toJS.toJS(this, "", ctx);
			if (typeof onAnchor === "function") for (const { count, res } of ctx.anchors.values()) onAnchor(res, count);
			return typeof reviver === "function" ? applyReviver.applyReviver(reviver, { "": res }, "", res) : res;
		}
	};
	exports.NodeBase = NodeBase;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Alias.js
var require_Alias = /* @__PURE__ */ __commonJSMin(((exports) => {
	var anchors = require_anchors();
	var visit = require_visit();
	var identity = require_identity();
	var Node = require_Node();
	var toJS = require_toJS();
	var Alias = class extends Node.NodeBase {
		constructor(source) {
			super(identity.ALIAS);
			this.source = source;
			Object.defineProperty(this, "tag", { set() {
				throw new Error("Alias nodes cannot have tags");
			} });
		}
		/**
		* Resolve the value of this alias within `doc`, finding the last
		* instance of the `source` anchor before this node.
		*/
		resolve(doc, ctx) {
			let nodes;
			if (ctx?.aliasResolveCache) nodes = ctx.aliasResolveCache;
			else {
				nodes = [];
				visit.visit(doc, { Node: (_key, node) => {
					if (identity.isAlias(node) || identity.hasAnchor(node)) nodes.push(node);
				} });
				if (ctx) ctx.aliasResolveCache = nodes;
			}
			let found = void 0;
			for (const node of nodes) {
				if (node === this) break;
				if (node.anchor === this.source) found = node;
			}
			return found;
		}
		toJSON(_arg, ctx) {
			if (!ctx) return { source: this.source };
			const { anchors, doc, maxAliasCount } = ctx;
			const source = this.resolve(doc, ctx);
			if (!source) {
				const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;
				throw new ReferenceError(msg);
			}
			let data = anchors.get(source);
			if (!data) {
				toJS.toJS(source, null, ctx);
				data = anchors.get(source);
			}
			/* istanbul ignore if */
			if (data?.res === void 0) throw new ReferenceError("This should not happen: Alias anchor was not resolved?");
			if (maxAliasCount >= 0) {
				data.count += 1;
				if (data.aliasCount === 0) data.aliasCount = getAliasCount(doc, source, anchors);
				if (data.count * data.aliasCount > maxAliasCount) throw new ReferenceError("Excessive alias count indicates a resource exhaustion attack");
			}
			return data.res;
		}
		toString(ctx, _onComment, _onChompKeep) {
			const src = `*${this.source}`;
			if (ctx) {
				anchors.anchorIsValid(this.source);
				if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {
					const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;
					throw new Error(msg);
				}
				if (ctx.implicitKey) return `${src} `;
			}
			return src;
		}
	};
	function getAliasCount(doc, node, anchors) {
		if (identity.isAlias(node)) {
			const source = node.resolve(doc);
			const anchor = anchors && source && anchors.get(source);
			return anchor ? anchor.count * anchor.aliasCount : 0;
		} else if (identity.isCollection(node)) {
			let count = 0;
			for (const item of node.items) {
				const c = getAliasCount(doc, item, anchors);
				if (c > count) count = c;
			}
			return count;
		} else if (identity.isPair(node)) {
			const kc = getAliasCount(doc, node.key, anchors);
			const vc = getAliasCount(doc, node.value, anchors);
			return Math.max(kc, vc);
		}
		return 1;
	}
	exports.Alias = Alias;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Scalar.js
var require_Scalar = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Node = require_Node();
	var toJS = require_toJS();
	const isScalarValue = (value) => !value || typeof value !== "function" && typeof value !== "object";
	var Scalar = class extends Node.NodeBase {
		constructor(value) {
			super(identity.SCALAR);
			this.value = value;
		}
		toJSON(arg, ctx) {
			return ctx?.keep ? this.value : toJS.toJS(this.value, arg, ctx);
		}
		toString() {
			return String(this.value);
		}
	};
	Scalar.BLOCK_FOLDED = "BLOCK_FOLDED";
	Scalar.BLOCK_LITERAL = "BLOCK_LITERAL";
	Scalar.PLAIN = "PLAIN";
	Scalar.QUOTE_DOUBLE = "QUOTE_DOUBLE";
	Scalar.QUOTE_SINGLE = "QUOTE_SINGLE";
	exports.Scalar = Scalar;
	exports.isScalarValue = isScalarValue;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/createNode.js
var require_createNode = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Alias = require_Alias();
	var identity = require_identity();
	var Scalar = require_Scalar();
	const defaultTagPrefix = "tag:yaml.org,2002:";
	function findTagObject(value, tagName, tags) {
		if (tagName) {
			const match = tags.filter((t) => t.tag === tagName);
			const tagObj = match.find((t) => !t.format) ?? match[0];
			if (!tagObj) throw new Error(`Tag ${tagName} not found`);
			return tagObj;
		}
		return tags.find((t) => t.identify?.(value) && !t.format);
	}
	function createNode(value, tagName, ctx) {
		if (identity.isDocument(value)) value = value.contents;
		if (identity.isNode(value)) return value;
		if (identity.isPair(value)) {
			const map = ctx.schema[identity.MAP].createNode?.(ctx.schema, null, ctx);
			map.items.push(value);
			return map;
		}
		if (value instanceof String || value instanceof Number || value instanceof Boolean || typeof BigInt !== "undefined" && value instanceof BigInt) value = value.valueOf();
		const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } = ctx;
		let ref = void 0;
		if (aliasDuplicateObjects && value && typeof value === "object") {
			ref = sourceObjects.get(value);
			if (ref) {
				ref.anchor ?? (ref.anchor = onAnchor(value));
				return new Alias.Alias(ref.anchor);
			} else {
				ref = {
					anchor: null,
					node: null
				};
				sourceObjects.set(value, ref);
			}
		}
		if (tagName?.startsWith("!!")) tagName = defaultTagPrefix + tagName.slice(2);
		let tagObj = findTagObject(value, tagName, schema.tags);
		if (!tagObj) {
			if (value && typeof value.toJSON === "function") value = value.toJSON();
			if (!value || typeof value !== "object") {
				const node = new Scalar.Scalar(value);
				if (ref) ref.node = node;
				return node;
			}
			tagObj = value instanceof Map ? schema[identity.MAP] : Symbol.iterator in Object(value) ? schema[identity.SEQ] : schema[identity.MAP];
		}
		if (onTagObj) {
			onTagObj(tagObj);
			delete ctx.onTagObj;
		}
		const node = tagObj?.createNode ? tagObj.createNode(ctx.schema, value, ctx) : typeof tagObj?.nodeClass?.from === "function" ? tagObj.nodeClass.from(ctx.schema, value, ctx) : new Scalar.Scalar(value);
		if (tagName) node.tag = tagName;
		else if (!tagObj.default) node.tag = tagObj.tag;
		if (ref) ref.node = node;
		return node;
	}
	exports.createNode = createNode;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Collection.js
var require_Collection = /* @__PURE__ */ __commonJSMin(((exports) => {
	var createNode = require_createNode();
	var identity = require_identity();
	var Node = require_Node();
	function collectionFromPath(schema, path, value) {
		let v = value;
		for (let i = path.length - 1; i >= 0; --i) {
			const k = path[i];
			if (typeof k === "number" && Number.isInteger(k) && k >= 0) {
				const a = [];
				a[k] = v;
				v = a;
			} else v = new Map([[k, v]]);
		}
		return createNode.createNode(v, void 0, {
			aliasDuplicateObjects: false,
			keepUndefined: false,
			onAnchor: () => {
				throw new Error("This should not happen, please report a bug.");
			},
			schema,
			sourceObjects: /* @__PURE__ */ new Map()
		});
	}
	const isEmptyPath = (path) => path == null || typeof path === "object" && !!path[Symbol.iterator]().next().done;
	var Collection = class extends Node.NodeBase {
		constructor(type, schema) {
			super(type);
			Object.defineProperty(this, "schema", {
				value: schema,
				configurable: true,
				enumerable: false,
				writable: true
			});
		}
		/**
		* Create a copy of this collection.
		*
		* @param schema - If defined, overwrites the original's schema
		*/
		clone(schema) {
			const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));
			if (schema) copy.schema = schema;
			copy.items = copy.items.map((it) => identity.isNode(it) || identity.isPair(it) ? it.clone(schema) : it);
			if (this.range) copy.range = this.range.slice();
			return copy;
		}
		/**
		* Adds a value to the collection. For `!!map` and `!!omap` the value must
		* be a Pair instance or a `{ key, value }` object, which may not have a key
		* that already exists in the map.
		*/
		addIn(path, value) {
			if (isEmptyPath(path)) this.add(value);
			else {
				const [key, ...rest] = path;
				const node = this.get(key, true);
				if (identity.isCollection(node)) node.addIn(rest, value);
				else if (node === void 0 && this.schema) this.set(key, collectionFromPath(this.schema, rest, value));
				else throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
			}
		}
		/**
		* Removes a value from the collection.
		* @returns `true` if the item was found and removed.
		*/
		deleteIn(path) {
			const [key, ...rest] = path;
			if (rest.length === 0) return this.delete(key);
			const node = this.get(key, true);
			if (identity.isCollection(node)) return node.deleteIn(rest);
			else throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
		}
		/**
		* Returns item at `key`, or `undefined` if not found. By default unwraps
		* scalar values from their surrounding node; to disable set `keepScalar` to
		* `true` (collections are always returned intact).
		*/
		getIn(path, keepScalar) {
			const [key, ...rest] = path;
			const node = this.get(key, true);
			if (rest.length === 0) return !keepScalar && identity.isScalar(node) ? node.value : node;
			else return identity.isCollection(node) ? node.getIn(rest, keepScalar) : void 0;
		}
		hasAllNullValues(allowScalar) {
			return this.items.every((node) => {
				if (!identity.isPair(node)) return false;
				const n = node.value;
				return n == null || allowScalar && identity.isScalar(n) && n.value == null && !n.commentBefore && !n.comment && !n.tag;
			});
		}
		/**
		* Checks if the collection includes a value with the key `key`.
		*/
		hasIn(path) {
			const [key, ...rest] = path;
			if (rest.length === 0) return this.has(key);
			const node = this.get(key, true);
			return identity.isCollection(node) ? node.hasIn(rest) : false;
		}
		/**
		* Sets a value in this collection. For `!!set`, `value` needs to be a
		* boolean to add/remove the item from the set.
		*/
		setIn(path, value) {
			const [key, ...rest] = path;
			if (rest.length === 0) this.set(key, value);
			else {
				const node = this.get(key, true);
				if (identity.isCollection(node)) node.setIn(rest, value);
				else if (node === void 0 && this.schema) this.set(key, collectionFromPath(this.schema, rest, value));
				else throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
			}
		}
	};
	exports.Collection = Collection;
	exports.collectionFromPath = collectionFromPath;
	exports.isEmptyPath = isEmptyPath;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyComment.js
var require_stringifyComment = /* @__PURE__ */ __commonJSMin(((exports) => {
	/**
	* Stringifies a comment.
	*
	* Empty comment lines are left empty,
	* lines consisting of a single space are replaced by `#`,
	* and all other lines are prefixed with a `#`.
	*/
	const stringifyComment = (str) => str.replace(/^(?!$)(?: $)?/gm, "#");
	function indentComment(comment, indent) {
		if (/^\n+$/.test(comment)) return comment.substring(1);
		return indent ? comment.replace(/^(?! *$)/gm, indent) : comment;
	}
	const lineComment = (str, indent, comment) => str.endsWith("\n") ? indentComment(comment, indent) : comment.includes("\n") ? "\n" + indentComment(comment, indent) : (str.endsWith(" ") ? "" : " ") + comment;
	exports.indentComment = indentComment;
	exports.lineComment = lineComment;
	exports.stringifyComment = stringifyComment;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/foldFlowLines.js
var require_foldFlowLines = /* @__PURE__ */ __commonJSMin(((exports) => {
	const FOLD_FLOW = "flow";
	const FOLD_BLOCK = "block";
	const FOLD_QUOTED = "quoted";
	/**
	* Tries to keep input at up to `lineWidth` characters, splitting only on spaces
	* not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are
	* terminated with `\n` and started with `indent`.
	*/
	function foldFlowLines(text, indent, mode = "flow", { indentAtStart, lineWidth = 80, minContentWidth = 20, onFold, onOverflow } = {}) {
		if (!lineWidth || lineWidth < 0) return text;
		if (lineWidth < minContentWidth) minContentWidth = 0;
		const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);
		if (text.length <= endStep) return text;
		const folds = [];
		const escapedFolds = {};
		let end = lineWidth - indent.length;
		if (typeof indentAtStart === "number") if (indentAtStart > lineWidth - Math.max(2, minContentWidth)) folds.push(0);
		else end = lineWidth - indentAtStart;
		let split = void 0;
		let prev = void 0;
		let overflow = false;
		let i = -1;
		let escStart = -1;
		let escEnd = -1;
		if (mode === FOLD_BLOCK) {
			i = consumeMoreIndentedLines(text, i, indent.length);
			if (i !== -1) end = i + endStep;
		}
		for (let ch; ch = text[i += 1];) {
			if (mode === FOLD_QUOTED && ch === "\\") {
				escStart = i;
				switch (text[i + 1]) {
					case "x":
						i += 3;
						break;
					case "u":
						i += 5;
						break;
					case "U":
						i += 9;
						break;
					default: i += 1;
				}
				escEnd = i;
			}
			if (ch === "\n") {
				if (mode === FOLD_BLOCK) i = consumeMoreIndentedLines(text, i, indent.length);
				end = i + indent.length + endStep;
				split = void 0;
			} else {
				if (ch === " " && prev && prev !== " " && prev !== "\n" && prev !== "	") {
					const next = text[i + 1];
					if (next && next !== " " && next !== "\n" && next !== "	") split = i;
				}
				if (i >= end) if (split) {
					folds.push(split);
					end = split + endStep;
					split = void 0;
				} else if (mode === FOLD_QUOTED) {
					while (prev === " " || prev === "	") {
						prev = ch;
						ch = text[i += 1];
						overflow = true;
					}
					const j = i > escEnd + 1 ? i - 2 : escStart - 1;
					if (escapedFolds[j]) return text;
					folds.push(j);
					escapedFolds[j] = true;
					end = j + endStep;
					split = void 0;
				} else overflow = true;
			}
			prev = ch;
		}
		if (overflow && onOverflow) onOverflow();
		if (folds.length === 0) return text;
		if (onFold) onFold();
		let res = text.slice(0, folds[0]);
		for (let i = 0; i < folds.length; ++i) {
			const fold = folds[i];
			const end = folds[i + 1] || text.length;
			if (fold === 0) res = `\n${indent}${text.slice(0, end)}`;
			else {
				if (mode === FOLD_QUOTED && escapedFolds[fold]) res += `${text[fold]}\\`;
				res += `\n${indent}${text.slice(fold + 1, end)}`;
			}
		}
		return res;
	}
	/**
	* Presumes `i + 1` is at the start of a line
	* @returns index of last newline in more-indented block
	*/
	function consumeMoreIndentedLines(text, i, indent) {
		let end = i;
		let start = i + 1;
		let ch = text[start];
		while (ch === " " || ch === "	") if (i < start + indent) ch = text[++i];
		else {
			do
				ch = text[++i];
			while (ch && ch !== "\n");
			end = i;
			start = i + 1;
			ch = text[start];
		}
		return end;
	}
	exports.FOLD_BLOCK = FOLD_BLOCK;
	exports.FOLD_FLOW = FOLD_FLOW;
	exports.FOLD_QUOTED = FOLD_QUOTED;
	exports.foldFlowLines = foldFlowLines;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyString.js
var require_stringifyString = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	var foldFlowLines = require_foldFlowLines();
	const getFoldOptions = (ctx, isBlock) => ({
		indentAtStart: isBlock ? ctx.indent.length : ctx.indentAtStart,
		lineWidth: ctx.options.lineWidth,
		minContentWidth: ctx.options.minContentWidth
	});
	const containsDocumentMarker = (str) => /^(%|---|\.\.\.)/m.test(str);
	function lineLengthOverLimit(str, lineWidth, indentLength) {
		if (!lineWidth || lineWidth < 0) return false;
		const limit = lineWidth - indentLength;
		const strLen = str.length;
		if (strLen <= limit) return false;
		for (let i = 0, start = 0; i < strLen; ++i) if (str[i] === "\n") {
			if (i - start > limit) return true;
			start = i + 1;
			if (strLen - start <= limit) return false;
		}
		return true;
	}
	function doubleQuotedString(value, ctx) {
		const json = JSON.stringify(value);
		if (ctx.options.doubleQuotedAsJSON) return json;
		const { implicitKey } = ctx;
		const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength;
		const indent = ctx.indent || (containsDocumentMarker(value) ? "  " : "");
		let str = "";
		let start = 0;
		for (let i = 0, ch = json[i]; ch; ch = json[++i]) {
			if (ch === " " && json[i + 1] === "\\" && json[i + 2] === "n") {
				str += json.slice(start, i) + "\\ ";
				i += 1;
				start = i;
				ch = "\\";
			}
			if (ch === "\\") switch (json[i + 1]) {
				case "u":
					{
						str += json.slice(start, i);
						const code = json.substr(i + 2, 4);
						switch (code) {
							case "0000":
								str += "\\0";
								break;
							case "0007":
								str += "\\a";
								break;
							case "000b":
								str += "\\v";
								break;
							case "001b":
								str += "\\e";
								break;
							case "0085":
								str += "\\N";
								break;
							case "00a0":
								str += "\\_";
								break;
							case "2028":
								str += "\\L";
								break;
							case "2029":
								str += "\\P";
								break;
							default: if (code.substr(0, 2) === "00") str += "\\x" + code.substr(2);
							else str += json.substr(i, 6);
						}
						i += 5;
						start = i + 1;
					}
					break;
				case "n":
					if (implicitKey || json[i + 2] === "\"" || json.length < minMultiLineLength) i += 1;
					else {
						str += json.slice(start, i) + "\n\n";
						while (json[i + 2] === "\\" && json[i + 3] === "n" && json[i + 4] !== "\"") {
							str += "\n";
							i += 2;
						}
						str += indent;
						if (json[i + 2] === " ") str += "\\";
						i += 1;
						start = i + 1;
					}
					break;
				default: i += 1;
			}
		}
		str = start ? str + json.slice(start) : json;
		return implicitKey ? str : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_QUOTED, getFoldOptions(ctx, false));
	}
	function singleQuotedString(value, ctx) {
		if (ctx.options.singleQuote === false || ctx.implicitKey && value.includes("\n") || /[ \t]\n|\n[ \t]/.test(value)) return doubleQuotedString(value, ctx);
		const indent = ctx.indent || (containsDocumentMarker(value) ? "  " : "");
		const res = "'" + value.replace(/'/g, "''").replace(/\n+/g, `$&\n${indent}`) + "'";
		return ctx.implicitKey ? res : foldFlowLines.foldFlowLines(res, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));
	}
	function quotedString(value, ctx) {
		const { singleQuote } = ctx.options;
		let qs;
		if (singleQuote === false) qs = doubleQuotedString;
		else {
			const hasDouble = value.includes("\"");
			const hasSingle = value.includes("'");
			if (hasDouble && !hasSingle) qs = singleQuotedString;
			else if (hasSingle && !hasDouble) qs = doubleQuotedString;
			else qs = singleQuote ? singleQuotedString : doubleQuotedString;
		}
		return qs(value, ctx);
	}
	let blockEndNewlines;
	try {
		blockEndNewlines = /* @__PURE__ */ new RegExp("(^|(?<!\n))\n+(?!\n|$)", "g");
	} catch {
		blockEndNewlines = /\n+(?!\n|$)/g;
	}
	function blockString({ comment, type, value }, ctx, onComment, onChompKeep) {
		const { blockQuote, commentString, lineWidth } = ctx.options;
		if (!blockQuote || /\n[\t ]+$/.test(value)) return quotedString(value, ctx);
		const indent = ctx.indent || (ctx.forceBlockIndent || containsDocumentMarker(value) ? "  " : "");
		const literal = blockQuote === "literal" ? true : blockQuote === "folded" || type === Scalar.Scalar.BLOCK_FOLDED ? false : type === Scalar.Scalar.BLOCK_LITERAL ? true : !lineLengthOverLimit(value, lineWidth, indent.length);
		if (!value) return literal ? "|\n" : ">\n";
		let chomp;
		let endStart;
		for (endStart = value.length; endStart > 0; --endStart) {
			const ch = value[endStart - 1];
			if (ch !== "\n" && ch !== "	" && ch !== " ") break;
		}
		let end = value.substring(endStart);
		const endNlPos = end.indexOf("\n");
		if (endNlPos === -1) chomp = "-";
		else if (value === end || endNlPos !== end.length - 1) {
			chomp = "+";
			if (onChompKeep) onChompKeep();
		} else chomp = "";
		if (end) {
			value = value.slice(0, -end.length);
			if (end[end.length - 1] === "\n") end = end.slice(0, -1);
			end = end.replace(blockEndNewlines, `$&${indent}`);
		}
		let startWithSpace = false;
		let startEnd;
		let startNlPos = -1;
		for (startEnd = 0; startEnd < value.length; ++startEnd) {
			const ch = value[startEnd];
			if (ch === " ") startWithSpace = true;
			else if (ch === "\n") startNlPos = startEnd;
			else break;
		}
		let start = value.substring(0, startNlPos < startEnd ? startNlPos + 1 : startEnd);
		if (start) {
			value = value.substring(start.length);
			start = start.replace(/\n+/g, `$&${indent}`);
		}
		let header = (startWithSpace ? indent ? "2" : "1" : "") + chomp;
		if (comment) {
			header += " " + commentString(comment.replace(/ ?[\r\n]+/g, " "));
			if (onComment) onComment();
		}
		if (!literal) {
			const foldedValue = value.replace(/\n+/g, "\n$&").replace(/(?:^|\n)([\t ].*)(?:([\n\t ]*)\n(?![\n\t ]))?/g, "$1$2").replace(/\n+/g, `$&${indent}`);
			let literalFallback = false;
			const foldOptions = getFoldOptions(ctx, true);
			if (blockQuote !== "folded" && type !== Scalar.Scalar.BLOCK_FOLDED) foldOptions.onOverflow = () => {
				literalFallback = true;
			};
			const body = foldFlowLines.foldFlowLines(`${start}${foldedValue}${end}`, indent, foldFlowLines.FOLD_BLOCK, foldOptions);
			if (!literalFallback) return `>${header}\n${indent}${body}`;
		}
		value = value.replace(/\n+/g, `$&${indent}`);
		return `|${header}\n${indent}${start}${value}${end}`;
	}
	function plainString(item, ctx, onComment, onChompKeep) {
		const { type, value } = item;
		const { actualString, implicitKey, indent, indentStep, inFlow } = ctx;
		if (implicitKey && value.includes("\n") || inFlow && /[[\]{},]/.test(value)) return quotedString(value, ctx);
		if (/^[\n\t ,[\]{}#&*!|>'"%@`]|^[?-]$|^[?-][ \t]|[\n:][ \t]|[ \t]\n|[\n\t ]#|[\n\t :]$/.test(value)) return implicitKey || inFlow || !value.includes("\n") ? quotedString(value, ctx) : blockString(item, ctx, onComment, onChompKeep);
		if (!implicitKey && !inFlow && type !== Scalar.Scalar.PLAIN && value.includes("\n")) return blockString(item, ctx, onComment, onChompKeep);
		if (containsDocumentMarker(value)) {
			if (indent === "") {
				ctx.forceBlockIndent = true;
				return blockString(item, ctx, onComment, onChompKeep);
			} else if (implicitKey && indent === indentStep) return quotedString(value, ctx);
		}
		const str = value.replace(/\n+/g, `$&\n${indent}`);
		if (actualString) {
			const test = (tag) => tag.default && tag.tag !== "tag:yaml.org,2002:str" && tag.test?.test(str);
			const { compat, tags } = ctx.doc.schema;
			if (tags.some(test) || compat?.some(test)) return quotedString(value, ctx);
		}
		return implicitKey ? str : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));
	}
	function stringifyString(item, ctx, onComment, onChompKeep) {
		const { implicitKey, inFlow } = ctx;
		const ss = typeof item.value === "string" ? item : Object.assign({}, item, { value: String(item.value) });
		let { type } = item;
		if (type !== Scalar.Scalar.QUOTE_DOUBLE) {
			if (/[\x00-\x08\x0b-\x1f\x7f-\x9f\u{D800}-\u{DFFF}]/u.test(ss.value)) type = Scalar.Scalar.QUOTE_DOUBLE;
		}
		const _stringify = (_type) => {
			switch (_type) {
				case Scalar.Scalar.BLOCK_FOLDED:
				case Scalar.Scalar.BLOCK_LITERAL: return implicitKey || inFlow ? quotedString(ss.value, ctx) : blockString(ss, ctx, onComment, onChompKeep);
				case Scalar.Scalar.QUOTE_DOUBLE: return doubleQuotedString(ss.value, ctx);
				case Scalar.Scalar.QUOTE_SINGLE: return singleQuotedString(ss.value, ctx);
				case Scalar.Scalar.PLAIN: return plainString(ss, ctx, onComment, onChompKeep);
				default: return null;
			}
		};
		let res = _stringify(type);
		if (res === null) {
			const { defaultKeyType, defaultStringType } = ctx.options;
			const t = implicitKey && defaultKeyType || defaultStringType;
			res = _stringify(t);
			if (res === null) throw new Error(`Unsupported default string type ${t}`);
		}
		return res;
	}
	exports.stringifyString = stringifyString;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringify.js
var require_stringify = /* @__PURE__ */ __commonJSMin(((exports) => {
	var anchors = require_anchors();
	var identity = require_identity();
	var stringifyComment = require_stringifyComment();
	var stringifyString = require_stringifyString();
	function createStringifyContext(doc, options) {
		const opt = Object.assign({
			blockQuote: true,
			commentString: stringifyComment.stringifyComment,
			defaultKeyType: null,
			defaultStringType: "PLAIN",
			directives: null,
			doubleQuotedAsJSON: false,
			doubleQuotedMinMultiLineLength: 40,
			falseStr: "false",
			flowCollectionPadding: true,
			indentSeq: true,
			lineWidth: 80,
			minContentWidth: 20,
			nullStr: "null",
			simpleKeys: false,
			singleQuote: null,
			trueStr: "true",
			verifyAliasOrder: true
		}, doc.schema.toStringOptions, options);
		let inFlow;
		switch (opt.collectionStyle) {
			case "block":
				inFlow = false;
				break;
			case "flow":
				inFlow = true;
				break;
			default: inFlow = null;
		}
		return {
			anchors: /* @__PURE__ */ new Set(),
			doc,
			flowCollectionPadding: opt.flowCollectionPadding ? " " : "",
			indent: "",
			indentStep: typeof opt.indent === "number" ? " ".repeat(opt.indent) : "  ",
			inFlow,
			options: opt
		};
	}
	function getTagObject(tags, item) {
		if (item.tag) {
			const match = tags.filter((t) => t.tag === item.tag);
			if (match.length > 0) return match.find((t) => t.format === item.format) ?? match[0];
		}
		let tagObj = void 0;
		let obj;
		if (identity.isScalar(item)) {
			obj = item.value;
			let match = tags.filter((t) => t.identify?.(obj));
			if (match.length > 1) {
				const testMatch = match.filter((t) => t.test);
				if (testMatch.length > 0) match = testMatch;
			}
			tagObj = match.find((t) => t.format === item.format) ?? match.find((t) => !t.format);
		} else {
			obj = item;
			tagObj = tags.find((t) => t.nodeClass && obj instanceof t.nodeClass);
		}
		if (!tagObj) {
			const name = obj?.constructor?.name ?? (obj === null ? "null" : typeof obj);
			throw new Error(`Tag not resolved for ${name} value`);
		}
		return tagObj;
	}
	function stringifyProps(node, tagObj, { anchors: anchors$1, doc }) {
		if (!doc.directives) return "";
		const props = [];
		const anchor = (identity.isScalar(node) || identity.isCollection(node)) && node.anchor;
		if (anchor && anchors.anchorIsValid(anchor)) {
			anchors$1.add(anchor);
			props.push(`&${anchor}`);
		}
		const tag = node.tag ?? (tagObj.default ? null : tagObj.tag);
		if (tag) props.push(doc.directives.tagString(tag));
		return props.join(" ");
	}
	function stringify(item, ctx, onComment, onChompKeep) {
		if (identity.isPair(item)) return item.toString(ctx, onComment, onChompKeep);
		if (identity.isAlias(item)) {
			if (ctx.doc.directives) return item.toString(ctx);
			if (ctx.resolvedAliases?.has(item)) throw new TypeError(`Cannot stringify circular structure without alias nodes`);
			else {
				if (ctx.resolvedAliases) ctx.resolvedAliases.add(item);
				else ctx.resolvedAliases = new Set([item]);
				item = item.resolve(ctx.doc);
			}
		}
		let tagObj = void 0;
		const node = identity.isNode(item) ? item : ctx.doc.createNode(item, { onTagObj: (o) => tagObj = o });
		tagObj ?? (tagObj = getTagObject(ctx.doc.schema.tags, node));
		const props = stringifyProps(node, tagObj, ctx);
		if (props.length > 0) ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1;
		const str = typeof tagObj.stringify === "function" ? tagObj.stringify(node, ctx, onComment, onChompKeep) : identity.isScalar(node) ? stringifyString.stringifyString(node, ctx, onComment, onChompKeep) : node.toString(ctx, onComment, onChompKeep);
		if (!props) return str;
		return identity.isScalar(node) || str[0] === "{" || str[0] === "[" ? `${props} ${str}` : `${props}\n${ctx.indent}${str}`;
	}
	exports.createStringifyContext = createStringifyContext;
	exports.stringify = stringify;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyPair.js
var require_stringifyPair = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Scalar = require_Scalar();
	var stringify = require_stringify();
	var stringifyComment = require_stringifyComment();
	function stringifyPair({ key, value }, ctx, onComment, onChompKeep) {
		const { allNullValues, doc, indent, indentStep, options: { commentString, indentSeq, simpleKeys } } = ctx;
		let keyComment = identity.isNode(key) && key.comment || null;
		if (simpleKeys) {
			if (keyComment) throw new Error("With simple keys, key nodes cannot have comments");
			if (identity.isCollection(key) || !identity.isNode(key) && typeof key === "object") throw new Error("With simple keys, collection cannot be used as a key value");
		}
		let explicitKey = !simpleKeys && (!key || keyComment && value == null && !ctx.inFlow || identity.isCollection(key) || (identity.isScalar(key) ? key.type === Scalar.Scalar.BLOCK_FOLDED || key.type === Scalar.Scalar.BLOCK_LITERAL : typeof key === "object"));
		ctx = Object.assign({}, ctx, {
			allNullValues: false,
			implicitKey: !explicitKey && (simpleKeys || !allNullValues),
			indent: indent + indentStep
		});
		let keyCommentDone = false;
		let chompKeep = false;
		let str = stringify.stringify(key, ctx, () => keyCommentDone = true, () => chompKeep = true);
		if (!explicitKey && !ctx.inFlow && str.length > 1024) {
			if (simpleKeys) throw new Error("With simple keys, single line scalar must not span more than 1024 characters");
			explicitKey = true;
		}
		if (ctx.inFlow) {
			if (allNullValues || value == null) {
				if (keyCommentDone && onComment) onComment();
				return str === "" ? "?" : explicitKey ? `? ${str}` : str;
			}
		} else if (allNullValues && !simpleKeys || value == null && explicitKey) {
			str = `? ${str}`;
			if (keyComment && !keyCommentDone) str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));
			else if (chompKeep && onChompKeep) onChompKeep();
			return str;
		}
		if (keyCommentDone) keyComment = null;
		if (explicitKey) {
			if (keyComment) str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));
			str = `? ${str}\n${indent}:`;
		} else {
			str = `${str}:`;
			if (keyComment) str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));
		}
		let vsb, vcb, valueComment;
		if (identity.isNode(value)) {
			vsb = !!value.spaceBefore;
			vcb = value.commentBefore;
			valueComment = value.comment;
		} else {
			vsb = false;
			vcb = null;
			valueComment = null;
			if (value && typeof value === "object") value = doc.createNode(value);
		}
		ctx.implicitKey = false;
		if (!explicitKey && !keyComment && identity.isScalar(value)) ctx.indentAtStart = str.length + 1;
		chompKeep = false;
		if (!indentSeq && indentStep.length >= 2 && !ctx.inFlow && !explicitKey && identity.isSeq(value) && !value.flow && !value.tag && !value.anchor) ctx.indent = ctx.indent.substring(2);
		let valueCommentDone = false;
		const valueStr = stringify.stringify(value, ctx, () => valueCommentDone = true, () => chompKeep = true);
		let ws = " ";
		if (keyComment || vsb || vcb) {
			ws = vsb ? "\n" : "";
			if (vcb) {
				const cs = commentString(vcb);
				ws += `\n${stringifyComment.indentComment(cs, ctx.indent)}`;
			}
			if (valueStr === "" && !ctx.inFlow) {
				if (ws === "\n" && valueComment) ws = "\n\n";
			} else ws += `\n${ctx.indent}`;
		} else if (!explicitKey && identity.isCollection(value)) {
			const vs0 = valueStr[0];
			const nl0 = valueStr.indexOf("\n");
			const hasNewline = nl0 !== -1;
			const flow = ctx.inFlow ?? value.flow ?? value.items.length === 0;
			if (hasNewline || !flow) {
				let hasPropsLine = false;
				if (hasNewline && (vs0 === "&" || vs0 === "!")) {
					let sp0 = valueStr.indexOf(" ");
					if (vs0 === "&" && sp0 !== -1 && sp0 < nl0 && valueStr[sp0 + 1] === "!") sp0 = valueStr.indexOf(" ", sp0 + 1);
					if (sp0 === -1 || nl0 < sp0) hasPropsLine = true;
				}
				if (!hasPropsLine) ws = `\n${ctx.indent}`;
			}
		} else if (valueStr === "" || valueStr[0] === "\n") ws = "";
		str += ws + valueStr;
		if (ctx.inFlow) {
			if (valueCommentDone && onComment) onComment();
		} else if (valueComment && !valueCommentDone) str += stringifyComment.lineComment(str, ctx.indent, commentString(valueComment));
		else if (chompKeep && onChompKeep) onChompKeep();
		return str;
	}
	exports.stringifyPair = stringifyPair;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/log.js
var require_log = /* @__PURE__ */ __commonJSMin(((exports) => {
	var node_process$2 = __require$1("process");
	function debug(logLevel, ...messages) {
		if (logLevel === "debug") console.log(...messages);
	}
	function warn(logLevel, warning) {
		if (logLevel === "debug" || logLevel === "warn") if (typeof node_process$2.emitWarning === "function") node_process$2.emitWarning(warning);
		else console.warn(warning);
	}
	exports.debug = debug;
	exports.warn = warn;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/merge.js
var require_merge = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Scalar = require_Scalar();
	const MERGE_KEY = "<<";
	const merge = {
		identify: (value) => value === MERGE_KEY || typeof value === "symbol" && value.description === MERGE_KEY,
		default: "key",
		tag: "tag:yaml.org,2002:merge",
		test: /^<<$/,
		resolve: () => Object.assign(new Scalar.Scalar(Symbol(MERGE_KEY)), { addToJSMap: addMergeToJSMap }),
		stringify: () => MERGE_KEY
	};
	const isMergeKey = (ctx, key) => (merge.identify(key) || identity.isScalar(key) && (!key.type || key.type === Scalar.Scalar.PLAIN) && merge.identify(key.value)) && ctx?.doc.schema.tags.some((tag) => tag.tag === merge.tag && tag.default);
	function addMergeToJSMap(ctx, map, value) {
		value = ctx && identity.isAlias(value) ? value.resolve(ctx.doc) : value;
		if (identity.isSeq(value)) for (const it of value.items) mergeValue(ctx, map, it);
		else if (Array.isArray(value)) for (const it of value) mergeValue(ctx, map, it);
		else mergeValue(ctx, map, value);
	}
	function mergeValue(ctx, map, value) {
		const source = ctx && identity.isAlias(value) ? value.resolve(ctx.doc) : value;
		if (!identity.isMap(source)) throw new Error("Merge sources must be maps or map aliases");
		const srcMap = source.toJSON(null, ctx, Map);
		for (const [key, value] of srcMap) if (map instanceof Map) {
			if (!map.has(key)) map.set(key, value);
		} else if (map instanceof Set) map.add(key);
		else if (!Object.prototype.hasOwnProperty.call(map, key)) Object.defineProperty(map, key, {
			value,
			writable: true,
			enumerable: true,
			configurable: true
		});
		return map;
	}
	exports.addMergeToJSMap = addMergeToJSMap;
	exports.isMergeKey = isMergeKey;
	exports.merge = merge;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/addPairToJSMap.js
var require_addPairToJSMap = /* @__PURE__ */ __commonJSMin(((exports) => {
	var log = require_log();
	var merge = require_merge();
	var stringify = require_stringify();
	var identity = require_identity();
	var toJS = require_toJS();
	function addPairToJSMap(ctx, map, { key, value }) {
		if (identity.isNode(key) && key.addToJSMap) key.addToJSMap(ctx, map, value);
		else if (merge.isMergeKey(ctx, key)) merge.addMergeToJSMap(ctx, map, value);
		else {
			const jsKey = toJS.toJS(key, "", ctx);
			if (map instanceof Map) map.set(jsKey, toJS.toJS(value, jsKey, ctx));
			else if (map instanceof Set) map.add(jsKey);
			else {
				const stringKey = stringifyKey(key, jsKey, ctx);
				const jsValue = toJS.toJS(value, stringKey, ctx);
				if (stringKey in map) Object.defineProperty(map, stringKey, {
					value: jsValue,
					writable: true,
					enumerable: true,
					configurable: true
				});
				else map[stringKey] = jsValue;
			}
		}
		return map;
	}
	function stringifyKey(key, jsKey, ctx) {
		if (jsKey === null) return "";
		if (typeof jsKey !== "object") return String(jsKey);
		if (identity.isNode(key) && ctx?.doc) {
			const strCtx = stringify.createStringifyContext(ctx.doc, {});
			strCtx.anchors = /* @__PURE__ */ new Set();
			for (const node of ctx.anchors.keys()) strCtx.anchors.add(node.anchor);
			strCtx.inFlow = true;
			strCtx.inStringifyKey = true;
			const strKey = key.toString(strCtx);
			if (!ctx.mapKeyWarned) {
				let jsonStr = JSON.stringify(strKey);
				if (jsonStr.length > 40) jsonStr = jsonStr.substring(0, 36) + "...\"";
				log.warn(ctx.doc.options.logLevel, `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`);
				ctx.mapKeyWarned = true;
			}
			return strKey;
		}
		return JSON.stringify(jsKey);
	}
	exports.addPairToJSMap = addPairToJSMap;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Pair.js
var require_Pair = /* @__PURE__ */ __commonJSMin(((exports) => {
	var createNode = require_createNode();
	var stringifyPair = require_stringifyPair();
	var addPairToJSMap = require_addPairToJSMap();
	var identity = require_identity();
	function createPair(key, value, ctx) {
		return new Pair(createNode.createNode(key, void 0, ctx), createNode.createNode(value, void 0, ctx));
	}
	var Pair = class Pair {
		constructor(key, value = null) {
			Object.defineProperty(this, identity.NODE_TYPE, { value: identity.PAIR });
			this.key = key;
			this.value = value;
		}
		clone(schema) {
			let { key, value } = this;
			if (identity.isNode(key)) key = key.clone(schema);
			if (identity.isNode(value)) value = value.clone(schema);
			return new Pair(key, value);
		}
		toJSON(_, ctx) {
			const pair = ctx?.mapAsMap ? /* @__PURE__ */ new Map() : {};
			return addPairToJSMap.addPairToJSMap(ctx, pair, this);
		}
		toString(ctx, onComment, onChompKeep) {
			return ctx?.doc ? stringifyPair.stringifyPair(this, ctx, onComment, onChompKeep) : JSON.stringify(this);
		}
	};
	exports.Pair = Pair;
	exports.createPair = createPair;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyCollection.js
var require_stringifyCollection = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var stringify = require_stringify();
	var stringifyComment = require_stringifyComment();
	function stringifyCollection(collection, ctx, options) {
		return (ctx.inFlow ?? collection.flow ? stringifyFlowCollection : stringifyBlockCollection)(collection, ctx, options);
	}
	function stringifyBlockCollection({ comment, items }, ctx, { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }) {
		const { indent, options: { commentString } } = ctx;
		const itemCtx = Object.assign({}, ctx, {
			indent: itemIndent,
			type: null
		});
		let chompKeep = false;
		const lines = [];
		for (let i = 0; i < items.length; ++i) {
			const item = items[i];
			let comment = null;
			if (identity.isNode(item)) {
				if (!chompKeep && item.spaceBefore) lines.push("");
				addCommentBefore(ctx, lines, item.commentBefore, chompKeep);
				if (item.comment) comment = item.comment;
			} else if (identity.isPair(item)) {
				const ik = identity.isNode(item.key) ? item.key : null;
				if (ik) {
					if (!chompKeep && ik.spaceBefore) lines.push("");
					addCommentBefore(ctx, lines, ik.commentBefore, chompKeep);
				}
			}
			chompKeep = false;
			let str = stringify.stringify(item, itemCtx, () => comment = null, () => chompKeep = true);
			if (comment) str += stringifyComment.lineComment(str, itemIndent, commentString(comment));
			if (chompKeep && comment) chompKeep = false;
			lines.push(blockItemPrefix + str);
		}
		let str;
		if (lines.length === 0) str = flowChars.start + flowChars.end;
		else {
			str = lines[0];
			for (let i = 1; i < lines.length; ++i) {
				const line = lines[i];
				str += line ? `\n${indent}${line}` : "\n";
			}
		}
		if (comment) {
			str += "\n" + stringifyComment.indentComment(commentString(comment), indent);
			if (onComment) onComment();
		} else if (chompKeep && onChompKeep) onChompKeep();
		return str;
	}
	function stringifyFlowCollection({ items }, ctx, { flowChars, itemIndent }) {
		const { indent, indentStep, flowCollectionPadding: fcPadding, options: { commentString } } = ctx;
		itemIndent += indentStep;
		const itemCtx = Object.assign({}, ctx, {
			indent: itemIndent,
			inFlow: true,
			type: null
		});
		let reqNewline = false;
		let linesAtValue = 0;
		const lines = [];
		for (let i = 0; i < items.length; ++i) {
			const item = items[i];
			let comment = null;
			if (identity.isNode(item)) {
				if (item.spaceBefore) lines.push("");
				addCommentBefore(ctx, lines, item.commentBefore, false);
				if (item.comment) comment = item.comment;
			} else if (identity.isPair(item)) {
				const ik = identity.isNode(item.key) ? item.key : null;
				if (ik) {
					if (ik.spaceBefore) lines.push("");
					addCommentBefore(ctx, lines, ik.commentBefore, false);
					if (ik.comment) reqNewline = true;
				}
				const iv = identity.isNode(item.value) ? item.value : null;
				if (iv) {
					if (iv.comment) comment = iv.comment;
					if (iv.commentBefore) reqNewline = true;
				} else if (item.value == null && ik?.comment) comment = ik.comment;
			}
			if (comment) reqNewline = true;
			let str = stringify.stringify(item, itemCtx, () => comment = null);
			if (i < items.length - 1) str += ",";
			if (comment) str += stringifyComment.lineComment(str, itemIndent, commentString(comment));
			if (!reqNewline && (lines.length > linesAtValue || str.includes("\n"))) reqNewline = true;
			lines.push(str);
			linesAtValue = lines.length;
		}
		const { start, end } = flowChars;
		if (lines.length === 0) return start + end;
		else {
			if (!reqNewline) {
				const len = lines.reduce((sum, line) => sum + line.length + 2, 2);
				reqNewline = ctx.options.lineWidth > 0 && len > ctx.options.lineWidth;
			}
			if (reqNewline) {
				let str = start;
				for (const line of lines) str += line ? `\n${indentStep}${indent}${line}` : "\n";
				return `${str}\n${indent}${end}`;
			} else return `${start}${fcPadding}${lines.join(" ")}${fcPadding}${end}`;
		}
	}
	function addCommentBefore({ indent, options: { commentString } }, lines, comment, chompKeep) {
		if (comment && chompKeep) comment = comment.replace(/^\n+/, "");
		if (comment) {
			const ic = stringifyComment.indentComment(commentString(comment), indent);
			lines.push(ic.trimStart());
		}
	}
	exports.stringifyCollection = stringifyCollection;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/YAMLMap.js
var require_YAMLMap = /* @__PURE__ */ __commonJSMin(((exports) => {
	var stringifyCollection = require_stringifyCollection();
	var addPairToJSMap = require_addPairToJSMap();
	var Collection = require_Collection();
	var identity = require_identity();
	var Pair = require_Pair();
	var Scalar = require_Scalar();
	function findPair(items, key) {
		const k = identity.isScalar(key) ? key.value : key;
		for (const it of items) if (identity.isPair(it)) {
			if (it.key === key || it.key === k) return it;
			if (identity.isScalar(it.key) && it.key.value === k) return it;
		}
	}
	var YAMLMap = class extends Collection.Collection {
		static get tagName() {
			return "tag:yaml.org,2002:map";
		}
		constructor(schema) {
			super(identity.MAP, schema);
			this.items = [];
		}
		/**
		* A generic collection parsing method that can be extended
		* to other node classes that inherit from YAMLMap
		*/
		static from(schema, obj, ctx) {
			const { keepUndefined, replacer } = ctx;
			const map = new this(schema);
			const add = (key, value) => {
				if (typeof replacer === "function") value = replacer.call(obj, key, value);
				else if (Array.isArray(replacer) && !replacer.includes(key)) return;
				if (value !== void 0 || keepUndefined) map.items.push(Pair.createPair(key, value, ctx));
			};
			if (obj instanceof Map) for (const [key, value] of obj) add(key, value);
			else if (obj && typeof obj === "object") for (const key of Object.keys(obj)) add(key, obj[key]);
			if (typeof schema.sortMapEntries === "function") map.items.sort(schema.sortMapEntries);
			return map;
		}
		/**
		* Adds a value to the collection.
		*
		* @param overwrite - If not set `true`, using a key that is already in the
		*   collection will throw. Otherwise, overwrites the previous value.
		*/
		add(pair, overwrite) {
			let _pair;
			if (identity.isPair(pair)) _pair = pair;
			else if (!pair || typeof pair !== "object" || !("key" in pair)) _pair = new Pair.Pair(pair, pair?.value);
			else _pair = new Pair.Pair(pair.key, pair.value);
			const prev = findPair(this.items, _pair.key);
			const sortEntries = this.schema?.sortMapEntries;
			if (prev) {
				if (!overwrite) throw new Error(`Key ${_pair.key} already set`);
				if (identity.isScalar(prev.value) && Scalar.isScalarValue(_pair.value)) prev.value.value = _pair.value;
				else prev.value = _pair.value;
			} else if (sortEntries) {
				const i = this.items.findIndex((item) => sortEntries(_pair, item) < 0);
				if (i === -1) this.items.push(_pair);
				else this.items.splice(i, 0, _pair);
			} else this.items.push(_pair);
		}
		delete(key) {
			const it = findPair(this.items, key);
			if (!it) return false;
			return this.items.splice(this.items.indexOf(it), 1).length > 0;
		}
		get(key, keepScalar) {
			const node = findPair(this.items, key)?.value;
			return (!keepScalar && identity.isScalar(node) ? node.value : node) ?? void 0;
		}
		has(key) {
			return !!findPair(this.items, key);
		}
		set(key, value) {
			this.add(new Pair.Pair(key, value), true);
		}
		/**
		* @param ctx - Conversion context, originally set in Document#toJS()
		* @param {Class} Type - If set, forces the returned collection type
		* @returns Instance of Type, Map, or Object
		*/
		toJSON(_, ctx, Type) {
			const map = Type ? new Type() : ctx?.mapAsMap ? /* @__PURE__ */ new Map() : {};
			if (ctx?.onCreate) ctx.onCreate(map);
			for (const item of this.items) addPairToJSMap.addPairToJSMap(ctx, map, item);
			return map;
		}
		toString(ctx, onComment, onChompKeep) {
			if (!ctx) return JSON.stringify(this);
			for (const item of this.items) if (!identity.isPair(item)) throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);
			if (!ctx.allNullValues && this.hasAllNullValues(false)) ctx = Object.assign({}, ctx, { allNullValues: true });
			return stringifyCollection.stringifyCollection(this, ctx, {
				blockItemPrefix: "",
				flowChars: {
					start: "{",
					end: "}"
				},
				itemIndent: ctx.indent || "",
				onChompKeep,
				onComment
			});
		}
	};
	exports.YAMLMap = YAMLMap;
	exports.findPair = findPair;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/map.js
var require_map = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var YAMLMap = require_YAMLMap();
	const map = {
		collection: "map",
		default: true,
		nodeClass: YAMLMap.YAMLMap,
		tag: "tag:yaml.org,2002:map",
		resolve(map, onError) {
			if (!identity.isMap(map)) onError("Expected a mapping for this tag");
			return map;
		},
		createNode: (schema, obj, ctx) => YAMLMap.YAMLMap.from(schema, obj, ctx)
	};
	exports.map = map;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/YAMLSeq.js
var require_YAMLSeq = /* @__PURE__ */ __commonJSMin(((exports) => {
	var createNode = require_createNode();
	var stringifyCollection = require_stringifyCollection();
	var Collection = require_Collection();
	var identity = require_identity();
	var Scalar = require_Scalar();
	var toJS = require_toJS();
	var YAMLSeq = class extends Collection.Collection {
		static get tagName() {
			return "tag:yaml.org,2002:seq";
		}
		constructor(schema) {
			super(identity.SEQ, schema);
			this.items = [];
		}
		add(value) {
			this.items.push(value);
		}
		/**
		* Removes a value from the collection.
		*
		* `key` must contain a representation of an integer for this to succeed.
		* It may be wrapped in a `Scalar`.
		*
		* @returns `true` if the item was found and removed.
		*/
		delete(key) {
			const idx = asItemIndex(key);
			if (typeof idx !== "number") return false;
			return this.items.splice(idx, 1).length > 0;
		}
		get(key, keepScalar) {
			const idx = asItemIndex(key);
			if (typeof idx !== "number") return void 0;
			const it = this.items[idx];
			return !keepScalar && identity.isScalar(it) ? it.value : it;
		}
		/**
		* Checks if the collection includes a value with the key `key`.
		*
		* `key` must contain a representation of an integer for this to succeed.
		* It may be wrapped in a `Scalar`.
		*/
		has(key) {
			const idx = asItemIndex(key);
			return typeof idx === "number" && idx < this.items.length;
		}
		/**
		* Sets a value in this collection. For `!!set`, `value` needs to be a
		* boolean to add/remove the item from the set.
		*
		* If `key` does not contain a representation of an integer, this will throw.
		* It may be wrapped in a `Scalar`.
		*/
		set(key, value) {
			const idx = asItemIndex(key);
			if (typeof idx !== "number") throw new Error(`Expected a valid index, not ${key}.`);
			const prev = this.items[idx];
			if (identity.isScalar(prev) && Scalar.isScalarValue(value)) prev.value = value;
			else this.items[idx] = value;
		}
		toJSON(_, ctx) {
			const seq = [];
			if (ctx?.onCreate) ctx.onCreate(seq);
			let i = 0;
			for (const item of this.items) seq.push(toJS.toJS(item, String(i++), ctx));
			return seq;
		}
		toString(ctx, onComment, onChompKeep) {
			if (!ctx) return JSON.stringify(this);
			return stringifyCollection.stringifyCollection(this, ctx, {
				blockItemPrefix: "- ",
				flowChars: {
					start: "[",
					end: "]"
				},
				itemIndent: (ctx.indent || "") + "  ",
				onChompKeep,
				onComment
			});
		}
		static from(schema, obj, ctx) {
			const { replacer } = ctx;
			const seq = new this(schema);
			if (obj && Symbol.iterator in Object(obj)) {
				let i = 0;
				for (let it of obj) {
					if (typeof replacer === "function") {
						const key = obj instanceof Set ? it : String(i++);
						it = replacer.call(obj, key, it);
					}
					seq.items.push(createNode.createNode(it, void 0, ctx));
				}
			}
			return seq;
		}
	};
	function asItemIndex(key) {
		let idx = identity.isScalar(key) ? key.value : key;
		if (idx && typeof idx === "string") idx = Number(idx);
		return typeof idx === "number" && Number.isInteger(idx) && idx >= 0 ? idx : null;
	}
	exports.YAMLSeq = YAMLSeq;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/seq.js
var require_seq = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var YAMLSeq = require_YAMLSeq();
	const seq = {
		collection: "seq",
		default: true,
		nodeClass: YAMLSeq.YAMLSeq,
		tag: "tag:yaml.org,2002:seq",
		resolve(seq, onError) {
			if (!identity.isSeq(seq)) onError("Expected a sequence for this tag");
			return seq;
		},
		createNode: (schema, obj, ctx) => YAMLSeq.YAMLSeq.from(schema, obj, ctx)
	};
	exports.seq = seq;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/string.js
var require_string = /* @__PURE__ */ __commonJSMin(((exports) => {
	var stringifyString = require_stringifyString();
	const string = {
		identify: (value) => typeof value === "string",
		default: true,
		tag: "tag:yaml.org,2002:str",
		resolve: (str) => str,
		stringify(item, ctx, onComment, onChompKeep) {
			ctx = Object.assign({ actualString: true }, ctx);
			return stringifyString.stringifyString(item, ctx, onComment, onChompKeep);
		}
	};
	exports.string = string;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/null.js
var require_null = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	const nullTag = {
		identify: (value) => value == null,
		createNode: () => new Scalar.Scalar(null),
		default: true,
		tag: "tag:yaml.org,2002:null",
		test: /^(?:~|[Nn]ull|NULL)?$/,
		resolve: () => new Scalar.Scalar(null),
		stringify: ({ source }, ctx) => typeof source === "string" && nullTag.test.test(source) ? source : ctx.options.nullStr
	};
	exports.nullTag = nullTag;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/bool.js
var require_bool$1 = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	const boolTag = {
		identify: (value) => typeof value === "boolean",
		default: true,
		tag: "tag:yaml.org,2002:bool",
		test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,
		resolve: (str) => new Scalar.Scalar(str[0] === "t" || str[0] === "T"),
		stringify({ source, value }, ctx) {
			if (source && boolTag.test.test(source)) {
				if (value === (source[0] === "t" || source[0] === "T")) return source;
			}
			return value ? ctx.options.trueStr : ctx.options.falseStr;
		}
	};
	exports.boolTag = boolTag;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyNumber.js
var require_stringifyNumber = /* @__PURE__ */ __commonJSMin(((exports) => {
	function stringifyNumber({ format, minFractionDigits, tag, value }) {
		if (typeof value === "bigint") return String(value);
		const num = typeof value === "number" ? value : Number(value);
		if (!isFinite(num)) return isNaN(num) ? ".nan" : num < 0 ? "-.inf" : ".inf";
		let n = Object.is(value, -0) ? "-0" : JSON.stringify(value);
		if (!format && minFractionDigits && (!tag || tag === "tag:yaml.org,2002:float") && /^\d/.test(n)) {
			let i = n.indexOf(".");
			if (i < 0) {
				i = n.length;
				n += ".";
			}
			let d = minFractionDigits - (n.length - i - 1);
			while (d-- > 0) n += "0";
		}
		return n;
	}
	exports.stringifyNumber = stringifyNumber;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/float.js
var require_float$1 = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	var stringifyNumber = require_stringifyNumber();
	const floatNaN = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		test: /^(?:[-+]?\.(?:inf|Inf|INF)|\.nan|\.NaN|\.NAN)$/,
		resolve: (str) => str.slice(-3).toLowerCase() === "nan" ? NaN : str[0] === "-" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
		stringify: stringifyNumber.stringifyNumber
	};
	const floatExp = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		format: "EXP",
		test: /^[-+]?(?:\.[0-9]+|[0-9]+(?:\.[0-9]*)?)[eE][-+]?[0-9]+$/,
		resolve: (str) => parseFloat(str),
		stringify(node) {
			const num = Number(node.value);
			return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);
		}
	};
	const float = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		test: /^[-+]?(?:\.[0-9]+|[0-9]+\.[0-9]*)$/,
		resolve(str) {
			const node = new Scalar.Scalar(parseFloat(str));
			const dot = str.indexOf(".");
			if (dot !== -1 && str[str.length - 1] === "0") node.minFractionDigits = str.length - dot - 1;
			return node;
		},
		stringify: stringifyNumber.stringifyNumber
	};
	exports.float = float;
	exports.floatExp = floatExp;
	exports.floatNaN = floatNaN;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/int.js
var require_int$1 = /* @__PURE__ */ __commonJSMin(((exports) => {
	var stringifyNumber = require_stringifyNumber();
	const intIdentify = (value) => typeof value === "bigint" || Number.isInteger(value);
	const intResolve = (str, offset, radix, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix);
	function intStringify(node, radix, prefix) {
		const { value } = node;
		if (intIdentify(value) && value >= 0) return prefix + value.toString(radix);
		return stringifyNumber.stringifyNumber(node);
	}
	const intOct = {
		identify: (value) => intIdentify(value) && value >= 0,
		default: true,
		tag: "tag:yaml.org,2002:int",
		format: "OCT",
		test: /^0o[0-7]+$/,
		resolve: (str, _onError, opt) => intResolve(str, 2, 8, opt),
		stringify: (node) => intStringify(node, 8, "0o")
	};
	const int = {
		identify: intIdentify,
		default: true,
		tag: "tag:yaml.org,2002:int",
		test: /^[-+]?[0-9]+$/,
		resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
		stringify: stringifyNumber.stringifyNumber
	};
	const intHex = {
		identify: (value) => intIdentify(value) && value >= 0,
		default: true,
		tag: "tag:yaml.org,2002:int",
		format: "HEX",
		test: /^0x[0-9a-fA-F]+$/,
		resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
		stringify: (node) => intStringify(node, 16, "0x")
	};
	exports.int = int;
	exports.intHex = intHex;
	exports.intOct = intOct;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/schema.js
var require_schema$2 = /* @__PURE__ */ __commonJSMin(((exports) => {
	var map = require_map();
	var _null = require_null();
	var seq = require_seq();
	var string = require_string();
	var bool = require_bool$1();
	var float = require_float$1();
	var int = require_int$1();
	const schema = [
		map.map,
		seq.seq,
		string.string,
		_null.nullTag,
		bool.boolTag,
		int.intOct,
		int.int,
		int.intHex,
		float.floatNaN,
		float.floatExp,
		float.float
	];
	exports.schema = schema;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/json/schema.js
var require_schema$1 = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	var map = require_map();
	var seq = require_seq();
	function intIdentify(value) {
		return typeof value === "bigint" || Number.isInteger(value);
	}
	const stringifyJSON = ({ value }) => JSON.stringify(value);
	const jsonScalars = [
		{
			identify: (value) => typeof value === "string",
			default: true,
			tag: "tag:yaml.org,2002:str",
			resolve: (str) => str,
			stringify: stringifyJSON
		},
		{
			identify: (value) => value == null,
			createNode: () => new Scalar.Scalar(null),
			default: true,
			tag: "tag:yaml.org,2002:null",
			test: /^null$/,
			resolve: () => null,
			stringify: stringifyJSON
		},
		{
			identify: (value) => typeof value === "boolean",
			default: true,
			tag: "tag:yaml.org,2002:bool",
			test: /^true$|^false$/,
			resolve: (str) => str === "true",
			stringify: stringifyJSON
		},
		{
			identify: intIdentify,
			default: true,
			tag: "tag:yaml.org,2002:int",
			test: /^-?(?:0|[1-9][0-9]*)$/,
			resolve: (str, _onError, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str, 10),
			stringify: ({ value }) => intIdentify(value) ? value.toString() : JSON.stringify(value)
		},
		{
			identify: (value) => typeof value === "number",
			default: true,
			tag: "tag:yaml.org,2002:float",
			test: /^-?(?:0|[1-9][0-9]*)(?:\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,
			resolve: (str) => parseFloat(str),
			stringify: stringifyJSON
		}
	];
	const schema = [map.map, seq.seq].concat(jsonScalars, {
		default: true,
		tag: "",
		test: /^/,
		resolve(str, onError) {
			onError(`Unresolved plain scalar ${JSON.stringify(str)}`);
			return str;
		}
	});
	exports.schema = schema;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/binary.js
var require_binary = /* @__PURE__ */ __commonJSMin(((exports) => {
	var node_buffer = __require$1("buffer");
	var Scalar = require_Scalar();
	var stringifyString = require_stringifyString();
	const binary = {
		identify: (value) => value instanceof Uint8Array,
		default: false,
		tag: "tag:yaml.org,2002:binary",
		resolve(src, onError) {
			if (typeof node_buffer.Buffer === "function") return node_buffer.Buffer.from(src, "base64");
			else if (typeof atob === "function") {
				const str = atob(src.replace(/[\n\r]/g, ""));
				const buffer = new Uint8Array(str.length);
				for (let i = 0; i < str.length; ++i) buffer[i] = str.charCodeAt(i);
				return buffer;
			} else {
				onError("This environment does not support reading binary tags; either Buffer or atob is required");
				return src;
			}
		},
		stringify({ comment, type, value }, ctx, onComment, onChompKeep) {
			if (!value) return "";
			const buf = value;
			let str;
			if (typeof node_buffer.Buffer === "function") str = buf instanceof node_buffer.Buffer ? buf.toString("base64") : node_buffer.Buffer.from(buf.buffer).toString("base64");
			else if (typeof btoa === "function") {
				let s = "";
				for (let i = 0; i < buf.length; ++i) s += String.fromCharCode(buf[i]);
				str = btoa(s);
			} else throw new Error("This environment does not support writing binary tags; either Buffer or btoa is required");
			type ?? (type = Scalar.Scalar.BLOCK_LITERAL);
			if (type !== Scalar.Scalar.QUOTE_DOUBLE) {
				const lineWidth = Math.max(ctx.options.lineWidth - ctx.indent.length, ctx.options.minContentWidth);
				const n = Math.ceil(str.length / lineWidth);
				const lines = new Array(n);
				for (let i = 0, o = 0; i < n; ++i, o += lineWidth) lines[i] = str.substr(o, lineWidth);
				str = lines.join(type === Scalar.Scalar.BLOCK_LITERAL ? "\n" : " ");
			}
			return stringifyString.stringifyString({
				comment,
				type,
				value: str
			}, ctx, onComment, onChompKeep);
		}
	};
	exports.binary = binary;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/pairs.js
var require_pairs = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Pair = require_Pair();
	var Scalar = require_Scalar();
	var YAMLSeq = require_YAMLSeq();
	function resolvePairs(seq, onError) {
		if (identity.isSeq(seq)) for (let i = 0; i < seq.items.length; ++i) {
			let item = seq.items[i];
			if (identity.isPair(item)) continue;
			else if (identity.isMap(item)) {
				if (item.items.length > 1) onError("Each pair must have its own sequence indicator");
				const pair = item.items[0] || new Pair.Pair(new Scalar.Scalar(null));
				if (item.commentBefore) pair.key.commentBefore = pair.key.commentBefore ? `${item.commentBefore}\n${pair.key.commentBefore}` : item.commentBefore;
				if (item.comment) {
					const cn = pair.value ?? pair.key;
					cn.comment = cn.comment ? `${item.comment}\n${cn.comment}` : item.comment;
				}
				item = pair;
			}
			seq.items[i] = identity.isPair(item) ? item : new Pair.Pair(item);
		}
		else onError("Expected a sequence for this tag");
		return seq;
	}
	function createPairs(schema, iterable, ctx) {
		const { replacer } = ctx;
		const pairs = new YAMLSeq.YAMLSeq(schema);
		pairs.tag = "tag:yaml.org,2002:pairs";
		let i = 0;
		if (iterable && Symbol.iterator in Object(iterable)) for (let it of iterable) {
			if (typeof replacer === "function") it = replacer.call(iterable, String(i++), it);
			let key, value;
			if (Array.isArray(it)) if (it.length === 2) {
				key = it[0];
				value = it[1];
			} else throw new TypeError(`Expected [key, value] tuple: ${it}`);
			else if (it && it instanceof Object) {
				const keys = Object.keys(it);
				if (keys.length === 1) {
					key = keys[0];
					value = it[key];
				} else throw new TypeError(`Expected tuple with one key, not ${keys.length} keys`);
			} else key = it;
			pairs.items.push(Pair.createPair(key, value, ctx));
		}
		return pairs;
	}
	const pairs = {
		collection: "seq",
		default: false,
		tag: "tag:yaml.org,2002:pairs",
		resolve: resolvePairs,
		createNode: createPairs
	};
	exports.createPairs = createPairs;
	exports.pairs = pairs;
	exports.resolvePairs = resolvePairs;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/omap.js
var require_omap = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var toJS = require_toJS();
	var YAMLMap = require_YAMLMap();
	var YAMLSeq = require_YAMLSeq();
	var pairs = require_pairs();
	var YAMLOMap = class YAMLOMap extends YAMLSeq.YAMLSeq {
		constructor() {
			super();
			this.add = YAMLMap.YAMLMap.prototype.add.bind(this);
			this.delete = YAMLMap.YAMLMap.prototype.delete.bind(this);
			this.get = YAMLMap.YAMLMap.prototype.get.bind(this);
			this.has = YAMLMap.YAMLMap.prototype.has.bind(this);
			this.set = YAMLMap.YAMLMap.prototype.set.bind(this);
			this.tag = YAMLOMap.tag;
		}
		/**
		* If `ctx` is given, the return type is actually `Map<unknown, unknown>`,
		* but TypeScript won't allow widening the signature of a child method.
		*/
		toJSON(_, ctx) {
			if (!ctx) return super.toJSON(_);
			const map = /* @__PURE__ */ new Map();
			if (ctx?.onCreate) ctx.onCreate(map);
			for (const pair of this.items) {
				let key, value;
				if (identity.isPair(pair)) {
					key = toJS.toJS(pair.key, "", ctx);
					value = toJS.toJS(pair.value, key, ctx);
				} else key = toJS.toJS(pair, "", ctx);
				if (map.has(key)) throw new Error("Ordered maps must not include duplicate keys");
				map.set(key, value);
			}
			return map;
		}
		static from(schema, iterable, ctx) {
			const pairs$1 = pairs.createPairs(schema, iterable, ctx);
			const omap = new this();
			omap.items = pairs$1.items;
			return omap;
		}
	};
	YAMLOMap.tag = "tag:yaml.org,2002:omap";
	const omap = {
		collection: "seq",
		identify: (value) => value instanceof Map,
		nodeClass: YAMLOMap,
		default: false,
		tag: "tag:yaml.org,2002:omap",
		resolve(seq, onError) {
			const pairs$1 = pairs.resolvePairs(seq, onError);
			const seenKeys = [];
			for (const { key } of pairs$1.items) if (identity.isScalar(key)) if (seenKeys.includes(key.value)) onError(`Ordered maps must not include duplicate keys: ${key.value}`);
			else seenKeys.push(key.value);
			return Object.assign(new YAMLOMap(), pairs$1);
		},
		createNode: (schema, iterable, ctx) => YAMLOMap.from(schema, iterable, ctx)
	};
	exports.YAMLOMap = YAMLOMap;
	exports.omap = omap;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/bool.js
var require_bool = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	function boolStringify({ value, source }, ctx) {
		if (source && (value ? trueTag : falseTag).test.test(source)) return source;
		return value ? ctx.options.trueStr : ctx.options.falseStr;
	}
	const trueTag = {
		identify: (value) => value === true,
		default: true,
		tag: "tag:yaml.org,2002:bool",
		test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,
		resolve: () => new Scalar.Scalar(true),
		stringify: boolStringify
	};
	const falseTag = {
		identify: (value) => value === false,
		default: true,
		tag: "tag:yaml.org,2002:bool",
		test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/,
		resolve: () => new Scalar.Scalar(false),
		stringify: boolStringify
	};
	exports.falseTag = falseTag;
	exports.trueTag = trueTag;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/float.js
var require_float = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	var stringifyNumber = require_stringifyNumber();
	const floatNaN = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		test: /^(?:[-+]?\.(?:inf|Inf|INF)|\.nan|\.NaN|\.NAN)$/,
		resolve: (str) => str.slice(-3).toLowerCase() === "nan" ? NaN : str[0] === "-" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
		stringify: stringifyNumber.stringifyNumber
	};
	const floatExp = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		format: "EXP",
		test: /^[-+]?(?:[0-9][0-9_]*)?(?:\.[0-9_]*)?[eE][-+]?[0-9]+$/,
		resolve: (str) => parseFloat(str.replace(/_/g, "")),
		stringify(node) {
			const num = Number(node.value);
			return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);
		}
	};
	const float = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		test: /^[-+]?(?:[0-9][0-9_]*)?\.[0-9_]*$/,
		resolve(str) {
			const node = new Scalar.Scalar(parseFloat(str.replace(/_/g, "")));
			const dot = str.indexOf(".");
			if (dot !== -1) {
				const f = str.substring(dot + 1).replace(/_/g, "");
				if (f[f.length - 1] === "0") node.minFractionDigits = f.length;
			}
			return node;
		},
		stringify: stringifyNumber.stringifyNumber
	};
	exports.float = float;
	exports.floatExp = floatExp;
	exports.floatNaN = floatNaN;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/int.js
var require_int = /* @__PURE__ */ __commonJSMin(((exports) => {
	var stringifyNumber = require_stringifyNumber();
	const intIdentify = (value) => typeof value === "bigint" || Number.isInteger(value);
	function intResolve(str, offset, radix, { intAsBigInt }) {
		const sign = str[0];
		if (sign === "-" || sign === "+") offset += 1;
		str = str.substring(offset).replace(/_/g, "");
		if (intAsBigInt) {
			switch (radix) {
				case 2:
					str = `0b${str}`;
					break;
				case 8:
					str = `0o${str}`;
					break;
				case 16:
					str = `0x${str}`;
					break;
			}
			const n = BigInt(str);
			return sign === "-" ? BigInt(-1) * n : n;
		}
		const n = parseInt(str, radix);
		return sign === "-" ? -1 * n : n;
	}
	function intStringify(node, radix, prefix) {
		const { value } = node;
		if (intIdentify(value)) {
			const str = value.toString(radix);
			return value < 0 ? "-" + prefix + str.substr(1) : prefix + str;
		}
		return stringifyNumber.stringifyNumber(node);
	}
	const intBin = {
		identify: intIdentify,
		default: true,
		tag: "tag:yaml.org,2002:int",
		format: "BIN",
		test: /^[-+]?0b[0-1_]+$/,
		resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),
		stringify: (node) => intStringify(node, 2, "0b")
	};
	const intOct = {
		identify: intIdentify,
		default: true,
		tag: "tag:yaml.org,2002:int",
		format: "OCT",
		test: /^[-+]?0[0-7_]+$/,
		resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),
		stringify: (node) => intStringify(node, 8, "0")
	};
	const int = {
		identify: intIdentify,
		default: true,
		tag: "tag:yaml.org,2002:int",
		test: /^[-+]?[0-9][0-9_]*$/,
		resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
		stringify: stringifyNumber.stringifyNumber
	};
	const intHex = {
		identify: intIdentify,
		default: true,
		tag: "tag:yaml.org,2002:int",
		format: "HEX",
		test: /^[-+]?0x[0-9a-fA-F_]+$/,
		resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
		stringify: (node) => intStringify(node, 16, "0x")
	};
	exports.int = int;
	exports.intBin = intBin;
	exports.intHex = intHex;
	exports.intOct = intOct;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/set.js
var require_set = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Pair = require_Pair();
	var YAMLMap = require_YAMLMap();
	var YAMLSet = class YAMLSet extends YAMLMap.YAMLMap {
		constructor(schema) {
			super(schema);
			this.tag = YAMLSet.tag;
		}
		add(key) {
			let pair;
			if (identity.isPair(key)) pair = key;
			else if (key && typeof key === "object" && "key" in key && "value" in key && key.value === null) pair = new Pair.Pair(key.key, null);
			else pair = new Pair.Pair(key, null);
			if (!YAMLMap.findPair(this.items, pair.key)) this.items.push(pair);
		}
		/**
		* If `keepPair` is `true`, returns the Pair matching `key`.
		* Otherwise, returns the value of that Pair's key.
		*/
		get(key, keepPair) {
			const pair = YAMLMap.findPair(this.items, key);
			return !keepPair && identity.isPair(pair) ? identity.isScalar(pair.key) ? pair.key.value : pair.key : pair;
		}
		set(key, value) {
			if (typeof value !== "boolean") throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`);
			const prev = YAMLMap.findPair(this.items, key);
			if (prev && !value) this.items.splice(this.items.indexOf(prev), 1);
			else if (!prev && value) this.items.push(new Pair.Pair(key));
		}
		toJSON(_, ctx) {
			return super.toJSON(_, ctx, Set);
		}
		toString(ctx, onComment, onChompKeep) {
			if (!ctx) return JSON.stringify(this);
			if (this.hasAllNullValues(true)) return super.toString(Object.assign({}, ctx, { allNullValues: true }), onComment, onChompKeep);
			else throw new Error("Set items must all have null values");
		}
		static from(schema, iterable, ctx) {
			const { replacer } = ctx;
			const set = new this(schema);
			if (iterable && Symbol.iterator in Object(iterable)) for (let value of iterable) {
				if (typeof replacer === "function") value = replacer.call(iterable, value, value);
				set.items.push(Pair.createPair(value, null, ctx));
			}
			return set;
		}
	};
	YAMLSet.tag = "tag:yaml.org,2002:set";
	const set = {
		collection: "map",
		identify: (value) => value instanceof Set,
		nodeClass: YAMLSet,
		default: false,
		tag: "tag:yaml.org,2002:set",
		createNode: (schema, iterable, ctx) => YAMLSet.from(schema, iterable, ctx),
		resolve(map, onError) {
			if (identity.isMap(map)) if (map.hasAllNullValues(true)) return Object.assign(new YAMLSet(), map);
			else onError("Set items must all have null values");
			else onError("Expected a mapping for this tag");
			return map;
		}
	};
	exports.YAMLSet = YAMLSet;
	exports.set = set;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/timestamp.js
var require_timestamp = /* @__PURE__ */ __commonJSMin(((exports) => {
	var stringifyNumber = require_stringifyNumber();
	/** Internal types handle bigint as number, because TS can't figure it out. */
	function parseSexagesimal(str, asBigInt) {
		const sign = str[0];
		const parts = sign === "-" || sign === "+" ? str.substring(1) : str;
		const num = (n) => asBigInt ? BigInt(n) : Number(n);
		const res = parts.replace(/_/g, "").split(":").reduce((res, p) => res * num(60) + num(p), num(0));
		return sign === "-" ? num(-1) * res : res;
	}
	/**
	* hhhh:mm:ss.sss
	*
	* Internal types handle bigint as number, because TS can't figure it out.
	*/
	function stringifySexagesimal(node) {
		let { value } = node;
		let num = (n) => n;
		if (typeof value === "bigint") num = (n) => BigInt(n);
		else if (isNaN(value) || !isFinite(value)) return stringifyNumber.stringifyNumber(node);
		let sign = "";
		if (value < 0) {
			sign = "-";
			value *= num(-1);
		}
		const _60 = num(60);
		const parts = [value % _60];
		if (value < 60) parts.unshift(0);
		else {
			value = (value - parts[0]) / _60;
			parts.unshift(value % _60);
			if (value >= 60) {
				value = (value - parts[0]) / _60;
				parts.unshift(value);
			}
		}
		return sign + parts.map((n) => String(n).padStart(2, "0")).join(":").replace(/000000\d*$/, "");
	}
	const intTime = {
		identify: (value) => typeof value === "bigint" || Number.isInteger(value),
		default: true,
		tag: "tag:yaml.org,2002:int",
		format: "TIME",
		test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,
		resolve: (str, _onError, { intAsBigInt }) => parseSexagesimal(str, intAsBigInt),
		stringify: stringifySexagesimal
	};
	const floatTime = {
		identify: (value) => typeof value === "number",
		default: true,
		tag: "tag:yaml.org,2002:float",
		format: "TIME",
		test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\.[0-9_]*$/,
		resolve: (str) => parseSexagesimal(str, false),
		stringify: stringifySexagesimal
	};
	const timestamp = {
		identify: (value) => value instanceof Date,
		default: true,
		tag: "tag:yaml.org,2002:timestamp",
		test: RegExp("^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})(?:(?:t|T|[ \\t]+)([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\.[0-9]+)?)(?:[ \\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?)?$"),
		resolve(str) {
			const match = str.match(timestamp.test);
			if (!match) throw new Error("!!timestamp expects a date, starting with yyyy-mm-dd");
			const [, year, month, day, hour, minute, second] = match.map(Number);
			const millisec = match[7] ? Number((match[7] + "00").substr(1, 3)) : 0;
			let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec);
			const tz = match[8];
			if (tz && tz !== "Z") {
				let d = parseSexagesimal(tz, false);
				if (Math.abs(d) < 30) d *= 60;
				date -= 6e4 * d;
			}
			return new Date(date);
		},
		stringify: ({ value }) => value?.toISOString().replace(/(T00:00:00)?\.000Z$/, "") ?? ""
	};
	exports.floatTime = floatTime;
	exports.intTime = intTime;
	exports.timestamp = timestamp;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/schema.js
var require_schema = /* @__PURE__ */ __commonJSMin(((exports) => {
	var map = require_map();
	var _null = require_null();
	var seq = require_seq();
	var string = require_string();
	var binary = require_binary();
	var bool = require_bool();
	var float = require_float();
	var int = require_int();
	var merge = require_merge();
	var omap = require_omap();
	var pairs = require_pairs();
	var set = require_set();
	var timestamp = require_timestamp();
	const schema = [
		map.map,
		seq.seq,
		string.string,
		_null.nullTag,
		bool.trueTag,
		bool.falseTag,
		int.intBin,
		int.intOct,
		int.int,
		int.intHex,
		float.floatNaN,
		float.floatExp,
		float.float,
		binary.binary,
		merge.merge,
		omap.omap,
		pairs.pairs,
		set.set,
		timestamp.intTime,
		timestamp.floatTime,
		timestamp.timestamp
	];
	exports.schema = schema;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/tags.js
var require_tags = /* @__PURE__ */ __commonJSMin(((exports) => {
	var map = require_map();
	var _null = require_null();
	var seq = require_seq();
	var string = require_string();
	var bool = require_bool$1();
	var float = require_float$1();
	var int = require_int$1();
	var schema = require_schema$2();
	var schema$1 = require_schema$1();
	var binary = require_binary();
	var merge = require_merge();
	var omap = require_omap();
	var pairs = require_pairs();
	var schema$2 = require_schema();
	var set = require_set();
	var timestamp = require_timestamp();
	const schemas = new Map([
		["core", schema.schema],
		["failsafe", [
			map.map,
			seq.seq,
			string.string
		]],
		["json", schema$1.schema],
		["yaml11", schema$2.schema],
		["yaml-1.1", schema$2.schema]
	]);
	const tagsByName = {
		binary: binary.binary,
		bool: bool.boolTag,
		float: float.float,
		floatExp: float.floatExp,
		floatNaN: float.floatNaN,
		floatTime: timestamp.floatTime,
		int: int.int,
		intHex: int.intHex,
		intOct: int.intOct,
		intTime: timestamp.intTime,
		map: map.map,
		merge: merge.merge,
		null: _null.nullTag,
		omap: omap.omap,
		pairs: pairs.pairs,
		seq: seq.seq,
		set: set.set,
		timestamp: timestamp.timestamp
	};
	const coreKnownTags = {
		"tag:yaml.org,2002:binary": binary.binary,
		"tag:yaml.org,2002:merge": merge.merge,
		"tag:yaml.org,2002:omap": omap.omap,
		"tag:yaml.org,2002:pairs": pairs.pairs,
		"tag:yaml.org,2002:set": set.set,
		"tag:yaml.org,2002:timestamp": timestamp.timestamp
	};
	function getTags(customTags, schemaName, addMergeTag) {
		const schemaTags = schemas.get(schemaName);
		if (schemaTags && !customTags) return addMergeTag && !schemaTags.includes(merge.merge) ? schemaTags.concat(merge.merge) : schemaTags.slice();
		let tags = schemaTags;
		if (!tags) if (Array.isArray(customTags)) tags = [];
		else {
			const keys = Array.from(schemas.keys()).filter((key) => key !== "yaml11").map((key) => JSON.stringify(key)).join(", ");
			throw new Error(`Unknown schema "${schemaName}"; use one of ${keys} or define customTags array`);
		}
		if (Array.isArray(customTags)) for (const tag of customTags) tags = tags.concat(tag);
		else if (typeof customTags === "function") tags = customTags(tags.slice());
		if (addMergeTag) tags = tags.concat(merge.merge);
		return tags.reduce((tags, tag) => {
			const tagObj = typeof tag === "string" ? tagsByName[tag] : tag;
			if (!tagObj) {
				const tagName = JSON.stringify(tag);
				const keys = Object.keys(tagsByName).map((key) => JSON.stringify(key)).join(", ");
				throw new Error(`Unknown custom tag ${tagName}; use one of ${keys}`);
			}
			if (!tags.includes(tagObj)) tags.push(tagObj);
			return tags;
		}, []);
	}
	exports.coreKnownTags = coreKnownTags;
	exports.getTags = getTags;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/Schema.js
var require_Schema = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var map = require_map();
	var seq = require_seq();
	var string = require_string();
	var tags = require_tags();
	const sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;
	var Schema = class Schema {
		constructor({ compat, customTags, merge, resolveKnownTags, schema, sortMapEntries, toStringDefaults }) {
			this.compat = Array.isArray(compat) ? tags.getTags(compat, "compat") : compat ? tags.getTags(null, compat) : null;
			this.name = typeof schema === "string" && schema || "core";
			this.knownTags = resolveKnownTags ? tags.coreKnownTags : {};
			this.tags = tags.getTags(customTags, this.name, merge);
			this.toStringOptions = toStringDefaults ?? null;
			Object.defineProperty(this, identity.MAP, { value: map.map });
			Object.defineProperty(this, identity.SCALAR, { value: string.string });
			Object.defineProperty(this, identity.SEQ, { value: seq.seq });
			this.sortMapEntries = typeof sortMapEntries === "function" ? sortMapEntries : sortMapEntries === true ? sortMapEntriesByKey : null;
		}
		clone() {
			const copy = Object.create(Schema.prototype, Object.getOwnPropertyDescriptors(this));
			copy.tags = this.tags.slice();
			return copy;
		}
	};
	exports.Schema = Schema;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyDocument.js
var require_stringifyDocument = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var stringify = require_stringify();
	var stringifyComment = require_stringifyComment();
	function stringifyDocument(doc, options) {
		const lines = [];
		let hasDirectives = options.directives === true;
		if (options.directives !== false && doc.directives) {
			const dir = doc.directives.toString(doc);
			if (dir) {
				lines.push(dir);
				hasDirectives = true;
			} else if (doc.directives.docStart) hasDirectives = true;
		}
		if (hasDirectives) lines.push("---");
		const ctx = stringify.createStringifyContext(doc, options);
		const { commentString } = ctx.options;
		if (doc.commentBefore) {
			if (lines.length !== 1) lines.unshift("");
			const cs = commentString(doc.commentBefore);
			lines.unshift(stringifyComment.indentComment(cs, ""));
		}
		let chompKeep = false;
		let contentComment = null;
		if (doc.contents) {
			if (identity.isNode(doc.contents)) {
				if (doc.contents.spaceBefore && hasDirectives) lines.push("");
				if (doc.contents.commentBefore) {
					const cs = commentString(doc.contents.commentBefore);
					lines.push(stringifyComment.indentComment(cs, ""));
				}
				ctx.forceBlockIndent = !!doc.comment;
				contentComment = doc.contents.comment;
			}
			const onChompKeep = contentComment ? void 0 : () => chompKeep = true;
			let body = stringify.stringify(doc.contents, ctx, () => contentComment = null, onChompKeep);
			if (contentComment) body += stringifyComment.lineComment(body, "", commentString(contentComment));
			if ((body[0] === "|" || body[0] === ">") && lines[lines.length - 1] === "---") lines[lines.length - 1] = `--- ${body}`;
			else lines.push(body);
		} else lines.push(stringify.stringify(doc.contents, ctx));
		if (doc.directives?.docEnd) if (doc.comment) {
			const cs = commentString(doc.comment);
			if (cs.includes("\n")) {
				lines.push("...");
				lines.push(stringifyComment.indentComment(cs, ""));
			} else lines.push(`... ${cs}`);
		} else lines.push("...");
		else {
			let dc = doc.comment;
			if (dc && chompKeep) dc = dc.replace(/^\n+/, "");
			if (dc) {
				if ((!chompKeep || contentComment) && lines[lines.length - 1] !== "") lines.push("");
				lines.push(stringifyComment.indentComment(commentString(dc), ""));
			}
		}
		return lines.join("\n") + "\n";
	}
	exports.stringifyDocument = stringifyDocument;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/Document.js
var require_Document = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Alias = require_Alias();
	var Collection = require_Collection();
	var identity = require_identity();
	var Pair = require_Pair();
	var toJS = require_toJS();
	var Schema = require_Schema();
	var stringifyDocument = require_stringifyDocument();
	var anchors = require_anchors();
	var applyReviver = require_applyReviver();
	var createNode = require_createNode();
	var directives = require_directives();
	var Document = class Document {
		constructor(value, replacer, options) {
			/** A comment before this Document */
			this.commentBefore = null;
			/** A comment immediately after this Document */
			this.comment = null;
			/** Errors encountered during parsing. */
			this.errors = [];
			/** Warnings encountered during parsing. */
			this.warnings = [];
			Object.defineProperty(this, identity.NODE_TYPE, { value: identity.DOC });
			let _replacer = null;
			if (typeof replacer === "function" || Array.isArray(replacer)) _replacer = replacer;
			else if (options === void 0 && replacer) {
				options = replacer;
				replacer = void 0;
			}
			const opt = Object.assign({
				intAsBigInt: false,
				keepSourceTokens: false,
				logLevel: "warn",
				prettyErrors: true,
				strict: true,
				stringKeys: false,
				uniqueKeys: true,
				version: "1.2"
			}, options);
			this.options = opt;
			let { version } = opt;
			if (options?._directives) {
				this.directives = options._directives.atDocument();
				if (this.directives.yaml.explicit) version = this.directives.yaml.version;
			} else this.directives = new directives.Directives({ version });
			this.setSchema(version, options);
			this.contents = value === void 0 ? null : this.createNode(value, _replacer, options);
		}
		/**
		* Create a deep copy of this Document and its contents.
		*
		* Custom Node values that inherit from `Object` still refer to their original instances.
		*/
		clone() {
			const copy = Object.create(Document.prototype, { [identity.NODE_TYPE]: { value: identity.DOC } });
			copy.commentBefore = this.commentBefore;
			copy.comment = this.comment;
			copy.errors = this.errors.slice();
			copy.warnings = this.warnings.slice();
			copy.options = Object.assign({}, this.options);
			if (this.directives) copy.directives = this.directives.clone();
			copy.schema = this.schema.clone();
			copy.contents = identity.isNode(this.contents) ? this.contents.clone(copy.schema) : this.contents;
			if (this.range) copy.range = this.range.slice();
			return copy;
		}
		/** Adds a value to the document. */
		add(value) {
			if (assertCollection(this.contents)) this.contents.add(value);
		}
		/** Adds a value to the document. */
		addIn(path, value) {
			if (assertCollection(this.contents)) this.contents.addIn(path, value);
		}
		/**
		* Create a new `Alias` node, ensuring that the target `node` has the required anchor.
		*
		* If `node` already has an anchor, `name` is ignored.
		* Otherwise, the `node.anchor` value will be set to `name`,
		* or if an anchor with that name is already present in the document,
		* `name` will be used as a prefix for a new unique anchor.
		* If `name` is undefined, the generated anchor will use 'a' as a prefix.
		*/
		createAlias(node, name) {
			if (!node.anchor) {
				const prev = anchors.anchorNames(this);
				node.anchor = !name || prev.has(name) ? anchors.findNewAnchor(name || "a", prev) : name;
			}
			return new Alias.Alias(node.anchor);
		}
		createNode(value, replacer, options) {
			let _replacer = void 0;
			if (typeof replacer === "function") {
				value = replacer.call({ "": value }, "", value);
				_replacer = replacer;
			} else if (Array.isArray(replacer)) {
				const keyToStr = (v) => typeof v === "number" || v instanceof String || v instanceof Number;
				const asStr = replacer.filter(keyToStr).map(String);
				if (asStr.length > 0) replacer = replacer.concat(asStr);
				_replacer = replacer;
			} else if (options === void 0 && replacer) {
				options = replacer;
				replacer = void 0;
			}
			const { aliasDuplicateObjects, anchorPrefix, flow, keepUndefined, onTagObj, tag } = options ?? {};
			const { onAnchor, setAnchors, sourceObjects } = anchors.createNodeAnchors(this, anchorPrefix || "a");
			const ctx = {
				aliasDuplicateObjects: aliasDuplicateObjects ?? true,
				keepUndefined: keepUndefined ?? false,
				onAnchor,
				onTagObj,
				replacer: _replacer,
				schema: this.schema,
				sourceObjects
			};
			const node = createNode.createNode(value, tag, ctx);
			if (flow && identity.isCollection(node)) node.flow = true;
			setAnchors();
			return node;
		}
		/**
		* Convert a key and a value into a `Pair` using the current schema,
		* recursively wrapping all values as `Scalar` or `Collection` nodes.
		*/
		createPair(key, value, options = {}) {
			const k = this.createNode(key, null, options);
			const v = this.createNode(value, null, options);
			return new Pair.Pair(k, v);
		}
		/**
		* Removes a value from the document.
		* @returns `true` if the item was found and removed.
		*/
		delete(key) {
			return assertCollection(this.contents) ? this.contents.delete(key) : false;
		}
		/**
		* Removes a value from the document.
		* @returns `true` if the item was found and removed.
		*/
		deleteIn(path) {
			if (Collection.isEmptyPath(path)) {
				if (this.contents == null) return false;
				this.contents = null;
				return true;
			}
			return assertCollection(this.contents) ? this.contents.deleteIn(path) : false;
		}
		/**
		* Returns item at `key`, or `undefined` if not found. By default unwraps
		* scalar values from their surrounding node; to disable set `keepScalar` to
		* `true` (collections are always returned intact).
		*/
		get(key, keepScalar) {
			return identity.isCollection(this.contents) ? this.contents.get(key, keepScalar) : void 0;
		}
		/**
		* Returns item at `path`, or `undefined` if not found. By default unwraps
		* scalar values from their surrounding node; to disable set `keepScalar` to
		* `true` (collections are always returned intact).
		*/
		getIn(path, keepScalar) {
			if (Collection.isEmptyPath(path)) return !keepScalar && identity.isScalar(this.contents) ? this.contents.value : this.contents;
			return identity.isCollection(this.contents) ? this.contents.getIn(path, keepScalar) : void 0;
		}
		/**
		* Checks if the document includes a value with the key `key`.
		*/
		has(key) {
			return identity.isCollection(this.contents) ? this.contents.has(key) : false;
		}
		/**
		* Checks if the document includes a value at `path`.
		*/
		hasIn(path) {
			if (Collection.isEmptyPath(path)) return this.contents !== void 0;
			return identity.isCollection(this.contents) ? this.contents.hasIn(path) : false;
		}
		/**
		* Sets a value in this document. For `!!set`, `value` needs to be a
		* boolean to add/remove the item from the set.
		*/
		set(key, value) {
			if (this.contents == null) this.contents = Collection.collectionFromPath(this.schema, [key], value);
			else if (assertCollection(this.contents)) this.contents.set(key, value);
		}
		/**
		* Sets a value in this document. For `!!set`, `value` needs to be a
		* boolean to add/remove the item from the set.
		*/
		setIn(path, value) {
			if (Collection.isEmptyPath(path)) this.contents = value;
			else if (this.contents == null) this.contents = Collection.collectionFromPath(this.schema, Array.from(path), value);
			else if (assertCollection(this.contents)) this.contents.setIn(path, value);
		}
		/**
		* Change the YAML version and schema used by the document.
		* A `null` version disables support for directives, explicit tags, anchors, and aliases.
		* It also requires the `schema` option to be given as a `Schema` instance value.
		*
		* Overrides all previously set schema options.
		*/
		setSchema(version, options = {}) {
			if (typeof version === "number") version = String(version);
			let opt;
			switch (version) {
				case "1.1":
					if (this.directives) this.directives.yaml.version = "1.1";
					else this.directives = new directives.Directives({ version: "1.1" });
					opt = {
						resolveKnownTags: false,
						schema: "yaml-1.1"
					};
					break;
				case "1.2":
				case "next":
					if (this.directives) this.directives.yaml.version = version;
					else this.directives = new directives.Directives({ version });
					opt = {
						resolveKnownTags: true,
						schema: "core"
					};
					break;
				case null:
					if (this.directives) delete this.directives;
					opt = null;
					break;
				default: {
					const sv = JSON.stringify(version);
					throw new Error(`Expected '1.1', '1.2' or null as first argument, but found: ${sv}`);
				}
			}
			if (options.schema instanceof Object) this.schema = options.schema;
			else if (opt) this.schema = new Schema.Schema(Object.assign(opt, options));
			else throw new Error(`With a null YAML version, the { schema: Schema } option is required`);
		}
		toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
			const ctx = {
				anchors: /* @__PURE__ */ new Map(),
				doc: this,
				keep: !json,
				mapAsMap: mapAsMap === true,
				mapKeyWarned: false,
				maxAliasCount: typeof maxAliasCount === "number" ? maxAliasCount : 100
			};
			const res = toJS.toJS(this.contents, jsonArg ?? "", ctx);
			if (typeof onAnchor === "function") for (const { count, res } of ctx.anchors.values()) onAnchor(res, count);
			return typeof reviver === "function" ? applyReviver.applyReviver(reviver, { "": res }, "", res) : res;
		}
		/**
		* A JSON representation of the document `contents`.
		*
		* @param jsonArg Used by `JSON.stringify` to indicate the array index or
		*   property name.
		*/
		toJSON(jsonArg, onAnchor) {
			return this.toJS({
				json: true,
				jsonArg,
				mapAsMap: false,
				onAnchor
			});
		}
		/** A YAML representation of the document. */
		toString(options = {}) {
			if (this.errors.length > 0) throw new Error("Document with errors cannot be stringified");
			if ("indent" in options && (!Number.isInteger(options.indent) || Number(options.indent) <= 0)) {
				const s = JSON.stringify(options.indent);
				throw new Error(`"indent" option must be a positive integer, not ${s}`);
			}
			return stringifyDocument.stringifyDocument(this, options);
		}
	};
	function assertCollection(contents) {
		if (identity.isCollection(contents)) return true;
		throw new Error("Expected a YAML collection as document contents");
	}
	exports.Document = Document;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/errors.js
var require_errors = /* @__PURE__ */ __commonJSMin(((exports) => {
	var YAMLError = class extends Error {
		constructor(name, pos, code, message) {
			super();
			this.name = name;
			this.code = code;
			this.message = message;
			this.pos = pos;
		}
	};
	var YAMLParseError = class extends YAMLError {
		constructor(pos, code, message) {
			super("YAMLParseError", pos, code, message);
		}
	};
	var YAMLWarning = class extends YAMLError {
		constructor(pos, code, message) {
			super("YAMLWarning", pos, code, message);
		}
	};
	const prettifyError = (src, lc) => (error) => {
		if (error.pos[0] === -1) return;
		error.linePos = error.pos.map((pos) => lc.linePos(pos));
		const { line, col } = error.linePos[0];
		error.message += ` at line ${line}, column ${col}`;
		let ci = col - 1;
		let lineStr = src.substring(lc.lineStarts[line - 1], lc.lineStarts[line]).replace(/[\n\r]+$/, "");
		if (ci >= 60 && lineStr.length > 80) {
			const trimStart = Math.min(ci - 39, lineStr.length - 79);
			lineStr = "" + lineStr.substring(trimStart);
			ci -= trimStart - 1;
		}
		if (lineStr.length > 80) lineStr = lineStr.substring(0, 79) + "";
		if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {
			let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1]);
			if (prev.length > 80) prev = prev.substring(0, 79) + "\n";
			lineStr = prev + lineStr;
		}
		if (/[^ ]/.test(lineStr)) {
			let count = 1;
			const end = error.linePos[1];
			if (end?.line === line && end.col > col) count = Math.max(1, Math.min(end.col - col, 80 - ci));
			const pointer = " ".repeat(ci) + "^".repeat(count);
			error.message += `:\n\n${lineStr}\n${pointer}\n`;
		}
	};
	exports.YAMLError = YAMLError;
	exports.YAMLParseError = YAMLParseError;
	exports.YAMLWarning = YAMLWarning;
	exports.prettifyError = prettifyError;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-props.js
var require_resolve_props = /* @__PURE__ */ __commonJSMin(((exports) => {
	function resolveProps(tokens, { flow, indicator, next, offset, onError, parentIndent, startOnNewline }) {
		let spaceBefore = false;
		let atNewline = startOnNewline;
		let hasSpace = startOnNewline;
		let comment = "";
		let commentSep = "";
		let hasNewline = false;
		let reqSpace = false;
		let tab = null;
		let anchor = null;
		let tag = null;
		let newlineAfterProp = null;
		let comma = null;
		let found = null;
		let start = null;
		for (const token of tokens) {
			if (reqSpace) {
				if (token.type !== "space" && token.type !== "newline" && token.type !== "comma") onError(token.offset, "MISSING_CHAR", "Tags and anchors must be separated from the next token by white space");
				reqSpace = false;
			}
			if (tab) {
				if (atNewline && token.type !== "comment" && token.type !== "newline") onError(tab, "TAB_AS_INDENT", "Tabs are not allowed as indentation");
				tab = null;
			}
			switch (token.type) {
				case "space":
					if (!flow && (indicator !== "doc-start" || next?.type !== "flow-collection") && token.source.includes("	")) tab = token;
					hasSpace = true;
					break;
				case "comment": {
					if (!hasSpace) onError(token, "MISSING_CHAR", "Comments must be separated from other tokens by white space characters");
					const cb = token.source.substring(1) || " ";
					if (!comment) comment = cb;
					else comment += commentSep + cb;
					commentSep = "";
					atNewline = false;
					break;
				}
				case "newline":
					if (atNewline) {
						if (comment) comment += token.source;
						else if (!found || indicator !== "seq-item-ind") spaceBefore = true;
					} else commentSep += token.source;
					atNewline = true;
					hasNewline = true;
					if (anchor || tag) newlineAfterProp = token;
					hasSpace = true;
					break;
				case "anchor":
					if (anchor) onError(token, "MULTIPLE_ANCHORS", "A node can have at most one anchor");
					if (token.source.endsWith(":")) onError(token.offset + token.source.length - 1, "BAD_ALIAS", "Anchor ending in : is ambiguous", true);
					anchor = token;
					start ?? (start = token.offset);
					atNewline = false;
					hasSpace = false;
					reqSpace = true;
					break;
				case "tag":
					if (tag) onError(token, "MULTIPLE_TAGS", "A node can have at most one tag");
					tag = token;
					start ?? (start = token.offset);
					atNewline = false;
					hasSpace = false;
					reqSpace = true;
					break;
				case indicator:
					if (anchor || tag) onError(token, "BAD_PROP_ORDER", `Anchors and tags must be after the ${token.source} indicator`);
					if (found) onError(token, "UNEXPECTED_TOKEN", `Unexpected ${token.source} in ${flow ?? "collection"}`);
					found = token;
					atNewline = indicator === "seq-item-ind" || indicator === "explicit-key-ind";
					hasSpace = false;
					break;
				case "comma": if (flow) {
					if (comma) onError(token, "UNEXPECTED_TOKEN", `Unexpected , in ${flow}`);
					comma = token;
					atNewline = false;
					hasSpace = false;
					break;
				}
				default:
					onError(token, "UNEXPECTED_TOKEN", `Unexpected ${token.type} token`);
					atNewline = false;
					hasSpace = false;
			}
		}
		const last = tokens[tokens.length - 1];
		const end = last ? last.offset + last.source.length : offset;
		if (reqSpace && next && next.type !== "space" && next.type !== "newline" && next.type !== "comma" && (next.type !== "scalar" || next.source !== "")) onError(next.offset, "MISSING_CHAR", "Tags and anchors must be separated from the next token by white space");
		if (tab && (atNewline && tab.indent <= parentIndent || next?.type === "block-map" || next?.type === "block-seq")) onError(tab, "TAB_AS_INDENT", "Tabs are not allowed as indentation");
		return {
			comma,
			found,
			spaceBefore,
			comment,
			hasNewline,
			anchor,
			tag,
			newlineAfterProp,
			end,
			start: start ?? end
		};
	}
	exports.resolveProps = resolveProps;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-contains-newline.js
var require_util_contains_newline = /* @__PURE__ */ __commonJSMin(((exports) => {
	function containsNewline(key) {
		if (!key) return null;
		switch (key.type) {
			case "alias":
			case "scalar":
			case "double-quoted-scalar":
			case "single-quoted-scalar":
				if (key.source.includes("\n")) return true;
				if (key.end) {
					for (const st of key.end) if (st.type === "newline") return true;
				}
				return false;
			case "flow-collection":
				for (const it of key.items) {
					for (const st of it.start) if (st.type === "newline") return true;
					if (it.sep) {
						for (const st of it.sep) if (st.type === "newline") return true;
					}
					if (containsNewline(it.key) || containsNewline(it.value)) return true;
				}
				return false;
			default: return true;
		}
	}
	exports.containsNewline = containsNewline;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-flow-indent-check.js
var require_util_flow_indent_check = /* @__PURE__ */ __commonJSMin(((exports) => {
	var utilContainsNewline = require_util_contains_newline();
	function flowIndentCheck(indent, fc, onError) {
		if (fc?.type === "flow-collection") {
			const end = fc.end[0];
			if (end.indent === indent && (end.source === "]" || end.source === "}") && utilContainsNewline.containsNewline(fc)) onError(end, "BAD_INDENT", "Flow end indicator should be more indented than parent", true);
		}
	}
	exports.flowIndentCheck = flowIndentCheck;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-map-includes.js
var require_util_map_includes = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	function mapIncludes(ctx, items, search) {
		const { uniqueKeys } = ctx.options;
		if (uniqueKeys === false) return false;
		const isEqual = typeof uniqueKeys === "function" ? uniqueKeys : (a, b) => a === b || identity.isScalar(a) && identity.isScalar(b) && a.value === b.value;
		return items.some((pair) => isEqual(pair.key, search));
	}
	exports.mapIncludes = mapIncludes;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-map.js
var require_resolve_block_map = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Pair = require_Pair();
	var YAMLMap = require_YAMLMap();
	var resolveProps = require_resolve_props();
	var utilContainsNewline = require_util_contains_newline();
	var utilFlowIndentCheck = require_util_flow_indent_check();
	var utilMapIncludes = require_util_map_includes();
	const startColMsg = "All mapping items must start at the same column";
	function resolveBlockMap({ composeNode, composeEmptyNode }, ctx, bm, onError, tag) {
		const map = new (tag?.nodeClass ?? YAMLMap.YAMLMap)(ctx.schema);
		if (ctx.atRoot) ctx.atRoot = false;
		let offset = bm.offset;
		let commentEnd = null;
		for (const collItem of bm.items) {
			const { start, key, sep, value } = collItem;
			const keyProps = resolveProps.resolveProps(start, {
				indicator: "explicit-key-ind",
				next: key ?? sep?.[0],
				offset,
				onError,
				parentIndent: bm.indent,
				startOnNewline: true
			});
			const implicitKey = !keyProps.found;
			if (implicitKey) {
				if (key) {
					if (key.type === "block-seq") onError(offset, "BLOCK_AS_IMPLICIT_KEY", "A block sequence may not be used as an implicit map key");
					else if ("indent" in key && key.indent !== bm.indent) onError(offset, "BAD_INDENT", startColMsg);
				}
				if (!keyProps.anchor && !keyProps.tag && !sep) {
					commentEnd = keyProps.end;
					if (keyProps.comment) if (map.comment) map.comment += "\n" + keyProps.comment;
					else map.comment = keyProps.comment;
					continue;
				}
				if (keyProps.newlineAfterProp || utilContainsNewline.containsNewline(key)) onError(key ?? start[start.length - 1], "MULTILINE_IMPLICIT_KEY", "Implicit keys need to be on a single line");
			} else if (keyProps.found?.indent !== bm.indent) onError(offset, "BAD_INDENT", startColMsg);
			ctx.atKey = true;
			const keyStart = keyProps.end;
			const keyNode = key ? composeNode(ctx, key, keyProps, onError) : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError);
			if (ctx.schema.compat) utilFlowIndentCheck.flowIndentCheck(bm.indent, key, onError);
			ctx.atKey = false;
			if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode)) onError(keyStart, "DUPLICATE_KEY", "Map keys must be unique");
			const valueProps = resolveProps.resolveProps(sep ?? [], {
				indicator: "map-value-ind",
				next: value,
				offset: keyNode.range[2],
				onError,
				parentIndent: bm.indent,
				startOnNewline: !key || key.type === "block-scalar"
			});
			offset = valueProps.end;
			if (valueProps.found) {
				if (implicitKey) {
					if (value?.type === "block-map" && !valueProps.hasNewline) onError(offset, "BLOCK_AS_IMPLICIT_KEY", "Nested mappings are not allowed in compact mappings");
					if (ctx.options.strict && keyProps.start < valueProps.found.offset - 1024) onError(keyNode.range, "KEY_OVER_1024_CHARS", "The : indicator must be at most 1024 chars after the start of an implicit block mapping key");
				}
				const valueNode = value ? composeNode(ctx, value, valueProps, onError) : composeEmptyNode(ctx, offset, sep, null, valueProps, onError);
				if (ctx.schema.compat) utilFlowIndentCheck.flowIndentCheck(bm.indent, value, onError);
				offset = valueNode.range[2];
				const pair = new Pair.Pair(keyNode, valueNode);
				if (ctx.options.keepSourceTokens) pair.srcToken = collItem;
				map.items.push(pair);
			} else {
				if (implicitKey) onError(keyNode.range, "MISSING_CHAR", "Implicit map keys need to be followed by map values");
				if (valueProps.comment) if (keyNode.comment) keyNode.comment += "\n" + valueProps.comment;
				else keyNode.comment = valueProps.comment;
				const pair = new Pair.Pair(keyNode);
				if (ctx.options.keepSourceTokens) pair.srcToken = collItem;
				map.items.push(pair);
			}
		}
		if (commentEnd && commentEnd < offset) onError(commentEnd, "IMPOSSIBLE", "Map comment with trailing content");
		map.range = [
			bm.offset,
			offset,
			commentEnd ?? offset
		];
		return map;
	}
	exports.resolveBlockMap = resolveBlockMap;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-seq.js
var require_resolve_block_seq = /* @__PURE__ */ __commonJSMin(((exports) => {
	var YAMLSeq = require_YAMLSeq();
	var resolveProps = require_resolve_props();
	var utilFlowIndentCheck = require_util_flow_indent_check();
	function resolveBlockSeq({ composeNode, composeEmptyNode }, ctx, bs, onError, tag) {
		const seq = new (tag?.nodeClass ?? YAMLSeq.YAMLSeq)(ctx.schema);
		if (ctx.atRoot) ctx.atRoot = false;
		if (ctx.atKey) ctx.atKey = false;
		let offset = bs.offset;
		let commentEnd = null;
		for (const { start, value } of bs.items) {
			const props = resolveProps.resolveProps(start, {
				indicator: "seq-item-ind",
				next: value,
				offset,
				onError,
				parentIndent: bs.indent,
				startOnNewline: true
			});
			if (!props.found) if (props.anchor || props.tag || value) if (value?.type === "block-seq") onError(props.end, "BAD_INDENT", "All sequence items must start at the same column");
			else onError(offset, "MISSING_CHAR", "Sequence item without - indicator");
			else {
				commentEnd = props.end;
				if (props.comment) seq.comment = props.comment;
				continue;
			}
			const node = value ? composeNode(ctx, value, props, onError) : composeEmptyNode(ctx, props.end, start, null, props, onError);
			if (ctx.schema.compat) utilFlowIndentCheck.flowIndentCheck(bs.indent, value, onError);
			offset = node.range[2];
			seq.items.push(node);
		}
		seq.range = [
			bs.offset,
			offset,
			commentEnd ?? offset
		];
		return seq;
	}
	exports.resolveBlockSeq = resolveBlockSeq;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-end.js
var require_resolve_end = /* @__PURE__ */ __commonJSMin(((exports) => {
	function resolveEnd(end, offset, reqSpace, onError) {
		let comment = "";
		if (end) {
			let hasSpace = false;
			let sep = "";
			for (const token of end) {
				const { source, type } = token;
				switch (type) {
					case "space":
						hasSpace = true;
						break;
					case "comment": {
						if (reqSpace && !hasSpace) onError(token, "MISSING_CHAR", "Comments must be separated from other tokens by white space characters");
						const cb = source.substring(1) || " ";
						if (!comment) comment = cb;
						else comment += sep + cb;
						sep = "";
						break;
					}
					case "newline":
						if (comment) sep += source;
						hasSpace = true;
						break;
					default: onError(token, "UNEXPECTED_TOKEN", `Unexpected ${type} at node end`);
				}
				offset += source.length;
			}
		}
		return {
			comment,
			offset
		};
	}
	exports.resolveEnd = resolveEnd;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-flow-collection.js
var require_resolve_flow_collection = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Pair = require_Pair();
	var YAMLMap = require_YAMLMap();
	var YAMLSeq = require_YAMLSeq();
	var resolveEnd = require_resolve_end();
	var resolveProps = require_resolve_props();
	var utilContainsNewline = require_util_contains_newline();
	var utilMapIncludes = require_util_map_includes();
	const blockMsg = "Block collections are not allowed within flow collections";
	const isBlock = (token) => token && (token.type === "block-map" || token.type === "block-seq");
	function resolveFlowCollection({ composeNode, composeEmptyNode }, ctx, fc, onError, tag) {
		const isMap = fc.start.source === "{";
		const fcName = isMap ? "flow map" : "flow sequence";
		const coll = new (tag?.nodeClass ?? (isMap ? YAMLMap.YAMLMap : YAMLSeq.YAMLSeq))(ctx.schema);
		coll.flow = true;
		const atRoot = ctx.atRoot;
		if (atRoot) ctx.atRoot = false;
		if (ctx.atKey) ctx.atKey = false;
		let offset = fc.offset + fc.start.source.length;
		for (let i = 0; i < fc.items.length; ++i) {
			const collItem = fc.items[i];
			const { start, key, sep, value } = collItem;
			const props = resolveProps.resolveProps(start, {
				flow: fcName,
				indicator: "explicit-key-ind",
				next: key ?? sep?.[0],
				offset,
				onError,
				parentIndent: fc.indent,
				startOnNewline: false
			});
			if (!props.found) {
				if (!props.anchor && !props.tag && !sep && !value) {
					if (i === 0 && props.comma) onError(props.comma, "UNEXPECTED_TOKEN", `Unexpected , in ${fcName}`);
					else if (i < fc.items.length - 1) onError(props.start, "UNEXPECTED_TOKEN", `Unexpected empty item in ${fcName}`);
					if (props.comment) if (coll.comment) coll.comment += "\n" + props.comment;
					else coll.comment = props.comment;
					offset = props.end;
					continue;
				}
				if (!isMap && ctx.options.strict && utilContainsNewline.containsNewline(key)) onError(key, "MULTILINE_IMPLICIT_KEY", "Implicit keys of flow sequence pairs need to be on a single line");
			}
			if (i === 0) {
				if (props.comma) onError(props.comma, "UNEXPECTED_TOKEN", `Unexpected , in ${fcName}`);
			} else {
				if (!props.comma) onError(props.start, "MISSING_CHAR", `Missing , between ${fcName} items`);
				if (props.comment) {
					let prevItemComment = "";
					loop: for (const st of start) switch (st.type) {
						case "comma":
						case "space": break;
						case "comment":
							prevItemComment = st.source.substring(1);
							break loop;
						default: break loop;
					}
					if (prevItemComment) {
						let prev = coll.items[coll.items.length - 1];
						if (identity.isPair(prev)) prev = prev.value ?? prev.key;
						if (prev.comment) prev.comment += "\n" + prevItemComment;
						else prev.comment = prevItemComment;
						props.comment = props.comment.substring(prevItemComment.length + 1);
					}
				}
			}
			if (!isMap && !sep && !props.found) {
				const valueNode = value ? composeNode(ctx, value, props, onError) : composeEmptyNode(ctx, props.end, sep, null, props, onError);
				coll.items.push(valueNode);
				offset = valueNode.range[2];
				if (isBlock(value)) onError(valueNode.range, "BLOCK_IN_FLOW", blockMsg);
			} else {
				ctx.atKey = true;
				const keyStart = props.end;
				const keyNode = key ? composeNode(ctx, key, props, onError) : composeEmptyNode(ctx, keyStart, start, null, props, onError);
				if (isBlock(key)) onError(keyNode.range, "BLOCK_IN_FLOW", blockMsg);
				ctx.atKey = false;
				const valueProps = resolveProps.resolveProps(sep ?? [], {
					flow: fcName,
					indicator: "map-value-ind",
					next: value,
					offset: keyNode.range[2],
					onError,
					parentIndent: fc.indent,
					startOnNewline: false
				});
				if (valueProps.found) {
					if (!isMap && !props.found && ctx.options.strict) {
						if (sep) for (const st of sep) {
							if (st === valueProps.found) break;
							if (st.type === "newline") {
								onError(st, "MULTILINE_IMPLICIT_KEY", "Implicit keys of flow sequence pairs need to be on a single line");
								break;
							}
						}
						if (props.start < valueProps.found.offset - 1024) onError(valueProps.found, "KEY_OVER_1024_CHARS", "The : indicator must be at most 1024 chars after the start of an implicit flow sequence key");
					}
				} else if (value) if ("source" in value && value.source?.[0] === ":") onError(value, "MISSING_CHAR", `Missing space after : in ${fcName}`);
				else onError(valueProps.start, "MISSING_CHAR", `Missing , or : between ${fcName} items`);
				const valueNode = value ? composeNode(ctx, value, valueProps, onError) : valueProps.found ? composeEmptyNode(ctx, valueProps.end, sep, null, valueProps, onError) : null;
				if (valueNode) {
					if (isBlock(value)) onError(valueNode.range, "BLOCK_IN_FLOW", blockMsg);
				} else if (valueProps.comment) if (keyNode.comment) keyNode.comment += "\n" + valueProps.comment;
				else keyNode.comment = valueProps.comment;
				const pair = new Pair.Pair(keyNode, valueNode);
				if (ctx.options.keepSourceTokens) pair.srcToken = collItem;
				if (isMap) {
					const map = coll;
					if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode)) onError(keyStart, "DUPLICATE_KEY", "Map keys must be unique");
					map.items.push(pair);
				} else {
					const map = new YAMLMap.YAMLMap(ctx.schema);
					map.flow = true;
					map.items.push(pair);
					const endRange = (valueNode ?? keyNode).range;
					map.range = [
						keyNode.range[0],
						endRange[1],
						endRange[2]
					];
					coll.items.push(map);
				}
				offset = valueNode ? valueNode.range[2] : valueProps.end;
			}
		}
		const expectedEnd = isMap ? "}" : "]";
		const [ce, ...ee] = fc.end;
		let cePos = offset;
		if (ce?.source === expectedEnd) cePos = ce.offset + ce.source.length;
		else {
			const name = fcName[0].toUpperCase() + fcName.substring(1);
			const msg = atRoot ? `${name} must end with a ${expectedEnd}` : `${name} in block collection must be sufficiently indented and end with a ${expectedEnd}`;
			onError(offset, atRoot ? "MISSING_CHAR" : "BAD_INDENT", msg);
			if (ce && ce.source.length !== 1) ee.unshift(ce);
		}
		if (ee.length > 0) {
			const end = resolveEnd.resolveEnd(ee, cePos, ctx.options.strict, onError);
			if (end.comment) if (coll.comment) coll.comment += "\n" + end.comment;
			else coll.comment = end.comment;
			coll.range = [
				fc.offset,
				cePos,
				end.offset
			];
		} else coll.range = [
			fc.offset,
			cePos,
			cePos
		];
		return coll;
	}
	exports.resolveFlowCollection = resolveFlowCollection;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-collection.js
var require_compose_collection = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Scalar = require_Scalar();
	var YAMLMap = require_YAMLMap();
	var YAMLSeq = require_YAMLSeq();
	var resolveBlockMap = require_resolve_block_map();
	var resolveBlockSeq = require_resolve_block_seq();
	var resolveFlowCollection = require_resolve_flow_collection();
	function resolveCollection(CN, ctx, token, onError, tagName, tag) {
		const coll = token.type === "block-map" ? resolveBlockMap.resolveBlockMap(CN, ctx, token, onError, tag) : token.type === "block-seq" ? resolveBlockSeq.resolveBlockSeq(CN, ctx, token, onError, tag) : resolveFlowCollection.resolveFlowCollection(CN, ctx, token, onError, tag);
		const Coll = coll.constructor;
		if (tagName === "!" || tagName === Coll.tagName) {
			coll.tag = Coll.tagName;
			return coll;
		}
		if (tagName) coll.tag = tagName;
		return coll;
	}
	function composeCollection(CN, ctx, token, props, onError) {
		const tagToken = props.tag;
		const tagName = !tagToken ? null : ctx.directives.tagName(tagToken.source, (msg) => onError(tagToken, "TAG_RESOLVE_FAILED", msg));
		if (token.type === "block-seq") {
			const { anchor, newlineAfterProp: nl } = props;
			const lastProp = anchor && tagToken ? anchor.offset > tagToken.offset ? anchor : tagToken : anchor ?? tagToken;
			if (lastProp && (!nl || nl.offset < lastProp.offset)) onError(lastProp, "MISSING_CHAR", "Missing newline after block sequence props");
		}
		const expType = token.type === "block-map" ? "map" : token.type === "block-seq" ? "seq" : token.start.source === "{" ? "map" : "seq";
		if (!tagToken || !tagName || tagName === "!" || tagName === YAMLMap.YAMLMap.tagName && expType === "map" || tagName === YAMLSeq.YAMLSeq.tagName && expType === "seq") return resolveCollection(CN, ctx, token, onError, tagName);
		let tag = ctx.schema.tags.find((t) => t.tag === tagName && t.collection === expType);
		if (!tag) {
			const kt = ctx.schema.knownTags[tagName];
			if (kt?.collection === expType) {
				ctx.schema.tags.push(Object.assign({}, kt, { default: false }));
				tag = kt;
			} else {
				if (kt) onError(tagToken, "BAD_COLLECTION_TYPE", `${kt.tag} used for ${expType} collection, but expects ${kt.collection ?? "scalar"}`, true);
				else onError(tagToken, "TAG_RESOLVE_FAILED", `Unresolved tag: ${tagName}`, true);
				return resolveCollection(CN, ctx, token, onError, tagName);
			}
		}
		const coll = resolveCollection(CN, ctx, token, onError, tagName, tag);
		const res = tag.resolve?.(coll, (msg) => onError(tagToken, "TAG_RESOLVE_FAILED", msg), ctx.options) ?? coll;
		const node = identity.isNode(res) ? res : new Scalar.Scalar(res);
		node.range = coll.range;
		node.tag = tagName;
		if (tag?.format) node.format = tag.format;
		return node;
	}
	exports.composeCollection = composeCollection;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-scalar.js
var require_resolve_block_scalar = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	function resolveBlockScalar(ctx, scalar, onError) {
		const start = scalar.offset;
		const header = parseBlockScalarHeader(scalar, ctx.options.strict, onError);
		if (!header) return {
			value: "",
			type: null,
			comment: "",
			range: [
				start,
				start,
				start
			]
		};
		const type = header.mode === ">" ? Scalar.Scalar.BLOCK_FOLDED : Scalar.Scalar.BLOCK_LITERAL;
		const lines = scalar.source ? splitLines(scalar.source) : [];
		let chompStart = lines.length;
		for (let i = lines.length - 1; i >= 0; --i) {
			const content = lines[i][1];
			if (content === "" || content === "\r") chompStart = i;
			else break;
		}
		if (chompStart === 0) {
			const value = header.chomp === "+" && lines.length > 0 ? "\n".repeat(Math.max(1, lines.length - 1)) : "";
			let end = start + header.length;
			if (scalar.source) end += scalar.source.length;
			return {
				value,
				type,
				comment: header.comment,
				range: [
					start,
					end,
					end
				]
			};
		}
		let trimIndent = scalar.indent + header.indent;
		let offset = scalar.offset + header.length;
		let contentStart = 0;
		for (let i = 0; i < chompStart; ++i) {
			const [indent, content] = lines[i];
			if (content === "" || content === "\r") {
				if (header.indent === 0 && indent.length > trimIndent) trimIndent = indent.length;
			} else {
				if (indent.length < trimIndent) onError(offset + indent.length, "MISSING_CHAR", "Block scalars with more-indented leading empty lines must use an explicit indentation indicator");
				if (header.indent === 0) trimIndent = indent.length;
				contentStart = i;
				if (trimIndent === 0 && !ctx.atRoot) onError(offset, "BAD_INDENT", "Block scalar values in collections must be indented");
				break;
			}
			offset += indent.length + content.length + 1;
		}
		for (let i = lines.length - 1; i >= chompStart; --i) if (lines[i][0].length > trimIndent) chompStart = i + 1;
		let value = "";
		let sep = "";
		let prevMoreIndented = false;
		for (let i = 0; i < contentStart; ++i) value += lines[i][0].slice(trimIndent) + "\n";
		for (let i = contentStart; i < chompStart; ++i) {
			let [indent, content] = lines[i];
			offset += indent.length + content.length + 1;
			const crlf = content[content.length - 1] === "\r";
			if (crlf) content = content.slice(0, -1);
			/* istanbul ignore if already caught in lexer */
			if (content && indent.length < trimIndent) {
				const message = `Block scalar lines must not be less indented than their ${header.indent ? "explicit indentation indicator" : "first line"}`;
				onError(offset - content.length - (crlf ? 2 : 1), "BAD_INDENT", message);
				indent = "";
			}
			if (type === Scalar.Scalar.BLOCK_LITERAL) {
				value += sep + indent.slice(trimIndent) + content;
				sep = "\n";
			} else if (indent.length > trimIndent || content[0] === "	") {
				if (sep === " ") sep = "\n";
				else if (!prevMoreIndented && sep === "\n") sep = "\n\n";
				value += sep + indent.slice(trimIndent) + content;
				sep = "\n";
				prevMoreIndented = true;
			} else if (content === "") if (sep === "\n") value += "\n";
			else sep = "\n";
			else {
				value += sep + content;
				sep = " ";
				prevMoreIndented = false;
			}
		}
		switch (header.chomp) {
			case "-": break;
			case "+":
				for (let i = chompStart; i < lines.length; ++i) value += "\n" + lines[i][0].slice(trimIndent);
				if (value[value.length - 1] !== "\n") value += "\n";
				break;
			default: value += "\n";
		}
		const end = start + header.length + scalar.source.length;
		return {
			value,
			type,
			comment: header.comment,
			range: [
				start,
				end,
				end
			]
		};
	}
	function parseBlockScalarHeader({ offset, props }, strict, onError) {
		/* istanbul ignore if should not happen */
		if (props[0].type !== "block-scalar-header") {
			onError(props[0], "IMPOSSIBLE", "Block scalar header not found");
			return null;
		}
		const { source } = props[0];
		const mode = source[0];
		let indent = 0;
		let chomp = "";
		let error = -1;
		for (let i = 1; i < source.length; ++i) {
			const ch = source[i];
			if (!chomp && (ch === "-" || ch === "+")) chomp = ch;
			else {
				const n = Number(ch);
				if (!indent && n) indent = n;
				else if (error === -1) error = offset + i;
			}
		}
		if (error !== -1) onError(error, "UNEXPECTED_TOKEN", `Block scalar header includes extra characters: ${source}`);
		let hasSpace = false;
		let comment = "";
		let length = source.length;
		for (let i = 1; i < props.length; ++i) {
			const token = props[i];
			switch (token.type) {
				case "space": hasSpace = true;
				case "newline":
					length += token.source.length;
					break;
				case "comment":
					if (strict && !hasSpace) onError(token, "MISSING_CHAR", "Comments must be separated from other tokens by white space characters");
					length += token.source.length;
					comment = token.source.substring(1);
					break;
				case "error":
					onError(token, "UNEXPECTED_TOKEN", token.message);
					length += token.source.length;
					break;
				default: {
					onError(token, "UNEXPECTED_TOKEN", `Unexpected token in block scalar header: ${token.type}`);
					const ts = token.source;
					if (ts && typeof ts === "string") length += ts.length;
				}
			}
		}
		return {
			mode,
			indent,
			chomp,
			comment,
			length
		};
	}
	/** @returns Array of lines split up as `[indent, content]` */
	function splitLines(source) {
		const split = source.split(/\n( *)/);
		const first = split[0];
		const m = first.match(/^( *)/);
		const lines = [m?.[1] ? [m[1], first.slice(m[1].length)] : ["", first]];
		for (let i = 1; i < split.length; i += 2) lines.push([split[i], split[i + 1]]);
		return lines;
	}
	exports.resolveBlockScalar = resolveBlockScalar;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-flow-scalar.js
var require_resolve_flow_scalar = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Scalar = require_Scalar();
	var resolveEnd = require_resolve_end();
	function resolveFlowScalar(scalar, strict, onError) {
		const { offset, type, source, end } = scalar;
		let _type;
		let value;
		const _onError = (rel, code, msg) => onError(offset + rel, code, msg);
		switch (type) {
			case "scalar":
				_type = Scalar.Scalar.PLAIN;
				value = plainValue(source, _onError);
				break;
			case "single-quoted-scalar":
				_type = Scalar.Scalar.QUOTE_SINGLE;
				value = singleQuotedValue(source, _onError);
				break;
			case "double-quoted-scalar":
				_type = Scalar.Scalar.QUOTE_DOUBLE;
				value = doubleQuotedValue(source, _onError);
				break;
			default:
				onError(scalar, "UNEXPECTED_TOKEN", `Expected a flow scalar value, but found: ${type}`);
				return {
					value: "",
					type: null,
					comment: "",
					range: [
						offset,
						offset + source.length,
						offset + source.length
					]
				};
		}
		const valueEnd = offset + source.length;
		const re = resolveEnd.resolveEnd(end, valueEnd, strict, onError);
		return {
			value,
			type: _type,
			comment: re.comment,
			range: [
				offset,
				valueEnd,
				re.offset
			]
		};
	}
	function plainValue(source, onError) {
		let badChar = "";
		switch (source[0]) {
			case "	":
				badChar = "a tab character";
				break;
			case ",":
				badChar = "flow indicator character ,";
				break;
			case "%":
				badChar = "directive indicator character %";
				break;
			case "|":
			case ">":
				badChar = `block scalar indicator ${source[0]}`;
				break;
			case "@":
			case "`":
				badChar = `reserved character ${source[0]}`;
				break;
		}
		if (badChar) onError(0, "BAD_SCALAR_START", `Plain value cannot start with ${badChar}`);
		return foldLines(source);
	}
	function singleQuotedValue(source, onError) {
		if (source[source.length - 1] !== "'" || source.length === 1) onError(source.length, "MISSING_CHAR", "Missing closing 'quote");
		return foldLines(source.slice(1, -1)).replace(/''/g, "'");
	}
	function foldLines(source) {
		/**
		* The negative lookbehind here and in the `re` RegExp is to
		* prevent causing a polynomial search time in certain cases.
		*
		* The try-catch is for Safari, which doesn't support this yet:
		* https://caniuse.com/js-regexp-lookbehind
		*/
		let first, line;
		try {
			first = /* @__PURE__ */ new RegExp("(.*?)(?<![ 	])[ 	]*\r?\n", "sy");
			line = /* @__PURE__ */ new RegExp("[ 	]*(.*?)(?:(?<![ 	])[ 	]*)?\r?\n", "sy");
		} catch {
			first = /(.*?)[ \t]*\r?\n/sy;
			line = /[ \t]*(.*?)[ \t]*\r?\n/sy;
		}
		let match = first.exec(source);
		if (!match) return source;
		let res = match[1];
		let sep = " ";
		let pos = first.lastIndex;
		line.lastIndex = pos;
		while (match = line.exec(source)) {
			if (match[1] === "") if (sep === "\n") res += sep;
			else sep = "\n";
			else {
				res += sep + match[1];
				sep = " ";
			}
			pos = line.lastIndex;
		}
		const last = /[ \t]*(.*)/sy;
		last.lastIndex = pos;
		match = last.exec(source);
		return res + sep + (match?.[1] ?? "");
	}
	function doubleQuotedValue(source, onError) {
		let res = "";
		for (let i = 1; i < source.length - 1; ++i) {
			const ch = source[i];
			if (ch === "\r" && source[i + 1] === "\n") continue;
			if (ch === "\n") {
				const { fold, offset } = foldNewline(source, i);
				res += fold;
				i = offset;
			} else if (ch === "\\") {
				let next = source[++i];
				const cc = escapeCodes[next];
				if (cc) res += cc;
				else if (next === "\n") {
					next = source[i + 1];
					while (next === " " || next === "	") next = source[++i + 1];
				} else if (next === "\r" && source[i + 1] === "\n") {
					next = source[++i + 1];
					while (next === " " || next === "	") next = source[++i + 1];
				} else if (next === "x" || next === "u" || next === "U") {
					const length = {
						x: 2,
						u: 4,
						U: 8
					}[next];
					res += parseCharCode(source, i + 1, length, onError);
					i += length;
				} else {
					const raw = source.substr(i - 1, 2);
					onError(i - 1, "BAD_DQ_ESCAPE", `Invalid escape sequence ${raw}`);
					res += raw;
				}
			} else if (ch === " " || ch === "	") {
				const wsStart = i;
				let next = source[i + 1];
				while (next === " " || next === "	") next = source[++i + 1];
				if (next !== "\n" && !(next === "\r" && source[i + 2] === "\n")) res += i > wsStart ? source.slice(wsStart, i + 1) : ch;
			} else res += ch;
		}
		if (source[source.length - 1] !== "\"" || source.length === 1) onError(source.length, "MISSING_CHAR", "Missing closing \"quote");
		return res;
	}
	/**
	* Fold a single newline into a space, multiple newlines to N - 1 newlines.
	* Presumes `source[offset] === '\n'`
	*/
	function foldNewline(source, offset) {
		let fold = "";
		let ch = source[offset + 1];
		while (ch === " " || ch === "	" || ch === "\n" || ch === "\r") {
			if (ch === "\r" && source[offset + 2] !== "\n") break;
			if (ch === "\n") fold += "\n";
			offset += 1;
			ch = source[offset + 1];
		}
		if (!fold) fold = " ";
		return {
			fold,
			offset
		};
	}
	const escapeCodes = {
		"0": "\0",
		a: "\x07",
		b: "\b",
		e: "\x1B",
		f: "\f",
		n: "\n",
		r: "\r",
		t: "	",
		v: "\v",
		N: "",
		_: "\xA0",
		L: "\u2028",
		P: "\u2029",
		" ": " ",
		"\"": "\"",
		"/": "/",
		"\\": "\\",
		"	": "	"
	};
	function parseCharCode(source, offset, length, onError) {
		const cc = source.substr(offset, length);
		const code = cc.length === length && /^[0-9a-fA-F]+$/.test(cc) ? parseInt(cc, 16) : NaN;
		if (isNaN(code)) {
			const raw = source.substr(offset - 2, length + 2);
			onError(offset - 2, "BAD_DQ_ESCAPE", `Invalid escape sequence ${raw}`);
			return raw;
		}
		return String.fromCodePoint(code);
	}
	exports.resolveFlowScalar = resolveFlowScalar;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-scalar.js
var require_compose_scalar = /* @__PURE__ */ __commonJSMin(((exports) => {
	var identity = require_identity();
	var Scalar = require_Scalar();
	var resolveBlockScalar = require_resolve_block_scalar();
	var resolveFlowScalar = require_resolve_flow_scalar();
	function composeScalar(ctx, token, tagToken, onError) {
		const { value, type, comment, range } = token.type === "block-scalar" ? resolveBlockScalar.resolveBlockScalar(ctx, token, onError) : resolveFlowScalar.resolveFlowScalar(token, ctx.options.strict, onError);
		const tagName = tagToken ? ctx.directives.tagName(tagToken.source, (msg) => onError(tagToken, "TAG_RESOLVE_FAILED", msg)) : null;
		let tag;
		if (ctx.options.stringKeys && ctx.atKey) tag = ctx.schema[identity.SCALAR];
		else if (tagName) tag = findScalarTagByName(ctx.schema, value, tagName, tagToken, onError);
		else if (token.type === "scalar") tag = findScalarTagByTest(ctx, value, token, onError);
		else tag = ctx.schema[identity.SCALAR];
		let scalar;
		try {
			const res = tag.resolve(value, (msg) => onError(tagToken ?? token, "TAG_RESOLVE_FAILED", msg), ctx.options);
			scalar = identity.isScalar(res) ? res : new Scalar.Scalar(res);
		} catch (error) {
			const msg = error instanceof Error ? error.message : String(error);
			onError(tagToken ?? token, "TAG_RESOLVE_FAILED", msg);
			scalar = new Scalar.Scalar(value);
		}
		scalar.range = range;
		scalar.source = value;
		if (type) scalar.type = type;
		if (tagName) scalar.tag = tagName;
		if (tag.format) scalar.format = tag.format;
		if (comment) scalar.comment = comment;
		return scalar;
	}
	function findScalarTagByName(schema, value, tagName, tagToken, onError) {
		if (tagName === "!") return schema[identity.SCALAR];
		const matchWithTest = [];
		for (const tag of schema.tags) if (!tag.collection && tag.tag === tagName) if (tag.default && tag.test) matchWithTest.push(tag);
		else return tag;
		for (const tag of matchWithTest) if (tag.test?.test(value)) return tag;
		const kt = schema.knownTags[tagName];
		if (kt && !kt.collection) {
			schema.tags.push(Object.assign({}, kt, {
				default: false,
				test: void 0
			}));
			return kt;
		}
		onError(tagToken, "TAG_RESOLVE_FAILED", `Unresolved tag: ${tagName}`, tagName !== "tag:yaml.org,2002:str");
		return schema[identity.SCALAR];
	}
	function findScalarTagByTest({ atKey, directives, schema }, value, token, onError) {
		const tag = schema.tags.find((tag) => (tag.default === true || atKey && tag.default === "key") && tag.test?.test(value)) || schema[identity.SCALAR];
		if (schema.compat) {
			const compat = schema.compat.find((tag) => tag.default && tag.test?.test(value)) ?? schema[identity.SCALAR];
			if (tag.tag !== compat.tag) onError(token, "TAG_RESOLVE_FAILED", `Value may be parsed as either ${directives.tagString(tag.tag)} or ${directives.tagString(compat.tag)}`, true);
		}
		return tag;
	}
	exports.composeScalar = composeScalar;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-empty-scalar-position.js
var require_util_empty_scalar_position = /* @__PURE__ */ __commonJSMin(((exports) => {
	function emptyScalarPosition(offset, before, pos) {
		if (before) {
			pos ?? (pos = before.length);
			for (let i = pos - 1; i >= 0; --i) {
				let st = before[i];
				switch (st.type) {
					case "space":
					case "comment":
					case "newline":
						offset -= st.source.length;
						continue;
				}
				st = before[++i];
				while (st?.type === "space") {
					offset += st.source.length;
					st = before[++i];
				}
				break;
			}
		}
		return offset;
	}
	exports.emptyScalarPosition = emptyScalarPosition;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-node.js
var require_compose_node = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Alias = require_Alias();
	var identity = require_identity();
	var composeCollection = require_compose_collection();
	var composeScalar = require_compose_scalar();
	var resolveEnd = require_resolve_end();
	var utilEmptyScalarPosition = require_util_empty_scalar_position();
	const CN = {
		composeNode,
		composeEmptyNode
	};
	function composeNode(ctx, token, props, onError) {
		const atKey = ctx.atKey;
		const { spaceBefore, comment, anchor, tag } = props;
		let node;
		let isSrcToken = true;
		switch (token.type) {
			case "alias":
				node = composeAlias(ctx, token, onError);
				if (anchor || tag) onError(token, "ALIAS_PROPS", "An alias node must not specify any properties");
				break;
			case "scalar":
			case "single-quoted-scalar":
			case "double-quoted-scalar":
			case "block-scalar":
				node = composeScalar.composeScalar(ctx, token, tag, onError);
				if (anchor) node.anchor = anchor.source.substring(1);
				break;
			case "block-map":
			case "block-seq":
			case "flow-collection":
				node = composeCollection.composeCollection(CN, ctx, token, props, onError);
				if (anchor) node.anchor = anchor.source.substring(1);
				break;
			default:
				onError(token, "UNEXPECTED_TOKEN", token.type === "error" ? token.message : `Unsupported token (type: ${token.type})`);
				node = composeEmptyNode(ctx, token.offset, void 0, null, props, onError);
				isSrcToken = false;
		}
		if (anchor && node.anchor === "") onError(anchor, "BAD_ALIAS", "Anchor cannot be an empty string");
		if (atKey && ctx.options.stringKeys && (!identity.isScalar(node) || typeof node.value !== "string" || node.tag && node.tag !== "tag:yaml.org,2002:str")) onError(tag ?? token, "NON_STRING_KEY", "With stringKeys, all keys must be strings");
		if (spaceBefore) node.spaceBefore = true;
		if (comment) if (token.type === "scalar" && token.source === "") node.comment = comment;
		else node.commentBefore = comment;
		if (ctx.options.keepSourceTokens && isSrcToken) node.srcToken = token;
		return node;
	}
	function composeEmptyNode(ctx, offset, before, pos, { spaceBefore, comment, anchor, tag, end }, onError) {
		const token = {
			type: "scalar",
			offset: utilEmptyScalarPosition.emptyScalarPosition(offset, before, pos),
			indent: -1,
			source: ""
		};
		const node = composeScalar.composeScalar(ctx, token, tag, onError);
		if (anchor) {
			node.anchor = anchor.source.substring(1);
			if (node.anchor === "") onError(anchor, "BAD_ALIAS", "Anchor cannot be an empty string");
		}
		if (spaceBefore) node.spaceBefore = true;
		if (comment) {
			node.comment = comment;
			node.range[2] = end;
		}
		return node;
	}
	function composeAlias({ options }, { offset, source, end }, onError) {
		const alias = new Alias.Alias(source.substring(1));
		if (alias.source === "") onError(offset, "BAD_ALIAS", "Alias cannot be an empty string");
		if (alias.source.endsWith(":")) onError(offset + source.length - 1, "BAD_ALIAS", "Alias ending in : is ambiguous", true);
		const valueEnd = offset + source.length;
		const re = resolveEnd.resolveEnd(end, valueEnd, options.strict, onError);
		alias.range = [
			offset,
			valueEnd,
			re.offset
		];
		if (re.comment) alias.comment = re.comment;
		return alias;
	}
	exports.composeEmptyNode = composeEmptyNode;
	exports.composeNode = composeNode;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-doc.js
var require_compose_doc = /* @__PURE__ */ __commonJSMin(((exports) => {
	var Document = require_Document();
	var composeNode = require_compose_node();
	var resolveEnd = require_resolve_end();
	var resolveProps = require_resolve_props();
	function composeDoc(options, directives, { offset, start, value, end }, onError) {
		const opts = Object.assign({ _directives: directives }, options);
		const doc = new Document.Document(void 0, opts);
		const ctx = {
			atKey: false,
			atRoot: true,
			directives: doc.directives,
			options: doc.options,
			schema: doc.schema
		};
		const props = resolveProps.resolveProps(start, {
			indicator: "doc-start",
			next: value ?? end?.[0],
			offset,
			onError,
			parentIndent: 0,
			startOnNewline: true
		});
		if (props.found) {
			doc.directives.docStart = true;
			if (value && (value.type === "block-map" || value.type === "block-seq") && !props.hasNewline) onError(props.end, "MISSING_CHAR", "Block collection cannot start on same line with directives-end marker");
		}
		doc.contents = value ? composeNode.composeNode(ctx, value, props, onError) : composeNode.composeEmptyNode(ctx, props.end, start, null, props, onError);
		const contentEnd = doc.contents.range[2];
		const re = resolveEnd.resolveEnd(end, contentEnd, false, onError);
		if (re.comment) doc.comment = re.comment;
		doc.range = [
			offset,
			contentEnd,
			re.offset
		];
		return doc;
	}
	exports.composeDoc = composeDoc;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/composer.js
var require_composer = /* @__PURE__ */ __commonJSMin(((exports) => {
	var node_process$1 = __require$1("process");
	var directives = require_directives();
	var Document = require_Document();
	var errors = require_errors();
	var identity = require_identity();
	var composeDoc = require_compose_doc();
	var resolveEnd = require_resolve_end();
	function getErrorPos(src) {
		if (typeof src === "number") return [src, src + 1];
		if (Array.isArray(src)) return src.length === 2 ? src : [src[0], src[1]];
		const { offset, source } = src;
		return [offset, offset + (typeof source === "string" ? source.length : 1)];
	}
	function parsePrelude(prelude) {
		let comment = "";
		let atComment = false;
		let afterEmptyLine = false;
		for (let i = 0; i < prelude.length; ++i) {
			const source = prelude[i];
			switch (source[0]) {
				case "#":
					comment += (comment === "" ? "" : afterEmptyLine ? "\n\n" : "\n") + (source.substring(1) || " ");
					atComment = true;
					afterEmptyLine = false;
					break;
				case "%":
					if (prelude[i + 1]?.[0] !== "#") i += 1;
					atComment = false;
					break;
				default:
					if (!atComment) afterEmptyLine = true;
					atComment = false;
			}
		}
		return {
			comment,
			afterEmptyLine
		};
	}
	/**
	* Compose a stream of CST nodes into a stream of YAML Documents.
	*
	* ```ts
	* import { Composer, Parser } from 'yaml'
	*
	* const src: string = ...
	* const tokens = new Parser().parse(src)
	* const docs = new Composer().compose(tokens)
	* ```
	*/
	var Composer = class {
		constructor(options = {}) {
			this.doc = null;
			this.atDirectives = false;
			this.prelude = [];
			this.errors = [];
			this.warnings = [];
			this.onError = (source, code, message, warning) => {
				const pos = getErrorPos(source);
				if (warning) this.warnings.push(new errors.YAMLWarning(pos, code, message));
				else this.errors.push(new errors.YAMLParseError(pos, code, message));
			};
			this.directives = new directives.Directives({ version: options.version || "1.2" });
			this.options = options;
		}
		decorate(doc, afterDoc) {
			const { comment, afterEmptyLine } = parsePrelude(this.prelude);
			if (comment) {
				const dc = doc.contents;
				if (afterDoc) doc.comment = doc.comment ? `${doc.comment}\n${comment}` : comment;
				else if (afterEmptyLine || doc.directives.docStart || !dc) doc.commentBefore = comment;
				else if (identity.isCollection(dc) && !dc.flow && dc.items.length > 0) {
					let it = dc.items[0];
					if (identity.isPair(it)) it = it.key;
					const cb = it.commentBefore;
					it.commentBefore = cb ? `${comment}\n${cb}` : comment;
				} else {
					const cb = dc.commentBefore;
					dc.commentBefore = cb ? `${comment}\n${cb}` : comment;
				}
			}
			if (afterDoc) {
				Array.prototype.push.apply(doc.errors, this.errors);
				Array.prototype.push.apply(doc.warnings, this.warnings);
			} else {
				doc.errors = this.errors;
				doc.warnings = this.warnings;
			}
			this.prelude = [];
			this.errors = [];
			this.warnings = [];
		}
		/**
		* Current stream status information.
		*
		* Mostly useful at the end of input for an empty stream.
		*/
		streamInfo() {
			return {
				comment: parsePrelude(this.prelude).comment,
				directives: this.directives,
				errors: this.errors,
				warnings: this.warnings
			};
		}
		/**
		* Compose tokens into documents.
		*
		* @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
		* @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
		*/
		*compose(tokens, forceDoc = false, endOffset = -1) {
			for (const token of tokens) yield* this.next(token);
			yield* this.end(forceDoc, endOffset);
		}
		/** Advance the composer by one CST token. */
		*next(token) {
			if (node_process$1.env.LOG_STREAM) console.dir(token, { depth: null });
			switch (token.type) {
				case "directive":
					this.directives.add(token.source, (offset, message, warning) => {
						const pos = getErrorPos(token);
						pos[0] += offset;
						this.onError(pos, "BAD_DIRECTIVE", message, warning);
					});
					this.prelude.push(token.source);
					this.atDirectives = true;
					break;
				case "document": {
					const doc = composeDoc.composeDoc(this.options, this.directives, token, this.onError);
					if (this.atDirectives && !doc.directives.docStart) this.onError(token, "MISSING_CHAR", "Missing directives-end/doc-start indicator line");
					this.decorate(doc, false);
					if (this.doc) yield this.doc;
					this.doc = doc;
					this.atDirectives = false;
					break;
				}
				case "byte-order-mark":
				case "space": break;
				case "comment":
				case "newline":
					this.prelude.push(token.source);
					break;
				case "error": {
					const msg = token.source ? `${token.message}: ${JSON.stringify(token.source)}` : token.message;
					const error = new errors.YAMLParseError(getErrorPos(token), "UNEXPECTED_TOKEN", msg);
					if (this.atDirectives || !this.doc) this.errors.push(error);
					else this.doc.errors.push(error);
					break;
				}
				case "doc-end": {
					if (!this.doc) {
						this.errors.push(new errors.YAMLParseError(getErrorPos(token), "UNEXPECTED_TOKEN", "Unexpected doc-end without preceding document"));
						break;
					}
					this.doc.directives.docEnd = true;
					const end = resolveEnd.resolveEnd(token.end, token.offset + token.source.length, this.doc.options.strict, this.onError);
					this.decorate(this.doc, true);
					if (end.comment) {
						const dc = this.doc.comment;
						this.doc.comment = dc ? `${dc}\n${end.comment}` : end.comment;
					}
					this.doc.range[2] = end.offset;
					break;
				}
				default: this.errors.push(new errors.YAMLParseError(getErrorPos(token), "UNEXPECTED_TOKEN", `Unsupported token ${token.type}`));
			}
		}
		/**
		* Call at end of input to yield any remaining document.
		*
		* @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
		* @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
		*/
		*end(forceDoc = false, endOffset = -1) {
			if (this.doc) {
				this.decorate(this.doc, true);
				yield this.doc;
				this.doc = null;
			} else if (forceDoc) {
				const opts = Object.assign({ _directives: this.directives }, this.options);
				const doc = new Document.Document(void 0, opts);
				if (this.atDirectives) this.onError(endOffset, "MISSING_CHAR", "Missing directives-end indicator line");
				doc.range = [
					0,
					endOffset,
					endOffset
				];
				this.decorate(doc, false);
				yield doc;
			}
		}
	};
	exports.Composer = Composer;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-scalar.js
var require_cst_scalar = /* @__PURE__ */ __commonJSMin(((exports) => {
	var resolveBlockScalar = require_resolve_block_scalar();
	var resolveFlowScalar = require_resolve_flow_scalar();
	var errors = require_errors();
	var stringifyString = require_stringifyString();
	function resolveAsScalar(token, strict = true, onError) {
		if (token) {
			const _onError = (pos, code, message) => {
				const offset = typeof pos === "number" ? pos : Array.isArray(pos) ? pos[0] : pos.offset;
				if (onError) onError(offset, code, message);
				else throw new errors.YAMLParseError([offset, offset + 1], code, message);
			};
			switch (token.type) {
				case "scalar":
				case "single-quoted-scalar":
				case "double-quoted-scalar": return resolveFlowScalar.resolveFlowScalar(token, strict, _onError);
				case "block-scalar": return resolveBlockScalar.resolveBlockScalar({ options: { strict } }, token, _onError);
			}
		}
		return null;
	}
	/**
	* Create a new scalar token with `value`
	*
	* Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,
	* as this function does not support any schema operations and won't check for such conflicts.
	*
	* @param value The string representation of the value, which will have its content properly indented.
	* @param context.end Comments and whitespace after the end of the value, or after the block scalar header. If undefined, a newline will be added.
	* @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.
	* @param context.indent The indent level of the token.
	* @param context.inFlow Is this scalar within a flow collection? This may affect the resolved type of the token's value.
	* @param context.offset The offset position of the token.
	* @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.
	*/
	function createScalarToken(value, context) {
		const { implicitKey = false, indent, inFlow = false, offset = -1, type = "PLAIN" } = context;
		const source = stringifyString.stringifyString({
			type,
			value
		}, {
			implicitKey,
			indent: indent > 0 ? " ".repeat(indent) : "",
			inFlow,
			options: {
				blockQuote: true,
				lineWidth: -1
			}
		});
		const end = context.end ?? [{
			type: "newline",
			offset: -1,
			indent,
			source: "\n"
		}];
		switch (source[0]) {
			case "|":
			case ">": {
				const he = source.indexOf("\n");
				const head = source.substring(0, he);
				const body = source.substring(he + 1) + "\n";
				const props = [{
					type: "block-scalar-header",
					offset,
					indent,
					source: head
				}];
				if (!addEndtoBlockProps(props, end)) props.push({
					type: "newline",
					offset: -1,
					indent,
					source: "\n"
				});
				return {
					type: "block-scalar",
					offset,
					indent,
					props,
					source: body
				};
			}
			case "\"": return {
				type: "double-quoted-scalar",
				offset,
				indent,
				source,
				end
			};
			case "'": return {
				type: "single-quoted-scalar",
				offset,
				indent,
				source,
				end
			};
			default: return {
				type: "scalar",
				offset,
				indent,
				source,
				end
			};
		}
	}
	/**
	* Set the value of `token` to the given string `value`, overwriting any previous contents and type that it may have.
	*
	* Best efforts are made to retain any comments previously associated with the `token`,
	* though all contents within a collection's `items` will be overwritten.
	*
	* Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,
	* as this function does not support any schema operations and won't check for such conflicts.
	*
	* @param token Any token. If it does not include an `indent` value, the value will be stringified as if it were an implicit key.
	* @param value The string representation of the value, which will have its content properly indented.
	* @param context.afterKey In most cases, values after a key should have an additional level of indentation.
	* @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.
	* @param context.inFlow Being within a flow collection may affect the resolved type of the token's value.
	* @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.
	*/
	function setScalarValue(token, value, context = {}) {
		let { afterKey = false, implicitKey = false, inFlow = false, type } = context;
		let indent = "indent" in token ? token.indent : null;
		if (afterKey && typeof indent === "number") indent += 2;
		if (!type) switch (token.type) {
			case "single-quoted-scalar":
				type = "QUOTE_SINGLE";
				break;
			case "double-quoted-scalar":
				type = "QUOTE_DOUBLE";
				break;
			case "block-scalar": {
				const header = token.props[0];
				if (header.type !== "block-scalar-header") throw new Error("Invalid block scalar header");
				type = header.source[0] === ">" ? "BLOCK_FOLDED" : "BLOCK_LITERAL";
				break;
			}
			default: type = "PLAIN";
		}
		const source = stringifyString.stringifyString({
			type,
			value
		}, {
			implicitKey: implicitKey || indent === null,
			indent: indent !== null && indent > 0 ? " ".repeat(indent) : "",
			inFlow,
			options: {
				blockQuote: true,
				lineWidth: -1
			}
		});
		switch (source[0]) {
			case "|":
			case ">":
				setBlockScalarValue(token, source);
				break;
			case "\"":
				setFlowScalarValue(token, source, "double-quoted-scalar");
				break;
			case "'":
				setFlowScalarValue(token, source, "single-quoted-scalar");
				break;
			default: setFlowScalarValue(token, source, "scalar");
		}
	}
	function setBlockScalarValue(token, source) {
		const he = source.indexOf("\n");
		const head = source.substring(0, he);
		const body = source.substring(he + 1) + "\n";
		if (token.type === "block-scalar") {
			const header = token.props[0];
			if (header.type !== "block-scalar-header") throw new Error("Invalid block scalar header");
			header.source = head;
			token.source = body;
		} else {
			const { offset } = token;
			const indent = "indent" in token ? token.indent : -1;
			const props = [{
				type: "block-scalar-header",
				offset,
				indent,
				source: head
			}];
			if (!addEndtoBlockProps(props, "end" in token ? token.end : void 0)) props.push({
				type: "newline",
				offset: -1,
				indent,
				source: "\n"
			});
			for (const key of Object.keys(token)) if (key !== "type" && key !== "offset") delete token[key];
			Object.assign(token, {
				type: "block-scalar",
				indent,
				props,
				source: body
			});
		}
	}
	/** @returns `true` if last token is a newline */
	function addEndtoBlockProps(props, end) {
		if (end) for (const st of end) switch (st.type) {
			case "space":
			case "comment":
				props.push(st);
				break;
			case "newline":
				props.push(st);
				return true;
		}
		return false;
	}
	function setFlowScalarValue(token, source, type) {
		switch (token.type) {
			case "scalar":
			case "double-quoted-scalar":
			case "single-quoted-scalar":
				token.type = type;
				token.source = source;
				break;
			case "block-scalar": {
				const end = token.props.slice(1);
				let oa = source.length;
				if (token.props[0].type === "block-scalar-header") oa -= token.props[0].source.length;
				for (const tok of end) tok.offset += oa;
				delete token.props;
				Object.assign(token, {
					type,
					source,
					end
				});
				break;
			}
			case "block-map":
			case "block-seq": {
				const nl = {
					type: "newline",
					offset: token.offset + source.length,
					indent: token.indent,
					source: "\n"
				};
				delete token.items;
				Object.assign(token, {
					type,
					source,
					end: [nl]
				});
				break;
			}
			default: {
				const indent = "indent" in token ? token.indent : -1;
				const end = "end" in token && Array.isArray(token.end) ? token.end.filter((st) => st.type === "space" || st.type === "comment" || st.type === "newline") : [];
				for (const key of Object.keys(token)) if (key !== "type" && key !== "offset") delete token[key];
				Object.assign(token, {
					type,
					indent,
					source,
					end
				});
			}
		}
	}
	exports.createScalarToken = createScalarToken;
	exports.resolveAsScalar = resolveAsScalar;
	exports.setScalarValue = setScalarValue;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-stringify.js
var require_cst_stringify = /* @__PURE__ */ __commonJSMin(((exports) => {
	/**
	* Stringify a CST document, token, or collection item
	*
	* Fair warning: This applies no validation whatsoever, and
	* simply concatenates the sources in their logical order.
	*/
	const stringify = (cst) => "type" in cst ? stringifyToken(cst) : stringifyItem(cst);
	function stringifyToken(token) {
		switch (token.type) {
			case "block-scalar": {
				let res = "";
				for (const tok of token.props) res += stringifyToken(tok);
				return res + token.source;
			}
			case "block-map":
			case "block-seq": {
				let res = "";
				for (const item of token.items) res += stringifyItem(item);
				return res;
			}
			case "flow-collection": {
				let res = token.start.source;
				for (const item of token.items) res += stringifyItem(item);
				for (const st of token.end) res += st.source;
				return res;
			}
			case "document": {
				let res = stringifyItem(token);
				if (token.end) for (const st of token.end) res += st.source;
				return res;
			}
			default: {
				let res = token.source;
				if ("end" in token && token.end) for (const st of token.end) res += st.source;
				return res;
			}
		}
	}
	function stringifyItem({ start, key, sep, value }) {
		let res = "";
		for (const st of start) res += st.source;
		if (key) res += stringifyToken(key);
		if (sep) for (const st of sep) res += st.source;
		if (value) res += stringifyToken(value);
		return res;
	}
	exports.stringify = stringify;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-visit.js
var require_cst_visit = /* @__PURE__ */ __commonJSMin(((exports) => {
	const BREAK = Symbol("break visit");
	const SKIP = Symbol("skip children");
	const REMOVE = Symbol("remove item");
	/**
	* Apply a visitor to a CST document or item.
	*
	* Walks through the tree (depth-first) starting from the root, calling a
	* `visitor` function with two arguments when entering each item:
	*   - `item`: The current item, which included the following members:
	*     - `start: SourceToken[]`  Source tokens before the key or value,
	*       possibly including its anchor or tag.
	*     - `key?: Token | null`  Set for pair values. May then be `null`, if
	*       the key before the `:` separator is empty.
	*     - `sep?: SourceToken[]`  Source tokens between the key and the value,
	*       which should include the `:` map value indicator if `value` is set.
	*     - `value?: Token`  The value of a sequence item, or of a map pair.
	*   - `path`: The steps from the root to the current node, as an array of
	*     `['key' | 'value', number]` tuples.
	*
	* The return value of the visitor may be used to control the traversal:
	*   - `undefined` (default): Do nothing and continue
	*   - `visit.SKIP`: Do not visit the children of this token, continue with
	*      next sibling
	*   - `visit.BREAK`: Terminate traversal completely
	*   - `visit.REMOVE`: Remove the current item, then continue with the next one
	*   - `number`: Set the index of the next step. This is useful especially if
	*     the index of the current token has changed.
	*   - `function`: Define the next visitor for this item. After the original
	*     visitor is called on item entry, next visitors are called after handling
	*     a non-empty `key` and when exiting the item.
	*/
	function visit(cst, visitor) {
		if ("type" in cst && cst.type === "document") cst = {
			start: cst.start,
			value: cst.value
		};
		_visit(Object.freeze([]), cst, visitor);
	}
	/** Terminate visit traversal completely */
	visit.BREAK = BREAK;
	/** Do not visit the children of the current item */
	visit.SKIP = SKIP;
	/** Remove the current item */
	visit.REMOVE = REMOVE;
	/** Find the item at `path` from `cst` as the root */
	visit.itemAtPath = (cst, path) => {
		let item = cst;
		for (const [field, index] of path) {
			const tok = item?.[field];
			if (tok && "items" in tok) item = tok.items[index];
			else return void 0;
		}
		return item;
	};
	/**
	* Get the immediate parent collection of the item at `path` from `cst` as the root.
	*
	* Throws an error if the collection is not found, which should never happen if the item itself exists.
	*/
	visit.parentCollection = (cst, path) => {
		const parent = visit.itemAtPath(cst, path.slice(0, -1));
		const field = path[path.length - 1][0];
		const coll = parent?.[field];
		if (coll && "items" in coll) return coll;
		throw new Error("Parent collection not found");
	};
	function _visit(path, item, visitor) {
		let ctrl = visitor(item, path);
		if (typeof ctrl === "symbol") return ctrl;
		for (const field of ["key", "value"]) {
			const token = item[field];
			if (token && "items" in token) {
				for (let i = 0; i < token.items.length; ++i) {
					const ci = _visit(Object.freeze(path.concat([[field, i]])), token.items[i], visitor);
					if (typeof ci === "number") i = ci - 1;
					else if (ci === BREAK) return BREAK;
					else if (ci === REMOVE) {
						token.items.splice(i, 1);
						i -= 1;
					}
				}
				if (typeof ctrl === "function" && field === "key") ctrl = ctrl(item, path);
			}
		}
		return typeof ctrl === "function" ? ctrl(item, path) : ctrl;
	}
	exports.visit = visit;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst.js
var require_cst = /* @__PURE__ */ __commonJSMin(((exports) => {
	var cstScalar = require_cst_scalar();
	var cstStringify = require_cst_stringify();
	var cstVisit = require_cst_visit();
	/** The byte order mark */
	const BOM = "";
	/** Start of doc-mode */
	const DOCUMENT = "";
	/** Unexpected end of flow-mode */
	const FLOW_END = "";
	/** Next token is a scalar value */
	const SCALAR = "";
	/** @returns `true` if `token` is a flow or block collection */
	const isCollection = (token) => !!token && "items" in token;
	/** @returns `true` if `token` is a flow or block scalar; not an alias */
	const isScalar = (token) => !!token && (token.type === "scalar" || token.type === "single-quoted-scalar" || token.type === "double-quoted-scalar" || token.type === "block-scalar");
	/* istanbul ignore next */
	/** Get a printable representation of a lexer token */
	function prettyToken(token) {
		switch (token) {
			case BOM: return "<BOM>";
			case DOCUMENT: return "<DOC>";
			case FLOW_END: return "<FLOW_END>";
			case SCALAR: return "<SCALAR>";
			default: return JSON.stringify(token);
		}
	}
	/** Identify the type of a lexer token. May return `null` for unknown tokens. */
	function tokenType(source) {
		switch (source) {
			case BOM: return "byte-order-mark";
			case DOCUMENT: return "doc-mode";
			case FLOW_END: return "flow-error-end";
			case SCALAR: return "scalar";
			case "---": return "doc-start";
			case "...": return "doc-end";
			case "":
			case "\n":
			case "\r\n": return "newline";
			case "-": return "seq-item-ind";
			case "?": return "explicit-key-ind";
			case ":": return "map-value-ind";
			case "{": return "flow-map-start";
			case "}": return "flow-map-end";
			case "[": return "flow-seq-start";
			case "]": return "flow-seq-end";
			case ",": return "comma";
		}
		switch (source[0]) {
			case " ":
			case "	": return "space";
			case "#": return "comment";
			case "%": return "directive-line";
			case "*": return "alias";
			case "&": return "anchor";
			case "!": return "tag";
			case "'": return "single-quoted-scalar";
			case "\"": return "double-quoted-scalar";
			case "|":
			case ">": return "block-scalar-header";
		}
		return null;
	}
	exports.createScalarToken = cstScalar.createScalarToken;
	exports.resolveAsScalar = cstScalar.resolveAsScalar;
	exports.setScalarValue = cstScalar.setScalarValue;
	exports.stringify = cstStringify.stringify;
	exports.visit = cstVisit.visit;
	exports.BOM = BOM;
	exports.DOCUMENT = DOCUMENT;
	exports.FLOW_END = FLOW_END;
	exports.SCALAR = SCALAR;
	exports.isCollection = isCollection;
	exports.isScalar = isScalar;
	exports.prettyToken = prettyToken;
	exports.tokenType = tokenType;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/lexer.js
var require_lexer = /* @__PURE__ */ __commonJSMin(((exports) => {
	var cst = require_cst();
	function isEmpty(ch) {
		switch (ch) {
			case void 0:
			case " ":
			case "\n":
			case "\r":
			case "	": return true;
			default: return false;
		}
	}
	const hexDigits = /* @__PURE__ */ new Set("0123456789ABCDEFabcdef");
	const tagChars = /* @__PURE__ */ new Set("0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()");
	const flowIndicatorChars = /* @__PURE__ */ new Set(",[]{}");
	const invalidAnchorChars = /* @__PURE__ */ new Set(" ,[]{}\n\r	");
	const isNotAnchorChar = (ch) => !ch || invalidAnchorChars.has(ch);
	/**
	* Splits an input string into lexical tokens, i.e. smaller strings that are
	* easily identifiable by `tokens.tokenType()`.
	*
	* Lexing starts always in a "stream" context. Incomplete input may be buffered
	* until a complete token can be emitted.
	*
	* In addition to slices of the original input, the following control characters
	* may also be emitted:
	*
	* - `\x02` (Start of Text): A document starts with the next token
	* - `\x18` (Cancel): Unexpected end of flow-mode (indicates an error)
	* - `\x1f` (Unit Separator): Next token is a scalar value
	* - `\u{FEFF}` (Byte order mark): Emitted separately outside documents
	*/
	var Lexer = class {
		constructor() {
			/**
			* Flag indicating whether the end of the current buffer marks the end of
			* all input
			*/
			this.atEnd = false;
			/**
			* Explicit indent set in block scalar header, as an offset from the current
			* minimum indent, so e.g. set to 1 from a header `|2+`. Set to -1 if not
			* explicitly set.
			*/
			this.blockScalarIndent = -1;
			/**
			* Block scalars that include a + (keep) chomping indicator in their header
			* include trailing empty lines, which are otherwise excluded from the
			* scalar's contents.
			*/
			this.blockScalarKeep = false;
			/** Current input */
			this.buffer = "";
			/**
			* Flag noting whether the map value indicator : can immediately follow this
			* node within a flow context.
			*/
			this.flowKey = false;
			/** Count of surrounding flow collection levels. */
			this.flowLevel = 0;
			/**
			* Minimum level of indentation required for next lines to be parsed as a
			* part of the current scalar value.
			*/
			this.indentNext = 0;
			/** Indentation level of the current line. */
			this.indentValue = 0;
			/** Position of the next \n character. */
			this.lineEndPos = null;
			/** Stores the state of the lexer if reaching the end of incpomplete input */
			this.next = null;
			/** A pointer to `buffer`; the current position of the lexer. */
			this.pos = 0;
		}
		/**
		* Generate YAML tokens from the `source` string. If `incomplete`,
		* a part of the last line may be left as a buffer for the next call.
		*
		* @returns A generator of lexical tokens
		*/
		*lex(source, incomplete = false) {
			if (source) {
				if (typeof source !== "string") throw TypeError("source is not a string");
				this.buffer = this.buffer ? this.buffer + source : source;
				this.lineEndPos = null;
			}
			this.atEnd = !incomplete;
			let next = this.next ?? "stream";
			while (next && (incomplete || this.hasChars(1))) next = yield* this.parseNext(next);
		}
		atLineEnd() {
			let i = this.pos;
			let ch = this.buffer[i];
			while (ch === " " || ch === "	") ch = this.buffer[++i];
			if (!ch || ch === "#" || ch === "\n") return true;
			if (ch === "\r") return this.buffer[i + 1] === "\n";
			return false;
		}
		charAt(n) {
			return this.buffer[this.pos + n];
		}
		continueScalar(offset) {
			let ch = this.buffer[offset];
			if (this.indentNext > 0) {
				let indent = 0;
				while (ch === " ") ch = this.buffer[++indent + offset];
				if (ch === "\r") {
					const next = this.buffer[indent + offset + 1];
					if (next === "\n" || !next && !this.atEnd) return offset + indent + 1;
				}
				return ch === "\n" || indent >= this.indentNext || !ch && !this.atEnd ? offset + indent : -1;
			}
			if (ch === "-" || ch === ".") {
				const dt = this.buffer.substr(offset, 3);
				if ((dt === "---" || dt === "...") && isEmpty(this.buffer[offset + 3])) return -1;
			}
			return offset;
		}
		getLine() {
			let end = this.lineEndPos;
			if (typeof end !== "number" || end !== -1 && end < this.pos) {
				end = this.buffer.indexOf("\n", this.pos);
				this.lineEndPos = end;
			}
			if (end === -1) return this.atEnd ? this.buffer.substring(this.pos) : null;
			if (this.buffer[end - 1] === "\r") end -= 1;
			return this.buffer.substring(this.pos, end);
		}
		hasChars(n) {
			return this.pos + n <= this.buffer.length;
		}
		setNext(state) {
			this.buffer = this.buffer.substring(this.pos);
			this.pos = 0;
			this.lineEndPos = null;
			this.next = state;
			return null;
		}
		peek(n) {
			return this.buffer.substr(this.pos, n);
		}
		*parseNext(next) {
			switch (next) {
				case "stream": return yield* this.parseStream();
				case "line-start": return yield* this.parseLineStart();
				case "block-start": return yield* this.parseBlockStart();
				case "doc": return yield* this.parseDocument();
				case "flow": return yield* this.parseFlowCollection();
				case "quoted-scalar": return yield* this.parseQuotedScalar();
				case "block-scalar": return yield* this.parseBlockScalar();
				case "plain-scalar": return yield* this.parsePlainScalar();
			}
		}
		*parseStream() {
			let line = this.getLine();
			if (line === null) return this.setNext("stream");
			if (line[0] === cst.BOM) {
				yield* this.pushCount(1);
				line = line.substring(1);
			}
			if (line[0] === "%") {
				let dirEnd = line.length;
				let cs = line.indexOf("#");
				while (cs !== -1) {
					const ch = line[cs - 1];
					if (ch === " " || ch === "	") {
						dirEnd = cs - 1;
						break;
					} else cs = line.indexOf("#", cs + 1);
				}
				while (true) {
					const ch = line[dirEnd - 1];
					if (ch === " " || ch === "	") dirEnd -= 1;
					else break;
				}
				const n = (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true));
				yield* this.pushCount(line.length - n);
				this.pushNewline();
				return "stream";
			}
			if (this.atLineEnd()) {
				const sp = yield* this.pushSpaces(true);
				yield* this.pushCount(line.length - sp);
				yield* this.pushNewline();
				return "stream";
			}
			yield cst.DOCUMENT;
			return yield* this.parseLineStart();
		}
		*parseLineStart() {
			const ch = this.charAt(0);
			if (!ch && !this.atEnd) return this.setNext("line-start");
			if (ch === "-" || ch === ".") {
				if (!this.atEnd && !this.hasChars(4)) return this.setNext("line-start");
				const s = this.peek(3);
				if ((s === "---" || s === "...") && isEmpty(this.charAt(3))) {
					yield* this.pushCount(3);
					this.indentValue = 0;
					this.indentNext = 0;
					return s === "---" ? "doc" : "stream";
				}
			}
			this.indentValue = yield* this.pushSpaces(false);
			if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1))) this.indentNext = this.indentValue;
			return yield* this.parseBlockStart();
		}
		*parseBlockStart() {
			const [ch0, ch1] = this.peek(2);
			if (!ch1 && !this.atEnd) return this.setNext("block-start");
			if ((ch0 === "-" || ch0 === "?" || ch0 === ":") && isEmpty(ch1)) {
				const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true));
				this.indentNext = this.indentValue + 1;
				this.indentValue += n;
				return yield* this.parseBlockStart();
			}
			return "doc";
		}
		*parseDocument() {
			yield* this.pushSpaces(true);
			const line = this.getLine();
			if (line === null) return this.setNext("doc");
			let n = yield* this.pushIndicators();
			switch (line[n]) {
				case "#": yield* this.pushCount(line.length - n);
				case void 0:
					yield* this.pushNewline();
					return yield* this.parseLineStart();
				case "{":
				case "[":
					yield* this.pushCount(1);
					this.flowKey = false;
					this.flowLevel = 1;
					return "flow";
				case "}":
				case "]":
					yield* this.pushCount(1);
					return "doc";
				case "*":
					yield* this.pushUntil(isNotAnchorChar);
					return "doc";
				case "\"":
				case "'": return yield* this.parseQuotedScalar();
				case "|":
				case ">":
					n += yield* this.parseBlockScalarHeader();
					n += yield* this.pushSpaces(true);
					yield* this.pushCount(line.length - n);
					yield* this.pushNewline();
					return yield* this.parseBlockScalar();
				default: return yield* this.parsePlainScalar();
			}
		}
		*parseFlowCollection() {
			let nl, sp;
			let indent = -1;
			do {
				nl = yield* this.pushNewline();
				if (nl > 0) {
					sp = yield* this.pushSpaces(false);
					this.indentValue = indent = sp;
				} else sp = 0;
				sp += yield* this.pushSpaces(true);
			} while (nl + sp > 0);
			const line = this.getLine();
			if (line === null) return this.setNext("flow");
			if (indent !== -1 && indent < this.indentNext && line[0] !== "#" || indent === 0 && (line.startsWith("---") || line.startsWith("...")) && isEmpty(line[3])) {
				if (!(indent === this.indentNext - 1 && this.flowLevel === 1 && (line[0] === "]" || line[0] === "}"))) {
					this.flowLevel = 0;
					yield cst.FLOW_END;
					return yield* this.parseLineStart();
				}
			}
			let n = 0;
			while (line[n] === ",") {
				n += yield* this.pushCount(1);
				n += yield* this.pushSpaces(true);
				this.flowKey = false;
			}
			n += yield* this.pushIndicators();
			switch (line[n]) {
				case void 0: return "flow";
				case "#":
					yield* this.pushCount(line.length - n);
					return "flow";
				case "{":
				case "[":
					yield* this.pushCount(1);
					this.flowKey = false;
					this.flowLevel += 1;
					return "flow";
				case "}":
				case "]":
					yield* this.pushCount(1);
					this.flowKey = true;
					this.flowLevel -= 1;
					return this.flowLevel ? "flow" : "doc";
				case "*":
					yield* this.pushUntil(isNotAnchorChar);
					return "flow";
				case "\"":
				case "'":
					this.flowKey = true;
					return yield* this.parseQuotedScalar();
				case ":": {
					const next = this.charAt(1);
					if (this.flowKey || isEmpty(next) || next === ",") {
						this.flowKey = false;
						yield* this.pushCount(1);
						yield* this.pushSpaces(true);
						return "flow";
					}
				}
				default:
					this.flowKey = false;
					return yield* this.parsePlainScalar();
			}
		}
		*parseQuotedScalar() {
			const quote = this.charAt(0);
			let end = this.buffer.indexOf(quote, this.pos + 1);
			if (quote === "'") while (end !== -1 && this.buffer[end + 1] === "'") end = this.buffer.indexOf("'", end + 2);
			else while (end !== -1) {
				let n = 0;
				while (this.buffer[end - 1 - n] === "\\") n += 1;
				if (n % 2 === 0) break;
				end = this.buffer.indexOf("\"", end + 1);
			}
			const qb = this.buffer.substring(0, end);
			let nl = qb.indexOf("\n", this.pos);
			if (nl !== -1) {
				while (nl !== -1) {
					const cs = this.continueScalar(nl + 1);
					if (cs === -1) break;
					nl = qb.indexOf("\n", cs);
				}
				if (nl !== -1) end = nl - (qb[nl - 1] === "\r" ? 2 : 1);
			}
			if (end === -1) {
				if (!this.atEnd) return this.setNext("quoted-scalar");
				end = this.buffer.length;
			}
			yield* this.pushToIndex(end + 1, false);
			return this.flowLevel ? "flow" : "doc";
		}
		*parseBlockScalarHeader() {
			this.blockScalarIndent = -1;
			this.blockScalarKeep = false;
			let i = this.pos;
			while (true) {
				const ch = this.buffer[++i];
				if (ch === "+") this.blockScalarKeep = true;
				else if (ch > "0" && ch <= "9") this.blockScalarIndent = Number(ch) - 1;
				else if (ch !== "-") break;
			}
			return yield* this.pushUntil((ch) => isEmpty(ch) || ch === "#");
		}
		*parseBlockScalar() {
			let nl = this.pos - 1;
			let indent = 0;
			let ch;
			loop: for (let i = this.pos; ch = this.buffer[i]; ++i) switch (ch) {
				case " ":
					indent += 1;
					break;
				case "\n":
					nl = i;
					indent = 0;
					break;
				case "\r": {
					const next = this.buffer[i + 1];
					if (!next && !this.atEnd) return this.setNext("block-scalar");
					if (next === "\n") break;
				}
				default: break loop;
			}
			if (!ch && !this.atEnd) return this.setNext("block-scalar");
			if (indent >= this.indentNext) {
				if (this.blockScalarIndent === -1) this.indentNext = indent;
				else this.indentNext = this.blockScalarIndent + (this.indentNext === 0 ? 1 : this.indentNext);
				do {
					const cs = this.continueScalar(nl + 1);
					if (cs === -1) break;
					nl = this.buffer.indexOf("\n", cs);
				} while (nl !== -1);
				if (nl === -1) {
					if (!this.atEnd) return this.setNext("block-scalar");
					nl = this.buffer.length;
				}
			}
			let i = nl + 1;
			ch = this.buffer[i];
			while (ch === " ") ch = this.buffer[++i];
			if (ch === "	") {
				while (ch === "	" || ch === " " || ch === "\r" || ch === "\n") ch = this.buffer[++i];
				nl = i - 1;
			} else if (!this.blockScalarKeep) do {
				let i = nl - 1;
				let ch = this.buffer[i];
				if (ch === "\r") ch = this.buffer[--i];
				const lastChar = i;
				while (ch === " ") ch = this.buffer[--i];
				if (ch === "\n" && i >= this.pos && i + 1 + indent > lastChar) nl = i;
				else break;
			} while (true);
			yield cst.SCALAR;
			yield* this.pushToIndex(nl + 1, true);
			return yield* this.parseLineStart();
		}
		*parsePlainScalar() {
			const inFlow = this.flowLevel > 0;
			let end = this.pos - 1;
			let i = this.pos - 1;
			let ch;
			while (ch = this.buffer[++i]) if (ch === ":") {
				const next = this.buffer[i + 1];
				if (isEmpty(next) || inFlow && flowIndicatorChars.has(next)) break;
				end = i;
			} else if (isEmpty(ch)) {
				let next = this.buffer[i + 1];
				if (ch === "\r") if (next === "\n") {
					i += 1;
					ch = "\n";
					next = this.buffer[i + 1];
				} else end = i;
				if (next === "#" || inFlow && flowIndicatorChars.has(next)) break;
				if (ch === "\n") {
					const cs = this.continueScalar(i + 1);
					if (cs === -1) break;
					i = Math.max(i, cs - 2);
				}
			} else {
				if (inFlow && flowIndicatorChars.has(ch)) break;
				end = i;
			}
			if (!ch && !this.atEnd) return this.setNext("plain-scalar");
			yield cst.SCALAR;
			yield* this.pushToIndex(end + 1, true);
			return inFlow ? "flow" : "doc";
		}
		*pushCount(n) {
			if (n > 0) {
				yield this.buffer.substr(this.pos, n);
				this.pos += n;
				return n;
			}
			return 0;
		}
		*pushToIndex(i, allowEmpty) {
			const s = this.buffer.slice(this.pos, i);
			if (s) {
				yield s;
				this.pos += s.length;
				return s.length;
			} else if (allowEmpty) yield "";
			return 0;
		}
		*pushIndicators() {
			switch (this.charAt(0)) {
				case "!": return (yield* this.pushTag()) + (yield* this.pushSpaces(true)) + (yield* this.pushIndicators());
				case "&": return (yield* this.pushUntil(isNotAnchorChar)) + (yield* this.pushSpaces(true)) + (yield* this.pushIndicators());
				case "-":
				case "?":
				case ":": {
					const inFlow = this.flowLevel > 0;
					const ch1 = this.charAt(1);
					if (isEmpty(ch1) || inFlow && flowIndicatorChars.has(ch1)) {
						if (!inFlow) this.indentNext = this.indentValue + 1;
						else if (this.flowKey) this.flowKey = false;
						return (yield* this.pushCount(1)) + (yield* this.pushSpaces(true)) + (yield* this.pushIndicators());
					}
				}
			}
			return 0;
		}
		*pushTag() {
			if (this.charAt(1) === "<") {
				let i = this.pos + 2;
				let ch = this.buffer[i];
				while (!isEmpty(ch) && ch !== ">") ch = this.buffer[++i];
				return yield* this.pushToIndex(ch === ">" ? i + 1 : i, false);
			} else {
				let i = this.pos + 1;
				let ch = this.buffer[i];
				while (ch) if (tagChars.has(ch)) ch = this.buffer[++i];
				else if (ch === "%" && hexDigits.has(this.buffer[i + 1]) && hexDigits.has(this.buffer[i + 2])) ch = this.buffer[i += 3];
				else break;
				return yield* this.pushToIndex(i, false);
			}
		}
		*pushNewline() {
			const ch = this.buffer[this.pos];
			if (ch === "\n") return yield* this.pushCount(1);
			else if (ch === "\r" && this.charAt(1) === "\n") return yield* this.pushCount(2);
			else return 0;
		}
		*pushSpaces(allowTabs) {
			let i = this.pos - 1;
			let ch;
			do
				ch = this.buffer[++i];
			while (ch === " " || allowTabs && ch === "	");
			const n = i - this.pos;
			if (n > 0) {
				yield this.buffer.substr(this.pos, n);
				this.pos = i;
			}
			return n;
		}
		*pushUntil(test) {
			let i = this.pos;
			let ch = this.buffer[i];
			while (!test(ch)) ch = this.buffer[++i];
			return yield* this.pushToIndex(i, false);
		}
	};
	exports.Lexer = Lexer;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/line-counter.js
var require_line_counter = /* @__PURE__ */ __commonJSMin(((exports) => {
	/**
	* Tracks newlines during parsing in order to provide an efficient API for
	* determining the one-indexed `{ line, col }` position for any offset
	* within the input.
	*/
	var LineCounter = class {
		constructor() {
			this.lineStarts = [];
			/**
			* Should be called in ascending order. Otherwise, call
			* `lineCounter.lineStarts.sort()` before calling `linePos()`.
			*/
			this.addNewLine = (offset) => this.lineStarts.push(offset);
			/**
			* Performs a binary search and returns the 1-indexed { line, col }
			* position of `offset`. If `line === 0`, `addNewLine` has never been
			* called or `offset` is before the first known newline.
			*/
			this.linePos = (offset) => {
				let low = 0;
				let high = this.lineStarts.length;
				while (low < high) {
					const mid = low + high >> 1;
					if (this.lineStarts[mid] < offset) low = mid + 1;
					else high = mid;
				}
				if (this.lineStarts[low] === offset) return {
					line: low + 1,
					col: 1
				};
				if (low === 0) return {
					line: 0,
					col: offset
				};
				const start = this.lineStarts[low - 1];
				return {
					line: low,
					col: offset - start + 1
				};
			};
		}
	};
	exports.LineCounter = LineCounter;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/parser.js
var require_parser = /* @__PURE__ */ __commonJSMin(((exports) => {
	var node_process = __require$1("process");
	var cst = require_cst();
	var lexer = require_lexer();
	function includesToken(list, type) {
		for (let i = 0; i < list.length; ++i) if (list[i].type === type) return true;
		return false;
	}
	function findNonEmptyIndex(list) {
		for (let i = 0; i < list.length; ++i) switch (list[i].type) {
			case "space":
			case "comment":
			case "newline": break;
			default: return i;
		}
		return -1;
	}
	function isFlowToken(token) {
		switch (token?.type) {
			case "alias":
			case "scalar":
			case "single-quoted-scalar":
			case "double-quoted-scalar":
			case "flow-collection": return true;
			default: return false;
		}
	}
	function getPrevProps(parent) {
		switch (parent.type) {
			case "document": return parent.start;
			case "block-map": {
				const it = parent.items[parent.items.length - 1];
				return it.sep ?? it.start;
			}
			case "block-seq": return parent.items[parent.items.length - 1].start;
			default: return [];
		}
	}
	/** Note: May modify input array */
	function getFirstKeyStartProps(prev) {
		if (prev.length === 0) return [];
		let i = prev.length;
		loop: while (--i >= 0) switch (prev[i].type) {
			case "doc-start":
			case "explicit-key-ind":
			case "map-value-ind":
			case "seq-item-ind":
			case "newline": break loop;
		}
		while (prev[++i]?.type === "space");
		return prev.splice(i, prev.length);
	}
	function fixFlowSeqItems(fc) {
		if (fc.start.type === "flow-seq-start") {
			for (const it of fc.items) if (it.sep && !it.value && !includesToken(it.start, "explicit-key-ind") && !includesToken(it.sep, "map-value-ind")) {
				if (it.key) it.value = it.key;
				delete it.key;
				if (isFlowToken(it.value)) if (it.value.end) Array.prototype.push.apply(it.value.end, it.sep);
				else it.value.end = it.sep;
				else Array.prototype.push.apply(it.start, it.sep);
				delete it.sep;
			}
		}
	}
	/**
	* A YAML concrete syntax tree (CST) parser
	*
	* ```ts
	* const src: string = ...
	* for (const token of new Parser().parse(src)) {
	*   // token: Token
	* }
	* ```
	*
	* To use the parser with a user-provided lexer:
	*
	* ```ts
	* function* parse(source: string, lexer: Lexer) {
	*   const parser = new Parser()
	*   for (const lexeme of lexer.lex(source))
	*     yield* parser.next(lexeme)
	*   yield* parser.end()
	* }
	*
	* const src: string = ...
	* const lexer = new Lexer()
	* for (const token of parse(src, lexer)) {
	*   // token: Token
	* }
	* ```
	*/
	var Parser = class {
		/**
		* @param onNewLine - If defined, called separately with the start position of
		*   each new line (in `parse()`, including the start of input).
		*/
		constructor(onNewLine) {
			/** If true, space and sequence indicators count as indentation */
			this.atNewLine = true;
			/** If true, next token is a scalar value */
			this.atScalar = false;
			/** Current indentation level */
			this.indent = 0;
			/** Current offset since the start of parsing */
			this.offset = 0;
			/** On the same line with a block map key */
			this.onKeyLine = false;
			/** Top indicates the node that's currently being built */
			this.stack = [];
			/** The source of the current token, set in parse() */
			this.source = "";
			/** The type of the current token, set in parse() */
			this.type = "";
			this.lexer = new lexer.Lexer();
			this.onNewLine = onNewLine;
		}
		/**
		* Parse `source` as a YAML stream.
		* If `incomplete`, a part of the last line may be left as a buffer for the next call.
		*
		* Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.
		*
		* @returns A generator of tokens representing each directive, document, and other structure.
		*/
		*parse(source, incomplete = false) {
			if (this.onNewLine && this.offset === 0) this.onNewLine(0);
			for (const lexeme of this.lexer.lex(source, incomplete)) yield* this.next(lexeme);
			if (!incomplete) yield* this.end();
		}
		/**
		* Advance the parser by the `source` of one lexical token.
		*/
		*next(source) {
			this.source = source;
			if (node_process.env.LOG_TOKENS) console.log("|", cst.prettyToken(source));
			if (this.atScalar) {
				this.atScalar = false;
				yield* this.step();
				this.offset += source.length;
				return;
			}
			const type = cst.tokenType(source);
			if (!type) {
				const message = `Not a YAML token: ${source}`;
				yield* this.pop({
					type: "error",
					offset: this.offset,
					message,
					source
				});
				this.offset += source.length;
			} else if (type === "scalar") {
				this.atNewLine = false;
				this.atScalar = true;
				this.type = "scalar";
			} else {
				this.type = type;
				yield* this.step();
				switch (type) {
					case "newline":
						this.atNewLine = true;
						this.indent = 0;
						if (this.onNewLine) this.onNewLine(this.offset + source.length);
						break;
					case "space":
						if (this.atNewLine && source[0] === " ") this.indent += source.length;
						break;
					case "explicit-key-ind":
					case "map-value-ind":
					case "seq-item-ind":
						if (this.atNewLine) this.indent += source.length;
						break;
					case "doc-mode":
					case "flow-error-end": return;
					default: this.atNewLine = false;
				}
				this.offset += source.length;
			}
		}
		/** Call at end of input to push out any remaining constructions */
		*end() {
			while (this.stack.length > 0) yield* this.pop();
		}
		get sourceToken() {
			return {
				type: this.type,
				offset: this.offset,
				indent: this.indent,
				source: this.source
			};
		}
		*step() {
			const top = this.peek(1);
			if (this.type === "doc-end" && top?.type !== "doc-end") {
				while (this.stack.length > 0) yield* this.pop();
				this.stack.push({
					type: "doc-end",
					offset: this.offset,
					source: this.source
				});
				return;
			}
			if (!top) return yield* this.stream();
			switch (top.type) {
				case "document": return yield* this.document(top);
				case "alias":
				case "scalar":
				case "single-quoted-scalar":
				case "double-quoted-scalar": return yield* this.scalar(top);
				case "block-scalar": return yield* this.blockScalar(top);
				case "block-map": return yield* this.blockMap(top);
				case "block-seq": return yield* this.blockSequence(top);
				case "flow-collection": return yield* this.flowCollection(top);
				case "doc-end": return yield* this.documentEnd(top);
			}
			/* istanbul ignore next should not happen */
			yield* this.pop();
		}
		peek(n) {
			return this.stack[this.stack.length - n];
		}
		*pop(error) {
			const token = error ?? this.stack.pop();
			/* istanbul ignore if should not happen */
			if (!token) yield {
				type: "error",
				offset: this.offset,
				source: "",
				message: "Tried to pop an empty stack"
			};
			else if (this.stack.length === 0) yield token;
			else {
				const top = this.peek(1);
				if (token.type === "block-scalar") token.indent = "indent" in top ? top.indent : 0;
				else if (token.type === "flow-collection" && top.type === "document") token.indent = 0;
				if (token.type === "flow-collection") fixFlowSeqItems(token);
				switch (top.type) {
					case "document":
						top.value = token;
						break;
					case "block-scalar":
						top.props.push(token);
						break;
					case "block-map": {
						const it = top.items[top.items.length - 1];
						if (it.value) {
							top.items.push({
								start: [],
								key: token,
								sep: []
							});
							this.onKeyLine = true;
							return;
						} else if (it.sep) it.value = token;
						else {
							Object.assign(it, {
								key: token,
								sep: []
							});
							this.onKeyLine = !it.explicitKey;
							return;
						}
						break;
					}
					case "block-seq": {
						const it = top.items[top.items.length - 1];
						if (it.value) top.items.push({
							start: [],
							value: token
						});
						else it.value = token;
						break;
					}
					case "flow-collection": {
						const it = top.items[top.items.length - 1];
						if (!it || it.value) top.items.push({
							start: [],
							key: token,
							sep: []
						});
						else if (it.sep) it.value = token;
						else Object.assign(it, {
							key: token,
							sep: []
						});
						return;
					}
					default:
						yield* this.pop();
						yield* this.pop(token);
				}
				if ((top.type === "document" || top.type === "block-map" || top.type === "block-seq") && (token.type === "block-map" || token.type === "block-seq")) {
					const last = token.items[token.items.length - 1];
					if (last && !last.sep && !last.value && last.start.length > 0 && findNonEmptyIndex(last.start) === -1 && (token.indent === 0 || last.start.every((st) => st.type !== "comment" || st.indent < token.indent))) {
						if (top.type === "document") top.end = last.start;
						else top.items.push({ start: last.start });
						token.items.splice(-1, 1);
					}
				}
			}
		}
		*stream() {
			switch (this.type) {
				case "directive-line":
					yield {
						type: "directive",
						offset: this.offset,
						source: this.source
					};
					return;
				case "byte-order-mark":
				case "space":
				case "comment":
				case "newline":
					yield this.sourceToken;
					return;
				case "doc-mode":
				case "doc-start": {
					const doc = {
						type: "document",
						offset: this.offset,
						start: []
					};
					if (this.type === "doc-start") doc.start.push(this.sourceToken);
					this.stack.push(doc);
					return;
				}
			}
			yield {
				type: "error",
				offset: this.offset,
				message: `Unexpected ${this.type} token in YAML stream`,
				source: this.source
			};
		}
		*document(doc) {
			if (doc.value) return yield* this.lineEnd(doc);
			switch (this.type) {
				case "doc-start":
					if (findNonEmptyIndex(doc.start) !== -1) {
						yield* this.pop();
						yield* this.step();
					} else doc.start.push(this.sourceToken);
					return;
				case "anchor":
				case "tag":
				case "space":
				case "comment":
				case "newline":
					doc.start.push(this.sourceToken);
					return;
			}
			const bv = this.startBlockValue(doc);
			if (bv) this.stack.push(bv);
			else yield {
				type: "error",
				offset: this.offset,
				message: `Unexpected ${this.type} token in YAML document`,
				source: this.source
			};
		}
		*scalar(scalar) {
			if (this.type === "map-value-ind") {
				const start = getFirstKeyStartProps(getPrevProps(this.peek(2)));
				let sep;
				if (scalar.end) {
					sep = scalar.end;
					sep.push(this.sourceToken);
					delete scalar.end;
				} else sep = [this.sourceToken];
				const map = {
					type: "block-map",
					offset: scalar.offset,
					indent: scalar.indent,
					items: [{
						start,
						key: scalar,
						sep
					}]
				};
				this.onKeyLine = true;
				this.stack[this.stack.length - 1] = map;
			} else yield* this.lineEnd(scalar);
		}
		*blockScalar(scalar) {
			switch (this.type) {
				case "space":
				case "comment":
				case "newline":
					scalar.props.push(this.sourceToken);
					return;
				case "scalar":
					scalar.source = this.source;
					this.atNewLine = true;
					this.indent = 0;
					if (this.onNewLine) {
						let nl = this.source.indexOf("\n") + 1;
						while (nl !== 0) {
							this.onNewLine(this.offset + nl);
							nl = this.source.indexOf("\n", nl) + 1;
						}
					}
					yield* this.pop();
					break;
				default:
					yield* this.pop();
					yield* this.step();
			}
		}
		*blockMap(map) {
			const it = map.items[map.items.length - 1];
			switch (this.type) {
				case "newline":
					this.onKeyLine = false;
					if (it.value) {
						const end = "end" in it.value ? it.value.end : void 0;
						if ((Array.isArray(end) ? end[end.length - 1] : void 0)?.type === "comment") end?.push(this.sourceToken);
						else map.items.push({ start: [this.sourceToken] });
					} else if (it.sep) it.sep.push(this.sourceToken);
					else it.start.push(this.sourceToken);
					return;
				case "space":
				case "comment":
					if (it.value) map.items.push({ start: [this.sourceToken] });
					else if (it.sep) it.sep.push(this.sourceToken);
					else {
						if (this.atIndentedComment(it.start, map.indent)) {
							const end = map.items[map.items.length - 2]?.value?.end;
							if (Array.isArray(end)) {
								Array.prototype.push.apply(end, it.start);
								end.push(this.sourceToken);
								map.items.pop();
								return;
							}
						}
						it.start.push(this.sourceToken);
					}
					return;
			}
			if (this.indent >= map.indent) {
				const atMapIndent = !this.onKeyLine && this.indent === map.indent;
				const atNextItem = atMapIndent && (it.sep || it.explicitKey) && this.type !== "seq-item-ind";
				let start = [];
				if (atNextItem && it.sep && !it.value) {
					const nl = [];
					for (let i = 0; i < it.sep.length; ++i) {
						const st = it.sep[i];
						switch (st.type) {
							case "newline":
								nl.push(i);
								break;
							case "space": break;
							case "comment":
								if (st.indent > map.indent) nl.length = 0;
								break;
							default: nl.length = 0;
						}
					}
					if (nl.length >= 2) start = it.sep.splice(nl[1]);
				}
				switch (this.type) {
					case "anchor":
					case "tag":
						if (atNextItem || it.value) {
							start.push(this.sourceToken);
							map.items.push({ start });
							this.onKeyLine = true;
						} else if (it.sep) it.sep.push(this.sourceToken);
						else it.start.push(this.sourceToken);
						return;
					case "explicit-key-ind":
						if (!it.sep && !it.explicitKey) {
							it.start.push(this.sourceToken);
							it.explicitKey = true;
						} else if (atNextItem || it.value) {
							start.push(this.sourceToken);
							map.items.push({
								start,
								explicitKey: true
							});
						} else this.stack.push({
							type: "block-map",
							offset: this.offset,
							indent: this.indent,
							items: [{
								start: [this.sourceToken],
								explicitKey: true
							}]
						});
						this.onKeyLine = true;
						return;
					case "map-value-ind":
						if (it.explicitKey) if (!it.sep) if (includesToken(it.start, "newline")) Object.assign(it, {
							key: null,
							sep: [this.sourceToken]
						});
						else {
							const start = getFirstKeyStartProps(it.start);
							this.stack.push({
								type: "block-map",
								offset: this.offset,
								indent: this.indent,
								items: [{
									start,
									key: null,
									sep: [this.sourceToken]
								}]
							});
						}
						else if (it.value) map.items.push({
							start: [],
							key: null,
							sep: [this.sourceToken]
						});
						else if (includesToken(it.sep, "map-value-ind")) this.stack.push({
							type: "block-map",
							offset: this.offset,
							indent: this.indent,
							items: [{
								start,
								key: null,
								sep: [this.sourceToken]
							}]
						});
						else if (isFlowToken(it.key) && !includesToken(it.sep, "newline")) {
							const start = getFirstKeyStartProps(it.start);
							const key = it.key;
							const sep = it.sep;
							sep.push(this.sourceToken);
							delete it.key;
							delete it.sep;
							this.stack.push({
								type: "block-map",
								offset: this.offset,
								indent: this.indent,
								items: [{
									start,
									key,
									sep
								}]
							});
						} else if (start.length > 0) it.sep = it.sep.concat(start, this.sourceToken);
						else it.sep.push(this.sourceToken);
						else if (!it.sep) Object.assign(it, {
							key: null,
							sep: [this.sourceToken]
						});
						else if (it.value || atNextItem) map.items.push({
							start,
							key: null,
							sep: [this.sourceToken]
						});
						else if (includesToken(it.sep, "map-value-ind")) this.stack.push({
							type: "block-map",
							offset: this.offset,
							indent: this.indent,
							items: [{
								start: [],
								key: null,
								sep: [this.sourceToken]
							}]
						});
						else it.sep.push(this.sourceToken);
						this.onKeyLine = true;
						return;
					case "alias":
					case "scalar":
					case "single-quoted-scalar":
					case "double-quoted-scalar": {
						const fs = this.flowScalar(this.type);
						if (atNextItem || it.value) {
							map.items.push({
								start,
								key: fs,
								sep: []
							});
							this.onKeyLine = true;
						} else if (it.sep) this.stack.push(fs);
						else {
							Object.assign(it, {
								key: fs,
								sep: []
							});
							this.onKeyLine = true;
						}
						return;
					}
					default: {
						const bv = this.startBlockValue(map);
						if (bv) {
							if (bv.type === "block-seq") {
								if (!it.explicitKey && it.sep && !includesToken(it.sep, "newline")) {
									yield* this.pop({
										type: "error",
										offset: this.offset,
										message: "Unexpected block-seq-ind on same line with key",
										source: this.source
									});
									return;
								}
							} else if (atMapIndent) map.items.push({ start });
							this.stack.push(bv);
							return;
						}
					}
				}
			}
			yield* this.pop();
			yield* this.step();
		}
		*blockSequence(seq) {
			const it = seq.items[seq.items.length - 1];
			switch (this.type) {
				case "newline":
					if (it.value) {
						const end = "end" in it.value ? it.value.end : void 0;
						if ((Array.isArray(end) ? end[end.length - 1] : void 0)?.type === "comment") end?.push(this.sourceToken);
						else seq.items.push({ start: [this.sourceToken] });
					} else it.start.push(this.sourceToken);
					return;
				case "space":
				case "comment":
					if (it.value) seq.items.push({ start: [this.sourceToken] });
					else {
						if (this.atIndentedComment(it.start, seq.indent)) {
							const end = seq.items[seq.items.length - 2]?.value?.end;
							if (Array.isArray(end)) {
								Array.prototype.push.apply(end, it.start);
								end.push(this.sourceToken);
								seq.items.pop();
								return;
							}
						}
						it.start.push(this.sourceToken);
					}
					return;
				case "anchor":
				case "tag":
					if (it.value || this.indent <= seq.indent) break;
					it.start.push(this.sourceToken);
					return;
				case "seq-item-ind":
					if (this.indent !== seq.indent) break;
					if (it.value || includesToken(it.start, "seq-item-ind")) seq.items.push({ start: [this.sourceToken] });
					else it.start.push(this.sourceToken);
					return;
			}
			if (this.indent > seq.indent) {
				const bv = this.startBlockValue(seq);
				if (bv) {
					this.stack.push(bv);
					return;
				}
			}
			yield* this.pop();
			yield* this.step();
		}
		*flowCollection(fc) {
			const it = fc.items[fc.items.length - 1];
			if (this.type === "flow-error-end") {
				let top;
				do {
					yield* this.pop();
					top = this.peek(1);
				} while (top?.type === "flow-collection");
			} else if (fc.end.length === 0) {
				switch (this.type) {
					case "comma":
					case "explicit-key-ind":
						if (!it || it.sep) fc.items.push({ start: [this.sourceToken] });
						else it.start.push(this.sourceToken);
						return;
					case "map-value-ind":
						if (!it || it.value) fc.items.push({
							start: [],
							key: null,
							sep: [this.sourceToken]
						});
						else if (it.sep) it.sep.push(this.sourceToken);
						else Object.assign(it, {
							key: null,
							sep: [this.sourceToken]
						});
						return;
					case "space":
					case "comment":
					case "newline":
					case "anchor":
					case "tag":
						if (!it || it.value) fc.items.push({ start: [this.sourceToken] });
						else if (it.sep) it.sep.push(this.sourceToken);
						else it.start.push(this.sourceToken);
						return;
					case "alias":
					case "scalar":
					case "single-quoted-scalar":
					case "double-quoted-scalar": {
						const fs = this.flowScalar(this.type);
						if (!it || it.value) fc.items.push({
							start: [],
							key: fs,
							sep: []
						});
						else if (it.sep) this.stack.push(fs);
						else Object.assign(it, {
							key: fs,
							sep: []
						});
						return;
					}
					case "flow-map-end":
					case "flow-seq-end":
						fc.end.push(this.sourceToken);
						return;
				}
				const bv = this.startBlockValue(fc);
				/* istanbul ignore else should not happen */
				if (bv) this.stack.push(bv);
				else {
					yield* this.pop();
					yield* this.step();
				}
			} else {
				const parent = this.peek(2);
				if (parent.type === "block-map" && (this.type === "map-value-ind" && parent.indent === fc.indent || this.type === "newline" && !parent.items[parent.items.length - 1].sep)) {
					yield* this.pop();
					yield* this.step();
				} else if (this.type === "map-value-ind" && parent.type !== "flow-collection") {
					const start = getFirstKeyStartProps(getPrevProps(parent));
					fixFlowSeqItems(fc);
					const sep = fc.end.splice(1, fc.end.length);
					sep.push(this.sourceToken);
					const map = {
						type: "block-map",
						offset: fc.offset,
						indent: fc.indent,
						items: [{
							start,
							key: fc,
							sep
						}]
					};
					this.onKeyLine = true;
					this.stack[this.stack.length - 1] = map;
				} else yield* this.lineEnd(fc);
			}
		}
		flowScalar(type) {
			if (this.onNewLine) {
				let nl = this.source.indexOf("\n") + 1;
				while (nl !== 0) {
					this.onNewLine(this.offset + nl);
					nl = this.source.indexOf("\n", nl) + 1;
				}
			}
			return {
				type,
				offset: this.offset,
				indent: this.indent,
				source: this.source
			};
		}
		startBlockValue(parent) {
			switch (this.type) {
				case "alias":
				case "scalar":
				case "single-quoted-scalar":
				case "double-quoted-scalar": return this.flowScalar(this.type);
				case "block-scalar-header": return {
					type: "block-scalar",
					offset: this.offset,
					indent: this.indent,
					props: [this.sourceToken],
					source: ""
				};
				case "flow-map-start":
				case "flow-seq-start": return {
					type: "flow-collection",
					offset: this.offset,
					indent: this.indent,
					start: this.sourceToken,
					items: [],
					end: []
				};
				case "seq-item-ind": return {
					type: "block-seq",
					offset: this.offset,
					indent: this.indent,
					items: [{ start: [this.sourceToken] }]
				};
				case "explicit-key-ind": {
					this.onKeyLine = true;
					const start = getFirstKeyStartProps(getPrevProps(parent));
					start.push(this.sourceToken);
					return {
						type: "block-map",
						offset: this.offset,
						indent: this.indent,
						items: [{
							start,
							explicitKey: true
						}]
					};
				}
				case "map-value-ind": {
					this.onKeyLine = true;
					const start = getFirstKeyStartProps(getPrevProps(parent));
					return {
						type: "block-map",
						offset: this.offset,
						indent: this.indent,
						items: [{
							start,
							key: null,
							sep: [this.sourceToken]
						}]
					};
				}
			}
			return null;
		}
		atIndentedComment(start, indent) {
			if (this.type !== "comment") return false;
			if (this.indent <= indent) return false;
			return start.every((st) => st.type === "newline" || st.type === "space");
		}
		*documentEnd(docEnd) {
			if (this.type !== "doc-mode") {
				if (docEnd.end) docEnd.end.push(this.sourceToken);
				else docEnd.end = [this.sourceToken];
				if (this.type === "newline") yield* this.pop();
			}
		}
		*lineEnd(token) {
			switch (this.type) {
				case "comma":
				case "doc-start":
				case "doc-end":
				case "flow-seq-end":
				case "flow-map-end":
				case "map-value-ind":
					yield* this.pop();
					yield* this.step();
					break;
				case "newline": this.onKeyLine = false;
				default:
					if (token.end) token.end.push(this.sourceToken);
					else token.end = [this.sourceToken];
					if (this.type === "newline") yield* this.pop();
			}
		}
	};
	exports.Parser = Parser;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/public-api.js
var require_public_api = /* @__PURE__ */ __commonJSMin(((exports) => {
	var composer = require_composer();
	var Document = require_Document();
	var errors = require_errors();
	var log = require_log();
	var identity = require_identity();
	var lineCounter = require_line_counter();
	var parser = require_parser();
	function parseOptions(options) {
		const prettyErrors = options.prettyErrors !== false;
		return {
			lineCounter: options.lineCounter || prettyErrors && new lineCounter.LineCounter() || null,
			prettyErrors
		};
	}
	/**
	* Parse the input as a stream of YAML documents.
	*
	* Documents should be separated from each other by `...` or `---` marker lines.
	*
	* @returns If an empty `docs` array is returned, it will be of type
	*   EmptyStream and contain additional stream information. In
	*   TypeScript, you should use `'empty' in docs` as a type guard for it.
	*/
	function parseAllDocuments(source, options = {}) {
		const { lineCounter, prettyErrors } = parseOptions(options);
		const parser$1 = new parser.Parser(lineCounter?.addNewLine);
		const composer$1 = new composer.Composer(options);
		const docs = Array.from(composer$1.compose(parser$1.parse(source)));
		if (prettyErrors && lineCounter) for (const doc of docs) {
			doc.errors.forEach(errors.prettifyError(source, lineCounter));
			doc.warnings.forEach(errors.prettifyError(source, lineCounter));
		}
		if (docs.length > 0) return docs;
		return Object.assign([], { empty: true }, composer$1.streamInfo());
	}
	/** Parse an input string into a single YAML.Document */
	function parseDocument(source, options = {}) {
		const { lineCounter, prettyErrors } = parseOptions(options);
		const parser$1 = new parser.Parser(lineCounter?.addNewLine);
		const composer$1 = new composer.Composer(options);
		let doc = null;
		for (const _doc of composer$1.compose(parser$1.parse(source), true, source.length)) if (!doc) doc = _doc;
		else if (doc.options.logLevel !== "silent") {
			doc.errors.push(new errors.YAMLParseError(_doc.range.slice(0, 2), "MULTIPLE_DOCS", "Source contains multiple documents; please use YAML.parseAllDocuments()"));
			break;
		}
		if (prettyErrors && lineCounter) {
			doc.errors.forEach(errors.prettifyError(source, lineCounter));
			doc.warnings.forEach(errors.prettifyError(source, lineCounter));
		}
		return doc;
	}
	function parse(src, reviver, options) {
		let _reviver = void 0;
		if (typeof reviver === "function") _reviver = reviver;
		else if (options === void 0 && reviver && typeof reviver === "object") options = reviver;
		const doc = parseDocument(src, options);
		if (!doc) return null;
		doc.warnings.forEach((warning) => log.warn(doc.options.logLevel, warning));
		if (doc.errors.length > 0) if (doc.options.logLevel !== "silent") throw doc.errors[0];
		else doc.errors = [];
		return doc.toJS(Object.assign({ reviver: _reviver }, options));
	}
	function stringify(value, replacer, options) {
		let _replacer = null;
		if (typeof replacer === "function" || Array.isArray(replacer)) _replacer = replacer;
		else if (options === void 0 && replacer) options = replacer;
		if (typeof options === "string") options = options.length;
		if (typeof options === "number") {
			const indent = Math.round(options);
			options = indent < 1 ? void 0 : indent > 8 ? { indent: 8 } : { indent };
		}
		if (value === void 0) {
			const { keepUndefined } = options ?? replacer ?? {};
			if (!keepUndefined) return void 0;
		}
		if (identity.isDocument(value) && !_replacer) return value.toString(options);
		return new Document.Document(value, _replacer, options).toString(options);
	}
	exports.parse = parse;
	exports.parseAllDocuments = parseAllDocuments;
	exports.parseDocument = parseDocument;
	exports.stringify = stringify;
}));

//#endregion
//#region ../node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/index.js
var require_dist = /* @__PURE__ */ __commonJSMin(((exports) => {
	var composer = require_composer();
	var Document = require_Document();
	var Schema = require_Schema();
	var errors = require_errors();
	var Alias = require_Alias();
	var identity = require_identity();
	var Pair = require_Pair();
	var Scalar = require_Scalar();
	var YAMLMap = require_YAMLMap();
	var YAMLSeq = require_YAMLSeq();
	var cst = require_cst();
	var lexer = require_lexer();
	var lineCounter = require_line_counter();
	var parser = require_parser();
	var publicApi = require_public_api();
	var visit = require_visit();
	exports.Composer = composer.Composer;
	exports.Document = Document.Document;
	exports.Schema = Schema.Schema;
	exports.YAMLError = errors.YAMLError;
	exports.YAMLParseError = errors.YAMLParseError;
	exports.YAMLWarning = errors.YAMLWarning;
	exports.Alias = Alias.Alias;
	exports.isAlias = identity.isAlias;
	exports.isCollection = identity.isCollection;
	exports.isDocument = identity.isDocument;
	exports.isMap = identity.isMap;
	exports.isNode = identity.isNode;
	exports.isPair = identity.isPair;
	exports.isScalar = identity.isScalar;
	exports.isSeq = identity.isSeq;
	exports.Pair = Pair.Pair;
	exports.Scalar = Scalar.Scalar;
	exports.YAMLMap = YAMLMap.YAMLMap;
	exports.YAMLSeq = YAMLSeq.YAMLSeq;
	exports.Lexer = lexer.Lexer;
	exports.LineCounter = lineCounter.LineCounter;
	exports.Parser = parser.Parser;
	exports.parse = publicApi.parse;
	exports.parseAllDocuments = publicApi.parseAllDocuments;
	exports.parseDocument = publicApi.parseDocument;
	exports.stringify = publicApi.stringify;
	exports.visit = visit.visit;
	exports.visitAsync = visit.visitAsync;
}));

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/UpdateConfig/CfgTree.js
const nodeValueSymbol = Symbol.for("cspell.config.nodeValue");
function isNodeValue(value) {
	if (!(typeof value === "object" && value !== null)) return false;
	if (nodeValueSymbol in value) return true;
	return "value" in value && "comment" in value && "commentBefore" in value && Object.keys(value).length === 3;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFile/CSpellConfigFileYaml.js
var import_dist = require_dist();
var CSpellConfigFileYaml = class CSpellConfigFileYaml extends MutableCSpellConfigFile {
	url;
	yamlDoc;
	indent;
	#settings = void 0;
	constructor(url, yamlDoc, indent) {
		super(url);
		this.url = url;
		this.yamlDoc = yamlDoc;
		this.indent = indent;
		this.#settings = this.yamlDoc.toJS();
	}
	get settings() {
		return this.#settings ?? this.yamlDoc.toJS();
	}
	addWords(wordsToAdd) {
		const cfgWords = this.yamlDoc.get("words") || new import_dist.YAMLSeq();
		assert((0, import_dist.isSeq)(cfgWords), "Expected words to be a YAML sequence");
		const knownWords = new Set(cfgWords.items.map((item) => getScalarValue(item)));
		wordsToAdd.forEach((w) => {
			if (knownWords.has(w)) return;
			cfgWords.add(w);
			knownWords.add(w);
		});
		const sorted = sortWords(cfgWords.items);
		sorted.forEach((item, index) => cfgWords.set(index, item));
		cfgWords.items.length = sorted.length;
		this.#setValue("words", cfgWords);
		this.#markAsMutable();
		return this;
	}
	serialize() {
		return (0, import_dist.stringify)(this.yamlDoc, { indent: this.indent });
	}
	setValue(key, value) {
		if (isNodeValue(value)) {
			let node = this.#getNode(key);
			if (!node) {
				node = this.yamlDoc.createNode(value.value);
				setYamlNodeComments(node, value);
				this.#setValue(key, node);
			} else setYamlNodeValue(node, value);
		} else this.#setValue(key, value);
		this.#markAsMutable();
		return this;
	}
	getValue(key) {
		return this.#getNode(key)?.toJS(this.yamlDoc);
	}
	#getNode(key) {
		return getYamlNode(this.yamlDoc, key);
	}
	getNode(key, defaultValue) {
		let yNode = this.#getNode(key);
		if (!yNode) {
			if (defaultValue === void 0) return;
			yNode = this.yamlDoc.createNode(defaultValue);
			this.#setValue(key, yNode);
		}
		this.#markAsMutable();
		return toConfigNode(this.yamlDoc, yNode);
	}
	getFieldNode(key) {
		const contents = this.yamlDoc.contents;
		if (!(0, import_dist.isMap)(contents)) return;
		const found = findPair(contents, key);
		const pair = found && this.#fixPair(found);
		if (!pair) return;
		return toConfigNode(this.yamlDoc, pair.key);
	}
	/**
	* Removes a value from the document.
	* @returns `true` if the item was found and removed.
	*/
	delete(key) {
		const removed = this.yamlDoc.delete(key);
		if (removed) this.#markAsMutable();
		return removed;
	}
	get comment() {
		return this.yamlDoc.comment ?? void 0;
	}
	set comment(comment) {
		this.yamlDoc.comment = comment ?? null;
	}
	setSchema(schemaRef) {
		removeSchemaComment(this.yamlDoc);
		let commentBefore = this.yamlDoc.commentBefore || "";
		commentBefore = commentBefore.replace(/^ yaml-language-server: \$schema=.*\n?/m, "");
		commentBefore = ` yaml-language-server: $schema=${schemaRef}` + (commentBefore ? "\n" + commentBefore : "");
		this.yamlDoc.commentBefore = commentBefore;
		const firstPair = this.#getContentsMap().items[0];
		if (firstPair && (0, import_dist.isPair)(firstPair)) {
			const key = firstPair.key;
			if ((0, import_dist.isNode)(key)) removeSchemaComment(key);
		}
		if (this.getNode("$schema")) this.setValue("$schema", schemaRef);
		return this;
	}
	removeAllComments() {
		const doc = this.yamlDoc;
		doc.comment = null;
		doc.commentBefore = null;
		(0, import_dist.visit)(this.yamlDoc, (_, node) => {
			if (!((0, import_dist.isScalar)(node) || (0, import_dist.isMap)(node) || (0, import_dist.isSeq)(node))) return;
			node.comment = null;
			node.commentBefore = null;
		});
		return this;
	}
	setComment(key, comment, inline) {
		const node = this.getFieldNode(key);
		if (!node) return this;
		if (inline) node.comment = comment;
		else node.commentBefore = comment;
		return this;
	}
	/**
	* Marks the config file as mutable. Any access to settings will the settings to be regenerated
	* from the YAML document.
	*/
	#markAsMutable() {
		this.#settings = void 0;
	}
	#setValue(key, value) {
		this.yamlDoc.set(key, value);
		const pair = findPair(this.#getContentsMap(), key);
		assert(pair, `Expected pair for key: ${String(key)}`);
		this.#fixPair(pair);
	}
	#toNode(value) {
		return (0, import_dist.isNode)(value) ? value : this.yamlDoc.createNode(value);
	}
	#fixPair(pair) {
		assert((0, import_dist.isPair)(pair), "Expected pair to be a Pair");
		pair.key = this.#toNode(pair.key);
		pair.value = this.#toNode(pair.value);
		return pair;
	}
	#getContentsMap() {
		const contents = this.yamlDoc.contents;
		assert((0, import_dist.isMap)(contents), "Expected contents to be a YAMLMap");
		return contents;
	}
	static parse(file) {
		return parseCSpellConfigFileYaml(file);
	}
	static from(url, settings, indent = 2) {
		return new CSpellConfigFileYaml(url, new import_dist.Document(settings), indent);
	}
};
function parseCSpellConfigFileYaml(file) {
	const { url, content } = file;
	try {
		const doc = (0, import_dist.parseDocument)(content);
		if (doc.contents === null || (0, import_dist.isScalar)(doc.contents) && !doc.contents.value) doc.contents = new import_dist.YAMLMap();
		if (!(0, import_dist.isMap)(doc.contents)) throw new ParseError(url, `Invalid YAML content ${url}`);
		return new CSpellConfigFileYaml(url, doc, detectIndentAsNum(content));
	} catch (e) {
		if (e instanceof ParseError) throw e;
		throw new ParseError(url, void 0, { cause: e });
	}
}
function getScalarValue(node) {
	if ((0, import_dist.isScalar)(node)) return node.value;
	return node;
}
function toScalar(node) {
	if ((0, import_dist.isScalar)(node)) return node;
	return new import_dist.Scalar(node);
}
function groupWords(words) {
	const groups = [];
	if (words.length === 0) return groups;
	let currentGroup = [];
	groups.push(currentGroup);
	for (const word of words) {
		if (isSectionHeader(word)) {
			currentGroup = [];
			groups.push(currentGroup);
		}
		currentGroup.push(cloneWord(word));
	}
	return groups;
}
function isSectionHeader(word) {
	if (!(0, import_dist.isScalar)(word) || !word.commentBefore && !word.spaceBefore) return false;
	if (word.spaceBefore) return true;
	if (!word.commentBefore) return false;
	return word.commentBefore.includes("\n\n");
}
function adjustSectionHeader(word, prev, isFirstSection) {
	if (!(0, import_dist.isScalar)(prev)) return;
	let captureComment = isFirstSection;
	if (prev.spaceBefore) {
		word.spaceBefore = true;
		captureComment = true;
		delete prev.spaceBefore;
	}
	if (!prev.commentBefore) return;
	const originalComment = prev.commentBefore;
	const lines = originalComment.split(/^\n/gm);
	const lastLine = lines[lines.length - 1];
	captureComment = captureComment && originalComment.trim() === lastLine.trim() || originalComment.endsWith("\n");
	let header = originalComment;
	if (captureComment) delete prev.commentBefore;
	else {
		prev.commentBefore = lastLine;
		lines.pop();
		header = lines.join("\n");
	}
	if (word.commentBefore) {
		header += header.endsWith("\n\n") ? "" : "\n";
		header += header.endsWith("\n\n") ? "" : "\n";
		header += word.commentBefore;
	}
	word.commentBefore = header;
}
function sortWords(words) {
	const compare = new Intl.Collator().compare;
	const groups = groupWords(words);
	let firstGroup = true;
	for (const group of groups) {
		const head = group[0];
		group.sort((a, b) => {
			return compare(getScalarValue(a), getScalarValue(b));
		});
		if (group[0] !== head && (0, import_dist.isScalar)(head)) adjustSectionHeader(group[0] = toScalar(group[0]), head, firstGroup);
		firstGroup = false;
	}
	return groups.flat().map((w) => toScalar(w));
}
function cloneWord(word) {
	if ((0, import_dist.isScalar)(word)) return word.clone();
	return word;
}
function getYamlNode(yamlDoc, key) {
	return Array.isArray(key) ? yamlDoc.getIn(key, true) : yamlDoc.get(key, true);
}
function toConfigNode(doc, yNode) {
	if (isYamlSeq(yNode)) return toConfigArrayNode(doc, yNode);
	if ((0, import_dist.isMap)(yNode)) return toConfigObjectNode(doc, yNode);
	if ((0, import_dist.isScalar)(yNode)) return toConfigScalarNode(doc, yNode);
	throw new Error(`Unsupported YAML node type: ${yamlNodeType(yNode)}`);
}
var ConfigNodeBase = class {
	type;
	constructor(type) {
		this.type = type;
	}
};
var ConfigArrayNode = class extends ConfigNodeBase {
	#doc;
	#yNode;
	constructor(doc, yNode) {
		super("array");
		this.#doc = doc;
		this.#yNode = yNode;
	}
	get value() {
		return this.#yNode.toJS(this.#doc);
	}
	get comment() {
		return this.#yNode.comment ?? void 0;
	}
	set comment(comment) {
		this.#yNode.comment = comment ?? null;
	}
	get commentBefore() {
		return this.#yNode.commentBefore ?? void 0;
	}
	set commentBefore(comment) {
		this.#yNode.commentBefore = comment ?? null;
	}
	getNode(key) {
		const node = getYamlNode(this.#yNode, key);
		if (!node) return void 0;
		return toConfigNode(this.#doc, node);
	}
	getValue(key) {
		const node = getYamlNode(this.#yNode, key);
		if (!node) return void 0;
		return node.toJS(this.#doc);
	}
	setValue(key, value) {
		if (!isNodeValue(value)) {
			this.#yNode.set(key, value);
			return;
		}
		this.#yNode.set(key, value.value);
		const yNodeValue = getYamlNode(this.#yNode, key);
		assert(yNodeValue);
		yNodeValue.comment = value.comment ?? null;
		yNodeValue.commentBefore = value.commentBefore ?? null;
	}
	delete(key) {
		return this.#yNode.delete(key);
	}
	push(value) {
		if (!isNodeValue(value)) {
			this.#yNode.add(value);
			return this.#yNode.items.length;
		}
		this.#yNode.add(value.value);
		setYamlNodeComments(getYamlNode(this.#yNode, this.#yNode.items.length - 1), value);
		return this.#yNode.items.length;
	}
	get length() {
		return this.#yNode.items.length;
	}
};
function toConfigArrayNode(doc, yNode) {
	return new ConfigArrayNode(doc, yNode);
}
var ConfigObjectNode = class extends ConfigNodeBase {
	#doc;
	#yNode;
	constructor(doc, yNode) {
		super("object");
		this.#doc = doc;
		this.#yNode = yNode;
	}
	get value() {
		return this.#yNode.toJS(this.#doc);
	}
	get comment() {
		return this.#yNode.comment ?? void 0;
	}
	set comment(comment) {
		this.#yNode.comment = comment ?? null;
	}
	get commentBefore() {
		return this.#yNode.commentBefore ?? void 0;
	}
	set commentBefore(comment) {
		this.#yNode.commentBefore = comment ?? null;
	}
	getValue(key) {
		const node = getYamlNode(this.#yNode, key);
		if (!node) return void 0;
		return node.toJS(this.#doc);
	}
	getNode(key) {
		const node = getYamlNode(this.#yNode, key);
		if (!node) return void 0;
		return toConfigNode(this.#doc, node);
	}
	setValue(key, value) {
		if (!isNodeValue(value)) {
			this.#yNode.set(key, value);
			return;
		}
		this.#yNode.set(key, value.value);
		const yNodeValue = getYamlNode(this.#yNode, key);
		assert(yNodeValue);
		yNodeValue.comment = value.comment ?? null;
		yNodeValue.commentBefore = value.commentBefore ?? null;
	}
	delete(key) {
		return this.#yNode.delete(key);
	}
};
function toConfigObjectNode(doc, yNode) {
	return new ConfigObjectNode(doc, yNode);
}
var ConfigScalarNode = class extends ConfigNodeBase {
	$doc;
	$yNode;
	type = "scalar";
	constructor(doc, yNode) {
		super("scalar");
		this.$doc = doc;
		this.$yNode = yNode;
		assert((0, import_dist.isScalar)(yNode), "Expected yNode to be a Scalar");
	}
	get value() {
		return this.$yNode.toJS(this.$doc);
	}
	set value(value) {
		this.$yNode.value = value;
	}
	get comment() {
		return this.$yNode.comment ?? void 0;
	}
	set comment(comment) {
		this.$yNode.comment = comment ?? null;
	}
	get commentBefore() {
		return this.$yNode.commentBefore ?? void 0;
	}
	set commentBefore(comment) {
		this.$yNode.commentBefore = comment ?? null;
	}
	toJSON() {
		return {
			type: this.type,
			value: this.value,
			comment: this.comment,
			commentBefore: this.commentBefore
		};
	}
};
function toConfigScalarNode(doc, yNode) {
	return new ConfigScalarNode(doc, yNode);
}
function isYamlSeq(node) {
	return (0, import_dist.isSeq)(node);
}
function yamlNodeType(node) {
	if ((0, import_dist.isScalar)(node)) return "scalar";
	if ((0, import_dist.isSeq)(node)) return "seq";
	if ((0, import_dist.isMap)(node)) return "map";
	if ((0, import_dist.isAlias)(node)) return "alias";
	return "unknown";
}
function setYamlNodeComments(yamlNode, comments) {
	if (!yamlNode) return;
	if ("comment" in comments) yamlNode.comment = comments.comment ?? null;
	if ("commentBefore" in comments) yamlNode.commentBefore = comments.commentBefore ?? null;
}
function setYamlNodeValue(yamlNode, nodeValue) {
	setYamlNodeComments(yamlNode, nodeValue);
	if ((0, import_dist.isScalar)(yamlNode)) {
		yamlNode.value = nodeValue.value;
		return;
	}
	const value = nodeValue.value;
	if ((0, import_dist.isSeq)(yamlNode)) {
		assert(Array.isArray(value), "Expected value to be an array for YAMLSeq");
		yamlNode.items = [];
		for (let i = 0; i < value.length; ++i) yamlNode.set(i, value[i]);
		return;
	}
	if ((0, import_dist.isMap)(yamlNode)) {
		assert(typeof value === "object" && value !== null, "Expected value to be an object for YAMLMap");
		yamlNode.items = [];
		for (const [key, val] of Object.entries(value)) yamlNode.set(key, val);
		return;
	}
	throw new Error(`Unsupported YAML node type: ${yamlNodeType(yamlNode)}`);
}
function findPair(yNode, yKey) {
	const key = (0, import_dist.isScalar)(yKey) ? yKey.value : yKey;
	if (!(0, import_dist.isMap)(yNode)) return void 0;
	const items = yNode.items;
	for (const item of items) {
		if (!(0, import_dist.isPair)(item)) continue;
		if (item.key === key) return item;
		if ((0, import_dist.isScalar)(item.key) && item.key.value === key) return item;
	}
}
function removeSchemaComment(node) {
	if (!node.commentBefore) return;
	node.commentBefore = node.commentBefore?.replaceAll(/^ yaml-language-server: \$schema=.*\n?/gm, "") ?? null;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/defaultNext.js
const defaultNextDeserializer = (content) => {
	throw new Error(`Unable to parse config file: "${content.url}"`);
};
const defaultNextSerializer = (file) => {
	throw new Error(`Unable to serialize config file: "${file.url}"`);
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/middlewareHelper.js
function getDeserializer(middleware) {
	let next = defaultNextDeserializer;
	for (const des of middleware) next = curryDeserialize(des, next);
	return next;
}
function getSerializer(middleware) {
	let next = defaultNextSerializer;
	for (const des of middleware) next = currySerialize(des, next);
	return next;
}
function curryDeserialize(middle, next) {
	return (content) => middle.deserialize(content, next);
}
function currySerialize(middle, next) {
	return (cfg) => middle.serialize(cfg, next);
}
function curryLoader(loader, next) {
	return (req) => loader.load(req, next);
}
async function defaultLoader(req) {
	const { io, deserialize } = req.context;
	const url = req.url;
	return deserialize(await io.readFile(url));
}
function getLoader(loaders) {
	let next = defaultLoader;
	for (const loader of loaders) next = curryLoader(loader, next);
	return next;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/util/toURL.js
function toURL(url) {
	return typeof url === "string" ? new URL(url) : url;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/CSpellConfigFileReaderWriter.js
var CSpellConfigFileReaderWriterImpl = class {
	io;
	middleware;
	loaders;
	/**
	* @param io - an optional injectable IO interface. The default is to use the file system.
	* @param deserializers - Additional deserializers to use when reading a config file. The order of the deserializers is
	*    important. The last one in the list will be the first one to be called.
	*/
	constructor(io, middleware, loaders) {
		this.io = io;
		this.middleware = middleware;
		this.loaders = loaders;
	}
	_untrustedExtensions = /* @__PURE__ */ new Set();
	_trustedUrls = [];
	/**
	* Untrusted extensions are extensions that are not trusted to be loaded from a file system.
	* Extension are case insensitive and should include the leading dot.
	*/
	get untrustedExtensions() {
		return [...this._untrustedExtensions];
	}
	/**
	* Urls starting with these urls are trusted to be loaded from a file system.
	*/
	get trustedUrls() {
		return [...this._trustedUrls].map((url) => new URL(url));
	}
	readConfig(uri) {
		const url = new URL(uri);
		if (!isTrusted(url, this._trustedUrls, this._untrustedExtensions)) return Promise.reject(new UntrustedUrlError(url));
		return getLoader(this.loaders)({
			url: toURL(uri),
			context: {
				deserialize: this.getDeserializer(),
				io: this.io
			}
		});
	}
	toCSpellConfigFile(configFile) {
		return configFile instanceof CSpellConfigFile ? configFile : new CSpellConfigFileInMemory(configFile.url, configFile.settings);
	}
	getDeserializer() {
		return getDeserializer(this.middleware);
	}
	parse(textFile) {
		return this.getDeserializer()(textFile);
	}
	serialize(configFile) {
		return getSerializer(this.middleware)(configFile);
	}
	async writeConfig(configFile) {
		if (configFile.readonly) throw new Error(`Config file is readonly: ${configFile.url.href}`);
		const content = this.serialize(configFile);
		return { url: (await this.io.writeFile({
			url: configFile.url,
			content
		})).url };
	}
	setUntrustedExtensions(ext) {
		this._untrustedExtensions.clear();
		ext.forEach((e) => this._untrustedExtensions.add(e.toLowerCase()));
		return this;
	}
	setTrustedUrls(urls) {
		this._trustedUrls = [...new Set(urls.map((url) => new URL(url).href))].sort();
		return this;
	}
	clearCachedFiles() {
		for (const loader of this.loaders) loader.reset?.();
	}
};
function isTrusted(url, trustedUrls, untrustedExtensions) {
	const path = url.pathname;
	const ext = extname(path).toLowerCase();
	if (!untrustedExtensions.has(ext)) return true;
	const href = url.href;
	return trustedUrls.some((trustedUrl) => href.startsWith(trustedUrl));
}
var UntrustedUrlError = class extends Error {
	constructor(url) {
		super(`Untrusted URL: "${url.href}"`);
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/defaultIO.js
const defaultIO = {
	readFile: readFile$2,
	writeFile: writeFile$1
};
async function readFile$2(url) {
	return {
		url,
		content: await promises.readFile(url, "utf8")
	};
}
async function writeFile$1(file) {
	await promises.writeFile(file.url, file.content);
	return { url: file.url };
}

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/loaders/loaderJavaScript.js
const _log = () => void 0;
async function importJavaScript(url, hashSuffix) {
	try {
		const _url = new URL(url.href);
		_url.hash = `${_url.hash};loaderSuffix=${hashSuffix}`;
		_log("importJavaScript: %o", { url: _url.href });
		let result = await import(_url.href);
		result = result.default ?? result;
		result = result.default ?? result;
		const settingsOrFunction = await result;
		return new CSpellConfigFileJavaScript(url, typeof settingsOrFunction === "function" ? await settingsOrFunction() : settingsOrFunction);
	} catch (e) {
		_log("importJavaScript Error: %o", {
			url: url.href,
			error: e,
			hashSuffix
		});
		throw e;
	} finally {
		_log("importJavaScript Done: %o", {
			url: url.href,
			hashSuffix
		});
	}
}
var LoaderJavaScript = class {
	hashSuffix = 1;
	async _load(req, next) {
		const { url } = req;
		switch (extname(url.pathname).toLowerCase()) {
			case ".js":
			case ".cjs":
			case ".mjs":
			case ".ts":
			case ".cts":
			case ".mts": return importJavaScript(url, this.hashSuffix);
		}
		return next(req);
	}
	load = this._load.bind(this);
	reset() {
		this.hashSuffix += 1;
	}
};
const loaderJavaScript = new LoaderJavaScript();

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/loaders/index.js
const defaultLoaders = [loaderJavaScript];

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/serializers/cspellJson.js
function deserializer$3(params, next) {
	if (!isJsonFile(params.url.pathname)) return next(params);
	return parseCSpellConfigFileJson(params);
}
function isJsonFile(pathname) {
	pathname = pathname.toLowerCase();
	return pathname.endsWith(".json") || pathname.endsWith(".jsonc");
}
function serializer$3(settings, next) {
	if (!(settings instanceof CSpellConfigFileJson)) return next(settings);
	return settings.serialize();
}
const serializerCSpellJson = {
	deserialize: deserializer$3,
	serialize: serializer$3
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/serializers/cspellToml.js
function deserializer$2(params, next) {
	if (!isTomlFile(params.url.pathname)) return next(params);
	return parseCSpellConfigFileToml(params);
}
function isTomlFile(pathname) {
	pathname = pathname.toLowerCase();
	return pathname.endsWith(".toml");
}
function serializer$2(settings, next) {
	if (!(settings instanceof CSpellConfigFileToml)) return next(settings);
	return settings.serialize();
}
const serializerCSpellToml = {
	deserialize: deserializer$2,
	serialize: serializer$2
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/serializers/cspellYaml.js
function deserializer$1(params, next) {
	if (!isYamlFile(params.url.pathname)) return next(params);
	return parseCSpellConfigFileYaml(params);
}
function isYamlFile(pathname) {
	pathname = pathname.toLowerCase();
	return pathname.endsWith(".yml") || pathname.endsWith(".yaml");
}
function serializer$1(settings, next) {
	if (!(settings instanceof CSpellConfigFileYaml)) return next(settings);
	return settings.serialize();
}
const serializerCSpellYaml = {
	deserialize: deserializer$1,
	serialize: serializer$1
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/serializers/packageJson.js
const isSupportedFormat = /\bpackage\.json$/i;
function deserializer(params, next) {
	if (!isSupportedFormat.test(params.url.pathname)) return next(params);
	return parseCSpellConfigFilePackageJson(params);
}
function serializer(settings, next) {
	if (!(settings instanceof CSpellConfigFilePackageJson)) return next(settings);
	return settings.serialize();
}
const serializerPackageJson = {
	deserialize: deserializer,
	serialize: serializer
};

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/serializers/index.js
const defaultDeserializers = [
	serializerCSpellJson,
	serializerCSpellYaml,
	serializerPackageJson,
	serializerCSpellToml
];

//#endregion
//#region ../node_modules/.pnpm/cspell-config-lib@9.6.4/node_modules/cspell-config-lib/dist/createReaderWriter.js
/**
*
* @param deserializers - Additional deserializers to use when reading a config file. The order of the deserializers is
*    important. The last one in the list will be the first one to be called.
* @param io - an optional injectable IO interface. The default it to use the file system.
* @returns
*/
function createReaderWriter(deserializers = [], loaders = [], io = defaultIO) {
	return new CSpellConfigFileReaderWriterImpl(io, [...defaultDeserializers, ...deserializers], [...defaultLoaders, ...loaders]);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/logger.js
let _logger = console;
/**
* See `Console.error`
*/
function logError(...args) {
	_logger.error(...args);
}
/**
* See `Console.warn`
*/
function logWarning(...args) {
	_logger.warn(...args);
}
/**
* Set the global cspell-lib logger
* @param logger - a logger like `console`
* @returns the old logger.
*/
function setLogger(logger) {
	const oldLogger = _logger;
	_logger = logger;
	return oldLogger;
}

//#endregion
//#region ../node_modules/.pnpm/is-safe-filename@0.1.1/node_modules/is-safe-filename/index.js
const unsafeFilenameFixtures = Object.freeze([
	"",
	"   ",
	".",
	"..",
	" .",
	". ",
	" ..",
	".. ",
	"../",
	"../foo",
	"foo/../bar",
	"foo/bar",
	"foo\\bar",
	"foo\0bar"
]);
function isSafeFilename(filename) {
	if (typeof filename !== "string") return false;
	const trimmed = filename.trim();
	return trimmed !== "" && trimmed !== "." && trimmed !== ".." && !filename.includes("/") && !filename.includes("\\") && !filename.includes("\0");
}
function assertSafeFilename(filename) {
	if (typeof filename !== "string") throw new TypeError("Expected a string");
	if (!isSafeFilename(filename)) throw new Error(`Unsafe filename: ${JSON.stringify(filename)}`);
}

//#endregion
//#region ../node_modules/.pnpm/env-paths@4.0.0/node_modules/env-paths/index.js
const homedir$1 = os$1.homedir();
const tmpdir = os$1.tmpdir();
const { env: env$2 } = process$1;
const macos = (name) => {
	const library = path.join(homedir$1, "Library");
	return {
		data: path.join(library, "Application Support", name),
		config: path.join(library, "Preferences", name),
		cache: path.join(library, "Caches", name),
		log: path.join(library, "Logs", name),
		temp: path.join(tmpdir, name)
	};
};
const windows = (name) => {
	const appData = env$2.APPDATA || path.join(homedir$1, "AppData", "Roaming");
	const localAppData = env$2.LOCALAPPDATA || path.join(homedir$1, "AppData", "Local");
	return {
		data: path.join(localAppData, name, "Data"),
		config: path.join(appData, name, "Config"),
		cache: path.join(localAppData, name, "Cache"),
		log: path.join(localAppData, name, "Log"),
		temp: path.join(tmpdir, name)
	};
};
const linux = (name) => {
	const username = path.basename(homedir$1);
	return {
		data: path.join(env$2.XDG_DATA_HOME || path.join(homedir$1, ".local", "share"), name),
		config: path.join(env$2.XDG_CONFIG_HOME || path.join(homedir$1, ".config"), name),
		cache: path.join(env$2.XDG_CACHE_HOME || path.join(homedir$1, ".cache"), name),
		log: path.join(env$2.XDG_STATE_HOME || path.join(homedir$1, ".local", "state"), name),
		temp: path.join(tmpdir, username, name)
	};
};
function envPaths(name, { suffix = "nodejs" } = {}) {
	assertSafeFilename(name);
	if (suffix) name += `-${suffix}`;
	assertSafeFilename(name);
	if (process$1.platform === "darwin") return macos(name);
	if (process$1.platform === "win32") return windows(name);
	return linux(name);
}

//#endregion
//#region ../node_modules/.pnpm/xdg-basedir@5.1.0/node_modules/xdg-basedir/index.js
const homeDirectory = os.homedir();
const { env: env$1 } = process;
const xdgData = env$1.XDG_DATA_HOME || (homeDirectory ? path$1.join(homeDirectory, ".local", "share") : void 0);
const xdgConfig = env$1.XDG_CONFIG_HOME || (homeDirectory ? path$1.join(homeDirectory, ".config") : void 0);
const xdgState = env$1.XDG_STATE_HOME || (homeDirectory ? path$1.join(homeDirectory, ".local", "state") : void 0);
const xdgCache = env$1.XDG_CACHE_HOME || (homeDirectory ? path$1.join(homeDirectory, ".cache") : void 0);
const xdgRuntime = env$1.XDG_RUNTIME_DIR || void 0;
const xdgDataDirectories = (env$1.XDG_DATA_DIRS || "/usr/local/share/:/usr/share/").split(":");
if (xdgData) xdgDataDirectories.unshift(xdgData);
const xdgConfigDirectories = (env$1.XDG_CONFIG_DIRS || "/etc/xdg").split(":");
if (xdgConfig) xdgConfigDirectories.unshift(xdgConfig);

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/cfgStore.js
const packageName = "cspell";
const legacyLocationDir = xdgConfig ? path.join(xdgConfig, "configstore") : void 0;
const cspellGlobalLocationDir = envPaths(packageName, { suffix: "" }).config;
const defaultConfigFileName = "cspell.json";
const searchOrder = [cspellGlobalLocationDir, legacyLocationDir].filter(isDefined$2);
var GlobalConfigStore = class {
	#foundLocation;
	#baseFilename;
	constructor(filename = defaultConfigFileName) {
		this.#baseFilename = filename;
	}
	async #readConfigFile(location) {
		try {
			const json = await fs$1.readFile(location, "utf8");
			return {
				filename: location,
				config: JSON.parse(json)
			};
		} catch {
			return;
		}
	}
	async readConfigFile() {
		if (this.#foundLocation) {
			const found = await this.#readConfigFile(this.#foundLocation);
			if (found) return found;
		}
		const firstFile = path.resolve(cspellGlobalLocationDir, this.#baseFilename);
		const possibleLocations = new Set([firstFile, ...searchOrder.map((p) => path.resolve(p, defaultConfigFileName))]);
		for (const filename of possibleLocations) {
			const found = await this.#readConfigFile(filename);
			if (found) {
				this.#foundLocation = found.filename;
				return found;
			}
		}
	}
	async writeConfigFile(cfg) {
		this.#foundLocation ??= path.join(cspellGlobalLocationDir, this.#baseFilename);
		await fs$1.mkdir(path.dirname(this.#foundLocation), { recursive: true });
		await fs$1.writeFile(this.#foundLocation, JSON.stringify(cfg, void 0, 2) + "\n");
		return this.#foundLocation;
	}
	get location() {
		return this.#foundLocation;
	}
	static create() {
		return new this();
	}
	static defaultLocation = path.join(cspellGlobalLocationDir, defaultConfigFileName);
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/toGlobDef.js
function toGlobDef(g, root, source) {
	if (g === void 0) return void 0;
	if (Array.isArray(g)) return g.map((g) => toGlobDef(g, root, source));
	if (typeof g === "string") {
		const glob = { glob: g };
		if (root !== void 0) glob.root = root;
		return toGlobDef(glob, root, source);
	}
	if (source) return {
		...g,
		source
	};
	return g;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/normalizeRawSettings.js
function normalizeRawConfig(config) {
	if (typeof config.version === "number") config.version = config.version.toString();
	if (config.import) config.import = normalizeImport(config.import);
}
function normalizeDictionaryDefs(settings, settingsFileUrl) {
	const dictionaryDefinitions = mapDictDefsToInternal(settings.dictionaryDefinitions, settingsFileUrl);
	const languageSettings = settings.languageSettings?.map((langSetting) => clean$1({
		...langSetting,
		dictionaryDefinitions: mapDictDefsToInternal(langSetting.dictionaryDefinitions, settingsFileUrl)
	}));
	return clean$1({
		dictionaryDefinitions,
		languageSettings
	});
}
function normalizeOverrides(settings, pathToSettingsFile) {
	const { globRoot = toFilePathOrHref(new URL(".", pathToSettingsFile)) } = settings;
	const overrides = settings.overrides?.map((override) => {
		const filename = toGlobDef(override.filename, globRoot, toFilePathOrHref(pathToSettingsFile));
		const { dictionaryDefinitions, languageSettings } = normalizeDictionaryDefs(override, pathToSettingsFile);
		return clean$1({
			...override,
			filename,
			dictionaryDefinitions,
			languageSettings: normalizeLanguageSettings(languageSettings)
		});
	});
	return overrides ? { overrides } : {};
}
async function normalizeReporters(settings, pathToSettingsFile) {
	if (settings.reporters === void 0) return {};
	async function resolve(s) {
		if (s === "default") return s;
		const r = await resolveFile(s, pathToSettingsFile);
		if (!r.found) throw new Error(`Not found: "${s}"`);
		return r.filename;
	}
	async function resolveReporter(s) {
		if (typeof s === "string") return resolve(s);
		if (!Array.isArray(s) || typeof s[0] !== "string") throw new Error("Invalid Reporter");
		const [r, ...rest] = s;
		return [await resolve(r), ...rest];
	}
	return { reporters: await Promise.all(settings.reporters.map(resolveReporter)) };
}
function normalizeLanguageSettings(languageSettings) {
	if (!languageSettings) return void 0;
	function fixLocale(s) {
		const { local: locale, ...rest } = s;
		return clean$1({
			locale,
			...rest
		});
	}
	return languageSettings.map(fixLocale);
}
function normalizeGitignoreRoot(settings, pathToSettingsFile) {
	const { gitignoreRoot } = settings;
	if (!gitignoreRoot) return {};
	return { gitignoreRoot: (Array.isArray(gitignoreRoot) ? gitignoreRoot : [gitignoreRoot]).map((p) => resolveFilePathToPath(p, pathToSettingsFile)) };
}
function normalizeSettingsGlobs(settings, pathToSettingsFile) {
	const { globRoot } = settings;
	const normalized = {};
	if (settings.ignorePaths) normalized.ignorePaths = toGlobDef(settings.ignorePaths, globRoot, toFilePathOrHref(pathToSettingsFile));
	if (settings.files) normalized.files = toGlobDef(settings.files, globRoot, toFilePathOrHref(pathToSettingsFile));
	return normalized;
}
function normalizeCacheSettings(settings, pathToSettingsFile) {
	const { cache } = settings;
	if (cache === void 0) return {};
	const { cacheLocation } = cache;
	if (cacheLocation === void 0) return { cache };
	return { cache: {
		...cache,
		cacheLocation: toFilePathOrHref(resolveFilePath(cacheLocation, pathToSettingsFile))
	} };
}
function resolveFilePath(filename, pathToSettingsFile) {
	const cwd = process.cwd();
	return toFileURL(filename.replace("${cwd}", cwd).replace(/^~/, homedir()), pathToSettingsFile);
}
function resolveFilePathToPath(filename, pathToSettingsFile) {
	const url = resolveFilePath(filename, pathToSettingsFile);
	return url.protocol === "file:" ? fileURLToPath(url) : url.toString();
}
function normalizeImport(imports) {
	if (typeof imports === "string") return [imports];
	if (Array.isArray(imports)) return imports;
	return [];
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/configToRawSettings.js
function configErrorToRawSettings(error, url) {
	const filename = toFilePathOrHref(url);
	return {
		__importRef: {
			filename,
			error
		},
		source: {
			name: filename,
			filename
		}
	};
}
function configToRawSettings(cfgFile) {
	if (!cfgFile) return {};
	const url = cfgFile.url;
	const filename = toFilePathOrHref(url);
	const fileRef = {
		filename,
		error: void 0
	};
	const source = {
		name: cfgFile.settings.name || filename,
		filename: cfgFile.virtual ? void 0 : filename
	};
	const rawSettings = { ...cfgFile.settings };
	rawSettings.import = normalizeImport(rawSettings.import);
	normalizeRawConfig(rawSettings);
	rawSettings.source = source;
	if (!cfgFile.virtual) rawSettings.__importRef = fileRef;
	const id = rawSettings.id || urlToSimpleId(url);
	const name = rawSettings.name || id;
	rawSettings.id = id;
	rawSettings.name = cfgFile.settings.name || name;
	return rawSettings;
}
function urlToSimpleId(url) {
	return url.pathname.split("/").slice(-2).join("/");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/GlobalSettings.js
const globalConfig = new GlobalConfigStore();
async function getGlobalConfig() {
	const name = "CSpell Configstore";
	const configPath = getGlobalConfigPath();
	let urlGlobal = configPath ? toFileURL(configPath) : new URL("global-config.json", getSourceDirectoryUrl());
	const source = {
		name,
		filename: toFilePathOrHref(urlGlobal)
	};
	const globalConf = { source };
	let hasGlobalConfig = false;
	const found = await globalConfig.readConfigFile();
	if (found && found.config && found.filename) {
		const cfg = found.config;
		urlGlobal = toFileURL(found.filename);
		if (cfg && Object.keys(cfg).length) {
			Object.assign(globalConf, cfg);
			globalConf.source = {
				name,
				filename: found.filename
			};
			hasGlobalConfig = Object.keys(cfg).length > 0;
		}
	}
	const settings = {
		...globalConf,
		name,
		source
	};
	return new (hasGlobalConfig ? CSpellConfigFileJson : CSpellConfigFileInMemory)(urlGlobal, settings);
}
function getGlobalConfigPath() {
	try {
		return globalConfig.location || GlobalConfigStore.defaultLocation;
	} catch {
		return;
	}
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/ImportError.js
var ImportError = class extends Error {
	cause;
	constructor(msg, cause) {
		if (isError$4(cause)) msg += `\n  ${cause.message}`;
		super(msg);
		this.cause = isError$4(cause) ? cause : void 0;
	}
};
var UnsupportedPnpFile = class extends Error {
	constructor(msg) {
		super(msg);
	}
};

//#endregion
//#region ../node_modules/.pnpm/callsites@3.1.0/node_modules/callsites/index.js
var require_callsites = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const callsites = () => {
		const _prepareStackTrace = Error.prepareStackTrace;
		Error.prepareStackTrace = (_, stack) => stack;
		const stack = (/* @__PURE__ */ new Error()).stack.slice(1);
		Error.prepareStackTrace = _prepareStackTrace;
		return stack;
	};
	module.exports = callsites;
	module.exports.default = callsites;
}));

//#endregion
//#region ../node_modules/.pnpm/parent-module@2.0.0/node_modules/parent-module/index.js
var require_parent_module$1 = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const callsites = require_callsites();
	module.exports = (filePath) => {
		const stacks = callsites();
		if (!filePath) return stacks[2].getFileName();
		let hasSeenValue = false;
		stacks.shift();
		for (const stack of stacks) {
			const parentFilePath = stack.getFileName();
			if (typeof parentFilePath !== "string") continue;
			if (parentFilePath === filePath) {
				hasSeenValue = true;
				continue;
			}
			if (parentFilePath === "module.js") continue;
			if (hasSeenValue && parentFilePath !== filePath) return parentFilePath;
		}
	};
}));

//#endregion
//#region ../node_modules/.pnpm/clear-module@4.1.2/node_modules/clear-module/index.js
var require_clear_module = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const path$4 = __require$1("path");
	const resolveFrom = require_resolve_from$1();
	const parentModule = require_parent_module$1();
	const resolve = (moduleId) => {
		try {
			return resolveFrom(path$4.dirname(parentModule(__filename)), moduleId);
		} catch (_) {}
	};
	const clear = (moduleId) => {
		if (typeof moduleId !== "string") throw new TypeError(`Expected a \`string\`, got \`${typeof moduleId}\``);
		const filePath = resolve(moduleId);
		if (!filePath) return;
		if (__require$1.cache[filePath] && __require$1.cache[filePath].parent) {
			let i = __require$1.cache[filePath].parent.children.length;
			while (i--) if (__require$1.cache[filePath].parent.children[i].id === filePath) __require$1.cache[filePath].parent.children.splice(i, 1);
		}
		if (__require$1.cache[filePath]) {
			const children = __require$1.cache[filePath].children.map((child) => child.id);
			delete __require$1.cache[filePath];
			for (const id of children) clear(id);
		}
	};
	clear.all = () => {
		const directory = path$4.dirname(parentModule(__filename));
		for (const moduleId of Object.keys(__require$1.cache)) delete __require$1.cache[resolveFrom(directory, moduleId)];
	};
	clear.match = (regex) => {
		for (const moduleId of Object.keys(__require$1.cache)) if (regex.test(moduleId)) clear(moduleId);
	};
	clear.single = (moduleId) => {
		if (typeof moduleId !== "string") throw new TypeError(`Expected a \`string\`, got \`${typeof moduleId}\``);
		delete __require$1.cache[resolve(moduleId)];
	};
	module.exports = clear;
}));

//#endregion
//#region ../node_modules/.pnpm/resolve-from@4.0.0/node_modules/resolve-from/index.js
var require_resolve_from = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const path$3 = __require$1("path");
	const Module = __require$1("module");
	const fs$2 = __require$1("fs");
	const resolveFrom = (fromDir, moduleId, silent) => {
		if (typeof fromDir !== "string") throw new TypeError(`Expected \`fromDir\` to be of type \`string\`, got \`${typeof fromDir}\``);
		if (typeof moduleId !== "string") throw new TypeError(`Expected \`moduleId\` to be of type \`string\`, got \`${typeof moduleId}\``);
		try {
			fromDir = fs$2.realpathSync(fromDir);
		} catch (err) {
			if (err.code === "ENOENT") fromDir = path$3.resolve(fromDir);
			else if (silent) return null;
			else throw err;
		}
		const fromFile = path$3.join(fromDir, "noop.js");
		const resolveFileName = () => Module._resolveFilename(moduleId, {
			id: fromFile,
			filename: fromFile,
			paths: Module._nodeModulePaths(fromDir)
		});
		if (silent) try {
			return resolveFileName();
		} catch (err) {
			return null;
		}
		return resolveFileName();
	};
	module.exports = (fromDir, moduleId) => resolveFrom(fromDir, moduleId);
	module.exports.silent = (fromDir, moduleId) => resolveFrom(fromDir, moduleId, true);
}));

//#endregion
//#region ../node_modules/.pnpm/parent-module@1.0.1/node_modules/parent-module/index.js
var require_parent_module = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const callsites = require_callsites();
	module.exports = (filepath) => {
		const stacks = callsites();
		if (!filepath) return stacks[2].getFileName();
		let seenVal = false;
		stacks.shift();
		for (const stack of stacks) {
			const parentFilepath = stack.getFileName();
			if (typeof parentFilepath !== "string") continue;
			if (parentFilepath === filepath) {
				seenVal = true;
				continue;
			}
			if (parentFilepath === "module.js") continue;
			if (seenVal && parentFilepath !== filepath) return parentFilepath;
		}
	};
}));

//#endregion
//#region ../node_modules/.pnpm/import-fresh@3.3.1/node_modules/import-fresh/index.js
var require_import_fresh = /* @__PURE__ */ __commonJSMin(((exports, module) => {
	const path$2 = __require$1("path");
	const resolveFrom = require_resolve_from();
	const parentModule = require_parent_module();
	module.exports = (moduleId) => {
		if (typeof moduleId !== "string") throw new TypeError("Expected a string");
		const parentPath = parentModule(__filename);
		const filePath = resolveFrom(parentPath ? path$2.dirname(parentPath) : __dirname, moduleId);
		const oldModule = __require$1.cache[filePath];
		if (oldModule && oldModule.parent) {
			let i = oldModule.parent.children.length;
			while (i--) if (oldModule.parent.children[i].id === filePath) oldModule.parent.children.splice(i, 1);
		}
		delete __require$1.cache[filePath];
		const parent = __require$1.cache[parentPath];
		return parent === void 0 || parent.require === void 0 ? __require$1(filePath) : parent.require(filePath);
	};
}));

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/findUp.js
async function findUp(name, options = {}) {
	const { cwd = process.cwd(), type: entryType = "file", stopAt } = options;
	let dir = path.resolve(toDirPath(cwd));
	const root = path.parse(dir).root;
	const predicate = makePredicate(name, entryType);
	const stopAtDir = path.resolve(toDirPath(stopAt || root));
	while (dir !== root && dir !== stopAtDir) {
		const found = await predicate(dir);
		if (found !== void 0) return found;
		dir = path.dirname(dir);
	}
}
function makePredicate(name, entryType) {
	if (typeof name === "function") return name;
	const checkStat = entryType === "file" ? "isFile" : "isDirectory";
	function checkName(dir, name) {
		const f = path.join(dir, name);
		return stat(f).then((stats) => stats[checkStat]() && f || void 0).catch(() => void 0);
	}
	if (!Array.isArray(name)) return (dir) => checkName(dir, name);
	return async (dir) => {
		const pending = name.map((n) => checkName(dir, n));
		for (const p of pending) {
			const found = await p;
			if (found) return found;
		}
	};
}
function toDirPath(urlOrPath) {
	return urlOrPath instanceof URL ? fileURLToPath(new URL(".", urlOrPath)) : urlOrPath;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/pnpLoader.js
/**
* Handles loading of `.pnp.js` and `.pnp.js` files.
*/
var import_clear_module = /* @__PURE__ */ __toESM(require_clear_module(), 1);
var import_import_fresh = /* @__PURE__ */ __toESM(require_import_fresh(), 1);
const defaultPnpFiles = [".pnp.cjs", ".pnp.js"];
const supportedSchemas = new Set(["file:"]);
const cachedRequests = /* @__PURE__ */ new Map();
let lock = void 0;
const cachedPnpImportsSync = /* @__PURE__ */ new Map();
const cachedRequestsSync = /* @__PURE__ */ new Map();
var PnpLoader = class {
	pnpFiles;
	cacheKeySuffix;
	constructor(pnpFiles = defaultPnpFiles) {
		this.pnpFiles = pnpFiles;
		this.cacheKeySuffix = ":" + pnpFiles.join(",");
	}
	/**
	* Request that the nearest .pnp file gets loaded
	* @param urlDirectory starting directory
	* @returns promise - rejects on error - success if loaded or not found.
	*/
	async load(urlDirectory) {
		if (!isSupported(urlDirectory)) return void 0;
		await lock;
		const cacheKey = this.calcKey(urlDirectory);
		const cached = cachedRequests.get(cacheKey);
		if (cached) return cached;
		const r = findPnpAndLoad(urlDirectory, this.pnpFiles);
		cachedRequests.set(cacheKey, r);
		const result = await r;
		cachedRequestsSync.set(cacheKey, result);
		return result;
	}
	async peek(urlDirectory) {
		if (!isSupported(urlDirectory)) return void 0;
		await lock;
		const cacheKey = this.calcKey(urlDirectory);
		return cachedRequests.get(cacheKey) ?? Promise.resolve(void 0);
	}
	/**
	* Clears the cached so .pnp files will get reloaded on request.
	*/
	clearCache() {
		return clearPnPGlobalCache();
	}
	calcKey(urlDirectory) {
		return urlDirectory.toString() + this.cacheKeySuffix;
	}
};
function pnpLoader(pnpFiles) {
	return new PnpLoader(pnpFiles);
}
/**
* @param urlDirectory - directory to start at.
*/
async function findPnpAndLoad(urlDirectory, pnpFiles) {
	return loadPnpIfNeeded(await findUp(pnpFiles, { cwd: fileURLToPath(urlDirectory) }));
}
function loadPnpIfNeeded(found) {
	if (!found) return void 0;
	const c = cachedPnpImportsSync.get(found);
	if (c || cachedPnpImportsSync.has(found)) return c;
	const r = loadPnp(found);
	cachedPnpImportsSync.set(found, r);
	return r;
}
function loadPnp(pnpFile) {
	const pnp = (0, import_import_fresh.default)(pnpFile);
	if (pnp.setup) {
		pnp.setup();
		return toFileUrl(pnpFile);
	}
	throw new UnsupportedPnpFile(`Unsupported pnp file: "${pnpFile}"`);
}
function clearPnPGlobalCache() {
	if (lock) return lock;
	lock = _cleanCache().finally(() => {
		lock = void 0;
	});
	return lock;
}
async function _cleanCache() {
	await Promise.all([...cachedRequests.values()].map(rejectToUndefined));
	[...cachedPnpImportsSync.values()].forEach((r) => r && import_clear_module.default.single(fileURLToPath(r)));
	cachedRequests.clear();
	cachedRequestsSync.clear();
	cachedPnpImportsSync.clear();
}
function rejectToUndefined(p) {
	return p.catch(() => void 0);
}
function isSupported(url) {
	return supportedSchemas.has(url.protocol);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/configLocations.js
const supportedExtensions = [
	".json",
	".jsonc",
	".yaml",
	".yml",
	".mjs",
	".cjs",
	".js",
	".toml",
	".mts",
	".ts",
	".cts"
];
/**
* Logic of the locations:
* - Support backward compatibility with the VS Code Spell Checker
*   the spell checker extension can only write to `.json` files because
*   it would be too difficult to automatically modify a `.js` or `.cjs` file.
* - To support `cspell.config.js` in a VS Code environment, have a `cspell.json` import
*   the `cspell.config.js`.
*/
const setOfLocations = new Set([
	"package.json",
	".cspell.json",
	"cspell.json",
	".cSpell.json",
	"cSpell.json",
	".cspell.jsonc",
	"cspell.jsonc",
	".vscode/cspell.json",
	".vscode/cSpell.json",
	".vscode/.cspell.json",
	".cspell.config.json",
	".cspell.config.jsonc",
	".cspell.config.yaml",
	".cspell.config.yml",
	"cspell.config.json",
	"cspell.config.jsonc",
	"cspell.config.yaml",
	"cspell.config.yml",
	...genCfgLoc("cspell.config", supportedExtensions),
	...genCfgLoc(".cspell.config", supportedExtensions),
	".cspell.yaml",
	".cspell.yml",
	"cspell.yaml",
	"cspell.yml",
	".config/.cspell.json",
	".config/cspell.json",
	".config/.cSpell.json",
	".config/cSpell.json",
	".config/.cspell.jsonc",
	".config/cspell.jsonc",
	...genCfgLoc(".config/cspell.config", supportedExtensions),
	...genCfgLoc(".config/.cspell.config", supportedExtensions),
	".config/cspell.yaml",
	".config/cspell.yml"
]);
const searchPlaces = Object.freeze([...setOfLocations]);
const defaultConfigFilenames = Object.freeze([...searchPlaces]);
function genCfgLoc(filename, extensions) {
	return extensions.map((ext) => filename + ext);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/findUpFromUrl.js
async function findUpFromUrl(name, from, options = {}) {
	return (options.fs ?? getVirtualFS().fs).findUp(name, from, options);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/configSearch.js
var ConfigSearch = class {
	/**
	* Cache of search results.
	*/
	#searchCache = /* @__PURE__ */ new Map();
	/**
	* The scanner to use to search for config files.
	*/
	#scanner;
	/**
	* @param searchPlaces - The list of file names to search for.
	* @param allowedExtensionsByProtocol - Map of allowed extensions by protocol, '*' is used to match all protocols.
	* @param fs - The file system to use.
	*/
	constructor(searchPlaces, allowedExtensionsByProtocol, fs) {
		this.#scanner = new DirConfigScanner(searchPlaces, allowedExtensionsByProtocol, fs);
	}
	async searchForConfig(searchFromURL, stopSearchAtURL) {
		const dirUrl = searchFromURL.pathname.endsWith("/") ? searchFromURL : new URL("./", searchFromURL);
		const stopDirUrls = stopSearchAtURL ? stopSearchAtURL.map((url) => url.pathname.endsWith("/") ? url : new URL("./", url)) : void 0;
		return this.#findUp(dirUrl, stopDirUrls);
	}
	clearCache() {
		this.#searchCache.clear();
		this.#scanner.clearCache();
	}
	#findUp(fromDir, stopDirUrls) {
		const searchDirCache = this.#searchCache;
		const cached = searchDirCache.get(fromDir.href);
		if (cached) return cached;
		const visited = [];
		let result = void 0;
		const predicate = (dir) => {
			visit(dir);
			return this.#scanner.scanDirForConfigFile(dir);
		};
		result = findUpFromUrl(predicate, fromDir, {
			type: "file",
			...stopDirUrls && { stopAt: stopDirUrls }
		});
		searchDirCache.set(fromDir.href, result);
		visited.forEach((dir) => searchDirCache.set(dir.href, result));
		return result;
		/**
		* Record directories that are visited while walking up the directory tree.
		* This will help speed up future searches.
		* @param dir - the directory that was visited.
		*/
		function visit(dir) {
			if (!result) {
				visited.push(dir);
				return;
			}
			searchDirCache.set(dir.href, searchDirCache.get(dir.href) || result);
		}
	}
};
/**
* A Scanner that searches for a config file in a directory. It caches the results to speed up future requests.
*/
var DirConfigScanner = class {
	allowedExtensionsByProtocol;
	fs;
	#searchDirCache = /* @__PURE__ */ new Map();
	#searchPlacesByProtocol;
	#searchPlaces;
	/**
	* @param searchPlaces - The list of file names to search for.
	* @param allowedExtensionsByProtocol - Map of allowed extensions by protocol, '*' is used to match all protocols.
	* @param fs - The file system to use.
	*/
	constructor(searchPlaces, allowedExtensionsByProtocol, fs) {
		this.allowedExtensionsByProtocol = allowedExtensionsByProtocol;
		this.fs = fs;
		this.#searchPlacesByProtocol = setupSearchPlacesByProtocol(searchPlaces, allowedExtensionsByProtocol);
		this.#searchPlaces = this.#searchPlacesByProtocol.get("*") || searchPlaces;
	}
	clearCache() {
		this.#searchDirCache.clear();
	}
	/**
	*
	* @param dir - the directory to search for a config file.
	* @param visited - a callback to be called for each directory visited.
	* @returns A promise that resolves to the url of the config file or `undefined`.
	*/
	scanDirForConfigFile(dir) {
		const searchDirCache = this.#searchDirCache;
		const href = dir.href;
		const cached = searchDirCache.get(href);
		if (cached) return cached;
		const result = this.#scanDirForConfig(dir);
		searchDirCache.set(href, result);
		return result;
	}
	#createHasFileDirSearch() {
		const dirInfoCache = createAutoResolveCache();
		const hasFile = async (filename) => {
			const dir = new URL(".", filename);
			const parentHref = new URL("..", dir).href;
			const parentInfoP = dirInfoCache.get(parentHref);
			if (parentInfoP) {
				const parentInfo = await parentInfoP;
				const name = urlBasename(dir).slice(0, -1);
				const found = parentInfo.get(name);
				if (!found?.isDirectory() && !found?.isSymbolicLink()) return false;
			}
			const dirUrlHref = dir.href;
			const dirInfo = await dirInfoCache.get(dirUrlHref, async () => await this.#readDir(dir));
			const name = urlBasename(filename);
			const found = dirInfo.get(name);
			return found?.isFile() || found?.isSymbolicLink() || false;
		};
		return hasFile;
	}
	async #readDir(dir) {
		try {
			const dirInfo = await this.fs.readDirectory(dir);
			return new Map(dirInfo.map((ent) => [ent.name, ent]));
		} catch {
			return /* @__PURE__ */ new Map();
		}
	}
	#createHasFileStatCheck() {
		const hasFile = async (filename) => {
			return !!(await this.fs.stat(filename).catch(() => void 0))?.isFile();
		};
		return hasFile;
	}
	/**
	* Scan the directory for the first matching config file.
	* @param dir - url of the directory to scan.
	* @returns A promise that resolves to the url of the config file or `undefined`.
	*/
	async #scanDirForConfig(dir) {
		const hasFile = this.fs.getCapabilities(dir).readDirectory ? this.#createHasFileDirSearch() : this.#createHasFileStatCheck();
		const searchPlaces = this.#searchPlacesByProtocol.get(dir.protocol) || this.#searchPlaces;
		for (const searchPlace of searchPlaces) {
			const file = new URL(searchPlace, dir);
			if (await hasFile(file)) {
				if (urlBasename(file) !== "package.json") return file;
				if (await checkPackageJson(this.fs, file)) return file;
			}
		}
	}
};
function setupSearchPlacesByProtocol(searchPlaces, allowedExtensionsByProtocol) {
	return new Map([...allowedExtensionsByProtocol.entries()].map(([k, v]) => [k, new Set(v)]).map(([protocol, exts]) => [protocol, searchPlaces.filter((url) => exts.has(extname(url)))]));
}
async function checkPackageJson(fs, filename) {
	try {
		const file = await fs.readFile(filename);
		return typeof JSON.parse(file.getText()).cspell === "object";
	} catch {
		return false;
	}
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/defaultSettings.js
const defaultSettings = createCSpellSettingsInternal({
	id: "default",
	name: "default",
	version: currentSettingsFileVersion
});

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/PnPSettings.js
const defaultPnPSettings = Object.freeze({});
let lastPnP = defaultPnPSettings;
/**
* create PnPSettings object that can be used to compare to the last call.
* This is to reduce object churn and unnecessary configuration loading.
* @param settings - value to normalize
* @returns
*/
function normalizePnPSettings(settings) {
	if (equal(lastPnP, settings)) return lastPnP;
	if (equal(defaultPnPSettings, settings)) return defaultPnPSettings;
	const { usePnP, pnpFiles } = settings;
	return lastPnP = clean$1({
		usePnP,
		pnpFiles
	});
}
function equal(a, b) {
	return a === b || a.usePnP === b.usePnP && (a.pnpFiles === b.pnpFiles || a.pnpFiles?.join("|") === b.pnpFiles?.join("|"));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/configLoader.js
const supportedCSpellConfigVersions = [configSettingsFileVersion0_2];
const setOfSupportedConfigVersions = Object.freeze(new Set(supportedCSpellConfigVersions));
let defaultConfigLoader = void 0;
const defaultExtensions = [
	".json",
	".yaml",
	".yml",
	".jsonc",
	".toml"
];
const defaultJsExtensions = [
	".js",
	".cjs",
	".mjs",
	".ts",
	".mts",
	".cts"
];
const defaultExtensionsAll = [...defaultExtensions, ...defaultJsExtensions];
const trustedSearch = new Map([["*", defaultExtensions], ["file:", defaultExtensionsAll]]);
const unTrustedSearch = new Map([["*", defaultExtensions]]);
var ConfigLoader = class {
	fs;
	templateVariables;
	onReady;
	fileResolver;
	_isTrusted = true;
	/**
	* Use `createConfigLoader`
	* @param virtualFs - virtual file system to use.
	*/
	constructor(fs, templateVariables = envToTemplateVars(process.env)) {
		this.fs = fs;
		this.templateVariables = templateVariables;
		this.configSearch = new ConfigSearch(searchPlaces, trustedSearch, fs);
		this.cspellConfigFileReaderWriter = createReaderWriter(void 0, void 0, createIO(fs));
		this.fileResolver = new FileResolver(fs, this.templateVariables);
		this.onReady = this.init();
		this.subscribeToEvents();
	}
	subscribeToEvents() {
		this.toDispose.push(onClearCache(() => this.clearCachedSettingsFiles()));
	}
	cachedConfig = /* @__PURE__ */ new Map();
	cachedConfigFiles = /* @__PURE__ */ new Map();
	cachedPendingConfigFile = new AutoResolveCache();
	cachedMergedConfig = /* @__PURE__ */ new WeakMap();
	cachedCSpellConfigFileInMemory = /* @__PURE__ */ new WeakMap();
	globalSettings;
	cspellConfigFileReaderWriter;
	configSearch;
	stopSearchAtCache = /* @__PURE__ */ new WeakMap();
	toDispose = [];
	async readSettingsAsync(filename, relativeTo, pnpSettings) {
		await this.onReady;
		const ref = await this.resolveFilename(filename, relativeTo || toFileDirURL("./"));
		return this.importSettings(ref, pnpSettings || defaultPnPSettings, []).onReady;
	}
	async readConfigFile(filenameOrURL, relativeTo) {
		const ref = await this.resolveFilename(filenameOrURL.toString(), relativeTo || toFileDirURL("./"));
		const href = toFileURL(ref.filename).href;
		if (ref.error) return new ImportError(`Failed to read config file: "${ref.filename}"`, ref.error);
		const cached = this.cachedConfigFiles.get(href);
		if (cached) return cached;
		return this.cachedPendingConfigFile.get(href, async () => {
			try {
				const file = await this.cspellConfigFileReaderWriter.readConfig(href);
				this.cachedConfigFiles.set(href, file);
				return file;
			} catch (error) {
				return new ImportError(`Failed to read config file: "${ref.filename}"`, error);
			} finally {
				setTimeout(() => this.cachedPendingConfigFile.delete(href), 1);
			}
		});
	}
	async searchForConfigFileLocation(searchFrom, stopSearchAt) {
		const searchFromURL = await this.#normalizeDirURL(searchFrom) || cwdURL();
		return this.configSearch.searchForConfig(searchFromURL, stopSearchAt);
	}
	async searchForConfigFile(searchFrom, stopSearchAt) {
		const location = await this.searchForConfigFileLocation(searchFrom, stopSearchAt);
		if (!location) return void 0;
		const file = await this.readConfigFile(location);
		if (file instanceof Error) return new CSpellConfigFileWithErrors(location, configErrorToRawSettings(file, location), file);
		return file;
	}
	/**
	*
	* @param searchFrom the directory / file URL to start searching from.
	* @param options - Optional settings including stop location and Yarn PnP configuration.
	* @returns the resulting settings
	*/
	async searchForConfig(searchFrom, options) {
		const stopAt = await this.#extractStopSearchAtURLs(options);
		const configFile = await this.searchForConfigFile(searchFrom, stopAt);
		if (!configFile) return void 0;
		if (configFile instanceof CSpellConfigFileWithErrors) return toInternalSettings(configFile.settings);
		return this.mergeConfigFileWithImports(configFile, options);
	}
	getGlobalSettings() {
		assert(this.globalSettings, "Global settings not loaded");
		return this.globalSettings;
	}
	async getGlobalSettingsAsync() {
		if (!this.globalSettings) {
			const globalConfFile = await getGlobalConfig();
			const normalized = await this.mergeConfigFileWithImports(globalConfFile, void 0);
			normalized.id ??= "global_config";
			this.globalSettings = normalized;
		}
		return this.globalSettings;
	}
	clearCachedSettingsFiles() {
		this.globalSettings = void 0;
		this.cachedConfig.clear();
		this.cachedConfigFiles.clear();
		this.configSearch.clearCache();
		this.cachedPendingConfigFile.clear();
		this.cspellConfigFileReaderWriter.clearCachedFiles();
		this.cachedMergedConfig = /* @__PURE__ */ new WeakMap();
		this.cachedCSpellConfigFileInMemory = /* @__PURE__ */ new WeakMap();
		this.prefetchGlobalSettingsAsync();
	}
	/**
	* Resolve and merge the settings from the imports.
	* @param settings - settings to resolve imports for
	* @param filename - the path / URL to the settings file. Used to resolve imports.
	*/
	resolveSettingsImports(settings, filename) {
		const settingsFile = this.createCSpellConfigFile(filename, settings);
		return this.mergeConfigFileWithImports(settingsFile, settings);
	}
	init() {
		this.onReady = Promise.all([this.prefetchGlobalSettingsAsync(), this.resolveDefaultConfig()]).then(() => void 0);
		return this.onReady;
	}
	async prefetchGlobalSettingsAsync() {
		await this.getGlobalSettingsAsync().catch((e) => logError(e));
	}
	async resolveDefaultConfig() {
		const url = toFileURL((await this.fileResolver.resolveFile(defaultConfigFileModuleRef, srcDirectory)).filename);
		this.cspellConfigFileReaderWriter.setTrustedUrls([new URL("../..", url)]);
		return url;
	}
	importSettings(fileRef, pnpSettings, backReferences) {
		const cacheKey = toFileURL(fileRef.filename).href;
		const cachedImport = this.cachedConfig.get(cacheKey);
		if (cachedImport) {
			backReferences.forEach((ref) => cachedImport.referencedSet.add(ref));
			return cachedImport;
		}
		if (fileRef.error) {
			const settings = createCSpellSettingsInternal({
				__importRef: fileRef,
				source: {
					name: fileRef.filename,
					filename: fileRef.filename
				}
			});
			const importedConfig = {
				href: cacheKey,
				fileRef,
				configFile: void 0,
				settings,
				isReady: true,
				onReady: Promise.resolve(settings),
				onConfigFileReady: Promise.resolve(fileRef.error),
				referencedSet: new Set(backReferences)
			};
			this.cachedConfig.set(cacheKey, importedConfig);
			return importedConfig;
		}
		const source = {
			name: fileRef.filename,
			filename: fileRef.filename
		};
		const mergeImports = (cfgFile) => {
			if (cfgFile instanceof Error) {
				fileRef.error = cfgFile;
				return createCSpellSettingsInternal({
					__importRef: fileRef,
					source
				});
			}
			return this.mergeConfigFileWithImports(cfgFile, pnpSettings, backReferences);
		};
		const referencedSet = new Set(backReferences);
		const onConfigFileReady = onConfigFileReadyFixUp(this.readConfigFile(fileRef.filename));
		const importedConfig = {
			href: cacheKey,
			fileRef,
			configFile: void 0,
			settings: void 0,
			isReady: false,
			onReady: onReadyFixUp(onConfigFileReady.then(mergeImports)),
			onConfigFileReady,
			referencedSet
		};
		this.cachedConfig.set(cacheKey, importedConfig);
		return importedConfig;
		async function onReadyFixUp(pSettings) {
			const settings = await pSettings;
			settings.source ??= source;
			settings.__importRef ??= fileRef;
			importedConfig.isReady = true;
			importedConfig.settings = settings;
			return settings;
		}
		async function onConfigFileReadyFixUp(pCfgFile) {
			const cfgFile = await pCfgFile;
			if (cfgFile instanceof Error) {
				importedConfig.fileRef.error = cfgFile;
				return cfgFile;
			}
			source.name = cfgFile.settings.name || source.name;
			importedConfig.configFile = cfgFile;
			return cfgFile;
		}
	}
	async setupPnp(cfgFile, pnpSettings) {
		if (!pnpSettings?.usePnP || pnpSettings === defaultPnPSettings) return;
		if (cfgFile.url.protocol !== "file:") return;
		const { usePnP = pnpSettings.usePnP, pnpFiles = pnpSettings.pnpFiles } = cfgFile.settings;
		await loadPnP(normalizePnPSettings({
			usePnP,
			pnpFiles
		}), new URL(".", cfgFile.url));
	}
	mergeConfigFileWithImports(cfg, pnpSettings, referencedBy) {
		const cfgFile = this.toCSpellConfigFile(cfg);
		const cached = this.cachedMergedConfig.get(cfgFile);
		if (cached && cached.pnpSettings === pnpSettings && cached.referencedBy === referencedBy) return cached.result;
		const pnp = {
			usePnP: cfg.settings.usePnP ?? pnpSettings?.usePnP ?? !!process.versions.pnp,
			pnpFiles: cfg.settings.pnpFiles ?? pnpSettings?.pnpFiles
		};
		const result = this._mergeConfigFileWithImports(cfgFile, pnp, referencedBy);
		this.cachedMergedConfig.set(cfgFile, {
			pnpSettings,
			referencedBy,
			result
		});
		return result;
	}
	async _mergeConfigFileWithImports(cfgFile, pnpSettings, referencedBy = []) {
		await this.setupPnp(cfgFile, pnpSettings);
		const href = cfgFile.url.href;
		const referencedSet = new Set(referencedBy);
		const imports = normalizeImport(cfgFile.settings.import);
		const toImport = (await Promise.all(imports.map((name) => this.resolveFilename(name, cfgFile.url)))).map((ref) => this.importSettings(ref, pnpSettings, [...referencedBy, href]));
		toImport.forEach((entry) => {
			entry.referencedSet.add(href);
		});
		const pendingImports = toImport.map((entry) => {
			return referencedSet.has(entry.href) ? entry.settings || configToRawSettings(entry.configFile) : entry.onReady;
		});
		const importSettings = await Promise.all(pendingImports);
		return await this.mergeImports(cfgFile, importSettings);
	}
	/**
	* normalizeSettings handles correcting all relative paths, anchoring globs, and importing other config files.
	* @param rawSettings - raw configuration settings
	* @param pathToSettingsFile - path to the source file of the configuration settings.
	*/
	async mergeImports(cfgFile, importedSettings) {
		const rawSettings = configToRawSettings(cfgFile);
		const url = cfgFile.url;
		const fileRef = rawSettings.__importRef;
		const source = rawSettings.source;
		assert(source);
		const settings = {
			version: defaultSettings.version,
			...rawSettings,
			globRoot: resolveGlobRoot(rawSettings, cfgFile.url),
			languageSettings: normalizeLanguageSettings(rawSettings.languageSettings)
		};
		const normalizedDictionaryDefs = normalizeDictionaryDefs(settings, url);
		const normalizedSettingsGlobs = normalizeSettingsGlobs(settings, url);
		const normalizedOverrides = normalizeOverrides(settings, url);
		const normalizedReporters = await normalizeReporters(settings, url);
		const normalizedGitignoreRoot = normalizeGitignoreRoot(settings, url);
		const normalizedCacheSettings = normalizeCacheSettings(settings, url);
		const fileSettings = createCSpellSettingsInternal({
			...settings,
			source,
			...normalizedDictionaryDefs,
			...normalizedSettingsGlobs,
			...normalizedOverrides,
			...normalizedReporters,
			...normalizedGitignoreRoot,
			...normalizedCacheSettings
		});
		if (!importedSettings.length) return fileSettings;
		const finalizeSettings = mergeSettings(importedSettings.reduce((a, b) => mergeSettings(a, b)), fileSettings);
		finalizeSettings.name = settings.name || finalizeSettings.name || "";
		finalizeSettings.id = settings.id || finalizeSettings.id || "";
		if (fileRef) finalizeSettings.__importRef = fileRef;
		return finalizeSettings;
	}
	createCSpellConfigFile(filename, settings) {
		return autoResolve$1(autoResolveWeak(this.cachedCSpellConfigFileInMemory, settings, () => /* @__PURE__ */ new Map()), filename, () => this.cspellConfigFileReaderWriter.toCSpellConfigFile({
			url: toFileURL(filename),
			settings
		}));
	}
	toCSpellConfigFile(cfg) {
		if (cfg instanceof CSpellConfigFile) return cfg;
		return this.createCSpellConfigFile(cfg.url, cfg.settings);
	}
	dispose() {
		while (this.toDispose.length) try {
			this.toDispose.pop()?.dispose();
		} catch (e) {
			logError(e);
		}
	}
	getStats() {
		return { ...stats() };
	}
	async resolveConfigFileLocation(filenameOrURL, relativeTo) {
		const r = await this.fileResolver.resolveFile(filenameOrURL, relativeTo);
		return r.found ? toFileURL(r.filename) : void 0;
	}
	async resolveFilename(filename, relativeTo) {
		if (filename instanceof URL) return { filename: toFilePathOrHref(filename) };
		if (isUrlLike(filename)) return { filename: toFilePathOrHref(filename) };
		const r = await this.fileResolver.resolveFile(filename, relativeTo);
		if (r.warning) logWarning(r.warning);
		return {
			filename: r.filename.startsWith("file:/") ? fileURLToPath(r.filename) : r.filename,
			error: r.found ? void 0 : new ConfigurationLoaderFailedToResolveError(filename, relativeTo)
		};
	}
	get isTrusted() {
		return this._isTrusted;
	}
	setIsTrusted(isTrusted) {
		this._isTrusted = isTrusted;
		this.clearCachedSettingsFiles();
		this.configSearch = new ConfigSearch(searchPlaces, isTrusted ? trustedSearch : unTrustedSearch, this.fs);
		this.cspellConfigFileReaderWriter.setUntrustedExtensions(isTrusted ? [] : defaultJsExtensions);
	}
	async #extractStopSearchAtURLs(options) {
		if (!options?.stopSearchAt) return void 0;
		if (this.stopSearchAtCache.has(options)) return this.stopSearchAtCache.get(options);
		const rawStops = Array.isArray(options.stopSearchAt) ? options.stopSearchAt : [options.stopSearchAt];
		const stopURLs = await Promise.all(rawStops.map((s) => this.#normalizeDirURL(s)));
		this.stopSearchAtCache.set(options, stopURLs);
		return stopURLs;
	}
	async #normalizeDirURL(input) {
		if (!input) return void 0;
		const url = toFileURL(input, cwdURL());
		if (url.pathname.endsWith("/")) return url;
		if (input instanceof URL) return new URL(".", url);
		if (typeof input === "string" && !isUrlLike(input) && url.protocol === "file:" && await isDirectory(this.fs, url)) return addTrailingSlash(url);
		return new URL(".", url);
	}
};
var ConfigLoaderInternal = class extends ConfigLoader {
	constructor(vfs) {
		super(vfs);
	}
	get _cachedFiles() {
		return this.cachedConfig;
	}
};
function loadPnP(pnpSettings, searchFrom) {
	if (!pnpSettings.usePnP) return Promise.resolve(void 0);
	return pnpLoader(pnpSettings.pnpFiles).load(searchFrom);
}
const nestedConfigDirectories = {
	".vscode": true,
	".config": true
};
function resolveGlobRoot(settings, urlSettingsFile) {
	const urlSettingsFileDir = new URL(".", urlSettingsFile);
	const uriSettingsFileDir = URI.parse(urlSettingsFileDir.href);
	const settingsFileDirName = Utils.basename(uriSettingsFileDir);
	const isNestedConfig = settingsFileDirName in nestedConfigDirectories;
	const isVSCode = settingsFileDirName === ".vscode";
	const settingsFileDir = (isNestedConfig ? Utils.dirname(uriSettingsFileDir) : uriSettingsFileDir).toString();
	const envGlobRoot = process.env[ENV_CSPELL_GLOB_ROOT];
	const defaultGlobRoot = envGlobRoot ?? "${cwd}";
	const rawRoot = settings.globRoot ?? (settings.version === configSettingsFileVersion0_1 || envGlobRoot && !settings.version || isVSCode && !settings.version ? defaultGlobRoot : settingsFileDir);
	const globRoot = rawRoot.startsWith("${cwd}") ? rawRoot : toFileURL(rawRoot, new URL(settingsFileDir));
	return typeof globRoot === "string" ? globRoot : globRoot.protocol === "file:" ? windowsDriveLetterToUpper(path.resolve(fileURLToPath(globRoot))) : addTrailingSlash(globRoot).href;
}
function createConfigLoaderInternal(fs) {
	return new ConfigLoaderInternal(fs ?? getVirtualFS().fs);
}
function getDefaultConfigLoaderInternal() {
	if (defaultConfigLoader) return defaultConfigLoader;
	return defaultConfigLoader = createConfigLoaderInternal();
}
function createIO(fs) {
	const readFile = (url) => fs.readFile(url).then((file) => ({
		url: file.url,
		content: file.getText()
	}));
	const writeFile = (file) => fs.writeFile(file);
	return {
		readFile,
		writeFile
	};
}
async function isDirectory(fs, path) {
	try {
		return (await fs.stat(path)).isDirectory();
	} catch {
		return false;
	}
}
var ConfigurationLoaderError = class extends Error {
	configurationFile;
	relativeTo;
	constructor(message, configurationFile, relativeTo, cause) {
		super(message);
		this.configurationFile = configurationFile;
		this.relativeTo = relativeTo;
		this.name = "Configuration Loader Error";
		if (cause) this.cause = cause;
	}
};
var ConfigurationLoaderFailedToResolveError = class extends ConfigurationLoaderError {
	configurationFile;
	relativeTo;
	constructor(configurationFile, relativeTo, cause) {
		const message = `Failed to resolve configuration file: "${configurationFile.startsWith("file:/") ? fileURLToPath(configurationFile) : configurationFile}" referenced from "${relativeToCwd$1(relativeTo)}"`;
		super(message, configurationFile, relativeTo, cause);
		this.configurationFile = configurationFile;
		this.relativeTo = relativeTo;
	}
};
function relativeToCwd$1(file) {
	const url = toFileUrl(file);
	const cwdPath = cwdURL().pathname.split("/").slice(0, -1);
	const urlPath = url.pathname.split("/");
	if (urlPath[0] !== cwdPath[0]) return toFilePathOrHref(file);
	let i = 0;
	for (; i < cwdPath.length; ++i) if (cwdPath[i] !== urlPath[i]) break;
	const segments = cwdPath.length - i;
	if (segments > 3) return toFilePathOrHref(file);
	return [[...".".repeat(segments)].map(() => "..").join("/") || ".", ...urlPath.slice(i)].join("/");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/defaultConfigLoader.js
const gcl = getDefaultConfigLoaderInternal;
/**
*
* @param searchFrom the directory / file to start searching from.
* @param options - Optional settings including stop location and Yarn PnP configuration.
* @returns the resulting settings
*/
function searchForConfig(searchFrom, options) {
	return gcl().searchForConfig(searchFrom, options);
}
/**
* Load a CSpell configuration files.
* @param file - path or package reference to load.
* @param pnpSettings - PnP settings
* @returns normalized CSpellSettings
*/
async function loadConfig(file, pnpSettings) {
	return gcl().readSettingsAsync(file, void 0, pnpSettings);
}
/**
* Resolve the imports in the settings file.
* @param settings - settings to resolve imports for
* @param filename - the filename of the settings file, use cwd if not available.
* @returns
*/
async function resolveSettingsImports(settings, filename) {
	return gcl().resolveSettingsImports(settings, filename);
}
async function readConfigFile$1(filename, relativeTo) {
	const result = await gcl().readConfigFile(filename, relativeTo);
	if (result instanceof Error) throw result;
	return result;
}
async function resolveConfigFileImports(configFile) {
	return gcl().mergeConfigFileWithImports(configFile, configFile.settings);
}
/**
* Loads and caches the global settings.
* @returns - global settings
*/
function getGlobalSettingsAsync() {
	return gcl().getGlobalSettingsAsync();
}
function getDefaultConfigLoader() {
	return getDefaultConfigLoaderInternal();
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/extractImportErrors.js
function extractImportErrors(settings) {
	const imports = mergeImportRefs(settings);
	return !imports ? [] : [...imports.values()].filter(isImportFileRefWithError);
}
function mergeImportRefs(left, right = {}) {
	const imports = new Map(left.__imports || []);
	if (left.__importRef) imports.set(left.__importRef.filename, left.__importRef);
	if (right.__importRef) imports.set(right.__importRef.filename, right.__importRef);
	const rightImports = right.__imports?.values() || [];
	for (const ref of rightImports) imports.set(ref.filename, ref);
	return imports.size ? imports : void 0;
}
function isImportFileRefWithError(ref) {
	return !!ref.error;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/Controller/configLoader/readSettings.js
async function readSettings(filename, relativeToOrPnP, pnpSettings) {
	const loader = getDefaultConfigLoader();
	const relativeTo = typeof relativeToOrPnP === "string" || relativeToOrPnP instanceof URL ? relativeToOrPnP : void 0;
	const pnp = pnpSettings ? pnpSettings : !(typeof relativeToOrPnP === "string" || relativeToOrPnP instanceof URL) ? relativeToOrPnP : void 0;
	return loader.readSettingsAsync(filename, relativeTo, pnp);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/grammarTypesHelpers.js
function isPatternInclude(p) {
	return !!p.include;
}
const TypeofMatch = {
	object: true,
	string: true
};
const TypeofBegin = TypeofMatch;
const TypeofEnd = {
	...TypeofBegin,
	undefined: true
};
function isPatternMatch(pattern) {
	const p = pattern;
	return !!p.match && typeof p.match in TypeofMatch;
}
function isPatternBeginEnd(pattern) {
	const p = pattern;
	return p.begin !== void 0 && typeof p.begin in TypeofBegin && typeof p.end in TypeofEnd;
}
function isPatternPatterns(p) {
	return Array.isArray(p.patterns);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/matchResult.js
/**
* Try to assign group names and numbers to segments of the matching text.
* Note: this is NOT a perfect match. It tries its best given limited information.
* For example, it will give back the wrong indexes for the following RegExp and text:
* `/.+(a(?=p)).+/g.exec('bad apple')`. Group 1 will be the `a` in `bad`, not the `a` in apple.
* @param mr - match result
* @returns a list of matching segments in group number order.
*/
function segmentMatch(mr) {
	const { matches, index, groups, input } = mr;
	const segments = [];
	let p = index;
	for (let groupNum = 0; groupNum < matches.length; ++groupNum) {
		const m = matches[groupNum];
		if (!m) continue;
		const idx0 = input.indexOf(m, p);
		const idx = idx0 >= p ? idx0 : input.lastIndexOf(m, p);
		if (idx < 0) continue;
		segments.push({
			match: m,
			index: idx,
			groupNum,
			groupName: void 0
		});
		p = idx;
	}
	const textToSeg = new Map(segments.map((s) => [s.match, s]));
	for (const [name, value] of Object.entries(groups)) {
		const s = value && textToSeg.get(value);
		if (!s) continue;
		s.groupName = s.groupName ? Array.isArray(s.groupName) ? [...s.groupName, name] : [s.groupName, name] : name;
	}
	return segments;
}
function createMatchResult(r, lineNumber) {
	const groups = Object.create(null);
	r.groups && Object.assign(groups, r.groups);
	const matches = r;
	const match = r[0];
	return {
		index: r.index,
		input: r.input,
		match,
		matches,
		groups,
		lineNumber
	};
}
function createSimpleMatchResult(match, input, index, lineNumber) {
	return {
		index,
		input,
		match,
		matches: [match],
		groups: Object.create(null),
		lineNumber
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/scope.js
var Scope = class Scope {
	value;
	parent;
	constructor(value, parent) {
		this.value = value;
		this.parent = parent;
	}
	/**
	* Convert the scope hierarchy to a string
	* @param ltr - return ancestry from left-to-right
	* @returns the scope hierarchy as a string separated by a space.
	*/
	toString(ltr = false) {
		if (!this.parent) return this.value;
		return ltr ? this.parent.toString(ltr) + " " + this.value : this.value + " " + this.parent.toString(ltr);
	}
	static isScope(value) {
		return value instanceof Scope;
	}
};
/**
* A Scope Pool is used to keep the number of scope chains down to a minimum. It ensure that if two scopes match,
* then they will be the same object.
*/
var ScopePool = class {
	pool = /* @__PURE__ */ new Map();
	/**
	* Get a Scope that matches the scope. This method is idempotent.
	* @param scopeValue - a single scope value: i.e. `source.ts`
	* @param parent - optional parent Scope
	*/
	getScope(scopeValue, parent) {
		const foundPoolMap = this.pool.get(scopeValue);
		const poolMap = foundPoolMap || /* @__PURE__ */ new Map();
		if (poolMap !== foundPoolMap) this.pool.set(scopeValue, poolMap);
		const foundScope = poolMap.get(parent);
		if (foundScope) return foundScope.v;
		const scope = new Scope(scopeValue, parent);
		poolMap.set(parent, { v: scope });
		return scope;
	}
	parseScope(scopes, ltr = false) {
		if (Scope.isScope(scopes)) return scopes;
		if (isScopeLike(scopes)) {
			const parent = scopes.parent ? this.parseScope(scopes.parent) : void 0;
			return this.getScope(scopes.value, parent);
		}
		return this.parseScopeString(scopes, ltr);
	}
	parseScopeString(scopes, ltr) {
		scopes = Array.isArray(scopes) ? scopes : scopes.split(" ");
		const parentToChild = ltr ? scopes : scopes.reverse();
		let parent = void 0;
		for (const value of parentToChild) parent = this.getScope(value, parent);
		assert(parent, "Empty scope is not allowed.");
		return parent;
	}
};
function isScopeLike(value) {
	return typeof value === "object" && !Array.isArray(value) && value.value !== void 0;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/grammarNormalizer.js
function normalizeGrammar(grammar) {
	return new ImplNGrammar(grammar);
}
const SpecialRepositoryReferences = {
	$self: true,
	$base: true
};
function nPattern(p) {
	if (isPatternMatch(p)) return normalizePatternMatch(p);
	if (isPatternBeginEnd(p)) return normalizePatternBeginEnd(p);
	if (isPatternInclude(p)) return normalizePatternInclude(p);
	if (isPatternPatterns(p)) return normalizePatternsPatterns(p);
	return normalizePatternName(p);
}
function normalizePatternMatch(p) {
	const regExec = makeTestMatchFn(p.match);
	const self = {
		...p,
		captures: normalizeCapture(p.captures),
		findMatch
	};
	function findMatch(line, parentRule) {
		const match = regExec(line);
		if (!match) return void 0;
		return {
			rule: factoryRule(parentRule, self),
			match,
			line
		};
	}
	return self;
}
function normalizePatternBeginEnd(p) {
	const patterns = normalizePatterns(p.patterns);
	const self = {
		...p,
		captures: normalizeCapture(p.captures),
		beginCaptures: normalizeCapture(p.beginCaptures),
		endCaptures: normalizeCapture(p.endCaptures),
		patterns,
		findMatch
	};
	function findMatch(line, parentRule) {
		const match = testBegin(line);
		if (!match) return void 0;
		return {
			rule: factoryRule(parentRule, self, findNext, end),
			match,
			line
		};
	}
	const testBegin = makeTestMatchFn(p.begin);
	const testEnd = p.end !== void 0 ? makeTestMatchFn(p.end) : () => void 0;
	function findNext(line) {
		return patterns && findInPatterns(patterns, line, this);
	}
	function end(line) {
		return testEnd(line);
	}
	return self;
}
function normalizePatternName(p) {
	const patterns = void 0;
	const self = {
		...p,
		patterns,
		findMatch
	};
	function findMatch(line, parentRule) {
		const rule = factoryRule(parentRule, self);
		const input = line.text.slice(line.offset);
		return {
			rule,
			match: createSimpleMatchResult(input, input, line.offset, line.lineNumber),
			line
		};
	}
	return self;
}
function normalizePatternInclude(p) {
	const { include } = p;
	return include.startsWith("#") || include in SpecialRepositoryReferences ? normalizePatternIncludeRef(p) : normalizePatternIncludeExt(p);
}
function normalizePatternIncludeRef(p) {
	const { include, ...rest } = p;
	const reference = include.startsWith("#") ? include.slice(1) : include;
	const self = {
		...rest,
		reference,
		findMatch
	};
	function findMatch(line, parentRule) {
		const pat = parentRule.repository[reference];
		if (pat === void 0) throw new Error(`Unknown Include Reference ${include}`);
		return pat.findMatch(line, parentRule);
	}
	return self;
}
function normalizePatternIncludeExt(p) {
	function findMatch(_line) {}
	return {
		...p,
		findMatch
	};
}
function normalizePatternsPatterns(p) {
	return new ImplNPatternPatterns(p);
}
function findInPatterns(patterns, line, rule) {
	let r = void 0;
	for (const pat of patterns) {
		if (pat.disabled) continue;
		const er = pat.findMatch(line, rule);
		if (er?.match !== void 0 && !er.rule.pattern.disabled) r = r && r.match && r.match.index <= er.match.index && r || er;
	}
	return r;
}
function normalizePatterns(patterns) {
	if (!patterns) return void 0;
	return patterns.map((p) => typeof p === "string" ? { include: p } : p).map(nPattern);
}
const emptyRepository = Object.freeze(Object.create(null));
function normalizePatternRepository(rep) {
	if (!rep) return emptyRepository;
	return normalizeRepository(rep);
}
function normalizeRepository(rep) {
	const repository = Object.create(null);
	for (const [key, pat] of Object.entries(rep)) repository[key] = nPattern(pat);
	return repository;
}
let ruleCounter = 0;
function factoryRuleBase(parent, pattern, repository, grammar, findNext, end) {
	const depth = parent ? parent.depth + 1 : 0;
	return {
		id: ruleCounter++,
		grammar,
		pattern,
		parent,
		repository,
		depth,
		findNext,
		end
	};
}
function factoryRule(parent, pattern, findNext, end) {
	return factoryRuleBase(parent, pattern, parent.repository, parent.grammar, findNext, end);
}
function normalizeCapture(cap) {
	if (cap === void 0) return void 0;
	if (typeof cap === "string") return { [0]: cap };
	const capture = Object.create(null);
	for (const [key, pat] of Object.entries(cap)) capture[key] = typeof pat === "string" ? pat : normalizePatternName(pat).name;
	return capture;
}
function makeTestMatchFn(reg) {
	if (typeof reg === "string") return matchString(reg);
	return matchRegExp(reg);
}
function matchString(s) {
	return (line) => {
		const input = line.text;
		const index = input.indexOf(s, line.offset);
		if (index < 0) return void 0;
		return createSimpleMatchResult(s, input, index, line.lineNumber);
	};
}
function matchRegExp(r) {
	return (line) => {
		const rg = RegExp(r, "gm");
		rg.lastIndex = line.offset;
		const m = rg.exec(line.text);
		return (m && createMatchResult(m, line.lineNumber)) ?? void 0;
	};
}
function extractScope(er, isContent = true) {
	const scope = [];
	for (let rule = er; rule; rule = rule.parent) {
		const { name, contentName } = rule.pattern;
		if (contentName && isContent) scope.push(contentName);
		if (name !== void 0) scope.push(name);
		isContent = true;
	}
	return er.grammar.scopePool.parseScope(scope);
}
var ImplNGrammar = class {
	scopeName;
	name;
	comment;
	disabled;
	patterns;
	repository;
	grammarName;
	self;
	scopePool;
	constructor(grammar) {
		this.scopeName = grammar.scopeName;
		this.name = grammar.scopeName;
		this.comment = grammar.comment;
		this.disabled = grammar.disabled;
		this.grammarName = grammar.name;
		const self = nPattern({ patterns: [{ patterns: grammar.patterns }] });
		const repository = normalizePatternRepository(grammar.repository);
		this.patterns = self.patterns;
		this.repository = repository;
		this.self = self;
		this.scopePool = new ScopePool();
	}
	begin(parentRule) {
		const patterns = this.patterns;
		function grammarToRule(grammar, baseGrammar, parent) {
			const repository = Object.create(null);
			Object.assign(repository, grammar.repository);
			repository["$self"] = grammar.self;
			repository["$base"] = repository["$base"] || baseGrammar.self;
			function findNext(line) {
				return findInPatterns(patterns, line, this);
			}
			function end(_line) {}
			return factoryRuleBase(parent, grammar, repository, grammar, findNext, end);
		}
		return grammarToRule(this, parentRule?.grammar ?? this, parentRule);
	}
};
var ImplNPatternPatterns = class {
	name;
	comment;
	disabled;
	patterns;
	constructor(p) {
		const { name, comment, disabled, ...rest } = p;
		this.patterns = normalizePatterns(rest.patterns);
		this.name = name;
		this.comment = comment;
		this.disabled = disabled;
	}
	findMatch(line, parentRule) {
		const patterns = this.patterns;
		const rule = factoryRule(parentRule, this, findNext);
		function findNext(line) {
			return findInPatterns(patterns, line, this);
		}
		return rule.findNext?.(line);
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/grammar.js
function compileGrammar(grammar) {
	return normalizeGrammar(grammar);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/util.js
function isDefined$1(t) {
	return t !== void 0 && t !== null;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/processors/procMatchingRule.js
/**
* Apply the scopes to the line
* @param line - line of text
* @param matchRuleResult - the matching rule
*/
function applyCaptureToBeginOrMatch(matchRuleResult) {
	const { match, rule } = matchRuleResult;
	const bePattern = rule.pattern;
	return applyCaptures(rule, match, bePattern.beginCaptures ?? bePattern.captures);
}
/**
* Apply the scopes to the line
* @param line - line of text
* @param rule - the matching rule
*/
function applyCaptureToEnd(rule, match) {
	const { pattern } = rule;
	const bePattern = pattern;
	return applyCaptures(rule, match, bePattern.endCaptures ?? bePattern.captures);
}
/**
* Apply the scopes to the line
* @param line - line of text
* @param rule - the matching rule
*/
function applyCaptures(rule, match, captures) {
	const scope = extractScope(rule, false);
	const pool = rule.grammar.scopePool;
	const text = match.match;
	const input = match.input;
	const range = [
		match.index,
		match.index + text.length,
		match.lineNumber
	];
	if (!text && !captures) return [];
	if (!captures) return [{
		scope,
		text,
		range
	}];
	const captureScopes = new Map(Object.entries(captures));
	const cap0 = captureScopes.get("0");
	if (captureScopes.size === 1 && cap0) return [{
		scope: rule.grammar.scopePool.getScope(cap0, scope),
		text,
		range
	}];
	const min = match.index;
	const max = match.index + text.length;
	function trimSegment(seg) {
		const { index, match } = seg;
		const right = match.length;
		if (index >= min && right <= max) return seg;
		if (index >= max || right < min) return void 0;
		const a = Math.max(index, min) - index;
		const b = Math.min(right, max) - index;
		const text = match.slice(a, b);
		return {
			...seg,
			index: index + a,
			match: text
		};
	}
	const segments = segmentMatch(match).map(trimSegment).filter(isDefined$1);
	function processSegments(segments) {
		const base = segments[0];
		const root = {
			a: base.index,
			b: base.index + base.match.length,
			s: { seg: base }
		};
		let m;
		for (let i = 1; i < segments.length; ++i) {
			const seg = segments[i];
			const index = seg.index;
			const end = index + seg.match.length;
			m = m && m.a <= index ? m : root;
			while (m && m.b <= index) m = m.n;
			while (m && m.a < end) {
				if (m.a < index) {
					const n = {
						...m,
						a: index
					};
					m.n = n;
					m.b = index;
					m = n;
				}
				if (m.b > end) {
					const n = {
						...m,
						a: end
					};
					m.b = end;
					m.n = n;
				}
				m.s = {
					seg,
					next: m.s
				};
				m = m.n;
			}
		}
		return root;
	}
	function segChainToScope(chain) {
		function* _chain(chain) {
			while (chain) {
				const seg = chain.seg;
				if (seg.groupName) if (Array.isArray(seg.groupName)) yield* seg.groupName;
				else yield seg.groupName;
				yield seg.groupNum.toString();
				chain = chain.next;
			}
		}
		return [..._chain(chain)].map((cap) => captureScopes.get(cap)).filter(isDefined$1).reverse().reduce((s, v) => pool.getScope(v, s), scope);
	}
	const merged = processSegments(segments);
	function* emit(m) {
		while (m) {
			yield {
				text: input.slice(m.a, m.b),
				range: [
					m.a,
					m.b,
					match.lineNumber
				],
				scope: segChainToScope(m.s)
			};
			m = m.n;
		}
	}
	return [...emit(merged)];
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/tokenizeLine.js
function tokenizeLine(line, rule) {
	const text = line.text;
	const lineLen = line.text.length;
	const parsedText = [];
	let ctx = buildContext({
		...line,
		offset: 0,
		anchor: -1
	}, rule);
	while (ctx.line.offset <= lineLen) {
		let endMatch = ctx.rule.end?.(ctx.line);
		while (endMatch?.index === ctx.line.offset) {
			parsedText.push(...applyCaptureToEnd(ctx.rule, endMatch));
			ctx = findParentWithEnd(ctx);
			ctx.line.offset = endMatch.index + endMatch.match.length;
			endMatch = ctx.rule.end?.(ctx.line);
		}
		if (ctx.line.offset >= lineLen) break;
		const { line, rule } = ctx;
		const offset = line.offset;
		const match = rule.findNext?.(line);
		const limit = endMatch?.index ?? lineLen;
		const emitTil = match ? Math.min(match.match.index, limit) : limit;
		if (offset < emitTil) {
			const scope = extractScope(rule);
			const start = offset;
			const end = emitTil;
			parsedText.push({
				scope,
				text: text.slice(start, end),
				range: [
					start,
					end,
					line.lineNumber
				]
			});
			ctx.line.offset = emitTil;
		}
		if (!match || endMatch && endMatch.index <= match.match.index) continue;
		parsedText.push(...applyCaptureToBeginOrMatch(match));
		line.anchor = match.match.index + match.match.match.length;
		line.offset = line.anchor;
		ctx = findNearestWithEnd(buildContext(line, match.rule));
	}
	return toParseLineResult(line, ctx.rule, parsedText);
}
function* tokenizeTextIterable(text, grammar) {
	const lines = text.split(/(?<=\r\n|\n|\r(?!\n))/);
	const rule = grammar.begin();
	let documentOffset = 0;
	let tr = tokenizeLine({
		text: lines[0],
		lineNumber: 0,
		documentOffset
	}, rule);
	documentOffset += lines[0].length;
	yield toParsedLine(tr);
	for (let i = 1; i < lines.length; ++i) {
		const line = {
			text: lines[i],
			lineNumber: i,
			documentOffset
		};
		documentOffset += line.text.length;
		tr = tr.parse(line);
		yield toParsedLine(tr);
	}
}
function toParsedLine(pr) {
	const { tokens: parsedText, line, offset } = pr;
	return {
		tokens: parsedText,
		line,
		offset
	};
}
function toParseLineResult(line, rule, parsedText) {
	return {
		tokens: parsedText,
		line,
		offset: line.documentOffset,
		parse: (line) => tokenizeLine(line, rule)
	};
}
function buildContext(line, rule) {
	const rules = calcRuleStack(rule);
	const rootNum = rules.length - 1;
	let ctx = {
		line,
		rule: rules[rootNum]
	};
	for (let i = rootNum - 1; i >= 0; --i) {
		const rule = rules[i];
		ctx = {
			line: ctx.line,
			rule,
			parent: ctx
		};
	}
	return ctx;
}
function calcRuleStack(rule) {
	const rules = [];
	let r = rule;
	while (r) {
		rules.push(r);
		r = r.parent;
	}
	return rules;
}
function must(t, msg = "Must be defined") {
	assert(t !== void 0 && t !== null, msg);
	return t;
}
function findParentWithEnd(ctx) {
	return findNearestWithEnd(must(ctx.parent));
}
function findNearestWithEnd(ctx) {
	while (!ctx.rule.end) ctx = must(ctx.parent);
	return ctx;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/grammars/typescript.js
const repository = {
	statements: {
		name: "code.ts",
		patterns: [
			"#keyword",
			"#regexp",
			"#string",
			"#comment",
			"#braces",
			"#punctuation",
			"#space",
			{
				name: "identifier",
				match: /[^\s;,!|&:^%{}[\]()*/+=<>]+/
			}
		]
	},
	keyword: { patterns: [
		"#keywordBase",
		"#standardTypes",
		"#standardLib"
	] },
	keywordBase: {
		name: "keyword.typescript.ts",
		match: /\b(?:any|as|async|await|bigint|boolean|break|case|catch|const|continue|do|else|enum|export|extends|false|finally|for|from|function|get|if|implements|in|instanceof|interface|import|let|map|module|new|new|null|number|of|package|private|public|require|return|set|static|string|super|switch|this|throw|true|try|type|typeof|unknown|undefined|var|void|while|yield)\b/
	},
	standardTypes: {
		name: "keyword.type.ts",
		match: /\b(?:Promise|Record|Omit|Extract|Exclude|BigInt|Array)\b/
	},
	standardLib: {
		name: "keyword.lib.ts",
		match: /\b(?:console|process|window)\b/
	},
	string: { patterns: [
		"#string_q_single",
		"#string_q_double",
		"#string_template"
	] },
	string_q_single: {
		name: "string.quoted.single.ts",
		begin: "'",
		end: /'|((?:[^\\\n])$)/,
		captures: "punctuation.string.ts",
		patterns: [{ include: "#string_character_escape" }]
	},
	string_q_double: {
		name: "string.quoted.double.ts",
		begin: "\"",
		end: /"|((?:[^\\\n])$)/,
		captures: "punctuation.string.ts",
		patterns: [{ include: "#string_character_escape" }]
	},
	string_template: {
		name: "string.template.ts",
		begin: "`",
		end: "`",
		captures: "punctuation.string.ts",
		patterns: [{
			name: "meta.template.expression.ts",
			contentName: "meta.embedded.line.ts",
			begin: "${",
			end: "}",
			patterns: ["#statements"],
			captures: "punctuation.definition.template.expression.ts"
		}, { include: "#string_character_escape" }]
	},
	string_character_escape: {
		name: "constant.character.escape.ts",
		match: /\\(x[0-9A-Fa-f]{2}|[0-3][0-7]{0,2}|[4-7][0-7]?|u[0-9A-Fa-f]{4}|.|\r?\n?$)/
	},
	braces: { patterns: [
		{
			begin: "(",
			end: ")",
			captures: "punctuation.meta.brace.ts",
			patterns: ["#statements"],
			name: "meta.brace.ts",
			contentName: "code.ts"
		},
		{
			begin: "{",
			end: "}",
			captures: "punctuation.meta.brace.ts",
			patterns: ["#statements"],
			name: "meta.brace.ts",
			contentName: "code.ts"
		},
		{
			begin: "[",
			end: "]",
			captures: "punctuation.meta.brace.ts",
			patterns: ["#statements"],
			name: "meta.brace.ts",
			contentName: "code.ts"
		}
	] },
	punctuation: {
		name: "punctuation.ts",
		match: /[-;:,!|&^%*/+=<>\n\r]/
	},
	space: {
		name: "punctuation.space.ts",
		match: /\s+/
	},
	comment: { patterns: [
		{
			name: "comment.line.ts",
			comment: "line comment",
			begin: "//",
			end: /(?=$)/,
			captures: "punctuation.definition.comment.ts"
		},
		{
			name: "comment.block.documentation.ts",
			comment: "DocBlock",
			begin: /\/\*\*(?!\/)/,
			captures: "punctuation.definition.comment.ts",
			end: "*/"
		},
		{
			name: "comment.block.ts",
			begin: "/*",
			end: "*/",
			captures: "punctuation.definition.comment.ts"
		}
	] },
	regexp: {
		name: "regexp.ts",
		begin: /\/(?![/*])/,
		end: /\/([a-z]*)/i,
		beginCaptures: "punctuation.begin.regexp.ts",
		endCaptures: "punctuation.end.regexp.ts",
		patterns: ["#regexp_escape", "#regexp_brace"]
	},
	regexp_escape: {
		name: "escape.regexp.ts",
		match: /\\./
	},
	regexp_brace: {
		name: "brace.regexp.ts",
		begin: "[",
		end: "]",
		contentName: "character-class.regexp.ts",
		patterns: ["#regexp_escape"]
	}
};
const grammar = {
	name: "TypeScript",
	scopeName: "source.ts",
	patterns: [{
		name: "comment.line.shebang.ts",
		match: /^#!.*(?=$)/
	}, { include: "#statements" }],
	repository
};

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/mappers/appendMappedText.js
function appendMappedText(a, b) {
	if (!a.map && !b.map) return { text: a.text + b.text };
	const aLen = a.text.length;
	const bLen = b.text.length;
	const aMap = [
		0,
		0,
		...a.map || [
			0,
			0,
			aLen,
			aLen
		]
	];
	const bMap = [
		0,
		0,
		...b.map || [
			0,
			0,
			bLen,
			bLen
		]
	];
	assert(aMap[aMap.length - 1] === aLen);
	assert(bMap[bMap.length - 1] === bLen);
	assert((aMap.length & 1) === 0);
	assert((bMap.length & 1) === 0);
	return {
		text: a.text + b.text,
		map: joinMaps(aMap, bMap)
	};
}
function joinMaps(aMap, bMap) {
	const n = aMap.length - 1;
	const offsets = [aMap[n - 1], aMap[n]];
	const ab = [...aMap, ...bMap.map((v, i) => v + offsets[i & 1])];
	const r = [0, 0];
	let last0 = 0, last1 = 0;
	for (let i = 0; i < ab.length; i += 2) {
		const v0 = ab[i];
		const v1 = ab[i + 1];
		if (v0 === last0 && v1 === last1) continue;
		r.push(v0, v1);
		last0 = v0;
		last1 = v1;
	}
	return r;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/mappers/typescript.js
/**
* Mappers for TypeScript and JavaScript
*/
const hexChars = {
	"0": 0,
	"1": 1,
	"2": 2,
	"3": 3,
	"4": 4,
	"5": 5,
	"6": 6,
	"7": 7,
	"8": 8,
	"9": 9,
	A: 10,
	B: 11,
	C: 12,
	D: 13,
	E: 14,
	F: 15,
	a: 10,
	b: 11,
	c: 12,
	d: 13,
	e: 14,
	f: 15
};
const escapeChars = {
	t: "	",
	n: "\n",
	r: "\r",
	b: "\b",
	"\\": "\\",
	"\"": "\"",
	"'": "'",
	"\n": ""
};
function mapRawString(text) {
	const end = text.length;
	let t = "";
	const map = [];
	const isHex = /^[0-9a-fA-F]+$/;
	let i, j;
	for (i = 0, j = 0; i < end; ++i) {
		let parsed;
		const ti = text[i];
		if (ti === "\\") {
			map.push(i, j);
			const tc = text[++i];
			const ec = escapeChars[tc];
			if (ec) {
				t += ec;
				j += ec.length;
				map.push(i, j);
				continue;
			}
			switch (tc) {
				case "u":
					{
						let char;
						let end;
						if (text[i + 1] !== "{") {
							const digits = text.slice(i + 1, i + 5);
							parsed = isHex.test(digits) ? Number.parseInt(digits, 16) : NaN;
							char = Number.isNaN(parsed) ? "" : String.fromCodePoint(parsed);
							end = i + 4;
						} else {
							for (end = i + 2; text[end] in hexChars; ++end);
							if (text[end] !== "}") char = "";
							else {
								const digits = text.slice(i + 2, end);
								parsed = isHex.test(digits) ? Number.parseInt(digits, 16) : NaN;
								char = Number.isNaN(parsed) ? "" : String.fromCodePoint(parsed);
							}
						}
						if (!char) {
							t += tc;
							j += 1;
						} else {
							t += char;
							j += char.length;
							i = end;
						}
					}
					break;
				case "x":
					{
						const digits = text.slice(i + 1, i + 3);
						parsed = isHex.test(digits) ? Number.parseInt(digits, 16) : NaN;
						if (Number.isNaN(parsed)) {
							t += tc;
							j += 1;
						} else {
							t += String.fromCodePoint(parsed);
							i += 2;
							++j;
						}
					}
					break;
				case "0":
					t += "0";
					j += 1;
					break;
				case "\r":
					i += text[i + 1] === "\n" ? 1 : 0;
					break;
				case "\n": break;
				case void 0: break;
				default:
					t += tc;
					++j;
					break;
			}
			map.push(i + 1, j);
			continue;
		}
		t += ti;
		++j;
	}
	if (map.length) {
		const ii = map[map.length - 2];
		const jj = map[map.length - 1];
		if (ii !== i || jj !== j) map.push(i, j);
	}
	return {
		text: t,
		map
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parser/parser.js
function mapTokenizedLine$1(tl) {
	return tl.tokens.map((t) => ({
		text: t.text,
		range: [tl.offset + t.range[0], tl.offset + t.range[1]],
		scope: t.scope
	}));
}
function mapTokenizedLines$1(itl) {
	return pipeSync$1(itl, opMapSync$1(mapTokenizedLine$1), opFlattenSync$1());
}
function createParser(grammar, name, transform = mapTokenizedLines$1) {
	function parse(content, filename) {
		return {
			content,
			filename,
			parsedTexts: pipeSync$1(tokenizeTextIterable(content, grammar), transform)
		};
	}
	return {
		name,
		parse
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parsers/typescript/TypeScriptParser.js
const tsGrammar = compileGrammar(grammar);
const pool = new ScopePool();
const useScope = /* @__PURE__ */ new WeakMap();
function* transform(texts) {
	for (const parsed of texts) {
		if (doesScopeMatch(parsed.scope, "constant.character.escape.ts")) {
			const mapped = mapRawString(parsed.text);
			const scope = parsed.scope ? pool.parseScope(parsed.scope) : void 0;
			yield {
				text: mapped.text,
				scope: scope?.parent,
				map: mapped.map,
				range: parsed.range
			};
			continue;
		}
		yield parsed;
	}
}
function* mergeStringResults(results) {
	let last;
	for (const next of results) {
		if (!doesScopeMatch(next.scope, "string.")) {
			if (last) {
				yield last;
				last = void 0;
			}
			yield next;
			continue;
		}
		if (!last) {
			last = next;
			continue;
		}
		if (next.scope !== last.scope || last.range[1] !== next.range[0]) {
			yield last;
			last = next;
			continue;
		}
		last = mergeParsedText(last, next);
	}
	if (last) yield last;
}
function mergeParsedText(a, b) {
	const abT = appendMappedText(a, b);
	return {
		text: abT.text,
		scope: a.scope,
		range: [a.range[0], b.range[1]],
		map: abT.map,
		delegate: a.delegate
	};
}
function filterScope(scope) {
	const cached = useScope.get(scope);
	if (cached !== void 0) return cached;
	const value = scope.value;
	const use = !value.startsWith("punctuation") && !value.startsWith("keyword.");
	useScope.set(scope, use);
	return use;
}
function mapTokenizedLine(tl) {
	return tl.tokens.filter((t) => filterScope(t.scope)).map((t) => ({
		text: t.text,
		range: [tl.offset + t.range[0], tl.offset + t.range[1]],
		scope: t.scope
	}));
}
function mapTokenizedLines(itl) {
	return pipeSync$1(itl, opMapSync$1(mapTokenizedLine), opFlattenSync$1(), transform, mergeStringResults);
}
const parser = createParser(tsGrammar, "typescript", mapTokenizedLines);
function doesScopeMatch(s, match) {
	if (!s) return false;
	return typeof s === "string" ? s.startsWith(match) : s.value.startsWith(match);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-grammar@9.6.4/node_modules/cspell-grammar/dist/parsers/index.js
const parsers = [parser];

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Models/PatternRegExp.js
var PatternRegExp = class extends RegExp {
	constructor(pattern) {
		super(pattern);
	}
	toJSON() {
		return this.toString();
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/LanguageSettings.js
const defaultLocale = "en";
const defaultLanguageSettings = [];
function getDefaultLanguageSettings() {
	return defaultLanguageSettings;
}
function localesToList(locales) {
	return stringToList(locales.replaceAll(/\s+/g, ","));
}
function stringToList(sList) {
	return sList.replaceAll(/[|;]/g, ",").split(",").map((s) => s.trim()).filter((s) => !!s);
}
function memoize(resolver) {
	const cache = createAutoResolveCache();
	return (k) => cache.get(k, resolver);
}
const _normalizeLanguageId = memoize(__normalizeLanguageId);
function __normalizeLanguageId(langId) {
	const langIds = stringToList(langId);
	return new Set(langIds.map((a) => a.toLowerCase()));
}
function normalizeLanguageId(langId) {
	return _normalizeLanguageId(typeof langId === "string" ? langId : langId.join(","));
}
const _normalizeLocale = memoize(__normalizeLocale);
function __normalizeLocale(locale) {
	const locales = localesToList(locale);
	return new Set(locales.map((locale) => locale.toLowerCase().replaceAll(/[^a-z]/g, "")));
}
function normalizeLocale(locale) {
	locale = typeof locale === "string" ? locale : locale.join(",");
	return _normalizeLocale(locale);
}
function normalizeLocaleIntl(locale) {
	const values = [...normalizeLocale(locale)].map((locale) => locale.replace(/^([a-z]{2})-?([a-z]{2})$/, (_, lang, locale) => locale ? `${lang}-${locale.toUpperCase()}` : lang));
	return new Set(values);
}
function isLocaleInSet(locale, setOfLocals) {
	return doSetsIntersect(normalizeLocale(locale), setOfLocals);
}
const regExpValidIntlLocaleStrict = /^[a-z]{2}(-[A-Z]{2})?$/;
const regExpValidIntlLocale = new RegExp(regExpValidIntlLocaleStrict, "i");
/**
* Test if a locale should be ok with Intl
* @param locale - locale string
* @param strict - case must match
* @returns true if it matches the standard 2 letter or 4 letter forms.
*/
function isValidLocaleIntlFormat(locale, strict = false) {
	if (typeof locale === "string") return strict ? regExpValidIntlLocaleStrict.test(locale) : regExpValidIntlLocale.test(locale);
	for (const item of locale) if (!isValidLocaleIntlFormat(item, strict)) return false;
	return locale.length > 0;
}
const cacheCalcSettingsForLanguage = createAutoResolveWeakCache();
function calcSettingsForLanguage(languageSettings, languageId, locale) {
	return cacheCalcSettingsForLanguage.get(languageSettings, () => new AutoResolveCache()).get(languageId, () => new AutoResolveCache()).get(locale, () => _calcSettingsForLanguage(languageSettings, languageId, locale));
}
function _calcSettingsForLanguage(languageSettings, languageId, locale) {
	languageId = languageId.toLowerCase();
	const allowedLocals = normalizeLocale(locale);
	const ls = languageSettings.filter((s) => doesLanguageSettingMatchLanguageId(s, languageId)).filter((s) => !s.locale || s.locale === "*" || isLocaleInSet(s.locale, allowedLocals)).map((langSetting) => {
		const { languageId: _languageId, locale: _locale, ...s } = langSetting;
		return s;
	}).reduce((langSetting, setting) => mergeSettings(langSetting, setting), {});
	ls.languageId = languageId;
	ls.locale = locale;
	return ls;
}
const cacheDoesLanguageSettingMatchLanguageId = createAutoResolveWeakCache();
function doesLanguageSettingMatchLanguageId(s, languageId) {
	return cacheDoesLanguageSettingMatchLanguageId.get(s, () => new AutoResolveCache()).get(languageId, () => _doesLanguageSettingMatchLanguageId(s, languageId));
}
function _doesLanguageSettingMatchLanguageId(s, languageId) {
	const languageSettingsLanguageIds = s.languageId;
	if (!languageSettingsLanguageIds || languageSettingsLanguageIds === "*") return true;
	const ids = normalizeLanguageId(languageSettingsLanguageIds);
	if (ids.has(languageId)) return true;
	if (ids.has("!" + languageId)) return false;
	return [...ids].filter((id) => id.startsWith("!")).length === ids.size;
}
function calcUserSettingsForLanguage(settings, languageId) {
	const { languageSettings = [], language: locale = defaultLocale, allowCompoundWords, enabled } = settings;
	const langSettings = {
		allowCompoundWords,
		enabled,
		...calcSettingsForLanguage(languageSettings, languageId, locale)
	};
	return mergeSettings(settings, langSettings);
}
function calcSettingsForLanguageId(baseSettings, languageId) {
	return ["*", ...normalizeLanguageId(languageId)].reduce((settings, languageId) => {
		return calcUserSettingsForLanguage(settings, languageId);
	}, baseSettings);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/RegExpPatterns.js
const regExMatchUrls = /(?:https?|ftp):\/\/[^\s"]+/gi;
const regExHRef = /\bhref\s*=\s*".*?"/gi;
const regExMatchCommonHexFormats = /(?:#[0-9a-f]{3,8})|(?:0x[0-9a-f]+)|(?:\\u[0-9a-f]{4})|(?:\\x\{[0-9a-f]{4}\})/gi;
const regExCommitHash = /\b(?![a-f]+\b)(?:0x)?[0-9a-f]{7,}\b/gi;
const regExCommitHashLink = /\[[0-9a-f]{7,}\]/gi;
const regExCStyleHexValue = /\b0x[0-9a-f_]+n?\b/gi;
const regExCSSHexValue = /#[0-9a-f]{3,8}\b/gi;
const regExUUID = /\b[0-9a-fx]{8}-[0-9a-fx]{4}-[0-9a-fx]{4}-[0-9a-fx]{4}-[0-9a-fx]{12}\b/gi;
const regExUnicodeRef = /\bU\+[0-9a-f]{4,5}(?:-[0-9a-f]{4,5})?/gi;
const regExSpellingGuardBlock = /(\bc?spell(?:-?checker)?::?)\s*disable(?!-line|-next)\b(?!-)[\s\S]*?((?:\1\s*enable\b)|$)/gi;
const regExSpellingGuardNext = /\bc?spell(?:-?checker)?::?\s*disable-next\b.*\s\s?.*/gi;
const regExSpellingGuardLine = /^.*\bc?spell(?:-?checker)?::?\s*disable-line\b.*/gim;
const regExIgnoreSpellingDirectives = /\bc?spell(?:-?checker)?::?\s*(ignoreRegExp|word|ignore).*/gim;
const regExPublicKey = /-{5}BEGIN\s+((?:RSA\s+)?PUBLIC\s+KEY)[\w=+\-/=\\\s]+?END\s+\1-{5}/g;
const regExCert = /-{5}BEGIN\s+(CERTIFICATE|(?:RSA\s+)?(?:PRIVATE|PUBLIC)\s+KEY)[\w=+\-/=\\\s]+?END\s+\1-{5}/g;
const regExSshRSA = /ssh-rsa\s+[a-z0-9/+]{28,}={0,3}(?![a-z0-9/+=])/gi;
const regExEscapeCharacters = /\\(?:[anrvtbf]|[xu][a-f0-9]+)/gi;
const regExBase64 = /(?<![A-Za-z0-9/+])(?:[A-Za-z0-9/+]{40,})(?:\s^\s*[A-Za-z0-9/+]{40,})*(?:\s^\s*[A-Za-z0-9/+]+=*)?(?![A-Za-z0-9/+=])/gm;
/**
* Detect a string of characters that look like a Base64 string.
*
* It must be:
* - at least 40 characters
* - preceded by a non-Base64
* - contain at least 1 of [0-9+/]
* - contain at least 1 of [A-Z][a-z][A-Z]
* - contain at least 1 of [A-Z][0-9][A-Z] | [a-z][0-9][a-z] | [A-Z][0-9][a-z] | [0-9][A-Za-z][0-9]
* - contain at least 1 of [a-z]{3} | [A-Z]{3}
*/
const regExBase64SingleLine = /(?<=[^A-Za-z0-9/+_]|^)(?=[A-Za-z]{0,80}[0-9+/])(?=[A-Za-z0-9/+]{0,80}?[A-Z][a-z][A-Z])(?=[A-Za-z0-9/+]{0,80}?(?:[A-Z][0-9][A-Z]|[a-z][0-9][a-z]|[A-Z][0-9][a-z]|[a-z][0-9][A-Z]|[0-9][A-Za-z][0-9]))(?=[A-Za-z0-9/+]{0,80}?(?:[a-z]{3}|[A-Z]{3}))(?:[A-Za-z0-9/+]{40,})=*/gm;
const regExBase64MultiLine = /(?<![A-Za-z0-9/+])["']?(?:[A-Za-z0-9/+]{40,})["']?(?:\s^\s*["']?[A-Za-z0-9/+]{40,}["']?)+(?:\s^\s*["']?[A-Za-z0-9/+]+={0,3}["']?)?(?![A-Za-z0-9/+=])/gm;
const regExPhpHereDoc = /<<<['"]?(\w+)['"]?[\s\S]+?^\1;/gm;
const regExString = /(?:(['"]).*?(?<![^\\]\\(\\\\)*)\1)|(?:`[\s\S]*?(?<![^\\]\\(\\\\)*)`)/g;
const regExCStyleComments = /(?<!\w:)(?:\/\/.*)|(?:\/\*[\s\S]*?\*\/)/g;
const regExEmail = /<?\b[\w.\-+]{1,128}@\w{1,63}(\.\w{1,63}){1,4}\b>?/gi;
const regExRepeatedChar = /^(\w)\1{3,}$/i;
const regExSha = /\bsha\d+-[a-z0-9+/]{25,}={0,3}/gi;
/**
* Detect common hash strings like:
* - `sha1`, `sha256`, `sha512`
* - `md5`
* - `base64` - used in email
* - `crypt`, `bcrypt`, `script`
* - `token`
* - `assertion` - use with jwt
*/
const regExHashStrings = /(?:\b(?:sha\d+|md5|base64|crypt|bcrypt|scrypt|security-token|assertion)[-,:$=]|#code[/])[-\w/+%.]{25,}={0,3}(?:(['"])\s*\+?\s*\1?[-\w/+%.]+={0,3})*(?![-\w/+=%.])/gi;

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/DefaultSettings.js
const defaultConfigFile = () => resolveConfigModule(defaultConfigFileModuleRef);
const regExpSpellCheckerDisable = [
	new PatternRegExp(regExSpellingGuardBlock),
	new PatternRegExp(regExSpellingGuardLine),
	new PatternRegExp(regExSpellingGuardNext)
];
const defaultRegExpPatterns = [...[
	{
		name: "CommitHash",
		pattern: regExCommitHash
	},
	{
		name: "CommitHashLink",
		pattern: regExCommitHashLink
	},
	{
		name: "CStyleHexValue",
		pattern: regExCStyleHexValue
	},
	{
		name: "CSSHexValue",
		pattern: regExCSSHexValue
	},
	{
		name: "Urls",
		pattern: regExMatchUrls
	},
	{
		name: "HexValues",
		pattern: regExMatchCommonHexFormats
	},
	{
		name: "SpellCheckerDisable",
		pattern: regExpSpellCheckerDisable
	},
	{
		name: "PublicKey",
		pattern: regExPublicKey
	},
	{
		name: "RsaCert",
		pattern: regExCert
	},
	{
		name: "SshRsa",
		pattern: regExSshRSA
	},
	{
		name: "EscapeCharacters",
		pattern: regExEscapeCharacters
	},
	{
		name: "Base64",
		pattern: regExBase64
	},
	{
		name: "Base64SingleLine",
		pattern: regExBase64SingleLine
	},
	{
		name: "Base64MultiLine",
		pattern: regExBase64MultiLine
	},
	{
		name: "Email",
		pattern: regExEmail
	},
	{
		name: "SHA",
		pattern: regExSha
	},
	{
		name: "HashStrings",
		pattern: regExHashStrings
	},
	{
		name: "UnicodeRef",
		pattern: regExUnicodeRef
	},
	{
		name: "UUID",
		pattern: regExUUID
	},
	{
		name: "href",
		pattern: regExHRef
	},
	{
		name: "SpellCheckerDisableBlock",
		pattern: regExSpellingGuardBlock
	},
	{
		name: "SpellCheckerDisableLine",
		pattern: regExSpellingGuardLine
	},
	{
		name: "SpellCheckerDisableNext",
		pattern: regExSpellingGuardNext
	},
	{
		name: "SpellCheckerIgnoreInDocSetting",
		pattern: regExIgnoreSpellingDirectives
	},
	{
		name: "PhpHereDoc",
		pattern: regExPhpHereDoc
	},
	{
		name: "string",
		pattern: regExString
	},
	{
		name: "CStyleComment",
		pattern: regExCStyleComments
	},
	{
		name: "Everything",
		pattern: ".*"
	}
]].map(normalizePattern$1);
const defaultRegExpExcludeList = [
	"SpellCheckerDisable",
	"SpellCheckerIgnoreInDocSetting",
	"Urls",
	"Email",
	"RsaCert",
	"SshRsa",
	"Base64MultiLine",
	"Base64SingleLine",
	"CommitHash",
	"CommitHashLink",
	"CStyleHexValue",
	"CSSHexValue",
	"SHA",
	"HashStrings",
	"UnicodeRef",
	"UUID"
];
const _defaultSettingsBasis = Object.freeze(createCSpellSettingsInternal({
	id: "static_defaults",
	language: "en",
	name: "Static Defaults",
	enabled: true,
	enabledLanguageIds: [],
	maxNumberOfProblems: 100,
	numSuggestions: 10,
	suggestionsTimeout: 500,
	suggestionNumChanges: 3,
	words: [],
	userWords: [],
	ignorePaths: [],
	allowCompoundWords: false,
	patterns: defaultRegExpPatterns,
	ignoreRegExpList: [],
	languageSettings: [],
	source: { name: "defaultSettings" },
	reporters: [],
	plugins: [{ parsers }]
}));
const _defaultSettings = Object.freeze(createCSpellSettingsInternal({
	..._defaultSettingsBasis,
	enabledFileTypes: { "*": true },
	ignoreRegExpList: defaultRegExpExcludeList,
	languageSettings: getDefaultLanguageSettings()
}));
async function resolveConfigModule(configModuleName) {
	return (await resolveFile(configModuleName, srcDirectory)).filename;
}
function normalizePattern$1(pat) {
	const { name, pattern, description } = pat;
	if (!(pattern instanceof RegExp)) return pat;
	return {
		name,
		pattern: new PatternRegExp(pattern),
		description
	};
}
var DefaultSettingsLoader = class {
	settings = void 0;
	pending = void 0;
	constructor() {
		this.getDefaultSettingsAsync().catch(() => void 0);
	}
	getDefaultSettingsAsync(useDefaultDictionaries = true) {
		if (!useDefaultDictionaries) return Promise.resolve(_defaultSettingsBasis);
		if (this.settings) return Promise.resolve(this.settings);
		if (this.pending) return this.pending;
		this.pending = (async () => {
			const jsonSettings = await readSettings(await defaultConfigFile());
			this.settings = mergeSettings(_defaultSettings, jsonSettings);
			if (jsonSettings.name !== void 0) this.settings.name = jsonSettings.name;
			else delete this.settings.name;
			return this.settings;
		})();
		return this.pending;
	}
};
const defaultSettingsLoader = new DefaultSettingsLoader();
function getDefaultSettings(useDefaultDictionaries = true) {
	return defaultSettingsLoader.getDefaultSettingsAsync(useDefaultDictionaries);
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+strong-weak-map@9.6.4/node_modules/@cspell/strong-weak-map/dist/esm/StrongWeakMap.js
var StrongWeakMap = class {
	map;
	constructor(init) {
		this.map = new Map(init?.map(([k, v]) => [k, new WeakRef(v)]));
	}
	clear() {
		this.map.clear();
	}
	/**
	* @returns true if an element in the Map existed and has been removed, or false if the element does not exist.
	*/
	delete(key) {
		return this.map.delete(key);
	}
	/**
	* Executes a provided function once per each key/value pair in the Map, in insertion order.
	*/
	forEach(callbackfn, thisArg) {
		if (thisArg) callbackfn = callbackfn.bind(thisArg);
		for (const [key, value] of this) callbackfn(value, key, this);
	}
	/**
	* Returns a specified element from the Map object. You will get a reference to the value object and any change made to that
	* object will effectively modify it inside the Map.
	* @returns Returns the element associated with the specified key.
	*   If no element is associated with the specified key, undefined is returned.
	*/
	get(key) {
		const ref = this.map.get(key);
		if (!ref) return void 0;
		const value = ref.deref();
		if (!value) {
			this.map.delete(key);
			return;
		}
		return value;
	}
	/**
	* Returns a specified element from the Map. If the element isn't found, the resolver function is called and the result is stored in the map and returned.
	*/
	autoGet(key, resolver) {
		const found = this.get(key);
		if (found) return found;
		const created = resolver(key);
		this.set(key, created);
		return created;
	}
	/**
	* Note: has will cause the value object to live longer.
	* See: [WeakRef - JavaScript | MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WeakRef#notes_on_weakrefs)
	* @returns boolean indicating whether an element with the specified key exists or not.
	*/
	has(key) {
		return !!this.get(key);
	}
	/**
	* Adds a new element with a specified key and value to the Map. If an element with the same key already exists, the element will be updated.
	*/
	set(key, value) {
		this.map.set(key, new WeakRef(value));
		return this;
	}
	/**
	* @returns the number of elements in the Map. Note: it is possible that some of the values have been dereferenced
	*/
	get size() {
		return this.map.size;
	}
	/** Returns an iterable of entries in the map. */
	[Symbol.iterator]() {
		return this.entries();
	}
	/**
	* Returns an iterable of key, value pairs for every entry in the map.
	*/
	*entries() {
		for (const key of this.map.keys()) {
			const value = this.get(key);
			if (!value) continue;
			yield [key, value];
		}
	}
	/**
	* Returns an iterable of keys in the map
	*
	* Note: It is possible that the value associated with the key was released.
	*/
	keys() {
		return this.map.keys();
	}
	/**
	* Returns an iterable of values in the map
	*/
	*values() {
		for (const [_, value] of this) yield value;
	}
	/**
	* Removes any keys that reference released objects.
	*/
	cleanKeys() {
		const keysToDel = [];
		for (const [key, ref] of this.map.entries()) if (!ref.deref()) keysToDel.push(key);
		for (const key of keysToDel) this.map.delete(key);
		return this;
	}
	[Symbol.toStringTag] = "StrongWeakMap";
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/perf/timer.js
function createPerfTimer(name, onEnd, timeNowFn) {
	return new SimpleTimer(name, onEnd, timeNowFn);
}
var SimpleTimer = class {
	name;
	onEnd;
	timeNowFn;
	_start = performance.now();
	_elapsed = void 0;
	_running = true;
	constructor(name, onEnd, timeNowFn = performance.now) {
		this.name = name;
		this.onEnd = onEnd;
		this.timeNowFn = timeNowFn;
	}
	get startTime() {
		return this._start;
	}
	get elapsed() {
		return this._elapsed ?? performance.now() - this._start;
	}
	end() {
		if (!this._running) return;
		this._running = false;
		this._elapsed = performance.now() - this._start;
		this.onEnd?.(this._elapsed, this.name);
	}
	start() {
		this._start = performance.now();
		this._running = true;
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/simpleCache.js
/**
* This will cache between `size` and 3 x `size` items.
* It has three stashes, L0, L1, and L2. Each can contain `size` items.
* When L0 is full, its items are given to L1 and L1's are given to L2, and L2 is empties.
*
* The stashes are searched in order, L0...L2. If an item is found in L1, or L2, it is
* promoted to L0.
*/
var SimpleCache = class {
	size;
	L0 = /* @__PURE__ */ new Map();
	L1 = /* @__PURE__ */ new Map();
	L2 = /* @__PURE__ */ new Map();
	constructor(size) {
		this.size = size;
	}
	has(key) {
		for (const c of this.caches()) if (c.has(key)) return true;
		return false;
	}
	get(key) {
		for (const c of this.caches()) {
			const entry = c.get(key);
			if (entry) {
				if (c !== this.L0) this._set(key, entry);
				return entry.v;
			}
		}
	}
	set(key, value) {
		this._set(key, { v: value });
	}
	delete(key) {
		let deleted = false;
		for (const c of this.caches()) deleted = c.delete(key) || deleted;
		return deleted;
	}
	_set(key, entry) {
		if (this.L0.has(key)) {
			this.L0.set(key, entry);
			return this;
		}
		if (this.L0.size >= this.size) this.rotate();
		this.L0.set(key, entry);
	}
	caches() {
		return [
			this.L0,
			this.L1,
			this.L2
		];
	}
	rotate() {
		const L2 = this.L2;
		this.L2 = this.L1;
		this.L1 = this.L0;
		this.L0 = L2;
		this.L0.clear();
	}
};
var AutoCache = class extends SimpleCache {
	factory;
	constructor(factory, size) {
		super(size);
		this.factory = factory;
	}
	get(key) {
		const v = super.get(key);
		if (v !== void 0) return v;
		const val = this.factory(key);
		this.set(key, val);
		return val;
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/SpellingDictionary/SpellingDictionaryError.js
var SpellingDictionaryLoadError = class extends Error {
	uri;
	options;
	cause;
	name;
	constructor(uri, options, cause, message) {
		super(message);
		this.uri = uri;
		this.options = options;
		this.cause = cause;
		this.name = options.name;
	}
};
function isSpellingDictionaryLoadError(e) {
	return e instanceof SpellingDictionaryLoadError;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/SpellingDictionary/DictionaryController/DictionaryLoader.js
var __addDisposableResource = void 0 && (void 0).__addDisposableResource || function(env, value, async) {
	if (value !== null && value !== void 0) {
		if (typeof value !== "object" && typeof value !== "function") throw new TypeError("Object expected.");
		var dispose, inner;
		if (async) {
			if (!Symbol.asyncDispose) throw new TypeError("Symbol.asyncDispose is not defined.");
			dispose = value[Symbol.asyncDispose];
		}
		if (dispose === void 0) {
			if (!Symbol.dispose) throw new TypeError("Symbol.dispose is not defined.");
			dispose = value[Symbol.dispose];
			if (async) inner = dispose;
		}
		if (typeof dispose !== "function") throw new TypeError("Object not disposable.");
		if (inner) dispose = function() {
			try {
				inner.call(this);
			} catch (e) {
				return Promise.reject(e);
			}
		};
		env.stack.push({
			value,
			dispose,
			async
		});
	} else if (async) env.stack.push({ async: true });
	return value;
};
var __disposeResources = void 0 && (void 0).__disposeResources || (function(SuppressedError) {
	return function(env) {
		function fail(e) {
			env.error = env.hasError ? new SuppressedError(e, env.error, "An error was suppressed during disposal.") : e;
			env.hasError = true;
		}
		var r, s = 0;
		function next() {
			while (r = env.stack.pop()) try {
				if (!r.async && s === 1) return s = 0, env.stack.push(r), Promise.resolve().then(next);
				if (r.dispose) {
					var result = r.dispose.call(r.value);
					if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) {
						fail(e);
						return next();
					});
				} else s |= 1;
			} catch (e) {
				fail(e);
			}
			if (s === 1) return env.hasError ? Promise.reject(env.error) : Promise.resolve();
			if (env.hasError) throw env.error;
		}
		return next();
	};
})(typeof SuppressedError === "function" ? SuppressedError : function(error, suppressed, message) {
	var e = new Error(message);
	return e.name = "SuppressedError", e.error = error, e.suppressed = suppressed, e;
});
const MAX_AGE = 1e4;
const loaders = {
	S: loadSimpleWordList,
	C: legacyWordList,
	W: wordsPerLineWordList,
	T: loadTrie,
	default: loadSimpleWordList
};
var LoadingState;
(function(LoadingState) {
	LoadingState[LoadingState["Loaded"] = 0] = "Loaded";
	LoadingState[LoadingState["Loading"] = 1] = "Loading";
})(LoadingState || (LoadingState = {}));
var DictionaryLoader = class {
	fs;
	dictionaryCache = new StrongWeakMap();
	inlineDictionaryCache = new AutoResolveWeakCache();
	dictionaryCacheByDef = new AutoResolveWeakWeakCache();
	reader;
	/** The keepAliveCache is to hold onto the most recently loaded dictionaries. */
	keepAliveCache;
	constructor(fs, keepAliveSize = 10) {
		this.fs = fs;
		this.reader = toReader(fs);
		this.keepAliveCache = new SimpleCache(keepAliveSize);
	}
	loadDictionary(def) {
		if (isDictionaryDefinitionInlineInternal(def)) return Promise.resolve(this.loadInlineDict(def));
		if (isDictionaryFileDefinitionInternal(def)) {
			const { key, entry } = this.getCacheEntry(def);
			if (entry) return entry.pending.then(([dictionary]) => dictionary);
			const loadedEntry = this.loadEntry(def.btrie || def.path, def);
			this.setCacheEntry(key, loadedEntry, def);
			this.keepAliveCache.set(def, loadedEntry);
			return loadedEntry.pending.then(([dictionary]) => dictionary);
		}
		return Promise.resolve(this.loadSimpleDict(def));
	}
	/**
	* Check to see if any of the cached dictionaries have changed. If one has changed, reload it.
	* @param maxAge - Only check the dictionary if it has been at least `maxAge` ms since the last check.
	* @param now - optional timestamp representing now. (Mostly used in testing)
	*/
	async refreshCacheEntries(maxAge = MAX_AGE, now = Date.now()) {
		await Promise.all([...this.dictionaryCache.values()].map((entry) => this.refreshEntry(entry, maxAge, now)));
	}
	getCacheEntry(def) {
		const defEntry = this.dictionaryCacheByDef.get(def);
		if (defEntry) {
			this.keepAliveCache.get(def);
			return defEntry;
		}
		const key = this.calcKey(def);
		const entry = this.dictionaryCache.get(key);
		if (entry) {
			entry.options = def;
			this.keepAliveCache.set(def, entry);
		}
		return {
			key,
			entry
		};
	}
	setCacheEntry(key, entry, def) {
		this.dictionaryCache.set(key, entry);
		this.dictionaryCacheByDef.set(def, {
			key,
			entry
		});
	}
	async refreshEntry(entry, maxAge, now) {
		if (now - entry.ts >= maxAge) {
			const sig = now + Math.random();
			entry.sig = sig;
			entry.ts = now;
			const pStat = this.getStat(entry.uri);
			const [newStat] = await Promise.all([pStat, entry.pending]);
			const hasChanged = !this.isEqual(newStat, entry.stat);
			if (entry.sig === sig && hasChanged) {
				entry.loadingState = LoadingState.Loading;
				const key = this.calcKey(entry.options);
				const newEntry = this.loadEntry(entry.uri, entry.options);
				this.dictionaryCache.set(key, newEntry);
				this.dictionaryCacheByDef.set(entry.options, {
					key,
					entry: newEntry
				});
			}
		}
	}
	loadEntry(fileOrUri, options, now = Date.now()) {
		const url = toFileURL(fileOrUri);
		options = this.normalizeOptions(url, options);
		const pDictionary = load(this.reader, url, options).catch((e) => createFailedToLoadDictionary(options.name, fileOrUri, new SpellingDictionaryLoadError(url.href, options, e, "failed to load"), options));
		const pStat = this.getStat(url);
		const pending = Promise.all([pDictionary, pStat]);
		const sig = now + Math.random();
		const entry = {
			uri: url.href,
			options,
			ts: now,
			stat: void 0,
			dictionary: void 0,
			pending,
			loadingState: LoadingState.Loading,
			sig
		};
		pending.then(([dictionary, stat]) => {
			entry.stat = stat;
			entry.dictionary = dictionary;
			entry.loadingState = LoadingState.Loaded;
		}).catch(() => void 0);
		return entry;
	}
	getStat(uri) {
		return this.fs.stat(toFileURL(uri)).catch(toError$4);
	}
	isEqual(a, b) {
		if (!b) return false;
		if (isError$1(a)) return isError$1(b) && a.message === b.message && a.name === b.name;
		return !isError$1(b) && !compareStats(a, b);
	}
	normalizeOptions(uri, options) {
		if (options.name) return options;
		return {
			...options,
			name: urlBasename(uri)
		};
	}
	loadInlineDict(def) {
		return this.inlineDictionaryCache.get(def, (def) => createInlineSpellingDictionary(def, def.__source || "memory"));
	}
	loadSimpleDict(def) {
		return createInlineSpellingDictionary({
			name: def.name,
			words: []
		}, def.__source || "memory");
	}
	calcKey(def) {
		const path = def.path;
		return [
			path,
			determineType(toFileURL(path), def),
			...importantOptionKeys.map((k) => def[k]?.toString() || "")
		].join("|");
	}
};
function toReader(fs) {
	function readResource(url) {
		return fs.readFile(url);
	}
	async function readText(url) {
		return (await readResource(url)).getText();
	}
	async function read(url) {
		return (await readResource(url)).getBytes();
	}
	return {
		read,
		readText,
		readLines: async (filename) => toLines(await readText(filename))
	};
}
const importantOptionKeys = [
	"name",
	"noSuggest",
	"useCompounds",
	"type"
];
function isError$1(e) {
	return !!e.message;
}
function determineType(uri, opts) {
	const defLoaderType = opts.type && opts.type in loaders && opts.type || "S";
	const defType = uri.pathname.endsWith(".trie.gz") ? "T" : defLoaderType;
	return /\.b?trie\b/i.test(uri.pathname) ? "T" : defType;
}
async function load(reader, uri, options) {
	return (loaders[determineType(uri, options)] || loaders.default)(reader, uri, options);
}
async function legacyWordList(reader, filename, options) {
	const env_1 = {
		stack: [],
		error: void 0,
		hasError: false
	};
	try {
		const lines = await reader.readLines(filename);
		__addDisposableResource(env_1, measurePerf("legacyWords"), false);
		return createSpellingDictionary(pipeSync$1(lines, opMapSync$1((line) => line.replaceAll(/#.*/g, "")), opConcatMapSync$1((line) => line.split(/[^\w\p{L}\p{M}']+/gu)), opFilterSync$1((word) => !!word)), options.name, filename.toString(), options, true);
	} catch (e_1) {
		env_1.error = e_1;
		env_1.hasError = true;
	} finally {
		__disposeResources(env_1);
	}
}
async function wordsPerLineWordList(reader, filename, options) {
	return createSpellingDictionary(pipeSync$1(await reader.readLines(filename), opMapSync$1((line) => line.replaceAll(/#.*/g, "")), opConcatMapSync$1((line) => line.split(/\s+/gu)), opFilterSync$1((word) => !!word)), options.name, filename.href, options, true);
}
async function loadSimpleWordList(reader, filename, options) {
	const env_2 = {
		stack: [],
		error: void 0,
		hasError: false
	};
	try {
		const lines = await reader.readLines(filename);
		__addDisposableResource(env_2, measurePerf("loadSimpleWordList"), false);
		return createSpellingDictionary(lines, options.name, filename.href, options);
	} catch (e_2) {
		env_2.error = e_2;
		env_2.hasError = true;
	} finally {
		__disposeResources(env_2);
	}
}
async function loadTrie(reader, filename, options) {
	const env_3 = {
		stack: [],
		error: void 0,
		hasError: false
	};
	try {
		const content = await reader.read(filename);
		__addDisposableResource(env_3, measurePerf("loadTrie"), false);
		return createSpellingDictionaryFromTrieFile(content, options.name, filename.href, options);
	} catch (e_3) {
		env_3.error = e_3;
		env_3.hasError = true;
	} finally {
		__disposeResources(env_3);
	}
}
function toLines(content) {
	return content.split(/\n|\r\n|\r/);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/SpellingDictionary/DictionaryLoader.js
let loader;
function getDictionaryLoader(vfs) {
	if (loader) return loader;
	return loader = new DictionaryLoader(vfs || getFileSystem());
}
function loadDictionary(def) {
	return getDictionaryLoader().loadDictionary(def);
}
/**
* Check to see if any of the cached dictionaries have changed. If one has changed, reload it.
* @param maxAge - Only check the dictionary if it has been at least `maxAge` ms since the last check.
* @param now - optional timestamp representing now. (Mostly used in testing)
*/
async function refreshCacheEntries(maxAge, now) {
	return getDictionaryLoader().refreshCacheEntries(maxAge, now);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/SpellingDictionary/Dictionaries.js
function loadDictionaryDefs(defsToLoad) {
	return defsToLoad.map(loadDictionary);
}
function refreshDictionaryCache(maxAge) {
	return refreshCacheEntries(maxAge);
}
const emptyWords = Object.freeze([]);
async function getDictionaryInternal(settings) {
	return _getDictionaryInternal(settings, await Promise.all(loadDictionaryDefs(calcDictionaryDefsToLoad(settings))));
}
const specialDictionaryNames = {
	words: "[words]",
	userWords: "[userWords]",
	flagWords: "[flagWords]",
	ignoreWords: "[ignoreWords]",
	suggestWords: "[suggestWords]"
};
const mapSpecialDictionaryNamesToSettings = new Map(Object.entries(specialDictionaryNames).map(([k, v]) => [v, k]));
function getInlineConfigDictionaries(settings) {
	const { words = emptyWords, userWords = emptyWords, flagWords = emptyWords, ignoreWords = emptyWords, suggestWords = emptyWords } = settings;
	return [
		createSpellingDictionary(words, specialDictionaryNames.words, "From Settings `words`", {
			caseSensitive: true,
			weightMap: void 0
		}),
		userWords.length ? createSpellingDictionary(userWords, specialDictionaryNames.userWords, "From Settings `userWords`", {
			caseSensitive: true,
			weightMap: void 0
		}) : void 0,
		createIgnoreWordsDictionary(ignoreWords, specialDictionaryNames.ignoreWords, "From Settings `ignoreWords`"),
		createFlagWordsDictionary(flagWords, specialDictionaryNames.flagWords, "From Settings `flagWords`"),
		createSuggestDictionary(suggestWords, "[suggestWords]", "From Settings `suggestWords`")
	].filter(isDefined$2);
}
function _getDictionaryInternal(settings, spellDictionaries) {
	return createCollection([...spellDictionaries, ...getInlineConfigDictionaries(settings)], "dictionary collection");
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+filetypes@9.6.4/node_modules/@cspell/filetypes/dist/definitions.js
const definitions = [
	{
		id: "ada",
		extensions: [".adb", ".ads"]
	},
	{
		id: "apiblueprint",
		extensions: [".apib", ".apiblueprint"]
	},
	{
		id: "argdown",
		extensions: [
			".ad",
			".adown",
			".argdn",
			".argdown"
		]
	},
	{
		id: "asciidoc",
		extensions: [
			".adoc",
			".asc",
			".asciidoc"
		]
	},
	{
		id: "bat",
		extensions: [".bat", ".cmd"]
	},
	{
		id: "bazel",
		extensions: [".bazel", ".bzl"]
	},
	{
		id: "bibtex",
		extensions: [".bib"]
	},
	{
		id: "bicep",
		extensions: [".bicep"]
	},
	{
		id: "c",
		extensions: [".c", ".i"]
	},
	{
		id: "cache_files",
		extensions: [],
		filenames: [
			".DS_Store",
			".cspellcache",
			".eslintcache"
		]
	},
	{
		id: "clojure",
		extensions: [
			".clj",
			".cljc",
			".cljs",
			".cljx",
			".clojure",
			".edn"
		]
	},
	{
		id: "cmake",
		extensions: [".cmake"],
		filenames: ["CMakeLists.txt"]
	},
	{
		id: "codeowners",
		extensions: [],
		filenames: ["codeowners"]
	},
	{
		id: "coffeescript",
		extensions: [
			".coffee",
			".cson",
			".iced"
		]
	},
	{
		id: "cpp",
		extensions: [
			".c++",
			".c++m",
			".cc",
			".ccm",
			".cpp",
			".cppm",
			".cxx",
			".cxxm",
			".h",
			".h++",
			".h.in",
			".hh",
			".hpp",
			".hpp.in",
			".hxx",
			".ii",
			".inl",
			".ino",
			".ipp",
			".ixx",
			".mm",
			".tpp",
			".txx"
		]
	},
	{
		id: "cpp_embedded_latex",
		extensions: []
	},
	{
		id: "csharp",
		extensions: [
			".cake",
			".cs",
			".csx"
		]
	},
	{
		id: "css",
		extensions: [".css"]
	},
	{
		id: "cuda-cpp",
		extensions: [".cu", ".cuh"]
	},
	{
		id: "dart",
		extensions: [".dart"]
	},
	{
		id: "dhall",
		extensions: [".dhall"]
	},
	{
		id: "diff",
		extensions: [
			".diff",
			".patch",
			".rej"
		]
	},
	{
		id: "dockercompose",
		extensions: [],
		filenames: [
			"*docker*compose*.yaml",
			"*docker*compose*.yml",
			"compose.*.yaml",
			"compose.*.yml",
			"compose.yaml",
			"compose.yml"
		]
	},
	{
		id: "dockerfile",
		extensions: [".containerfile", ".dockerfile"],
		filenames: [
			"*.Dockerfile.*",
			"Containerfile",
			"Containerfile.*",
			"Dockerfile",
			"Dockerfile.*",
			"Dockerfile.dev",
			"dockerfile"
		]
	},
	{
		id: "elisp",
		extensions: [".el"]
	},
	{
		id: "elixir",
		extensions: [".ex", ".exs"]
	},
	{
		id: "elm",
		extensions: [".elm"]
	},
	{
		id: "erb",
		extensions: [
			".erb",
			".html.erb",
			".rhtml"
		]
	},
	{
		id: "fsharp",
		extensions: [
			".fs",
			".fsi",
			".fsscript",
			".fsx"
		]
	},
	{
		id: "git-commit",
		extensions: [],
		filenames: ["COMMIT_EDITMSG", "MERGE_MSG"]
	},
	{
		id: "git-rebase",
		extensions: [],
		filenames: ["git-rebase-todo"]
	},
	{
		id: "github-issues",
		extensions: [".github-issues"]
	},
	{
		id: "go",
		extensions: [".go"]
	},
	{
		id: "godot",
		extensions: [
			".gd",
			".godot",
			".tres",
			".tscn"
		]
	},
	{
		id: "gradle",
		extensions: [".gradle"]
	},
	{
		id: "groovy",
		extensions: [
			".gradle",
			".groovy",
			".gvy",
			".jenkinsfile",
			".nf"
		],
		filenames: ["Jenkinsfile", "Jenkinsfile*"]
	},
	{
		id: "haml",
		extensions: [".haml"]
	},
	{
		id: "handlebars",
		extensions: [
			".handlebars",
			".hbs",
			".hjs"
		]
	},
	{
		id: "haskell",
		extensions: [".hs", ".lhs"]
	},
	{
		id: "haxe",
		extensions: [".hx"]
	},
	{
		id: "hlsl",
		extensions: [
			".cginc",
			".compute",
			".fx",
			".fxh",
			".hlsl",
			".hlsli",
			".psh",
			".vsh"
		]
	},
	{
		id: "html",
		extensions: [
			".asp",
			".aspx",
			".ejs",
			".htm",
			".html",
			".jshtm",
			".jsp",
			".mdoc",
			".rhtml",
			".shtml",
			".volt",
			".vue",
			".xht",
			".xhtml"
		]
	},
	{
		id: "ignore",
		extensions: [
			".git-blame-ignore-revs",
			".gitignore",
			".gitignore_global",
			".npmignore"
		],
		filenames: [".*ignore"]
	},
	{
		id: "ini",
		extensions: [".conf", ".ini"]
	},
	{
		id: "jade",
		extensions: [".jade", ".pug"]
	},
	{
		id: "java",
		extensions: [".jav", ".java"]
	},
	{
		id: "javascript",
		extensions: [
			".cjs",
			".es6",
			".js",
			".mjs",
			".pac"
		],
		filenames: ["jakefile"]
	},
	{
		id: "javascriptreact",
		extensions: [".jsx"]
	},
	{
		id: "jinja",
		extensions: [
			".j2",
			".jinja",
			".jinja2"
		]
	},
	{
		id: "json",
		extensions: [
			".babelrc",
			".bowerrc",
			".code-profile",
			".css.map",
			".eslintrc",
			".geojson",
			".har",
			".ipynb",
			".js.map",
			".jscsrc",
			".jshintrc",
			".jslintrc",
			".json",
			".jsonc",
			".jsonld",
			".ts.map",
			".tsbuildinfo",
			".vuerc",
			".webmanifest"
		],
		filenames: [".watchmanconfig", "composer.lock"]
	},
	{
		id: "jsonc",
		extensions: [
			".babelrc",
			".code-workspace",
			".color-theme.json",
			".eslintrc",
			".eslintrc.json",
			".hintrc",
			".icon-theme.json",
			".jsfmtrc",
			".jshintrc",
			".jsonc",
			".language-configuration.json",
			".swcrc"
		],
		filenames: [
			".babelrc.json",
			".code-workspace",
			".devcontainer.json",
			".ember-cli",
			"argv.json",
			"babel.config.json",
			"devcontainer.json",
			"extensions.json",
			"jsconfig-*.json",
			"jsconfig.*.json",
			"jsconfig.json",
			"keybindings.json",
			"launch.json",
			"profiles.json",
			"settings.json",
			"tasks.json",
			"tsconfig-*.json",
			"tsconfig.*.json",
			"tsconfig.json",
			"typedoc.json"
		]
	},
	{
		id: "jsonl",
		extensions: [".jsonl"]
	},
	{
		id: "jsx-tags",
		extensions: []
	},
	{
		id: "julia",
		extensions: [".jl"]
	},
	{
		id: "juliamarkdown",
		extensions: [".jmd"]
	},
	{
		id: "jungle",
		extensions: [".jungle"]
	},
	{
		id: "kotlin",
		extensions: [".kt"]
	},
	{
		id: "latex",
		extensions: [
			".ctx",
			".ltx",
			".tex"
		]
	},
	{
		id: "less",
		extensions: [".less"]
	},
	{
		id: "lisp",
		extensions: [
			".fasl",
			".l",
			".lisp",
			".lsp"
		]
	},
	{
		id: "literate haskell",
		extensions: [".lhs"]
	},
	{
		id: "lock",
		extensions: [".lock"],
		filenames: [
			"Cargo.lock",
			"berksfile.lock",
			"composer.lock",
			"package-lock.json"
		]
	},
	{
		id: "log",
		extensions: [".log"],
		filenames: ["*.log.?"]
	},
	{
		id: "lua",
		extensions: [".lua"]
	},
	{
		id: "makefile",
		extensions: [".mak", ".mk"],
		filenames: [
			"GNUmakefile",
			"Makefile",
			"OCamlMakefile",
			"makefile"
		]
	},
	{
		id: "map",
		extensions: [
			".map",
			".css.map",
			".ts.map",
			".js.map"
		]
	},
	{
		id: "markdown",
		extensions: [
			".markdn",
			".markdown",
			".md",
			".mdown",
			".mdtext",
			".mdtxt",
			".mdwn",
			".mkd",
			".workbook"
		]
	},
	{
		id: "markdown_latex_combined",
		extensions: []
	},
	{
		id: "markdown-math",
		extensions: []
	},
	{
		id: "mdx",
		extensions: [".mdx"]
	},
	{
		id: "monkeyc",
		extensions: [".mb", ".mc"]
	},
	{
		id: "mustache",
		extensions: [
			".mst",
			".mu",
			".mustache",
			".stache"
		]
	},
	{
		id: "nix",
		extensions: [".nix"]
	},
	{
		id: "nunjucks",
		extensions: [
			".nj",
			".njk",
			".nunj",
			".nunjs",
			".nunjucks",
			".tmpl",
			".tpl"
		]
	},
	{
		id: "objective-c",
		extensions: [".m"]
	},
	{
		id: "objective-cpp",
		extensions: [".mm"]
	},
	{
		id: "ocaml",
		extensions: [
			".eliom",
			".eliomi",
			".ml",
			".mli",
			".mll",
			".mly"
		]
	},
	{
		id: "pdf",
		extensions: [".pdf"]
	},
	{
		id: "pem",
		extensions: [".pem", ".private-key.pem"]
	},
	{
		id: "pem-private-key",
		extensions: [".private-key.pem"]
	},
	{
		id: "perl",
		extensions: [
			".PL",
			".pl",
			".pm",
			".pod",
			".psgi",
			".t"
		]
	},
	{
		id: "perl6",
		extensions: [
			".nqp",
			".p6",
			".pl6",
			".pm6"
		]
	},
	{
		id: "php",
		extensions: [
			".ctp",
			".php",
			".php4",
			".php5",
			".phtml"
		]
	},
	{
		id: "plaintext",
		extensions: [".txt"]
	},
	{
		id: "powershell",
		extensions: [
			".ps1",
			".psd1",
			".psm1",
			".psrc",
			".pssc"
		]
	},
	{
		id: "properties",
		extensions: [
			".cfg",
			".conf",
			".directory",
			".editorconfig",
			".gitattributes",
			".gitconfig",
			".gitmodules",
			".npmrc",
			".properties",
			".repo"
		],
		filenames: [".env", "gitconfig"]
	},
	{
		id: "protobuf",
		extensions: [
			".proto",
			".txtpb",
			".textproto",
			".textpb",
			".pbtxt"
		]
	},
	{
		id: "puppet",
		extensions: [".puppet"]
	},
	{
		id: "purescript",
		extensions: [".purs"]
	},
	{
		id: "python",
		extensions: [
			".cpy",
			".gyp",
			".gypi",
			".ipy",
			".py",
			".pyi",
			".pyt",
			".pyw",
			".rpy"
		],
		filenames: ["SConscript", "SConstruct"]
	},
	{
		id: "r",
		extensions: [
			".R",
			".r",
			".rhistory",
			".rprofile",
			".rt"
		]
	},
	{
		id: "raku",
		extensions: [
			".nqp",
			".p6",
			".pl6",
			".pm6",
			".raku",
			".rakudoc",
			".rakumod",
			".rakutest"
		]
	},
	{
		id: "razor",
		extensions: [".cshtml", ".razor"]
	},
	{
		id: "rescript",
		extensions: [".res", ".resi"]
	},
	{
		id: "restructuredtext",
		extensions: [".rst"]
	},
	{
		id: "rsa",
		extensions: [".pub"],
		filenames: ["id_rsa", "id_rsa.pub"]
	},
	{
		id: "ruby",
		extensions: [
			".erb",
			".gemspec",
			".podspec",
			".rake",
			".rb",
			".rbi",
			".rbx",
			".rjs",
			".ru"
		],
		filenames: [
			"Gemfile",
			"appfile",
			"appraisals",
			"berksfile",
			"berksfile.lock",
			"brewfile",
			"capfile",
			"cheffile",
			"dangerfile",
			"deliverfile",
			"fastfile",
			"gemfile",
			"guardfile",
			"gymfile",
			"hobofile",
			"matchfile",
			"podfile",
			"puppetfile",
			"rakefile",
			"rantfile",
			"scanfile",
			"snapfile",
			"thorfile",
			"vagrantfile"
		]
	},
	{
		id: "rust",
		extensions: [".rs"]
	},
	{
		id: "sass",
		extensions: [".sass"]
	},
	{
		id: "scala",
		extensions: [
			".sbt",
			".sc",
			".scala"
		]
	},
	{
		id: "scss",
		extensions: [".scss"]
	},
	{
		id: "search-result",
		extensions: [".code-search"]
	},
	{
		id: "shaderlab",
		extensions: [".cginc", ".shader"]
	},
	{
		id: "shellscript",
		extensions: [
			".Xsession",
			".bash",
			".bash_aliases",
			".bash_login",
			".bash_logout",
			".bash_profile",
			".bashrc",
			".csh",
			".cshrc",
			".ebuild",
			".eclass",
			".fish",
			".install",
			".ksh",
			".profile",
			".sh",
			".tcshrc",
			".xprofile",
			".xsession",
			".xsessionrc",
			".yash_profile",
			".yashrc",
			".zlogin",
			".zlogout",
			".zprofile",
			".zsh",
			".zsh-theme",
			".zshenv",
			".zshrc"
		],
		filenames: [
			".env.*",
			".envrc",
			".hushlogin",
			"APKBUILD",
			"PKGBUILD",
			"bashrc_Apple_Terminal",
			"zlogin",
			"zlogout",
			"zprofile",
			"zshenv",
			"zshrc",
			"zshrc_Apple_Terminal"
		]
	},
	{
		id: "snippets",
		extensions: [".code-snippets"]
	},
	{
		id: "sql",
		extensions: [".dsql", ".sql"]
	},
	{
		id: "stylus",
		extensions: [".styl"]
	},
	{
		id: "svelte",
		extensions: [".svelte"]
	},
	{
		id: "swift",
		extensions: [".swift"]
	},
	{
		id: "terraform",
		extensions: [
			".hcl",
			".tf",
			".tf.json",
			".tfvars"
		]
	},
	{
		id: "tex",
		extensions: [
			".bbx",
			".cbx",
			".cls",
			".sty"
		]
	},
	{
		id: "tfvars",
		extensions: [".tfvars"],
		description: "Terraform Variables"
	},
	{
		id: "todo",
		extensions: [],
		filenames: ["todo"]
	},
	{
		id: "toml",
		extensions: [".toml"],
		filenames: ["Cargo.lock", "Cargo.toml"]
	},
	{
		id: "typescript",
		extensions: [
			".cts",
			".mts",
			".ts"
		]
	},
	{
		id: "typescriptreact",
		extensions: [".tsx"]
	},
	{
		id: "typst",
		extensions: [".typst"]
	},
	{
		id: "vala",
		extensions: [".vala"]
	},
	{
		id: "vb",
		extensions: [
			".bas",
			".brs",
			".vb",
			".vba",
			".vbs"
		]
	},
	{
		id: "vue",
		extensions: [".vue"]
	},
	{
		id: "xml",
		extensions: [
			".ascx",
			".atom",
			".axaml",
			".axml",
			".bpmn",
			".config",
			".cpt",
			".csl",
			".csproj",
			".csproj.user",
			".dita",
			".ditamap",
			".dtd",
			".dtml",
			".ent",
			".fsproj",
			".fxml",
			".iml",
			".isml",
			".jmx",
			".launch",
			".menu",
			".mod",
			".mxml",
			".nuspec",
			".opml",
			".owl",
			".proj",
			".props",
			".pt",
			".publishsettings",
			".pubxml",
			".pubxml.user",
			".rbxlx",
			".rbxmx",
			".rdf",
			".rng",
			".rss",
			".shproj",
			".storyboard",
			".svg",
			".targets",
			".tld",
			".tmx",
			".vbproj",
			".vbproj.user",
			".vcxproj",
			".vcxproj.filters",
			".wsdl",
			".wxi",
			".wxl",
			".wxs",
			".xaml",
			".xbl",
			".xib",
			".xlf",
			".xliff",
			".xml",
			".xoml",
			".xpdl",
			".xsd",
			".xul"
		]
	},
	{
		id: "xsl",
		extensions: [".xsl", ".xslt"]
	},
	{
		id: "yaml",
		extensions: [
			".cff",
			".eyaml",
			".eyml",
			".yaml",
			".yaml-tmlanguage",
			".yaml-tmpreferences",
			".yaml-tmtheme",
			".yml"
		]
	},
	{
		id: "binary",
		extensions: [
			".bin",
			".cur",
			".dll",
			".eot",
			".exe",
			".gz",
			".lib",
			".o",
			".obj",
			".phar",
			".zip"
		],
		format: "Binary"
	},
	{
		id: "dll",
		extensions: [".dll"],
		format: "Binary"
	},
	{
		id: "exe",
		extensions: [".exe"],
		format: "Binary"
	},
	{
		id: "fonts",
		extensions: [
			".ttf",
			".woff",
			".woff2"
		],
		format: "Binary"
	},
	{
		id: "gzip",
		extensions: [".gz"],
		format: "Binary"
	},
	{
		id: "image",
		extensions: [
			".bmp",
			".exr",
			".gif",
			".heic",
			".ico",
			".jpeg",
			".jpg",
			".pbm",
			".pgm",
			".png",
			".ppm",
			".ras",
			".sgi",
			".tiff",
			".webp",
			".xbm"
		],
		format: "Binary",
		description: "Some image extensions"
	},
	{
		id: "jar",
		extensions: [".jar"],
		format: "Binary"
	},
	{
		id: "mdb",
		extensions: [".mdb"],
		format: "Binary",
		description: "Microsoft Access DB"
	},
	{
		id: "object-file",
		extensions: [".o", ".obj"],
		format: "Binary"
	},
	{
		id: "spv",
		extensions: [".spv"],
		format: "Binary",
		description: "SPSS Output Document"
	},
	{
		id: "trie",
		extensions: [".trie"],
		format: "Binary",
		description: "CSpell dictionary file."
	},
	{
		id: "video",
		extensions: [
			".avi",
			".flv",
			".mkv",
			".mov",
			".mp4",
			".mpeg",
			".mpg",
			".wmv"
		],
		format: "Binary"
	},
	{
		id: "webm",
		extensions: [".webm"],
		format: "Binary",
		description: "WebM is an audiovisual media file format."
	},
	{
		id: "wheel",
		extensions: [".whl"],
		format: "Binary"
	},
	{
		id: "zig",
		extensions: [".zig"],
		description: "Zig programming language"
	},
	{
		id: "zon",
		extensions: [".zon"],
		description: "Zig programming language package file"
	}
];

//#endregion
//#region ../node_modules/.pnpm/@cspell+filetypes@9.6.4/node_modules/@cspell/filetypes/dist/filetypes.js
const binaryFormatIds = definitions.filter((d) => d.format === "Binary").map((d) => d.id);
const binaryLanguages = new Set([
	"binary",
	"image",
	"video",
	"fonts",
	...binaryFormatIds
]);
const generatedFiles = new Set([
	...binaryLanguages,
	"map",
	"lock",
	"pdf",
	"cache_files",
	"rsa",
	"pem",
	"trie",
	"log"
]);
const languageIds = definitions.map(({ id }) => id);
const mapExtensionToLanguageIds = buildExtensionToLanguageIdMap(buildLanguageExtensionMapSet(definitions));
const idsWithRegExp = definitions.map(defToRegExp).filter((f) => !!f);
/**
* Check if a file type is auto generated. Generated files are files that are not typically edited by a human.
* Example:
* - package-lock.json
* @param fileTypeId - the file type id to check
* @returns true if the file type known to be generated.
*/
function isFileTypeGenerated(fileTypeId) {
	return doesSetContainAnyOf(generatedFiles, fileTypeId);
}
function doesSetContainAnyOf(setOfIds, fileTypeId) {
	if (typeof fileTypeId === "string") return setOfIds.has(fileTypeId);
	for (const id of fileTypeId) if (setOfIds.has(id)) return true;
	return false;
}
function buildLanguageExtensionMapSet(defs) {
	return defs.reduce((map, def) => {
		function addId(value) {
			autoResolve(map, value, () => /* @__PURE__ */ new Set()).add(def.id);
		}
		def.extensions.forEach(addId);
		def.filenames?.forEach((filename) => typeof filename === "string" ? addId(filename) : void 0);
		return map;
	}, /* @__PURE__ */ new Map());
}
function buildExtensionToLanguageIdMap(map) {
	return new Map([...map].map(([k, s]) => [k, [...s]]));
}
function matchPatternsToFilename(basename) {
	return idsWithRegExp.filter(({ regexp }) => regexp.test(basename)).map(({ id }) => id);
}
function _getLanguagesForBasename(basename) {
	const found = mapExtensionToLanguageIds.get(basename);
	if (found) return found;
	const patternMatches = matchPatternsToFilename(basename);
	if (patternMatches.length) return patternMatches;
	for (let pos = basename.indexOf("."); pos >= 0; pos = basename.indexOf(".", pos + 1)) {
		const ids = mapExtensionToLanguageIds.get(basename.slice(pos));
		if (ids) return ids;
	}
}
/**
* Find the matching file types for a given filename.
* @param filename - the full filename
* @returns an array of language ids that match the filename. The array is empty if no matches are found.
*/
function findMatchingFileTypes(filename) {
	filename = basename$2(filename);
	return _getLanguagesForBasename(filename) || _getLanguagesForBasename(filename.toLowerCase()) || [];
}
const regExpPathSep = /[\\/]/g;
function basename$2(filename) {
	return regExpPathSep.test(filename) ? filename.split(regExpPathSep).slice(-1).join("") : filename;
}
function autoResolve(map, key, resolve) {
	const found = map.get(key);
	if (found !== void 0 || map.has(key)) return found;
	const value = resolve(key);
	map.set(key, value);
	return value;
}
function escapeRegEx$1(s) {
	return s.replaceAll(/[|\\{}()[\]^$+*?.]/g, "\\$&").replaceAll("-", "\\x2d");
}
function stringOrGlob(s) {
	return s.includes("*") ? simpleGlob(s) : s;
}
function simpleGlob(s) {
	s = s.replaceAll("**", "*");
	let pattern = "";
	for (const char of s) switch (char) {
		case "?":
			pattern += ".";
			break;
		case "*":
			pattern += ".*";
			break;
		default: pattern += escapeRegEx$1(char);
	}
	return new RegExp(pattern);
}
function defToRegExp(def) {
	if (!def.filenames) return void 0;
	const regExps = def.filenames.map(stringOrGlob).map((f) => f instanceof RegExp ? f : void 0).filter((f) => !!f);
	if (!regExps.length) return void 0;
	return {
		regexp: new RegExp(regExps.map((r) => r.source).join("|")),
		id: def.id
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/Uri.js
const STDIN_PROTOCOL = "stdin:";
function toUri(uriOrFile) {
	if (UriImpl.isUri(uriOrFile)) return uriOrFile;
	if (URI.isUri(uriOrFile)) return UriImpl.from(uriOrFile);
	if (uriOrFile instanceof URL) return UriImpl.parse(uriOrFile.toString());
	if (isHRef(uriOrFile)) return UriImpl.parse(uriOrFile.href);
	if (isUri(uriOrFile)) return UriImpl.from(uriOrFile);
	if (isUrlLike(uriOrFile)) return UriImpl.parse(uriOrFile);
	return UriImpl.file(normalizeDriveLetter(uriOrFile));
}
const isWindows = process.platform === "win32";
const hasDriveLetter = /^[a-zA-Z]:[\\/]/;
const rootUrl = toFileDirURL("/");
function uriToFilePath(uri) {
	let url = documentUriToURL(uri);
	url = url.protocol === "stdin:" ? new URL(url.pathname, rootUrl) : url;
	return toFilePathOrHref(url);
}
function normalizeDriveLetter(path) {
	return hasDriveLetter.test(path) ? path[0].toUpperCase() + path.slice(1) : path;
}
function isHRef(url) {
	return !!url && typeof url === "object" && typeof url.href === "string" || false;
}
function isUri(uri) {
	if (!uri || typeof uri !== "object") return false;
	if (UriImpl.isUri(uri)) return true;
	if (URI.isUri(uri)) return true;
	const u = uri;
	return typeof u.path === "string" && typeof u.scheme === "string";
}
function basename$1(uri) {
	return Utils.basename(URI.from(uri));
}
function uriFrom(uri, ...parts) {
	return UriImpl.from(uri, ...parts);
}
const keys$1 = [
	"scheme",
	"authority",
	"path",
	"query",
	"fragment"
];
var UriImpl = class UriImpl extends URI {
	constructor(uri) {
		super(uri.scheme, uri.authority, uri.path, uri.query, uri.fragment);
	}
	toString() {
		const path = encodeURI(this.path || "").replaceAll(/[#?]/g, (c) => `%${(c.codePointAt(0) || 0).toString(16)}`);
		const base = `${this.scheme}://${this.authority || ""}${path}`;
		const query = this.query && `?${this.query}` || "";
		const fragment = this.fragment && `#${this.fragment}` || "";
		return base + query + fragment;
	}
	toJSON() {
		const { scheme, authority, path, query, fragment } = this;
		return {
			scheme,
			authority,
			path,
			query,
			fragment
		};
	}
	with(change) {
		const { scheme, authority, path, query, fragment } = this;
		const u = {
			scheme,
			authority,
			path,
			query,
			fragment
		};
		for (const key of keys$1) if (change[key] && typeof change[key] === "string") u[key] = change[key];
		return new UriImpl(u);
	}
	static isUri(uri) {
		return uri instanceof UriImpl;
	}
	static from(uri, ...parts) {
		let u = new UriImpl(uri);
		for (const part of parts) u = u.with(part);
		return u;
	}
	static parse(uri) {
		if (uri.startsWith(STDIN_PROTOCOL)) return UriImpl.from(parseStdinUri(uri));
		const u = URI.parse(uri);
		return UriImpl.from(u);
	}
	static file(filename) {
		if (!isWindows && hasDriveLetter.test(filename)) filename = "/" + filename.replaceAll("\\", "/");
		const url = toFileURL(filename);
		return UriImpl.parse(url.href);
	}
	static stdin(filePath = "") {
		return UriImpl.from(UriImpl.file(filePath), { scheme: "stdin" });
	}
};
function normalizeFilePath(path) {
	return normalizeDriveLetter(path.replaceAll("\\", "/"));
}
function parseStdinUri(uri) {
	assert(uri.startsWith(STDIN_PROTOCOL));
	const idxSlash = 6;
	let idxSlashEnd = idxSlash;
	for (; uri[idxSlashEnd] === "/"; ++idxSlashEnd);
	const pathStart = idxSlashEnd;
	const iH = uri.indexOf("#", pathStart);
	const idxHash = iH > 0 ? iH : uri.length;
	const iQ = uri.indexOf("?", pathStart);
	const idxQ = iQ > 0 && iQ < idxHash ? iQ : idxHash;
	const pathEnd = idxQ;
	const path = uri.slice(pathStart, pathEnd);
	const query = idxQ < idxHash ? uri.slice(idxQ + 1, idxHash) : "";
	const hash = uri.slice(idxHash + 1);
	return {
		scheme: "stdin",
		path: (idxSlashEnd - idxSlash > 2 ? "/" : "") + normalizeFilePath(decodeURI(path)),
		query: decodeURI(query),
		fragment: decodeURI(hash)
	};
}
function documentUriToURL(uri) {
	return toURL$2(uri instanceof URL ? uri : typeof uri === "string" ? toFileURL(uri) : new URL(uriFrom(uri).toString()));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Document/normalizeLanguageIds.js
function normalizeLanguageIds(languageId) {
	return (Array.isArray(languageId) ? languageId.join(",") : languageId).split(",").map((s) => s.trim());
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Document/isBinaryDoc.js
function isBinaryDoc(document) {
	return isBinaryFile(toUri(document.uri), document.languageId, document.text);
}
function isBinaryFile(filename, languageId, text) {
	const filenameUri = toUri(filename);
	if (languageId) {
		const ids = normalizeLanguageIds(languageId);
		if (ids.length) return isFileTypeGenerated(ids);
	}
	const ids = findMatchingFileTypes(basename$1(filenameUri));
	if (ids.length) return isFileTypeGenerated(ids);
	return text?.slice(0, 1024).includes("\0") || false;
}

//#endregion
//#region ../node_modules/.pnpm/vscode-languageserver-textdocument@1.0.12/node_modules/vscode-languageserver-textdocument/lib/esm/main.js
var FullTextDocument = class FullTextDocument {
	constructor(uri, languageId, version, content) {
		this._uri = uri;
		this._languageId = languageId;
		this._version = version;
		this._content = content;
		this._lineOffsets = void 0;
	}
	get uri() {
		return this._uri;
	}
	get languageId() {
		return this._languageId;
	}
	get version() {
		return this._version;
	}
	getText(range) {
		if (range) {
			const start = this.offsetAt(range.start);
			const end = this.offsetAt(range.end);
			return this._content.substring(start, end);
		}
		return this._content;
	}
	update(changes, version) {
		for (const change of changes) if (FullTextDocument.isIncremental(change)) {
			const range = getWellformedRange(change.range);
			const startOffset = this.offsetAt(range.start);
			const endOffset = this.offsetAt(range.end);
			this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);
			const startLine = Math.max(range.start.line, 0);
			const endLine = Math.max(range.end.line, 0);
			let lineOffsets = this._lineOffsets;
			const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);
			if (endLine - startLine === addedLineOffsets.length) for (let i = 0, len = addedLineOffsets.length; i < len; i++) lineOffsets[i + startLine + 1] = addedLineOffsets[i];
			else if (addedLineOffsets.length < 1e4) lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);
			else this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));
			const diff = change.text.length - (endOffset - startOffset);
			if (diff !== 0) for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) lineOffsets[i] = lineOffsets[i] + diff;
		} else if (FullTextDocument.isFull(change)) {
			this._content = change.text;
			this._lineOffsets = void 0;
		} else throw new Error("Unknown change event received");
		this._version = version;
	}
	getLineOffsets() {
		if (this._lineOffsets === void 0) this._lineOffsets = computeLineOffsets(this._content, true);
		return this._lineOffsets;
	}
	positionAt(offset) {
		offset = Math.max(Math.min(offset, this._content.length), 0);
		const lineOffsets = this.getLineOffsets();
		let low = 0, high = lineOffsets.length;
		if (high === 0) return {
			line: 0,
			character: offset
		};
		while (low < high) {
			const mid = Math.floor((low + high) / 2);
			if (lineOffsets[mid] > offset) high = mid;
			else low = mid + 1;
		}
		const line = low - 1;
		offset = this.ensureBeforeEOL(offset, lineOffsets[line]);
		return {
			line,
			character: offset - lineOffsets[line]
		};
	}
	offsetAt(position) {
		const lineOffsets = this.getLineOffsets();
		if (position.line >= lineOffsets.length) return this._content.length;
		else if (position.line < 0) return 0;
		const lineOffset = lineOffsets[position.line];
		if (position.character <= 0) return lineOffset;
		const nextLineOffset = position.line + 1 < lineOffsets.length ? lineOffsets[position.line + 1] : this._content.length;
		const offset = Math.min(lineOffset + position.character, nextLineOffset);
		return this.ensureBeforeEOL(offset, lineOffset);
	}
	ensureBeforeEOL(offset, lineOffset) {
		while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) offset--;
		return offset;
	}
	get lineCount() {
		return this.getLineOffsets().length;
	}
	static isIncremental(event) {
		const candidate = event;
		return candidate !== void 0 && candidate !== null && typeof candidate.text === "string" && candidate.range !== void 0 && (candidate.rangeLength === void 0 || typeof candidate.rangeLength === "number");
	}
	static isFull(event) {
		const candidate = event;
		return candidate !== void 0 && candidate !== null && typeof candidate.text === "string" && candidate.range === void 0 && candidate.rangeLength === void 0;
	}
};
var TextDocument;
(function(TextDocument) {
	/**
	* Creates a new text document.
	*
	* @param uri The document's uri.
	* @param languageId  The document's language Id.
	* @param version The document's initial version number.
	* @param content The document's content.
	*/
	function create(uri, languageId, version, content) {
		return new FullTextDocument(uri, languageId, version, content);
	}
	TextDocument.create = create;
	/**
	* Updates a TextDocument by modifying its content.
	*
	* @param document the document to update. Only documents created by TextDocument.create are valid inputs.
	* @param changes the changes to apply to the document.
	* @param version the changes version for the document.
	* @returns The updated TextDocument. Note: That's the same document instance passed in as first parameter.
	*
	*/
	function update(document, changes, version) {
		if (document instanceof FullTextDocument) {
			document.update(changes, version);
			return document;
		} else throw new Error("TextDocument.update: document must be created by TextDocument.create");
	}
	TextDocument.update = update;
	function applyEdits(document, edits) {
		const text = document.getText();
		const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {
			const diff = a.range.start.line - b.range.start.line;
			if (diff === 0) return a.range.start.character - b.range.start.character;
			return diff;
		});
		let lastModifiedOffset = 0;
		const spans = [];
		for (const e of sortedEdits) {
			const startOffset = document.offsetAt(e.range.start);
			if (startOffset < lastModifiedOffset) throw new Error("Overlapping edit");
			else if (startOffset > lastModifiedOffset) spans.push(text.substring(lastModifiedOffset, startOffset));
			if (e.newText.length) spans.push(e.newText);
			lastModifiedOffset = document.offsetAt(e.range.end);
		}
		spans.push(text.substr(lastModifiedOffset));
		return spans.join("");
	}
	TextDocument.applyEdits = applyEdits;
})(TextDocument || (TextDocument = {}));
function mergeSort(data, compare) {
	if (data.length <= 1) return data;
	const p = data.length / 2 | 0;
	const left = data.slice(0, p);
	const right = data.slice(p);
	mergeSort(left, compare);
	mergeSort(right, compare);
	let leftIdx = 0;
	let rightIdx = 0;
	let i = 0;
	while (leftIdx < left.length && rightIdx < right.length) if (compare(left[leftIdx], right[rightIdx]) <= 0) data[i++] = left[leftIdx++];
	else data[i++] = right[rightIdx++];
	while (leftIdx < left.length) data[i++] = left[leftIdx++];
	while (rightIdx < right.length) data[i++] = right[rightIdx++];
	return data;
}
function computeLineOffsets(text, isAtLineStart, textOffset = 0) {
	const result = isAtLineStart ? [textOffset] : [];
	for (let i = 0; i < text.length; i++) {
		const ch = text.charCodeAt(i);
		if (isEOL(ch)) {
			if (ch === 13 && i + 1 < text.length && text.charCodeAt(i + 1) === 10) i++;
			result.push(textOffset + i + 1);
		}
	}
	return result;
}
function isEOL(char) {
	return char === 13 || char === 10;
}
function getWellformedRange(range) {
	const start = range.start;
	const end = range.end;
	if (start.line > end.line || start.line === end.line && start.character > end.character) return {
		start: end,
		end: start
	};
	return range;
}
function getWellformedEdit(textEdit) {
	const range = getWellformedRange(textEdit.range);
	if (range !== textEdit.range) return {
		newText: textEdit.newText,
		range
	};
	return textEdit;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Models/TextDocument.js
var TextDocumentImpl = class {
	languageId;
	locale;
	vsTextDoc;
	uri;
	constructor(uri, text, languageId, locale, version) {
		this.languageId = languageId;
		this.locale = locale;
		const primaryLanguageId = typeof languageId === "string" ? languageId : languageId[0] || "plaintext";
		this.vsTextDoc = TextDocument.create(uri.toString(), primaryLanguageId, version, text);
		this.uri = documentUriToURL(uri);
	}
	get version() {
		return this.vsTextDoc.version;
	}
	get text() {
		return this.vsTextDoc.getText();
	}
	positionAt(offset) {
		return this.vsTextDoc.positionAt(offset);
	}
	offsetAt(position) {
		return this.vsTextDoc.offsetAt(position);
	}
	lineAt(offset) {
		const position = this.vsTextDoc.positionAt(offset);
		return this.getLine(position.line);
	}
	getLine(lineNum) {
		const position = {
			line: lineNum,
			character: 0
		};
		const range = {
			start: position,
			end: {
				line: lineNum + 1,
				character: 0
			}
		};
		const lineOffset = this.vsTextDoc.offsetAt(position);
		return {
			text: this.vsTextDoc.getText(range),
			offset: lineOffset,
			position
		};
	}
	/**
	* Iterate over the lines of a document one-by-one.
	* Changing the document between iterations can change the result
	*/
	*getLines() {
		const range = {
			start: {
				line: 0,
				character: 0
			},
			end: {
				line: 1,
				character: 0
			}
		};
		while (this.vsTextDoc.offsetAt(range.end) > this.vsTextDoc.offsetAt(range.start)) {
			const offset = this.vsTextDoc.offsetAt(range.start);
			yield {
				text: this.vsTextDoc.getText(range),
				offset,
				position: range.start
			};
			++range.start.line;
			++range.end.line;
		}
	}
	/**
	* Apply edits to the text.
	* Note: the edits are applied one after the other.
	* @param edits - changes to the text
	* @param version - optional version to use.
	* @returns this
	*/
	update(edits, version) {
		version = version ?? this.version + 1;
		for (const edit of edits) {
			const vsEdit = edit.range ? {
				range: {
					start: this.positionAt(edit.range[0]),
					end: this.positionAt(edit.range[1])
				},
				text: edit.text
			} : edit;
			TextDocument.update(this.vsTextDoc, [vsEdit], version);
		}
		return this;
	}
};
function createTextDocument({ uri, content, languageId, locale, version }) {
	version = version ?? 1;
	uri = toUri(uri);
	languageId = languageId ?? findMatchingFileTypes(basename$1(uri));
	languageId = languageId.length === 0 ? "text" : languageId;
	return new TextDocumentImpl(uri, content, languageId, locale, version);
}
function updateTextDocument(doc, edits, version) {
	assert(isTextDocumentImpl(doc), "Unknown TextDocument type");
	return doc.update(edits, version);
}
function isTextDocumentImpl(doc) {
	return doc instanceof TextDocumentImpl;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Document/resolveDocument.js
const defaultEncoding = "utf8";
function fileToDocument(file, text, languageId, locale) {
	return clean$1({
		uri: toUri(file).toString(),
		text,
		languageId,
		locale
	});
}
function documentToTextDocument(document) {
	const { uri, text: content, languageId, locale } = document;
	return createTextDocument({
		uri,
		content,
		languageId,
		locale
	});
}
async function readDocument(filename, encoding = defaultEncoding) {
	const text = await readFile(filename, encoding);
	return {
		uri: toUri(filename).toString(),
		text
	};
}
function resolveDocument(document, encoding) {
	if (isDocumentWithText(document)) return Promise.resolve(document);
	const uri = toUri(document.uri);
	if (uri.scheme !== "file") throw new Error(`Unsupported schema: "${uri.scheme}", open "${uri.toString()}"`);
	return readDocument(uriToFilePath(uri), encoding);
}
function isDocumentWithText(doc) {
	return doc.text !== void 0;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/FeatureFlags/FeatureFlags.js
let systemFeatureFlags;
/**
* Feature Flags are used to turn on/off features.
* These are primarily used before a feature has been fully released.
*/
var FeatureFlags = class {
	flags;
	flagValues = /* @__PURE__ */ new Map();
	constructor(flags = []) {
		this.flags = new Map(flags.map((f) => [f.name, f]));
	}
	register(flagOrName, description) {
		if (typeof flagOrName === "string") return this.register({
			name: flagOrName,
			description: description || ""
		});
		this.flags.set(flagOrName.name, flagOrName);
		return this;
	}
	getFlag(flag) {
		return this.flagValues.get(flag);
	}
	getFlagBool(flag) {
		return toBool(this.getFlag(flag));
	}
	setFlag(flag, value = true) {
		if (!this.flags.has(flag)) throw new UnknownFeatureFlagError(flag);
		this.flagValues.set(flag, value);
		return this;
	}
	getFlagInfo(flag) {
		return this.flags.get(flag);
	}
	getFlags() {
		return [...this.flags.values()];
	}
	getFlagValues() {
		return new Map(this.flagValues);
	}
	reset() {
		this.flagValues.clear();
		return this;
	}
};
var UnknownFeatureFlagError = class extends Error {
	flag;
	constructor(flag) {
		super(`Unknown feature flag: ${flag}`);
		this.flag = flag;
	}
};
function getSystemFeatureFlags() {
	return systemFeatureFlags || (systemFeatureFlags = new FeatureFlags());
}
const boolValues = {
	0: false,
	1: true,
	f: false,
	false: false,
	n: false,
	no: false,
	t: true,
	true: true,
	y: true,
	yes: true
};
function toBool(value) {
	if (typeof value !== "string") return value;
	return boolValues[value.toLowerCase()];
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/search.js
/**
* Search for an item in a sorted array.
* The value returned is either the position of the item or where it should be inserted.
*/
function binarySearch(arr, item, leftOffset, rightOffset) {
	let left = Math.max(leftOffset ?? 0, 0);
	let right = Math.min(rightOffset ?? arr.length, arr.length);
	while (left < right) {
		const pos = left + right >> 1;
		if (arr[pos] < item) left = pos + 1;
		else right = pos;
	}
	return left;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/text.js
function splitWordWithOffset(wo, regExpWordBreaks) {
	return splitWord(wo.text, regExpWordBreaks).map(scanMap((last, text) => ({
		text,
		offset: last.offset + last.text.length
	}), {
		text: "",
		offset: wo.offset
	}));
}
/**
* Split camelCase words into an array of strings.
*/
function splitWord(word, regExpWordBreaks) {
	return word.split(new RegExp(regExpWordBreaks));
}
/**
* This function lets you iterate over regular expression matches.
*/
function match(reg, text) {
	if (!text) return [];
	reg = reg.global ? new RegExp(reg) : new RegExp(reg.source, reg.flags + "g");
	return text.matchAll(reg);
}
function matchToTextOffset(reg, t) {
	const text = t.text;
	const offset = t.offset;
	return pipeSync$1(match(reg, text), opMapSync$1((m) => ({
		text: m[0],
		offset: offset + m.index
	})));
}
/**
* Extract out whole words from a string of text.
*/
function extractWordsFromTextOffset(text) {
	return matchToTextOffset(new RegExp(regExWords), cleanTextOffset(text));
}
/**
* Remove Hiragana, Han, Katakana, Hangul characters from the text.
* @param text
* @returns the text with the characters removed.
*/
function cleanText(text) {
	regExIgnoreCharacters.lastIndex = 0;
	if (!regExIgnoreCharacters.test(text)) return text;
	regExIgnoreCharacters.lastIndex = 0;
	text = text.replace(regExIgnoreCharacters, (match) => " ".repeat(match.length));
	return text;
}
function cleanTextOffset(text) {
	regExIgnoreCharacters.lastIndex = 0;
	if (!regExIgnoreCharacters.test(text.text)) return text;
	return {
		text: cleanText(text.text),
		offset: text.offset
	};
}
/**
* Extract out whole words and words containing numbers from a string of text.
*/
function extractPossibleWordsFromTextOffset(text) {
	return matchToTextOffset(new RegExp(regExWordsAndDigits), text);
}
function extractText(textOffset, startPos, endPos) {
	const { text, offset: orig } = textOffset;
	const a = Math.max(startPos - orig, 0);
	const b = Math.max(endPos - orig, 0);
	return text.slice(a, b);
}
function calculateTextDocumentOffsets(uri, doc, wordOffsets) {
	const lines = [
		-1,
		...pipeSync$1(match(/\n/g, doc), opMapSync$1((a) => a.index)),
		doc.length
	];
	let lastRow = -1;
	let lastOffset = doc.length + 1;
	let lastLineRow = -1;
	let lastLine;
	function findRowCol(offset) {
		const row = binarySearch(lines, offset, offset >= lastOffset ? lastRow : void 0);
		const col = offset - lines[Math.max(0, row - 1)];
		lastOffset = offset;
		lastRow = row;
		return [row, col];
	}
	function extractLine(row) {
		const offset = lines[row - 1] + 1;
		return {
			text: doc.slice(offset, lines[row] + 1),
			offset
		};
	}
	function calcLine(row) {
		const last = lastLineRow === row ? lastLine : void 0;
		lastLineRow = row;
		const r = last ?? extractLine(row);
		lastLine = r;
		return r;
	}
	const _uri = toUri(uri).toString();
	return wordOffsets.map((wo) => {
		const [row, col] = findRowCol(wo.offset);
		return {
			...wo,
			row,
			col,
			doc,
			uri: _uri,
			line: calcLine(row)
		};
	});
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/InDocSettings.js
const regExMatchRegEx = /\/.*\/[gimuy]*/;
const regExCSpellInDocDirective = /\b(?:spell-?checker|c?spell)::?(.*)/gi;
const regExCSpellDirectiveKey = /(?<=\b(?:spell-?checker|c?spell)::?)(?!:)(.*)/i;
const regExInFileSettings = [regExCSpellInDocDirective, /\b(LocalWords:?.*)/g];
const officialDirectives = [
	"enable",
	"disable",
	"disable-line",
	"disable-next",
	"disable-next-line",
	"word",
	"words",
	"ignore",
	"ignoreWord",
	"ignoreWords",
	"ignore-word",
	"ignore-words",
	"includeRegExp",
	"ignoreRegExp",
	"local",
	"locale",
	"language",
	"dictionaries",
	"dictionary",
	"forbid",
	"forbidWord",
	"forbid-word",
	"flag",
	"flagWord",
	"flag-word",
	"enableCompoundWords",
	"enableAllowCompoundWords",
	"disableCompoundWords",
	"disableAllowCompoundWords",
	"enableCaseSensitive",
	"disableCaseSensitive"
];
const noSuggestDirectives = new Set(["local"]);
const allDirectives = new Set([...[
	"enable",
	"disable",
	"disable-line",
	"disable-next-line",
	"words",
	"ignore",
	"forbid",
	"locale",
	"dictionary",
	"dictionaries",
	"enableCaseSensitive",
	"disableCaseSensitive"
], ...officialDirectives]);
const allDirectiveSuggestions = [...pipeSync$1(allDirectives, opMapSync$1((word) => ({ word })))];
const dictInDocSettings = createSpellingDictionary(allDirectives, "Directives", "Directive List", { supportNonStrictSearches: false });
const EmptyWords = [];
Object.freeze(EmptyWords);
const staticInDocumentDictionaryName = `[in-document-dict]`;
function collectInDocumentDirectives(text) {
	return [...getPossibleInDocSettings(text)].flatMap((a) => associateDirectivesWithParsers(a));
}
const baseInDocSettings = { id: "in-doc-settings" };
Object.freeze(baseInDocSettings);
function getInDocumentSettings(text) {
	const found = collectInDocumentDirectives(text);
	if (!found.length) return { ...baseInDocSettings };
	const { words, flagWords, ignoreWords, suggestWords, dictionaries = [], dictionaryDefinitions = [], ...rest } = reducePossibleMatchesToSettings(found, { ...baseInDocSettings });
	const dict = (words || flagWords || ignoreWords || suggestWords) && clean$1({
		name: staticInDocumentDictionaryName,
		words,
		flagWords,
		ignoreWords,
		suggestWords
	});
	const dictSettings = dict ? {
		dictionaries: [...dictionaries, staticInDocumentDictionaryName],
		dictionaryDefinitions: [...dictionaryDefinitions, dict]
	} : clean$1({
		dictionaries: dictionaries.length ? dictionaries : void 0,
		dictionaryDefinitions: dictionaryDefinitions.length ? dictionaryDefinitions : void 0
	});
	return {
		...rest,
		...dictSettings
	};
}
function validateInDocumentSettings(docText, _settings) {
	return pipeSync$1(getPossibleInDocSettings(docText), opMapSync$1(parseSettingMatchValidation), opFilterSync$1(isDefined$2));
}
const settingParsers = [
	[
		/^(?:enable|disable)(?:allow)?CompoundWords\b(?!-)/i,
		parseCompoundWords,
		"CompoundWords"
	],
	[
		/^(?:enable|disable)CaseSensitive\b(?!-)/i,
		parseCaseSensitive,
		"CaseSensitive"
	],
	[
		/^enable\b(?!-)/i,
		parseEnable,
		"Enable"
	],
	[
		/^disable(-line|-next(-line)?)?\b(?!-)/i,
		parseDisable,
		"Disable"
	],
	[
		/^words?\b(?!-)/i,
		parseWords,
		"Words"
	],
	[
		/^ignore(?:-?words?)?\b(?!-)/i,
		parseIgnoreWords,
		"Ignore"
	],
	[
		/^(?:flag|forbid)(?:-?words?)?\b(?!-)/i,
		parseFlagWords,
		"Flag"
	],
	[
		/^ignore_?Reg_?Exp\s+.+$/i,
		parseIgnoreRegExp,
		"IgnoreRegExp"
	],
	[
		/^include_?Reg_?Exp\s+.+$/i,
		parseIncludeRegExp,
		"IncludeRegExp"
	],
	[
		/^locale?\b(?!-)/i,
		parseLocale,
		"Locale"
	],
	[
		/^language\s\b(?!-)/i,
		parseLocale,
		"Locale"
	],
	[
		/^dictionar(?:y|ies)\b(?!-)/i,
		parseDictionaries,
		"Dictionaries"
	],
	[
		/^LocalWords:/,
		(acc, m) => reduceWordList(acc, m.replaceAll(/^LocalWords:?/gi, " "), "words"),
		"Words"
	]
];
const issueMessages = { unknownDirective: "Unknown CSpell directive" };
function parseSettingMatchValidation(possibleMatch) {
	const { fullDirective, offset } = possibleMatch;
	regExCSpellDirectiveKey.lastIndex = 0;
	const directiveMatch = fullDirective.match(regExCSpellDirectiveKey);
	if (!directiveMatch) return void 0;
	const match = directiveMatch[1];
	const possibleSetting = match.trim();
	if (!possibleSetting) return void 0;
	const start = offset + (directiveMatch.index || 0) + (match.length - match.trimStart().length);
	const text = possibleSetting.replace(/^([-\w]+)?.*/, "$1");
	const end = start + text.length;
	if (!text) return void 0;
	if (settingParsers.filter(([regex]) => regex.test(possibleSetting)).length > 0) return void 0;
	const suggestionsEx = [...pipeSync$1(dictInDocSettings.suggest(text, { ignoreCase: false }).map(({ word, isPreferred }) => isPreferred ? {
		word,
		isPreferred
	} : { word }).filter((a) => !noSuggestDirectives.has(a.word)), opAppendSync$1(allDirectiveSuggestions), filterUniqueSuggestions)].slice(0, 8);
	const suggestions = suggestionsEx.map((s) => s.word);
	return {
		range: [start, end],
		text,
		message: issueMessages.unknownDirective,
		suggestions,
		suggestionsEx
	};
}
function* filterUniqueSuggestions(sugs) {
	const map = /* @__PURE__ */ new Map();
	for (const sug of sugs) {
		const existing = map.get(sug.word);
		if (existing && sug.isPreferred) existing.isPreferred = true;
		yield sug;
	}
}
function associateDirectivesWithParsers(possibleMatch) {
	const { match } = possibleMatch;
	const possibleSetting = match.trim();
	return settingParsers.filter(([regex]) => regex.test(possibleSetting)).map(([, fn, directive]) => ({
		...possibleMatch,
		directive,
		fn
	}));
}
function mergeDirectiveIntoSettings(settings, directive) {
	return directive.fn(settings, directive.match);
}
function reducePossibleMatchesToSettings(directives, settings) {
	for (const directive of directives) settings = mergeDirectiveIntoSettings(settings, directive);
	return settings;
}
function parseCompoundWords(acc, match) {
	acc.allowCompoundWords = /enable/i.test(match);
	return acc;
}
function parseCaseSensitive(acc, match) {
	acc.caseSensitive = /enable/i.test(match);
	return acc;
}
function splitWords(match) {
	return match.split(/[,\s;]+/g).slice(1).filter((a) => !!a);
}
function mergeList(a, b) {
	if (!a) return b;
	if (!b) return a;
	return [...a, ...b];
}
function reduceWordList(acc, match, key) {
	const words = splitWords(match);
	if (words.length) acc[key] = mergeList(acc[key], words);
	return acc;
}
function parseWords(acc, match) {
	return reduceWordList(acc, match, "words");
}
function parseLocale(acc, match) {
	const language = match.trim().split(/[\s,]+/).slice(1).join(",");
	if (language) acc.language = language;
	return acc;
}
function parseIgnoreWords(acc, match) {
	return reduceWordList(acc, match, "ignoreWords");
}
function parseFlagWords(acc, match) {
	return reduceWordList(acc, match, "flagWords");
}
function parseRegEx(match) {
	return [match.replace(/^[^\s]+\s+/, "")].map((a) => {
		regExMatchRegEx.lastIndex = 0;
		const m = a.match(regExMatchRegEx);
		if (m && m[0]) return m[0];
		return a.replace(/((?:[^\s]|\\ )+).*/, "$1");
	});
}
function parseIgnoreRegExp(acc, match) {
	const ignoreRegExpList = parseRegEx(match);
	if (ignoreRegExpList.length) acc.ignoreRegExpList = mergeList(acc.ignoreRegExpList, ignoreRegExpList);
	return acc;
}
function parseIncludeRegExp(acc, match) {
	const includeRegExpList = parseRegEx(match);
	if (includeRegExpList.length) acc.includeRegExpList = mergeList(acc.includeRegExpList, includeRegExpList);
	return acc;
}
function parseDictionaries(acc, match) {
	const dictionaries = match.split(/[,\s]+/g).slice(1);
	if (dictionaries.length) acc.dictionaries = mergeList(acc.dictionaries, dictionaries);
	return acc;
}
function getPossibleInDocSettings(text) {
	return pipeSync$1(regExInFileSettings, opMapSync$1((regexp) => match(regexp, text)), opFlattenSync$1(), opMapSync$1((match) => ({
		fullDirective: match[0],
		offset: match.index,
		match: match[1].trim()
	})));
}
function parseEnable(acc, _match) {
	return acc;
}
function parseDisable(acc, _match) {
	return acc;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/TextDocumentSettings.js
function combineTextAndLanguageSettings(settings, text, languageId) {
	if (!text) return toInternalSettings(calcSettingsForLanguageId(settings, languageId));
	const docSettings = extractSettingsFromText(text);
	return mergeSettings(calcSettingsForLanguageId(mergeSettings(settings, docSettings), languageId), docSettings);
}
function extractSettingsFromText(text) {
	return getInDocumentSettings(text);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/clone.js
/**
* Clones the properties from src to dst using the provided handlers.
* @param src
* @param dst
* @param handlers
* @param keys
* @returns
*/
function cloneInto(src, dst, handlers, keys) {
	const keysToProcess = keys || Object.keys(handlers);
	for (const key of keysToProcess) {
		if (src[key] === void 0) continue;
		const handler = handlers[key];
		if (handler === skip) continue;
		handler(src, dst, key);
	}
	return dst;
}
function skip(_src, _dst, _key) {}
/**
* Copy the property from src to dst.
* If the property is undefined, it is not copied.
* @param src - source object
* @param dst - destination object
* @param key - property key
*/
function copy0(src, dst, key) {
	const value = src[key];
	if (value === void 0) return;
	dst[key] = value;
}
/**
* Copy the property from src to dst.
* If the property is undefined, it is not copied.
* If the property is an array, a shallow copy of the array is made.
* If the property is a Set, a shallow copy of the Set is made.
* If the property is a Map, a shallow copy of the Map is made.
* If the property is an object, a shallow copy of the object is made.
* @param src - source object
* @param dst - destination object
* @param key - property key
*/
function copy1(src, dst, key) {
	if (src[key] === void 0) return;
	const value = src[key];
	if (value === void 0) return;
	if (Array.isArray(value)) {
		dst[key] = [...value];
		return;
	}
	if (value instanceof Set) {
		dst[key] = new Set(value);
		return;
	}
	if (value instanceof Map) {
		dst[key] = new Map(value);
		return;
	}
	if (value instanceof RegExp) {
		dst[key] = value;
		return;
	}
	if (typeof value === "object") {
		dst[key] = { ...value };
		return;
	}
	dst[key] = value;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/Settings/sanitizeSettings.js
/**
* Sanitize settings for export by removing any internal only properties.
*
* @param settings - the input settings
*/
function cloneSettingsForExport(settings) {
	const result = {};
	cloneInto(settings, result, getHandlers());
	return result;
}
const handlers = {
	$schema: skip,
	__importRef: copyImportRefField,
	__imports: copyImportsField,
	source: copySourceField,
	id: skip,
	version: skip,
	allowCompoundWords: copy1,
	cache: skip,
	caseSensitive: copy1,
	description: skip,
	dictionaries: copy1,
	dictionaryDefinitions: copyDictionaryDefinitions,
	enabled: copy1,
	enabledLanguageIds: copy1,
	enableFiletypes: copy1,
	enabledFileTypes: copy1,
	enableGlobDot: copy1,
	engines: copy1,
	failFast: copy1,
	features: skip,
	files: copyGlobsSettingsFields,
	flagWords: copy1,
	gitignoreRoot: copy1,
	globRoot: copy1,
	ignorePaths: copyGlobsSettingsFields,
	ignoreRegExpList: copy1,
	ignoreWords: copy1,
	ignoreRandomStrings: copy1,
	import: skip,
	includeRegExpList: copy1,
	language: copy1,
	languageId: copy1,
	languageSettings: copyLanguageSettings,
	loadDefaultConfiguration: copy1,
	maxDuplicateProblems: copy1,
	maxFileSize: copy1,
	maxNumberOfProblems: copy1,
	minWordLength: copy1,
	minRandomLength: copy1,
	name: skip,
	noConfigSearch: copy1,
	noSuggestDictionaries: copy1,
	numSuggestions: copy1,
	overrides: copyOverrides,
	patterns: copyPatternsField,
	pnpFiles: skip,
	readonly: skip,
	reporters: skip,
	showStatus: copy1,
	spellCheckDelayMs: copy1,
	suggestionNumChanges: copy1,
	suggestionsTimeout: copy1,
	suggestWords: copy1,
	unknownWords: copy1,
	useGitignore: copy1,
	usePnP: skip,
	userWords: copy1,
	validateDirectives: copy1,
	vfs: skip,
	words: copy1,
	parser: skip
};
function getHandlers() {
	return handlers;
}
function copyImportRefField(src, dst, key) {
	const ref = src[key];
	if (!ref) return;
	dst[key] = copyImportFileRef(ref);
}
function copyImportsField(src, dst, key) {
	const imports = src[key];
	if (!imports) return;
	dst[key] = new Map([...imports.entries()].map(([k, v]) => [k, copyImportFileRef(v)]));
}
function copyImportFileRef(src) {
	const ref = { filename: src.filename };
	copy0(src, ref, "error");
	return ref;
}
function copySourceField(src, dst, key) {
	if (!src[key]) return;
	dst[key] = copySource(src[key]);
}
function copySource(src) {
	const source = { name: src.name };
	cpy(src, source, "filename");
	return source;
}
function copyGlobsSettingsFields(src, dst, key) {
	const globs = src[key];
	if (!globs) return;
	dst[key] = copyGlobOrGlobs(globs);
}
function copyGlobsOverrideFields(src, dst, key) {
	const globs = src[key];
	if (!globs) return;
	dst[key] = copyGlobOrGlobs(globs);
}
function copyGlobOrGlobs(globOrGlobs) {
	if (Array.isArray(globOrGlobs)) return globOrGlobs.map(copyGlob);
	return copyGlob(globOrGlobs);
}
function copyGlob(glob) {
	if (typeof glob === "string") return glob;
	const g = { glob: glob.glob };
	cpy(glob, g, "root");
	return g;
}
function copyDictionaryDefinitions(src, dst, key) {
	const defs = src[key];
	if (!defs) return;
	dst[key] = defs.map(copyDictionaryDefinition);
}
function copyDictionaryDefinition(src) {
	const def = { name: src.name };
	cpy(src, def, "path");
	cpy(src, def, "type");
	cpy(src, def, "description");
	return def;
}
function copyLanguageSettings(src, dst, key) {
	const langSettings = src[key];
	if (!langSettings) return;
	dst[key] = langSettings.map((src) => {
		const dst = { languageId: src.languageId };
		copyLanguageSetting(src, dst);
		return dst;
	});
}
function cpy(src, dst, key) {
	const value = src[key];
	if (value === void 0) return;
	dst[key] = value;
}
const LanguageSettingsHandlers = {
	id: cpy,
	locale: cpy,
	local: cpy,
	allowCompoundWords: copy1,
	caseSensitive: copy1,
	description: skip,
	dictionaries: copy1,
	dictionaryDefinitions: copyDictionaryDefinitions,
	enabled: copy1,
	flagWords: copy1,
	ignoreRegExpList: copy1,
	ignoreWords: copy1,
	includeRegExpList: copy1,
	languageId: copy1,
	name: skip,
	noSuggestDictionaries: copy1,
	patterns: copyPatternsField,
	suggestWords: copy1,
	unknownWords: copy1,
	words: copy1,
	parser: skip
};
function copyLanguageSetting(src, dst) {
	cloneInto(src, dst, LanguageSettingsHandlers);
}
const RegExpPatternDefinitionHandlers = {
	name: cpy,
	pattern: copy1,
	description: cpy
};
function copyPatternsField(src, dst, key) {
	const patterns = src[key];
	if (!patterns) return;
	dst[key] = patterns.map((p) => {
		const dst = {
			pattern: p.pattern,
			name: p.name
		};
		copyRegExpPatternDefinition(p, dst);
		return dst;
	});
}
function copyRegExpPatternDefinition(src, dst) {
	cloneInto(src, dst, RegExpPatternDefinitionHandlers);
}
const OverridesHandlers = {
	id: copy1,
	allowCompoundWords: copy1,
	caseSensitive: copy1,
	description: copy1,
	dictionaries: copy1,
	dictionaryDefinitions: copyDictionaryDefinitions,
	enabled: copy1,
	enabledFileTypes: copy1,
	enabledLanguageIds: copy1,
	enableFiletypes: copy1,
	filename: copyGlobsOverrideFields,
	flagWords: copy1,
	ignoreRandomStrings: copy1,
	ignoreRegExpList: copy1,
	ignoreWords: copy1,
	includeRegExpList: copy1,
	language: copy1,
	languageId: copy1,
	languageSettings: copyLanguageSettings,
	loadDefaultConfiguration: copy1,
	maxDuplicateProblems: copy1,
	maxFileSize: copy1,
	maxNumberOfProblems: copy1,
	minRandomLength: copy1,
	minWordLength: copy1,
	name: skip,
	noSuggestDictionaries: copy1,
	numSuggestions: copy1,
	patterns: copyPatternsField,
	pnpFiles: skip,
	suggestionNumChanges: copy1,
	suggestionsTimeout: copy1,
	suggestWords: copy1,
	unknownWords: copy1,
	usePnP: skip,
	words: copy1,
	parser: skip
};
function copyOverrides(src, dst, key) {
	const overrides = src[key];
	if (!overrides) return;
	dst[key] = overrides.map((src) => {
		const dst = {};
		cloneInto(src, dst, OverridesHandlers);
		return dst;
	});
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/determineTextDocumentSettings.js
/**
* Combines all relevant setting values into a final configuration to be used for spell checking.
* It applies any overrides and appropriate language settings by taking into account the document type (languageId)
* the locale (natural language) and any in document settings.
*
* Note: this method will not search for configuration files. Configuration files should already be merged into `settings`.
* It is NOT necessary to include the cspell defaultSettings or globalSettings. They will be applied within this function.
* @param document - The document to be spell checked. Note: if the URI doesn't have a path, overrides cannot be applied.
*   `locale` - if defined will be used unless it is overridden by an in-document setting.
*   `languageId` - if defined will be used to select appropriate file type dictionaries.
* @param settings - The near final settings. Should already be the combination of all configuration files.
*/
async function determineTextDocumentSettings(doc, settings) {
	const filename = uriToFilePath(doc.uri);
	const fileSettings = calcOverrideSettings(mergeSettings(await getDefaultSettings(settings.loadDefaultConfiguration ?? true), await getGlobalSettingsAsync(), settings), filename);
	const languageIds = fileSettings?.languageId?.length ? fileSettings.languageId : doc.languageId ? doc.languageId : getLanguageForFilename(filename);
	if (doc.locale) fileSettings.language = doc.locale;
	return combineTextAndLanguageSettings(fileSettings, doc.text, languageIds);
}
function getLanguageForFilename(filename) {
	return findMatchingFileTypes(Path.basename(filename));
}

//#endregion
//#region ../node_modules/.pnpm/@cspell+cspell-types@9.6.4/node_modules/@cspell/cspell-types/dist/index.mjs
let IssueType = /* @__PURE__ */ function(IssueType) {
	IssueType[IssueType["spelling"] = 0] = "spelling";
	IssueType[IssueType["directive"] = 1] = "directive";
	return IssueType;
}({});
const MessageTypes = {
	Debug: "Debug",
	Info: "Info",
	Warning: "Warning"
};
const unknownWordsChoices = {
	ReportAll: "report-all",
	ReportSimple: "report-simple",
	ReportCommonTypos: "report-common-typos",
	ReportFlagged: "report-flagged"
};
const defaultCSpellSettings = {
	ignoreRandomStrings: true,
	minRandomLength: 40
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/memoizeLastCall.js
function memoizeLastCall(fn) {
	let last;
	return (...p) => {
		if (last && isArrayEqual(last.args, p)) return last.value;
		const args = p;
		const value = fn(...args);
		last = {
			args,
			value
		};
		return value;
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/suggestions.js
const emptySuggestionOptions = Object.freeze({});
const emptyCSpellSettings = Object.freeze({});
const memoizeSuggestions = memoizeLastCall(cacheSuggestionsForWord);
function cacheSuggestionsForWord(options, settings) {
	const cache = createAutoResolveCache();
	return (word) => cache.get(word, (word) => _suggestionsForWord(word, options, settings));
}
async function _suggestionsForWord(word, options, settings) {
	const { languageId, locale: language, includeDefaultConfig = true, dictionaries } = options;
	async function determineDictionaries(config) {
		const withLocale = mergeSettings(config, clean$1({ language: language || config.language }));
		const settings = finalizeSettings(calcSettingsForLanguageId(withLocale, languageId ?? withLocale.languageId ?? "plaintext"));
		settings.dictionaries = dictionaries?.length ? dictionaries : settings.dictionaries || [];
		validateDictionaries(settings, dictionaries);
		const dictionaryCollection = await getDictionaryInternal(settings);
		settings.dictionaries = settings.dictionaryDefinitions?.map((def) => def.name) || [];
		return {
			dictionaryCollection,
			allDictionaryCollection: await getDictionaryInternal(settings)
		};
	}
	await refreshDictionaryCache();
	const { dictionaryCollection, allDictionaryCollection } = await determineDictionaries(includeDefaultConfig ? mergeSettings(await getDefaultSettings(settings.loadDefaultConfiguration ?? true), await getGlobalSettingsAsync(), settings) : settings);
	return _suggestionsForWordAsync(word, options, settings, dictionaryCollection, allDictionaryCollection);
}
async function _suggestionsForWordAsync(word, options, settings, dictionaryCollection, allDictionaryCollection) {
	const extendsDictionaryCollection = allDictionaryCollection || dictionaryCollection;
	const { locale: language, strict = true, numChanges = 4, numSuggestions = 8, includeTies = true, includeDefaultConfig = true } = options;
	const ignoreCase = !strict;
	const config = includeDefaultConfig ? mergeSettings(await getDefaultSettings(settings.loadDefaultConfiguration ?? true), await getGlobalSettingsAsync(), settings) : settings;
	const opts = {
		ignoreCase,
		numChanges,
		numSuggestions,
		includeTies
	};
	const suggestionsByDictionary = dictionaryCollection.dictionaries.flatMap((dict) => dict.suggest(word, opts).map((r) => ({
		...r,
		dictName: dict.name
	})));
	const locale = adjustLocale(language || config.language || void 0);
	const collator = Intl.Collator(locale);
	return {
		word,
		suggestions: limitResults(calcSuggestionAdjustedToToMatchCase(word, limitResults(combine(suggestionsByDictionary.sort((a, b) => a.cost - b.cost || collator.compare(a.word, b.word))), numSuggestions, includeTies), locale, ignoreCase, extendsDictionaryCollection).map((sug) => {
			const found = extendsDictionaryCollection.find(sug.word);
			return {
				...sug,
				forbidden: found?.forbidden || false,
				noSuggest: found?.noSuggest || false
			};
		}), numSuggestions, includeTies)
	};
}
function combine(suggestions) {
	const words = /* @__PURE__ */ new Map();
	for (const sug of suggestions) {
		const { word, cost, dictName, ...rest } = sug;
		const f = words.get(word) || {
			word,
			cost,
			...rest,
			dictionaries: []
		};
		f.cost = Math.min(f.cost, cost);
		f.dictionaries.push(dictName);
		f.dictionaries.sort();
		words.set(word, f);
	}
	return [...words.values()];
}
function adjustLocale(locale) {
	if (!locale) return void 0;
	const locales = [...normalizeLocaleIntl(locale)].filter((locale) => isValidLocaleIntlFormat(locale));
	if (!locales.length) return void 0;
	if (locales.length === 1) return locales[0];
	return locales;
}
function calcSuggestionAdjustedToToMatchCase(originalWord, sugs, locale, ignoreCase, dict) {
	locale = adjustLocale(locale);
	const knownSugs = new Set(sugs.map((sug) => sug.word));
	const matchStyle = {
		...analyzeCase(originalWord),
		locale,
		ignoreCase
	};
	return sugs.map((sug) => {
		const alt = matchCase(sug.word, !!sug.isPreferred, matchStyle);
		if (alt === sug.word || knownSugs.has(alt)) return sug;
		const found = dict.find(alt);
		if (!found || !found.forbidden || !found.noSuggest) {
			knownSugs.add(alt);
			return {
				...sug,
				wordAdjustedToMatchCase: alt
			};
		}
		return sug;
	});
}
function limitResults(suggestions, numSuggestions, includeTies) {
	let cost = suggestions[0]?.cost;
	let i = 0;
	for (; i < suggestions.length; ++i) {
		if (i >= numSuggestions && (!includeTies || suggestions[i].cost > cost)) break;
		cost = suggestions[i].cost;
	}
	return suggestions.slice(0, i);
}
function validateDictionaries(settings, dictionaries) {
	if (!dictionaries?.length) return;
	const knownDicts = new Set(settings.dictionaryDefinitions?.map((def) => def.name) || []);
	for (const dict of dictionaries) if (!knownDicts.has(dict)) throw new SuggestionError(`Unknown dictionary: "${dict}"`, "E_dictionary_unknown");
}
function matchCase(word, isPreferred, style) {
	const locale = style.locale;
	if (style.isMixedCaps)
 /**
	* Do not try matching mixed caps.
	*/
	return word;
	if (hasCaps(word)) {
		if (style.isAllCaps) return word.toLocaleUpperCase(locale);
		if (!style.ignoreCase || style.hasCaps || isPreferred) return word;
		if (isTitleCase(word) || isAllCaps(word)) return word.toLocaleLowerCase(locale);
		return word;
	}
	if (!style.hasCaps) return word;
	if (style.isAllCaps) return word.toLocaleUpperCase(locale);
	assert(style.isTitleCase);
	return word.replace(/^\p{L}/u, (firstLetter) => firstLetter.toLocaleUpperCase(locale));
}
const regExpHasCaps = /\p{Lu}/u;
const regExpIsAllCaps = /^[\P{L}\p{Lu}]+$/u;
const regExpIsTitleCase = /^\p{Lu}[\P{L}\p{Ll}]+$/u;
function analyzeCase(word) {
	const hasCaps = regExpHasCaps.test(word);
	const isAllCaps = hasCaps && regExpIsAllCaps.test(word);
	const isTitleCase = hasCaps && !isAllCaps && regExpIsTitleCase.test(word);
	return {
		hasCaps,
		isAllCaps,
		isMixedCaps: hasCaps && !isAllCaps && !isTitleCase,
		isTitleCase
	};
}
function hasCaps(word) {
	return regExpHasCaps.test(word);
}
function isTitleCase(word) {
	return regExpIsTitleCase.test(word);
}
function isAllCaps(word) {
	return regExpIsAllCaps.test(word);
}
var SuggestionError = class extends Error {
	code;
	constructor(message, code) {
		super(message);
		this.code = code;
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/cleanValidationIssue.js
function cleanValidationIssue(issue) {
	const cleanIssue = {};
	cloneInto(issue, cleanIssue, ValidationIssueHandlers);
	return cleanIssue;
}
const ValidationIssueHandlers = {
	text: copy0,
	offset: copy0,
	message: copy0,
	line: copy1,
	length: copy0,
	issueType: copy0,
	hasPreferredSuggestions: copy0,
	hasSimpleSuggestions: copy0,
	isFlagged: copy0,
	isFound: copy0,
	suggestions: copy1,
	suggestionsEx: copy1
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/defaultConstants.js
const defaultMaxNumberOfProblems = 200;
const defaultMaxDuplicateProblems = 5;
const defaultMinWordLength = 4;

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/PairingHeap.js
var PairingHeap = class {
	compare;
	_heap;
	_size = 0;
	constructor(compare) {
		this.compare = compare;
	}
	add(v) {
		this._heap = insert(this.compare, this._heap, v);
		++this._size;
		return this;
	}
	dequeue() {
		const n = this.next();
		if (n.done) return void 0;
		return n.value;
	}
	append(i) {
		for (const v of i) this.add(v);
		return this;
	}
	next() {
		if (!this._heap) return {
			value: void 0,
			done: true
		};
		const value = this._heap.v;
		--this._size;
		this._heap = removeHead(this.compare, this._heap);
		return { value };
	}
	peek() {
		return this._heap?.v;
	}
	[Symbol.iterator]() {
		return this;
	}
	get length() {
		return this._size;
	}
};
function removeHead(compare, heap) {
	if (!heap || !heap.c) return void 0;
	return mergeSiblings(compare, heap.c);
}
function insert(compare, heap, v) {
	const n = {
		v,
		s: void 0,
		c: void 0
	};
	if (!heap || compare(v, heap.v) <= 0) {
		n.c = heap;
		return n;
	}
	n.s = heap.c;
	heap.c = n;
	return heap;
}
function merge$1(compare, a, b) {
	if (compare(a.v, b.v) <= 0) {
		a.s = void 0;
		b.s = a.c;
		a.c = b;
		return a;
	}
	b.s = void 0;
	a.s = b.c;
	b.c = a;
	return b;
}
function mergeSiblings(compare, n) {
	if (!n.s) return n;
	const s = n.s;
	const ss = s.s;
	const m = merge$1(compare, n, s);
	return ss ? merge$1(compare, m, mergeSiblings(compare, ss)) : m;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/regexHelper.js
/**
* Escape a string so it can be used as an exact match within a RegExp.
* @param s - string to escape
* @returns - the escaped string.
*/
function escapeRegEx(s) {
	return s.replaceAll(/[|\\{}()[\]^$+*?.]/g, "\\$&").replaceAll("-", "\\x2d");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/wordSplitter.js
const ignoreBreak = Object.freeze([]);
function split(line, offset, isValidWord, options = {}) {
	const relWordToSplit = findNextWordText({
		text: line.text,
		offset: offset - line.offset
	});
	const lineOffset = line.offset;
	const requested = /* @__PURE__ */ new Map();
	const regExpIgnoreSegment = /^[-.+\d_eE'`\\\s]+$/;
	if (!relWordToSplit.text) {
		const text = rebaseTextOffset(relWordToSplit);
		return {
			line,
			offset,
			text,
			words: [],
			endOffset: text.offset + text.text.length
		};
	}
	const lineSegment = {
		line,
		relStart: relWordToSplit.offset,
		relEnd: relWordToSplit.offset + relWordToSplit.text.length
	};
	const possibleBreaks = generateWordBreaks(lineSegment, options);
	if (!possibleBreaks.length) {
		const text = rebaseTextOffset(relWordToSplit);
		return {
			line,
			offset,
			text,
			words: [{
				...text,
				isFound: isValidWord(text)
			}],
			endOffset: text.offset + text.text.length
		};
	}
	function rebaseTextOffset(relText) {
		return {
			...relText,
			offset: relText.offset + lineOffset
		};
	}
	function has(word) {
		if (regExpIgnoreSegment.test(word.text)) return true;
		const i = word.offset;
		const j = word.text.length;
		let v = i + (j << 20);
		if (i < 1 << 20 && j < 2048) {
			const b = requested.get(v);
			if (b !== void 0) return b;
		} else v = -1;
		const r = isValidWord(rebaseTextOffset(word));
		if (v >= 0) requested.set(v, r);
		return r;
	}
	possibleBreaks.push({
		offset: lineSegment.relEnd,
		breaks: [ignoreBreak]
	});
	return {
		line,
		offset,
		text: rebaseTextOffset(relWordToSplit),
		words: splitIntoWords(lineSegment, possibleBreaks, has).map(rebaseTextOffset),
		endOffset: lineOffset + lineSegment.relEnd
	};
}
function findNextWordText({ text, offset }) {
	const reg = new RegExp(regExWordsAndDigits);
	reg.lastIndex = offset;
	const m = reg.exec(text);
	if (!m) return {
		text: "",
		offset: offset + text.length
	};
	if (regExNumericLiteral.test(m[0])) return findNextWordText({
		text,
		offset: offset + m[0].length
	});
	return {
		text: m[0],
		offset: m.index
	};
}
function generateWordBreaks(line, options) {
	const camelBreaks = genWordBreakCamel(line);
	const symbolBreaks = genSymbolBreaks(line);
	const optionalBreaks = genOptionalWordBreaks(line, options.optionalWordBreakCharacters);
	return mergeSortedBreaks(...camelBreaks, ...symbolBreaks, ...optionalBreaks);
}
function offsetRegEx(reg, offset) {
	const r = new RegExp(reg);
	r.lastIndex = offset;
	return r;
}
function genWordBreakCamel(line) {
	const breaksCamel1 = [];
	const text = line.line.text.slice(0, line.relEnd);
	for (const m of text.matchAll(offsetRegEx(regExSplitWords, line.relStart))) {
		if (m.index === void 0) break;
		const i = m.index + m[1].length;
		breaksCamel1.push({
			offset: m.index,
			breaks: [[i, i], ignoreBreak]
		});
	}
	const breaksCamel2 = [];
	for (const m of text.matchAll(offsetRegEx(regExSplitWords2, line.relStart))) {
		if (m.index === void 0) break;
		const i = m.index + m[1].length;
		const j = i + m[3].length;
		breaksCamel2.push({
			offset: m.index,
			breaks: [
				[i, i],
				[j, j],
				ignoreBreak
			]
		});
	}
	return [breaksCamel1, breaksCamel2];
}
function calcBreaksForRegEx(line, reg, calcBreak) {
	const sb = [];
	const text = line.line.text.slice(0, line.relEnd);
	for (const m of text.matchAll(offsetRegEx(reg, line.relStart))) {
		const b = calcBreak(m);
		if (b) sb.push(b);
	}
	return sb;
}
function genOptionalWordBreaks(line, optionalBreakCharacters) {
	function calcBreaks(m) {
		const i = m.index;
		if (i === void 0) return;
		return {
			offset: i,
			breaks: [[i, i + m[0].length], ignoreBreak]
		};
	}
	const breaks = [calcBreaksForRegEx(line, regExDanglingQuote, calcBreaks), calcBreaksForRegEx(line, regExTrailingEndings, calcBreaks)];
	if (optionalBreakCharacters) {
		const regex = new RegExp(`[${escapeRegEx(optionalBreakCharacters)}]`, "gu");
		breaks.push(calcBreaksForRegEx(line, regex, calcBreaks));
	}
	return breaks;
}
function genSymbolBreaks(line) {
	function calcBreaks(m) {
		const i = m.index;
		if (i === void 0) return;
		const j = i + m[0].length;
		return {
			offset: i,
			breaks: [
				[i, j],
				[i, i],
				[j, j],
				ignoreBreak
			]
		};
	}
	return [
		calcBreaksForRegEx(line, regExPossibleWordBreaks, calcBreaks),
		calcBreaksForRegEx(line, /\d+/g, calcBreaks),
		calcBreaksForRegEx(line, regExEscapeCharacters$1, calcBreaks)
	];
}
function splitIntoWords(lineSeg, breaks, has) {
	const maxIndex = lineSeg.relEnd;
	const maxAttempts = 1e3;
	const knownPathsByIndex = /* @__PURE__ */ new Map();
	/**
	* Create a set of possible candidate to consider
	* @param p - prev candidate that lead to this one
	* @param i - offset within the string
	* @param bi - current index into the set of breaks
	* @param currentCost - current cost accrued
	*/
	function makeCandidates(p, i, bi, currentCost) {
		const len = maxIndex;
		while (bi < breaks.length && breaks[bi].offset < i) bi += 1;
		if (bi >= breaks.length) return [];
		const br = breaks[bi];
		function c(bp) {
			const ec = currentCost + (bp.length < 2 ? len - i : (bp[0] - i) * .5 + len - bp[1]);
			return {
				p,
				i,
				bi,
				bp,
				c: currentCost,
				ec,
				text: void 0
			};
		}
		return br.breaks.map(c);
	}
	function checkTextOffset(text, offset) {
		return {
			text,
			offset,
			isFound: has({
				text,
				offset
			})
		};
	}
	function compare(a, b) {
		return a.ec - b.ec || b.i - a.i;
	}
	function pathToWords(node) {
		const results = [];
		for (let p = node; p; p = p.n) if (p.text) results.push(p.text);
		return results;
	}
	function addToKnownPaths(candidate, path) {
		for (let can = candidate; can !== void 0; can = can.p) {
			const t = can.text;
			const i = can.i;
			const cost = (!t || t.isFound ? 0 : t.text.length) + (path?.c ?? 0);
			const exitingPath = knownPathsByIndex.get(i);
			if (exitingPath && exitingPath.c <= cost) return;
			const node = {
				n: path,
				i,
				c: cost,
				text: t
			};
			knownPathsByIndex.set(i, node);
			path = node;
		}
		return path;
	}
	let maxCost = lineSeg.relEnd - lineSeg.relStart;
	const candidates = new PairingHeap(compare);
	const text = lineSeg.line.text;
	candidates.append(makeCandidates(void 0, lineSeg.relStart, 0, 0));
	let attempts = 0;
	let bestPath;
	while (maxCost && candidates.length && attempts++ < maxAttempts) {
		/** Best Candidate Index */
		const best = candidates.dequeue();
		if (!best || best.c >= maxCost) continue;
		if (best.bp.length) {
			const i = best.bp[0];
			const j = best.bp[1];
			const t = i > best.i ? checkTextOffset(text.slice(best.i, i), best.i) : void 0;
			const cost = !t || t.isFound ? 0 : t.text.length;
			const mc = maxIndex - j;
			best.c += cost;
			best.ec = best.c + mc;
			best.text = t;
			const possiblePath = knownPathsByIndex.get(j);
			if (possiblePath) {
				const f = addToKnownPaths(best, possiblePath);
				bestPath = !bestPath || f && f.c < bestPath.c ? f : bestPath;
			} else if (best.c < maxCost) {
				const c = makeCandidates(t ? best : best.p, j, best.bi + 1, best.c);
				candidates.append(c);
			}
		} else {
			const c = makeCandidates(best.p, best.i, best.bi + 1, best.c);
			candidates.append(c);
			if (!c.length) {
				const t = maxIndex > best.i ? checkTextOffset(text.slice(best.i, maxIndex), best.i) : void 0;
				const cost = !t || t.isFound ? 0 : t.text.length;
				best.c += cost;
				best.ec = best.c;
				best.text = t;
				const segText = t || best.p?.text || checkTextOffset("", best.i);
				const f = addToKnownPaths(t ? {
					...best,
					text: segText
				} : {
					...best,
					...best.p,
					text: segText
				}, void 0);
				bestPath = !bestPath || f && f.c < bestPath.c ? f : bestPath;
			}
		}
		if (bestPath && bestPath.c < maxCost) maxCost = bestPath.c;
	}
	return pathToWords(bestPath);
}
function mergeSortedBreaks(...maps) {
	return maps.flat().sort((a, b) => a.offset - b.offset);
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/isRandomString.js
const maxRadio = .5;
/**
* Try to detect if a string is a random string of characters or is it camel case / snake case words.
* @param s - string to check
* @returns true if the string is considered random;
*/
function isRandomString(s, maxNoiseToLengthRatio = maxRadio) {
	return scoreRandomString(s) >= maxNoiseToLengthRatio;
}
/**
* Calculate the ratio of noise to the length of the string.
* @param s - string to check
* @returns true if the string is considered random;
*/
function scoreRandomString(s) {
	if (!s.length) return 0;
	return categorizeString(s).length / s.length;
}
function categorizeString(s) {
	return s.replaceAll(/\d+/g, "0").replaceAll(/\p{Ll}\p{M}+/gu, "a").replaceAll(/\p{Lu}\p{M}+/gu, "A").replaceAll(/\p{Lu}?\p{Ll}+/gu, "1").replaceAll(/\p{Lu}+/gu, "2").replaceAll(/\p{M}/gu, "4").replaceAll("_", "").replaceAll(/[-_.']+/g, "3");
}
const hexSequence = /(?:\b|(?<=[\W_]))[0-9a-fA-F][-0-9a-fA-F]*[0-9a-fA-F](?:\b|(?=[\W_]))/g;
const isLetter = /\p{L}/uy;
function isLetterAt(s, idx) {
	isLetter.lastIndex = idx;
	return isLetter.test(s);
}
const MIN_HEX_SEQUENCE_LENGTH$1 = 4;
function extractHexSequences(s, minLength = MIN_HEX_SEQUENCE_LENGTH$1) {
	return [...s.matchAll(hexSequence)].filter((m) => m[0].length >= minLength && (m.index === 0 || !isLetterAt(s, m.index - 1)) && !isLetterAt(s, m.index + m[0].length)).map((m) => ({
		text: m[0],
		offset: m.index
	}));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/isWordValid.js
function hasWordCheck(dict, word) {
	word = word.includes("\\") ? word.replaceAll("\\", "") : word;
	return dict.has(word);
}
function isWordValidWithEscapeRetry(dict, wo, line) {
	return hasWordCheck(dict, wo.text) || line.text[wo.offset - line.offset - 1] === "\\" && hasWordCheck(dict, wo.text.slice(1));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/TextMap.js
/**
* Extract a substring from a TextMap.
* @param textMap - A text range with an optional map
* @param extractRange - The range in the original document to extract
* @returns The TextMap covering extractRange
*/
function extractTextMapRangeOrigin(textMap, extractRange) {
	const { text: srcTxt, range: srcRange, map: srcMap } = textMap;
	const [r0, r1] = srcRange;
	const startOrig = Math.min(Math.max(extractRange[0], r0), r1);
	const endOrig = Math.min(Math.max(extractRange[1], r0), r1);
	const a = startOrig - r0;
	const b = endOrig - r0;
	const range = [startOrig, endOrig];
	if (!srcMap || !srcMap.length || a === b) return {
		text: srcTxt.slice(a, b),
		range
	};
	assert((srcMap.length & 1) === 0, "Map must be pairs of values.");
	const mapLen = srcMap.length;
	const mapEndSrc = srcMap[mapLen - 2];
	const mapEndDst = srcMap[mapLen - 1];
	const endDiff = srcTxt.length - mapEndDst;
	const head = !srcMap[0] && !srcMap[1] ? [] : [0, 0];
	const tail = [mapEndSrc + endDiff, mapEndDst + endDiff];
	const sMap = [
		...head,
		...srcMap,
		...tail
	];
	let idx = 0;
	for (; idx < sMap.length && a >= sMap[idx]; idx += 2);
	const aIdx = idx;
	idx -= 2;
	const a0 = a - sMap[idx];
	const a1 = a0 + sMap[idx + 1];
	for (; idx < sMap.length && b > sMap[idx]; idx += 2);
	const bIdx = idx;
	const b1 = b - sMap[idx] + sMap[idx + 1];
	const text = srcTxt.slice(a1, b1);
	if (bIdx === aIdx) return {
		text,
		range
	};
	const ab = [a0, a1];
	return {
		text,
		range,
		map: sMap.slice(aIdx, bIdx + 2).map((v, i) => v - ab[i & 1])
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/parsedText.js
function mapRangeBackToOriginalPos(offRange, map) {
	if (!map || !map.length) return offRange;
	const [start, end] = offRange;
	let i = 0, j = 0, p = 1;
	while (p < map.length && map[p] < start) {
		i = map[p - 1];
		j = map[p];
		p += 2;
	}
	const iA = start - j + i;
	while (p < map.length && map[p] < end) {
		i = map[p - 1];
		j = map[p];
		p += 2;
	}
	return [iA, end - j + i];
}
/**
* Factory to create a segmentation function that will segment MappedText against a set of includeRanges.
* The function produced is optimized for forward scanning. It will perform poorly for randomly ordered offsets.
* @param includeRanges Allowed ranges for words.
*/
function createMappedTextSegmenter(includeRanges) {
	let rangePos = 0;
	function* segmenter(pText) {
		if (!includeRanges.length) return;
		const range = pText.range;
		const textEndPos = range[1];
		let textStartPos = range[0];
		while (rangePos && (rangePos >= includeRanges.length || includeRanges[rangePos].startPos > textStartPos)) rangePos -= 1;
		const cur = includeRanges[rangePos];
		if (textEndPos <= cur.endPos && textStartPos >= cur.startPos) {
			yield pText;
			return;
		}
		while (textStartPos < textEndPos) {
			while (includeRanges[rangePos] && includeRanges[rangePos].endPos <= textStartPos) rangePos += 1;
			if (!includeRanges[rangePos]) break;
			const { startPos, endPos } = includeRanges[rangePos];
			if (textEndPos < startPos) break;
			const a = Math.max(textStartPos, startPos);
			const b = Math.min(textEndPos, endPos);
			if (a !== b) yield extractTextMapRangeOrigin(pText, [a, b]);
			textStartPos = b;
		}
	}
	return segmenter;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/lineValidatorFactory.js
const MIN_HEX_SEQUENCE_LENGTH = 8;
function lineValidatorFactory(sDict, options) {
	const { minWordLength = defaultMinWordLength, flagWords = [], allowCompoundWords = false, ignoreCase = true, ignoreRandomStrings = defaultCSpellSettings.ignoreRandomStrings, minRandomLength = defaultCSpellSettings.minRandomLength, unknownWords = unknownWordsChoices.ReportAll, numSuggestions } = options;
	const dictCol = createCachingDictionary(sDict, {
		ignoreCase,
		useCompounds: allowCompoundWords || void 0
	});
	const knownWords = /* @__PURE__ */ new Map();
	const setOfFlagWords = new Set(flagWords);
	const setOfKnownIssues = /* @__PURE__ */ new Map();
	const setOfKnownSuccessfulWords = /* @__PURE__ */ new Set();
	const rememberFilter = (fn) => (v) => {
		const keep = fn(v);
		if (!keep) setOfKnownSuccessfulWords.add(v.text);
		return keep;
	};
	const filterAlreadyChecked = (wo) => {
		return !setOfKnownSuccessfulWords.has(wo.text);
	};
	const hasDict = { has(word) {
		const info = getWordInfo(word);
		if (info.isFound !== void 0) return info.isFound;
		if (info.isFlagged) return true;
		if (info.isFlagged) return false;
		info.isFound = dictCol.has(word);
		return info.isFound;
	} };
	function calcIgnored(info) {
		info.isIgnored ??= dictCol.isNoSuggestWord(info.word);
		return info.isIgnored;
	}
	function calcFlagged(info) {
		if (info.isFlagged !== void 0) return info.isFlagged;
		const word = info.word;
		info.isFlagged = (setOfFlagWords.has(word) || setOfFlagWords.has(word.toLowerCase()) || dictCol.isForbidden(word)) && !calcIgnored(info);
		return info.isFlagged;
	}
	function isWordIgnored(word) {
		return calcIgnored(getWordInfo(word));
	}
	const cacheGetPreferredSuggestions = /* @__PURE__ */ new Map();
	function getPreferredSuggestions(word) {
		return autoResolve$1(cacheGetPreferredSuggestions, word, () => dictCol.getPreferredSuggestions(word));
	}
	const cacheHasSimpleSuggestions = /* @__PURE__ */ new Map();
	function getSimpleSuggestions(word) {
		const numSug = numSuggestions ?? 5;
		return autoResolve$1(cacheHasSimpleSuggestions, word, () => {
			const sugs = dictCol.suggest(word, {
				numSuggestions: 1,
				compoundMethod: 0,
				includeTies: true,
				ignoreCase,
				timeout: 100,
				numChanges: 1.8
			});
			if (sugs.length > numSug) sugs.length = numSug;
			return sugs;
		});
	}
	function isWordFlagged(wo) {
		return calcFlagged(getWordInfo(wo.text));
	}
	function annotateIsFlagged(word) {
		word.isFlagged = isWordFlagged(word);
		return word;
	}
	function annotateIssue(issue) {
		const sugs = getPreferredSuggestions(issue.text);
		if (!sugs?.length) {
			issue.hasPreferredSuggestions = sugs !== void 0 ? false : void 0;
			if (unknownWords === unknownWordsChoices.ReportSimple) {
				const sug = getSimpleSuggestions(issue.text);
				issue.hasSimpleSuggestions = !!sug.length;
				if (sug.length) issue.suggestionsEx = sug.map((s) => ({
					...s,
					isPreferred: !!s.isPreferred
				}));
			}
			return issue;
		}
		issue.suggestionsEx = sugs;
		issue.hasPreferredSuggestions = true;
		issue.hasSimpleSuggestions = true;
		return issue;
	}
	const isFlaggedOrMinLength = (wo) => wo.text.length >= minWordLength || !!wo.isFlagged;
	const isFlaggedOrNotFound = rememberFilter((wo) => wo.isFlagged || !wo.isFound);
	const isNotRepeatingChar = rememberFilter((wo) => !regExRepeatedChar.test(wo.text));
	function checkWord(issue) {
		const info = getWordInfo(issue.text);
		if (info.fin) {
			const { isFlagged: isForbidden, isFound, isIgnored } = info;
			const isFlagged = issue.isFlagged ?? (!isIgnored && isForbidden);
			issue.isFlagged = isFlagged;
			issue.isFound = isFlagged ? void 0 : isFound;
			return issue;
		}
		const isIgnored = calcIgnored(info);
		const isFlagged = issue.isFlagged ?? calcFlagged(info);
		info.isFound ??= isFlagged ? false : isIgnored || isWordValidWithEscapeRetry(hasDict, issue, issue.line);
		info.isFlagged = !!isFlagged;
		info.fin = true;
		issue.isFlagged = isFlagged;
		issue.isFound = isFlagged ? void 0 : info.isFound;
		return issue;
	}
	const regExUpperCaseWithTrailingCommonEnglishSuffix = /^([\p{Lu}\p{M}]{2,})[']?(?:s|ing|ies|es|ings|ize|ed|ning)$/u;
	const regExpIsLetter = /\p{L}/u;
	const fn = (lineSegment) => {
		const line = lineSegment.line;
		function isWordTooShort(word, ignoreSuffix = false) {
			if (word.text.length >= minWordLength * 2 || [...word.text].length >= minWordLength) return false;
			const offset = word.offset - line.offset;
			assert.equal(line.text.slice(offset, offset + word.text.length), word.text);
			const prefix = [...line.text.slice(Math.max(0, offset - 2), offset)];
			if (!!prefix.length && regExpIsLetter.test(prefix[prefix.length - 1])) return false;
			if (ignoreSuffix) return true;
			const suffix = [...line.text.slice(offset + word.text.length, offset + word.text.length + 2)];
			return !(!!suffix.length && regExpIsLetter.test(suffix[0]));
		}
		function splitterIsValid(word) {
			if (setOfKnownSuccessfulWords.has(word.text)) return true;
			if (isWordFlagged(word)) return false;
			if (isWordValidWithEscapeRetry(hasDict, word, lineSegment.line)) return true;
			if (isWordTooShort(word)) return true;
			return isAllCapsWithTrailingCommonEnglishSuffixOk(word);
		}
		function isAllCapsWithTrailingCommonEnglishSuffixOk(tWord) {
			if (!regExUpperCaseWithTrailingCommonEnglishSuffix.test(tWord.text)) return false;
			const m = tWord.text.match(regExUpperCaseWithTrailingCommonEnglishSuffix);
			if (!m) return false;
			const v = {
				offset: tWord.offset,
				text: m[1],
				line
			};
			const check = checkWord(v);
			if (check.isFlagged) return false;
			if (check.isFound) return true;
			if (isWordTooShort(v, true)) return true;
			return false;
		}
		function checkFullWord(vr) {
			if (vr.isFlagged) return [vr];
			if (isAllCapsWithTrailingCommonEnglishSuffixOk(vr)) return [];
			if (isWordIgnored(vr.text) || checkWord(vr).isFound) {
				rememberFilter((_) => false)(vr);
				return [];
			}
			if (vr.isFlagged) return [vr];
			const codeWordResults = checkCamelCaseWord(vr);
			if (!codeWordResults.length) {
				rememberFilter((_) => false)(vr);
				return [];
			}
			return codeWordResults;
		}
		/**
		* Break a camel case word into its parts and check each part.
		*
		* There are two word break patterns:
		* - `regExpCamelCaseWordBreaks`
		* - `regExpCamelCaseWordBreaksWithEnglishSuffix` is the default pattern with English suffixes on ALL CAPS words.
		*
		* Note: See [#6066](https://github.com/streetsidesoftware/cspell/pull/6066)
		* Using just `regExpCamelCaseWordBreaks` misses unknown 4-letter words.
		*
		* The code below was tried, but it missed words.
		* - `LSTM` was caught. // cspell:disable-line
		* - `LSTMs` was missed because it becomes `LST` and `Ms`. // cspell:disable-line
		*
		* ```ts
		* const results = _checkCamelCaseWord(vr, regExpCamelCaseWordBreaks);
		* if (!results.length) return results;
		* const resultsEnglishBreaks = _checkCamelCaseWord(vr, regExpCamelCaseWordBreaksWithEnglishSuffix);
		* return results.length < resultsEnglishBreaks.length ? results : resultsEnglishBreaks;
		* ```
		*/
		function checkCamelCaseWord(vr) {
			return _checkCamelCaseWord(vr, regExpCamelCaseWordBreaksWithEnglishSuffix);
		}
		function _checkCamelCaseWord(vr, regExpWordBreaks) {
			const codeWordResults = [];
			for (const wo of splitWordWithOffset(vr, regExpWordBreaks)) {
				if (setOfKnownSuccessfulWords.has(wo.text)) continue;
				const issue = wo;
				issue.line = vr.line;
				issue.isFlagged = void 0;
				issue.isFound = void 0;
				annotateIsFlagged(issue);
				if (!isFlaggedOrMinLength(issue)) continue;
				checkWord(issue);
				if (!isFlaggedOrNotFound(issue) || !isNotRepeatingChar(issue)) continue;
				issue.text = extractText(lineSegment.segment, issue.offset, issue.offset + issue.text.length);
				codeWordResults.push(issue);
			}
			return codeWordResults;
		}
		function rebaseKnownIssues(possibleWord, known) {
			const { issues } = known;
			const adjOffset = possibleWord.offset - known.possibleWord.offset;
			return issues.map((issue) => {
				issue = { ...issue };
				issue.offset += adjOffset;
				issue.line = lineSegment.line;
				return issue;
			});
		}
		function checkForFlaggedWord(possibleWord) {
			if (isWordFlagged(possibleWord)) return {
				...possibleWord,
				line: lineSegment.line,
				isFlagged: true
			};
			if (possibleWord.text.endsWith(".") && possibleWord.text.length > 1) {
				const pw = {
					...possibleWord,
					text: possibleWord.text.slice(0, -1)
				};
				if (isWordFlagged(pw)) return {
					...pw,
					line: lineSegment.line,
					isFlagged: true
				};
			}
		}
		function checkPossibleWords(possibleWord) {
			const known = setOfKnownIssues.get(possibleWord.text);
			if (known) {
				if (!known.issues.length) return known.issues;
				return rebaseKnownIssues(possibleWord, known);
			}
			const issues = _checkPossibleWords(possibleWord).map(annotateIssue);
			setOfKnownIssues.set(possibleWord.text, {
				possibleWord,
				issues
			});
			return issues;
		}
		function _checkPossibleWords(possibleWord) {
			const flagged = checkForFlaggedWord(possibleWord);
			if (flagged) return [flagged];
			let mismatches = [];
			for (const wo of extractWordsFromTextOffset(possibleWord)) {
				if (setOfKnownSuccessfulWords.has(wo.text)) continue;
				const issue = wo;
				issue.line = lineSegment.line;
				annotateIsFlagged(issue);
				if (!isFlaggedOrMinLength(issue)) continue;
				for (const w of checkFullWord(issue)) mismatches.push(w);
			}
			if (!mismatches.length) return mismatches;
			const hexSequences = !ignoreRandomStrings ? void 0 : extractHexSequences(possibleWord.text, MIN_HEX_SEQUENCE_LENGTH).filter((w) => (w.text === w.text.toLowerCase() || w.text === w.text.toUpperCase()) && /[\d-]/.test(w.text)).map((w) => (w.offset += possibleWord.offset, w));
			if (hexSequences?.length) mismatches = filterExcludedTextOffsets(mismatches, hexSequences);
			if (mismatches.length) {
				const filtered = filterExcludedTextOffsets(split(lineSegment.segment, possibleWord.offset, splitterIsValid).words.filter((w) => !w.isFound).filter((w) => {
					const m = w.text.match(regExUpperCaseWithTrailingCommonEnglishSuffix);
					if (!m) return true;
					const v = checkWord({
						...w,
						text: m[1],
						line: lineSegment.line
					});
					return v.isFlagged || !v.isFound;
				}).map((w) => ({
					...w,
					line: lineSegment.line
				})).map(annotateIsFlagged), hexSequences);
				if (filtered.length < mismatches.length) return filtered;
			}
			return mismatches;
		}
		function isNotRandom(textOff) {
			if (textOff.text.length < minRandomLength || !ignoreRandomStrings) return true;
			return !isRandomString(textOff.text);
		}
		return pipeSync$1(extractPossibleWordsFromTextOffset(lineSegment.segment), opFilterSync$1(isNotRandom), opFilterSync$1(filterAlreadyChecked), opConcatMapSync$1(checkPossibleWords));
	};
	function getWordInfo(word) {
		const info = knownWords.get(word);
		if (info) return info;
		const result = {
			word,
			isFound: void 0,
			isFlagged: void 0,
			isIgnored: void 0,
			fin: false
		};
		knownWords.set(word, result);
		return result;
	}
	return {
		fn,
		dict: dictCol
	};
}
function textValidatorFactory(dict, options) {
	const lineValidator = lineValidatorFactory(dict, options);
	const lineValidatorFn = lineValidator.fn;
	function validate(pText) {
		const { text, range: srcRange, map } = pText;
		const srcOffset = srcRange[0];
		const segment = {
			text,
			offset: 0
		};
		const lineSegment = {
			line: segment,
			segment
		};
		function mapBackToOriginSimple(vr) {
			const { text, offset, isFlagged, isFound, suggestionsEx, hasPreferredSuggestions, hasSimpleSuggestions } = vr;
			const r = mapRangeBackToOriginalPos([offset, offset + text.length], map);
			return {
				text,
				range: [r[0] + srcOffset, r[1] + srcOffset],
				isFlagged,
				isFound,
				suggestionsEx,
				hasPreferredSuggestions,
				hasSimpleSuggestions
			};
		}
		return [...lineValidatorFn(lineSegment)].map(mapBackToOriginSimple);
	}
	return {
		validate,
		lineValidator
	};
}
function filterExcludedTextOffsets(issues, excluded) {
	if (!excluded?.length) return issues;
	const keep = [];
	let i = 0;
	let j = 0;
	for (i = 0; i < issues.length && j < excluded.length; i++) {
		const issue = issues[i];
		while (j < excluded.length && excluded[j].offset + excluded[j].text.length <= issue.offset) j++;
		if (j >= excluded.length) break;
		if (issue.isFlagged || issue.offset < excluded[j].offset) keep.push(issue);
	}
	if (i < issues.length) keep.push(...issues.slice(i));
	return keep;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/settingsToValidateOptions.js
function settingsToValidateOptions(settings) {
	return {
		...settings,
		ignoreCase: !(settings.caseSensitive ?? false),
		ignoreRandomStrings: settings.ignoreRandomStrings,
		minRandomLength: settings.minRandomLength,
		unknownWords: settings.unknownWords || "report-all"
	};
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/util/TextRange.js
function toMatchRangeWithText(m) {
	const index = m.index || 0;
	const _text = m[0];
	return {
		startPos: index,
		endPos: index + _text.length,
		text: _text
	};
}
function findMatchingRanges(pattern, text) {
	if (pattern.source === ".*") return [{
		startPos: 0,
		endPos: text.length
	}];
	const regex = new RegExp(pattern);
	if (!regex.global) {
		const m = text.match(regex);
		if (!m) return [];
		return [toMatchRangeWithText(m)];
	}
	return [...text.matchAll(regex)].map(toMatchRangeWithText);
}
function compareRanges(a, b) {
	return a.startPos - b.startPos || a.endPos - b.endPos;
}
function unionRanges(ranges) {
	const sortedRanges = sortMatchRangeArray(ranges);
	ranges = sortedRanges.values;
	if (!ranges.length) return sortedRanges;
	let i = 0;
	let j = 0;
	let { startPos, endPos } = ranges[i++];
	for (; i < ranges.length; ++i) {
		const r = ranges[i];
		if (r.startPos > endPos) {
			ranges[j++] = {
				startPos,
				endPos
			};
			startPos = r.startPos;
			endPos = r.endPos;
			continue;
		}
		endPos = Math.max(endPos, r.endPos);
	}
	if (startPos < endPos) ranges[j++] = {
		startPos,
		endPos
	};
	ranges.length = j;
	return sortedRanges;
}
function findMatchingRangesForPatterns(patterns, text) {
	return unionRanges(flatten(patterns.map((pattern) => findMatchingRanges(pattern, text)))).values;
}
/**
* Create a new set of positions that have the excluded position ranges removed.
*/
function excludeRanges(includeRanges, excludeRanges) {
	return _excludeRanges(sortMatchRangeArray(includeRanges), sortMatchRangeArray(excludeRanges));
}
function _excludeRanges(sortedIncludeRanges, sortedExcludeRanges) {
	const includeRanges = sortedIncludeRanges.values;
	const excludeRanges = sortedExcludeRanges.values;
	if (!includeRanges.length) return includeRanges;
	if (!excludeRanges.length) return includeRanges;
	const ranges = [];
	ranges.length = includeRanges.length + excludeRanges.length + 1;
	let i = 0;
	let exIndex = 0;
	const limit = excludeRanges.length;
	for (const incRange of includeRanges) {
		const endPos = incRange.endPos;
		let startPos = incRange.startPos;
		for (; exIndex < limit; ++exIndex) {
			const ex = excludeRanges[exIndex];
			if (ex.startPos >= endPos) break;
			if (ex.endPos <= startPos) continue;
			if (ex.startPos > startPos) ranges[i++] = {
				startPos,
				endPos: ex.startPos
			};
			startPos = ex.endPos;
			if (startPos >= endPos) break;
		}
		if (startPos < endPos) ranges[i++] = {
			startPos,
			endPos
		};
	}
	ranges.length = i;
	return ranges;
}
function sortMatchRangeArray(values) {
	values.sort(compareRanges);
	return { values };
}
function flatten(data) {
	let size = 0;
	for (let i = data.length - 1; i >= 0; --i) size += data[i].length;
	const result = new Array(size);
	let k = 0;
	for (let i = 0; i < data.length; ++i) {
		const d = data[i];
		for (let j = 0; j < d.length; ++j) result[k++] = d[j];
	}
	return result;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/textValidator.js
function calcTextInclusionRanges(text, options) {
	const { ignoreRegExpList = [], includeRegExpList = [] } = options;
	const filteredIncludeList = includeRegExpList.filter((a) => !!a);
	const finalIncludeList = filteredIncludeList.length ? filteredIncludeList : [/.*/gim];
	return excludeRanges(findMatchingRangesForPatterns(finalIncludeList, text), findMatchingRangesForPatterns(ignoreRegExpList, text));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/traceWord.js
function traceWord(word, dictCollection, config) {
	const opts = {
		ignoreCase: config.ignoreCase ?? true,
		useCompounds: config.allowCompoundWords || false,
		compoundSeparator: ""
	};
	const wfSplits = split({
		text: word,
		offset: 0
	}, 0, checkWord).words.map((s) => ({
		word: s.text,
		found: s.isFound
	}));
	const unique = uniqueFn$1((w) => w.word + "|" + w.found);
	const wsFound = {
		word,
		found: dictCollection.has(word, opts)
	};
	const wordSplits = wfSplits.some((s) => s.word === word) ? wfSplits : [wsFound, ...wfSplits];
	const r = new CTraceResult(...wordSplits.filter(unique).map((s) => s.word).flatMap((word) => dictCollection.dictionaries.map((dict) => ({
		dict,
		word
	}))).map(({ dict, word }) => ({
		dict,
		findResult: dict.find(word, opts),
		word
	})).flatMap((r) => unpackDictionaryFindResult(r, config)));
	r.splits = wordSplits;
	return r;
	function checkWord(wo) {
		return dictCollection.has(wo.text, opts);
	}
}
/**
* Map FindInDictResult to DictionaryTraceResult
* If the word was found in a dictionary based upon a config field setting, then find the source config.
* @param found - a word found in a dictionary
* @param config - the trace config
* @returns DictionaryTraceResult[]
*/
function unpackDictionaryFindResult(found, config) {
	const { word, dict, findResult } = found;
	const dictPreferred = getPreferred(dict, word);
	const baseResult = {
		word,
		found: !!findResult?.found,
		foundWord: findResult?.found || void 0,
		forbidden: findResult?.forbidden || false,
		noSuggest: findResult?.noSuggest || false,
		dictName: dict.name,
		dictSource: dict.source,
		configSource: void 0,
		preferredSuggestions: dictPreferred,
		errors: normalizeErrors(dict.getErrors?.())
	};
	const configFieldName = mapSpecialDictionaryNamesToSettings.get(dict.name);
	if (!findResult?.found || !configFieldName || !config.source) return [baseResult];
	const opts = {
		ignoreCase: true,
		useCompounds: config.allowCompoundWords || false
	};
	const sources = getSources(config);
	const results = [];
	for (const src of sources) {
		if (!src[configFieldName] || !Array.isArray(src[configFieldName]) || !src[configFieldName]?.length || !src.source?.filename) continue;
		const configSource = toFileUrl(src.source.filename).href;
		const cfgDict = createCollection(getInlineConfigDictionaries({ [configFieldName]: src[configFieldName] }), dict.name, configSource);
		const findResult = cfgDict.find(word, opts);
		const preferredSuggestions = getPreferred(cfgDict, word);
		if (!findResult?.found && !preferredSuggestions) continue;
		const result = {
			word,
			found: !!findResult?.found,
			foundWord: findResult?.found || void 0,
			forbidden: findResult?.forbidden || false,
			noSuggest: findResult?.noSuggest || false,
			dictName: dict.name,
			dictSource: configSource,
			configSource,
			preferredSuggestions,
			errors: normalizeErrors(dict.getErrors?.())
		};
		results.push(result);
	}
	return results.length ? results : [baseResult];
}
function normalizeErrors(errors) {
	return errors?.length ? errors : void 0;
}
function getPreferred(dict, word) {
	const sugs = dict.getPreferredSuggestions?.(word);
	return sugs?.length ? sugs.filter((s) => s.isPreferred).map((s) => s.word) : void 0;
}
var CTraceResult = class extends Array {
	splits = [];
	constructor(...items) {
		super(...items);
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/textValidation/docValidator.js
const ERROR_NOT_PREPARED = "Validator Must be prepared before calling this function.";
var DocumentValidator = class DocumentValidator {
	settings;
	_document;
	_ready = false;
	errors = [];
	_prepared;
	_preparations;
	_preparationTime = -1;
	_suggestions = new AutoCache((text) => this.genSuggestions(text), 1e3);
	options;
	perfTiming = {};
	skipValidation;
	static async create(doc, options, settingsOrConfigFile) {
		const validator = new DocumentValidator(doc, options, satisfiesCSpellConfigFile(settingsOrConfigFile) ? await resolveConfigFileImports(settingsOrConfigFile) : settingsOrConfigFile);
		await validator.prepare();
		return validator;
	}
	/**
	* @param doc - Document to validate
	* @param config - configuration to use (not finalized).
	*/
	constructor(doc, options, settings) {
		this.settings = settings;
		this._document = doc;
		this.options = { ...options };
		const numSuggestions = this.options.numSuggestions ?? settings.numSuggestions;
		if (numSuggestions !== void 0) this.options.numSuggestions = numSuggestions;
		this.skipValidation = !!options.skipValidation;
	}
	get ready() {
		return this._ready;
	}
	prepare() {
		if (this._ready) return Promise.resolve();
		if (this._prepared) return this._prepared;
		this._prepared = this._prepareAsync();
		return this._prepared;
	}
	async _prepareAsync() {
		assert(!this._ready);
		const timer = createPerfTimer("_prepareAsync");
		const { options, settings: rawSettings } = this;
		const resolveImportsRelativeTo = toFileURL(options.resolveImportsRelativeTo || toFileURL("./virtual.settings.json"));
		const settings = rawSettings.import?.length ? await resolveSettingsImports(rawSettings, resolveImportsRelativeTo) : rawSettings;
		const useSearchForConfig = !options.noConfigSearch && !settings.noConfigSearch || options.noConfigSearch === false;
		const pLocalConfig = options.configFile ? loadConfig(options.configFile, settings) : useSearchForConfig ? timePromise(this.perfTiming, "__searchForDocumentConfig", searchForDocumentConfig(this._document, settings, settings)) : void 0;
		if (pLocalConfig) timePromise(this.perfTiming, "_loadConfig", pLocalConfig).catch(() => void 0);
		const localConfig = await catchPromiseError(pLocalConfig, (e) => this.addPossibleError(e)) || {};
		extractImportErrors(localConfig).forEach((e) => this.addPossibleError(e.error));
		const config = mergeSettings(settings, localConfig);
		const docSettings = await timePromise(this.perfTiming, "_determineTextDocumentSettings", determineTextDocumentSettings(this._document, config));
		const dict = await timePromise(this.perfTiming, "_getDictionaryInternal", getDictionaryInternal(docSettings));
		const stopMeasure = measurePerf("DocumentValidator._prepareAsync");
		const recGlobMatcherTime = recordPerfTime(this.perfTiming, "_GlobMatcher");
		const matcher = getGlobMatcherForExcluding(localConfig?.ignorePaths);
		const uri = this._document.uri;
		recGlobMatcherTime();
		const recShouldCheckTime = recordPerfTime(this.perfTiming, "_shouldCheck");
		const shouldCheck = !matcher.match(uriToFilePath(uri)) && (docSettings.enabled ?? true);
		recShouldCheckTime();
		const recFinalizeTime = recordPerfTime(this.perfTiming, "_finalizeSettings");
		const finalSettings = finalizeSettings(docSettings);
		const validateOptions = settingsToValidateOptions(finalSettings);
		const includeRanges = calcTextInclusionRanges(this._document.text, validateOptions);
		const segmenter = createMappedTextSegmenter(includeRanges);
		const textValidator = textValidatorFactory(dict, validateOptions);
		recFinalizeTime();
		this._preparations = {
			config,
			dictionary: dict,
			docSettings,
			finalSettings,
			shouldCheck,
			validateOptions,
			includeRanges,
			segmenter,
			textValidator,
			localConfig,
			localConfigFilepath: localConfig?.__importRef?.filename
		};
		this._ready = true;
		this._preparationTime = timer.elapsed;
		this.perfTiming.prepTime = this._preparationTime;
		stopMeasure();
	}
	async _updatePrep() {
		assert(this._preparations, ERROR_NOT_PREPARED);
		const timer = createPerfTimer("_updatePrep");
		const prep = this._preparations;
		const docSettings = await determineTextDocumentSettings(this._document, prep.config);
		const dict = await getDictionaryInternal(docSettings);
		const stopMeasure = measurePerf("DocumentValidator._updatePrep");
		const shouldCheck = docSettings.enabled ?? true;
		const validateOptions = settingsToValidateOptions(finalizeSettings(docSettings));
		const includeRanges = calcTextInclusionRanges(this._document.text, validateOptions);
		const segmenter = createMappedTextSegmenter(includeRanges);
		const textValidator = textValidatorFactory(dict, validateOptions);
		this._preparations = {
			...prep,
			dictionary: dict,
			docSettings,
			shouldCheck,
			validateOptions,
			includeRanges,
			segmenter,
			textValidator
		};
		this._preparationTime = timer.elapsed;
		stopMeasure();
	}
	/**
	* The amount of time in ms to prepare for validation.
	*/
	get prepTime() {
		return this._preparationTime;
	}
	get validateDirectives() {
		return this.options.validateDirectives ?? this._preparations?.config.validateDirectives ?? false;
	}
	/**
	* Check a range of text for validation issues.
	* @param range - the range of text to check.
	* @param _text - the text to check. If not given, the text will be taken from the document.
	* @param scope - the scope to use for validation. If not given, the default scope will be used.
	* @returns the validation issues.
	*/
	checkText(range, _text, scope) {
		const text = this._document.text.slice(range[0], range[1]);
		scope = (Array.isArray(scope) ? scope.join(" ") : scope) || "";
		return this.check({
			text,
			range,
			scope
		});
	}
	check(parsedText) {
		assert(this._ready);
		assert(this._preparations, ERROR_NOT_PREPARED);
		const { segmenter, textValidator } = this._preparations;
		const document = this._document;
		let line = void 0;
		function mapToIssue(issue) {
			const { range, text, isFlagged, isFound, suggestionsEx, hasPreferredSuggestions, hasSimpleSuggestions } = issue;
			const offset = range[0];
			const length = range[1] - range[0];
			assert(!line || line.offset <= offset);
			if (!line || line.offset + line.text.length <= offset) line = document.lineAt(offset);
			return {
				text,
				offset,
				line,
				length,
				isFlagged,
				isFound,
				suggestionsEx,
				hasPreferredSuggestions,
				hasSimpleSuggestions
			};
		}
		const issues = [...pipeSync$1(segmenter(parsedText), opConcatMapSync$1(textValidator.validate), opMapSync$1(mapToIssue))];
		if (!this.options.generateSuggestions) return issues.map((issue) => {
			if (!issue.suggestionsEx) return issue;
			const suggestionsEx = this.adjustSuggestions(issue.text, issue.suggestionsEx);
			const suggestions = suggestionsEx.map((s) => s.word);
			return {
				...issue,
				suggestionsEx,
				suggestions
			};
		});
		return issues.map((t) => {
			const text = t.text;
			const suggestionsEx = this.getSuggestions(text);
			t.suggestionsEx = suggestionsEx;
			t.suggestions = suggestionsEx.map((s) => s.word);
			return t;
		});
	}
	/**
	* Check a Document for Validation Issues.
	* @param forceCheck - force a check even if the document would normally be excluded.
	* @returns the validation issues.
	*/
	async checkDocumentAsync(forceCheck) {
		await this.prepare();
		return this.checkDocument(forceCheck);
	}
	/**
	* Check a Document for Validation Issues.
	*
	* Note: The validator must be prepared before calling this method.
	* @param forceCheck - force a check even if the document would normally be excluded.
	* @returns the validation issues.
	*/
	checkDocument(forceCheck = false) {
		const timerDone = recordPerfTime(this.perfTiming, "checkDocument");
		try {
			if (this.skipValidation) return [];
			assert(this._ready);
			assert(this._preparations, ERROR_NOT_PREPARED);
			const spellingIssues = forceCheck || this.shouldCheckDocument() ? [...this._checkParsedText(this._parse())] : [];
			const directiveIssues = this.checkDocumentDirectives();
			return [...spellingIssues, ...directiveIssues].map(cleanValidationIssue).sort((a, b) => a.offset - b.offset);
		} finally {
			timerDone();
		}
	}
	checkDocumentDirectives(forceCheck = false) {
		assert(this._ready);
		assert(this._preparations, ERROR_NOT_PREPARED);
		if (!(forceCheck || this.validateDirectives)) return [];
		const document = this.document;
		const issueType = IssueType.directive;
		function toValidationIssue(dirIssue) {
			const { text, range, suggestions, suggestionsEx, message } = dirIssue;
			const offset = range[0];
			const pos = document.positionAt(offset);
			return {
				text,
				offset,
				line: document.getLine(pos.line),
				suggestions,
				suggestionsEx,
				message,
				issueType
			};
		}
		return [...validateInDocumentSettings(this.document.text, this._preparations.config)].map(toValidationIssue);
	}
	get document() {
		return this._document;
	}
	async updateDocumentText(text) {
		updateTextDocument(this._document, [{ text }]);
		await this._updatePrep();
	}
	/**
	* Get the calculated ranges of text that should be included in the spell checking.
	* @returns MatchRanges of text to include.
	*/
	getCheckedTextRanges() {
		assert(this._preparations, ERROR_NOT_PREPARED);
		return this._preparations.includeRanges;
	}
	traceWord(word) {
		assert(this._preparations, ERROR_NOT_PREPARED);
		return traceWord(word, this._preparations.dictionary, this._preparations.config);
	}
	defaultParser() {
		return pipeSync$1(this.document.getLines(), opMapSync$1((line) => {
			const { text, offset } = line;
			return {
				text,
				range: [offset, offset + text.length]
			};
		}));
	}
	*_checkParsedText(parsedTexts) {
		assert(this._preparations, ERROR_NOT_PREPARED);
		const { maxNumberOfProblems = defaultMaxNumberOfProblems, maxDuplicateProblems = defaultMaxDuplicateProblems } = this._preparations.validateOptions;
		let numProblems = 0;
		const mapOfProblems = /* @__PURE__ */ new Map();
		const stopMeasure = measurePerf("DocumentValidator._checkParsedText");
		for (const pText of parsedTexts) for (const issue of this.check(pText)) {
			const { text } = issue;
			const n = (mapOfProblems.get(text) || 0) + 1;
			mapOfProblems.set(text, n);
			if (n > maxDuplicateProblems) continue;
			yield issue;
			if (++numProblems >= maxNumberOfProblems) return;
		}
		stopMeasure();
	}
	addPossibleError(error) {
		if (!error) return;
		error = this.errors.push(toError$4(error));
	}
	_parse() {
		assert(this._preparations, ERROR_NOT_PREPARED);
		const parser = this._preparations.finalSettings.parserFn;
		if (typeof parser !== "object") return this.defaultParser();
		return parser.parse(this.document.text, toFilePathOrHref(documentUriToURL(this.document.uri))).parsedTexts;
	}
	getSuggestions(text) {
		return this._suggestions.get(text);
	}
	genSuggestions(text) {
		assert(this._preparations, ERROR_NOT_PREPARED);
		const settings = this._preparations.docSettings;
		const dict = this._preparations.dictionary;
		const sugOptions = {
			compoundMethod: 0,
			numSuggestions: this.options.numSuggestions,
			includeTies: false,
			ignoreCase: !(settings.caseSensitive ?? false),
			timeout: settings.suggestionsTimeout,
			numChanges: settings.suggestionNumChanges
		};
		const rawSuggestions = dict.suggest(text, sugOptions);
		return this.adjustSuggestions(text, rawSuggestions);
	}
	adjustSuggestions(text, rawSuggestions) {
		assert(this._preparations, ERROR_NOT_PREPARED);
		const ignoreCase = !(this._preparations.docSettings.caseSensitive ?? false);
		const locale = this._preparations.config.language;
		const dict = this._preparations.dictionary;
		return calcSuggestionAdjustedToToMatchCase(text, rawSuggestions.map(mapSug), locale, ignoreCase, dict).map(sanitizeSuggestion);
	}
	getFinalizedDocSettings() {
		assert(this._ready);
		assert(this._preparations, ERROR_NOT_PREPARED);
		return this._preparations.docSettings;
	}
	getConfigErrors() {
		const errors = extractImportErrors(this.getFinalizedDocSettings());
		return errors.length ? errors : void 0;
	}
	getDictionaryErrors() {
		assert(this._ready);
		assert(this._preparations, ERROR_NOT_PREPARED);
		const { dictionary } = this._preparations;
		const errors = dictionary.dictionaries.map((dict) => [dict.name, dict.getErrors?.()]).filter((entry) => entry[1] && entry[1].length > 0 || false);
		return errors.length ? new Map(errors) : void 0;
	}
	/**
	* Returns true if the final result of the configuration calculation results
	* in the document being enabled. Note: in some cases, checking the document
	* might still make sense, for example, the `@cspell/eslint-plugin` relies on
	* `eslint` configuration to make that determination.
	* @returns true if the document settings have resolved to be `enabled`
	*/
	shouldCheckDocument() {
		assert(this._preparations, ERROR_NOT_PREPARED);
		return this._preparations.shouldCheck;
	}
	/**
	* Internal `cspell-lib` use.
	*/
	_getPreparations() {
		return this._preparations;
	}
};
function sanitizeSuggestion(sug) {
	const { word, isPreferred, wordAdjustedToMatchCase } = sug;
	if (isPreferred && wordAdjustedToMatchCase) return {
		word,
		wordAdjustedToMatchCase,
		isPreferred
	};
	if (isPreferred) return {
		word,
		isPreferred
	};
	if (wordAdjustedToMatchCase) return {
		word,
		wordAdjustedToMatchCase
	};
	return { word };
}
async function searchForDocumentConfig(document, defaultConfig, pnpSettings) {
	const url = documentUriToURL(document.uri);
	try {
		return await searchForConfig(url, pnpSettings).then((s) => s || defaultConfig);
	} catch (e) {
		if (url.protocol !== "file:") return defaultConfig;
		throw e;
	}
}
function mapSug(sug) {
	return {
		cost: 999,
		...sug
	};
}
/**
* Check if a document should be checked based upon the ignorePaths and override settings.
*
* This function will search and fetch settings based upon the location of the document if `noConfigSearch` is not true.
*
* @param doc - document to check
* @param options - options to override some of the settings.
* @param settings - current settings
* @returns ShouldCheckDocumentResult
*/
async function shouldCheckDocument(doc, options, settings) {
	const errors = [];
	function addPossibleError(error) {
		if (!error) return void 0;
		error = errors.push(toError$4(error));
	}
	async function shouldCheck() {
		const useSearchForConfig = !options.noConfigSearch && !settings.noConfigSearch || options.noConfigSearch === false;
		const localConfig = await catchPromiseError(options.configFile ? loadConfig(options.configFile, settings) : useSearchForConfig ? searchForDocumentConfig(doc, settings, settings) : void 0, addPossibleError) || {};
		extractImportErrors(localConfig).forEach((e) => addPossibleError(e.error));
		const config = mergeSettings(settings, localConfig);
		if (getGlobMatcherForExcluding(localConfig?.ignorePaths).match(uriToFilePath(doc.uri))) return {
			errors,
			shouldCheck: false,
			settings: localConfig,
			reason: "Excluded by ignorePaths."
		};
		const docSettings = await determineTextDocumentSettings(doc, config);
		const shouldCheck = docSettings.enabled ?? true;
		return {
			errors,
			shouldCheck,
			settings: docSettings,
			reason: shouldCheck ? void 0 : "Excluded by overrides or languageSettings."
		};
	}
	return await shouldCheck();
}
function recordPerfTime(timings, name) {
	const timer = createPerfTimer(name, (elapsed) => timings[name] = elapsed);
	return () => timer.end();
}
function timePromise(timings, name, p) {
	return p.finally(recordPerfTime(timings, name));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-lib@9.6.4/node_modules/cspell-lib/dist/lib/spellCheckFile.js
/**
* Spell Check a Document.
* @param document - document to be checked. If `document.text` is `undefined` the file will be loaded
* @param options - options to control checking
* @param settings - default settings to use.
*/
async function spellCheckDocument(document, options, settingsOrConfigFile) {
	const settingsUsed = satisfiesCSpellConfigFile(settingsOrConfigFile) ? settingsOrConfigFile.settings : settingsOrConfigFile;
	if (isBinaryDoc(document)) return {
		document,
		options,
		settingsUsed,
		localConfigFilepath: void 0,
		issues: [],
		checked: false,
		errors: void 0
	};
	try {
		const timer = createPerfTimer("loadFile");
		const doc = await resolveDocument(document).finally(() => timer.end());
		if (isBinaryDoc(doc)) return {
			document,
			options,
			settingsUsed,
			localConfigFilepath: void 0,
			issues: [],
			checked: false,
			errors: void 0
		};
		const result = await spellCheckFullDocument(doc, options, settingsOrConfigFile);
		const perf = result.perf || {};
		perf.loadTimeMs = timer.elapsed;
		result.perf = perf;
		return result;
	} catch (e) {
		return {
			document,
			options,
			settingsUsed,
			localConfigFilepath: void 0,
			issues: [],
			checked: false,
			errors: isError$4(e) ? [e] : []
		};
	}
}
const memoizedCloneSettingsForExport = memoizeLastCall(cloneSettingsForExport);
async function spellCheckFullDocument(document, options, settingsOrConfigFile) {
	const perf = {};
	const timer = createPerfTimer("spellCheckFullDocument", (elapsed) => perf.totalTimeMs = elapsed);
	const timerCheck = createPerfTimer("check", (elapsed) => perf.checkTimeMs = elapsed);
	const timerPrepare = createPerfTimer("prepare", (elapsed) => perf.prepareTimeMs = elapsed);
	const doc = documentToTextDocument(document);
	const docValOptions = options;
	const docValidator = await DocumentValidator.create(doc, docValOptions, settingsOrConfigFile).finally(() => timerPrepare.end());
	Object.assign(perf, Object.fromEntries(Object.entries(docValidator.perfTiming).map(([k, v]) => ["_" + k, v])));
	const prep = docValidator._getPreparations();
	if (docValidator.errors.length) return {
		document,
		options,
		settingsUsed: prep?.localConfig || (satisfiesCSpellConfigFile(settingsOrConfigFile) ? settingsOrConfigFile.settings : settingsOrConfigFile),
		localConfigFilepath: prep?.localConfigFilepath,
		issues: [],
		checked: false,
		errors: docValidator.errors,
		configErrors: docValidator.getConfigErrors(),
		dictionaryErrors: docValidator.getDictionaryErrors(),
		perf
	};
	timerCheck.start();
	const issues = docValidator.checkDocument();
	timerCheck.end();
	Object.assign(perf, Object.fromEntries(Object.entries(docValidator.perfTiming).map(([k, v]) => ["_" + k, v])));
	const result = {
		document,
		options,
		settingsUsed: docValidator.getFinalizedDocSettings(),
		localConfigFilepath: prep?.localConfigFilepath,
		issues,
		checked: docValidator.shouldCheckDocument(),
		errors: void 0,
		configErrors: docValidator.getConfigErrors(),
		dictionaryErrors: docValidator.getDictionaryErrors(),
		perf
	};
	timer.end();
	return result;
}

//#endregion
//#region ../node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/vendor/ansi-styles/index.js
const ANSI_BACKGROUND_OFFSET = 10;
const wrapAnsi16 = (offset = 0) => (code) => `\u001B[${code + offset}m`;
const wrapAnsi256 = (offset = 0) => (code) => `\u001B[${38 + offset};5;${code}m`;
const wrapAnsi16m = (offset = 0) => (red, green, blue) => `\u001B[${38 + offset};2;${red};${green};${blue}m`;
const styles$1 = {
	modifier: {
		reset: [0, 0],
		bold: [1, 22],
		dim: [2, 22],
		italic: [3, 23],
		underline: [4, 24],
		overline: [53, 55],
		inverse: [7, 27],
		hidden: [8, 28],
		strikethrough: [9, 29]
	},
	color: {
		black: [30, 39],
		red: [31, 39],
		green: [32, 39],
		yellow: [33, 39],
		blue: [34, 39],
		magenta: [35, 39],
		cyan: [36, 39],
		white: [37, 39],
		blackBright: [90, 39],
		gray: [90, 39],
		grey: [90, 39],
		redBright: [91, 39],
		greenBright: [92, 39],
		yellowBright: [93, 39],
		blueBright: [94, 39],
		magentaBright: [95, 39],
		cyanBright: [96, 39],
		whiteBright: [97, 39]
	},
	bgColor: {
		bgBlack: [40, 49],
		bgRed: [41, 49],
		bgGreen: [42, 49],
		bgYellow: [43, 49],
		bgBlue: [44, 49],
		bgMagenta: [45, 49],
		bgCyan: [46, 49],
		bgWhite: [47, 49],
		bgBlackBright: [100, 49],
		bgGray: [100, 49],
		bgGrey: [100, 49],
		bgRedBright: [101, 49],
		bgGreenBright: [102, 49],
		bgYellowBright: [103, 49],
		bgBlueBright: [104, 49],
		bgMagentaBright: [105, 49],
		bgCyanBright: [106, 49],
		bgWhiteBright: [107, 49]
	}
};
const modifierNames = Object.keys(styles$1.modifier);
const foregroundColorNames = Object.keys(styles$1.color);
const backgroundColorNames = Object.keys(styles$1.bgColor);
const colorNames = [...foregroundColorNames, ...backgroundColorNames];
function assembleStyles() {
	const codes = /* @__PURE__ */ new Map();
	for (const [groupName, group] of Object.entries(styles$1)) {
		for (const [styleName, style] of Object.entries(group)) {
			styles$1[styleName] = {
				open: `\u001B[${style[0]}m`,
				close: `\u001B[${style[1]}m`
			};
			group[styleName] = styles$1[styleName];
			codes.set(style[0], style[1]);
		}
		Object.defineProperty(styles$1, groupName, {
			value: group,
			enumerable: false
		});
	}
	Object.defineProperty(styles$1, "codes", {
		value: codes,
		enumerable: false
	});
	styles$1.color.close = "\x1B[39m";
	styles$1.bgColor.close = "\x1B[49m";
	styles$1.color.ansi = wrapAnsi16();
	styles$1.color.ansi256 = wrapAnsi256();
	styles$1.color.ansi16m = wrapAnsi16m();
	styles$1.bgColor.ansi = wrapAnsi16(ANSI_BACKGROUND_OFFSET);
	styles$1.bgColor.ansi256 = wrapAnsi256(ANSI_BACKGROUND_OFFSET);
	styles$1.bgColor.ansi16m = wrapAnsi16m(ANSI_BACKGROUND_OFFSET);
	Object.defineProperties(styles$1, {
		rgbToAnsi256: {
			value(red, green, blue) {
				if (red === green && green === blue) {
					if (red < 8) return 16;
					if (red > 248) return 231;
					return Math.round((red - 8) / 247 * 24) + 232;
				}
				return 16 + 36 * Math.round(red / 255 * 5) + 6 * Math.round(green / 255 * 5) + Math.round(blue / 255 * 5);
			},
			enumerable: false
		},
		hexToRgb: {
			value(hex) {
				const matches = /[a-f\d]{6}|[a-f\d]{3}/i.exec(hex.toString(16));
				if (!matches) return [
					0,
					0,
					0
				];
				let [colorString] = matches;
				if (colorString.length === 3) colorString = [...colorString].map((character) => character + character).join("");
				const integer = Number.parseInt(colorString, 16);
				return [
					integer >> 16 & 255,
					integer >> 8 & 255,
					integer & 255
				];
			},
			enumerable: false
		},
		hexToAnsi256: {
			value: (hex) => styles$1.rgbToAnsi256(...styles$1.hexToRgb(hex)),
			enumerable: false
		},
		ansi256ToAnsi: {
			value(code) {
				if (code < 8) return 30 + code;
				if (code < 16) return 90 + (code - 8);
				let red;
				let green;
				let blue;
				if (code >= 232) {
					red = ((code - 232) * 10 + 8) / 255;
					green = red;
					blue = red;
				} else {
					code -= 16;
					const remainder = code % 36;
					red = Math.floor(code / 36) / 5;
					green = Math.floor(remainder / 6) / 5;
					blue = remainder % 6 / 5;
				}
				const value = Math.max(red, green, blue) * 2;
				if (value === 0) return 30;
				let result = 30 + (Math.round(blue) << 2 | Math.round(green) << 1 | Math.round(red));
				if (value === 2) result += 60;
				return result;
			},
			enumerable: false
		},
		rgbToAnsi: {
			value: (red, green, blue) => styles$1.ansi256ToAnsi(styles$1.rgbToAnsi256(red, green, blue)),
			enumerable: false
		},
		hexToAnsi: {
			value: (hex) => styles$1.ansi256ToAnsi(styles$1.hexToAnsi256(hex)),
			enumerable: false
		}
	});
	return styles$1;
}
const ansiStyles = assembleStyles();
var ansi_styles_default = ansiStyles;

//#endregion
//#region ../node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/vendor/supports-color/index.js
function hasFlag(flag, argv = globalThis.Deno ? globalThis.Deno.args : process$1.argv) {
	const prefix = flag.startsWith("-") ? "" : flag.length === 1 ? "-" : "--";
	const position = argv.indexOf(prefix + flag);
	const terminatorPosition = argv.indexOf("--");
	return position !== -1 && (terminatorPosition === -1 || position < terminatorPosition);
}
const { env } = process$1;
let flagForceColor;
if (hasFlag("no-color") || hasFlag("no-colors") || hasFlag("color=false") || hasFlag("color=never")) flagForceColor = 0;
else if (hasFlag("color") || hasFlag("colors") || hasFlag("color=true") || hasFlag("color=always")) flagForceColor = 1;
function envForceColor() {
	if ("FORCE_COLOR" in env) {
		if (env.FORCE_COLOR === "true") return 1;
		if (env.FORCE_COLOR === "false") return 0;
		return env.FORCE_COLOR.length === 0 ? 1 : Math.min(Number.parseInt(env.FORCE_COLOR, 10), 3);
	}
}
function translateLevel(level) {
	if (level === 0) return false;
	return {
		level,
		hasBasic: true,
		has256: level >= 2,
		has16m: level >= 3
	};
}
function _supportsColor(haveStream, { streamIsTTY, sniffFlags = true } = {}) {
	const noFlagForceColor = envForceColor();
	if (noFlagForceColor !== void 0) flagForceColor = noFlagForceColor;
	const forceColor = sniffFlags ? flagForceColor : noFlagForceColor;
	if (forceColor === 0) return 0;
	if (sniffFlags) {
		if (hasFlag("color=16m") || hasFlag("color=full") || hasFlag("color=truecolor")) return 3;
		if (hasFlag("color=256")) return 2;
	}
	if ("TF_BUILD" in env && "AGENT_NAME" in env) return 1;
	if (haveStream && !streamIsTTY && forceColor === void 0) return 0;
	const min = forceColor || 0;
	if (env.TERM === "dumb") return min;
	if (process$1.platform === "win32") {
		const osRelease = os$1.release().split(".");
		if (Number(osRelease[0]) >= 10 && Number(osRelease[2]) >= 10586) return Number(osRelease[2]) >= 14931 ? 3 : 2;
		return 1;
	}
	if ("CI" in env) {
		if ([
			"GITHUB_ACTIONS",
			"GITEA_ACTIONS",
			"CIRCLECI"
		].some((key) => key in env)) return 3;
		if ([
			"TRAVIS",
			"APPVEYOR",
			"GITLAB_CI",
			"BUILDKITE",
			"DRONE"
		].some((sign) => sign in env) || env.CI_NAME === "codeship") return 1;
		return min;
	}
	if ("TEAMCITY_VERSION" in env) return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;
	if (env.COLORTERM === "truecolor") return 3;
	if (env.TERM === "xterm-kitty") return 3;
	if (env.TERM === "xterm-ghostty") return 3;
	if (env.TERM === "wezterm") return 3;
	if ("TERM_PROGRAM" in env) {
		const version = Number.parseInt((env.TERM_PROGRAM_VERSION || "").split(".")[0], 10);
		switch (env.TERM_PROGRAM) {
			case "iTerm.app": return version >= 3 ? 3 : 2;
			case "Apple_Terminal": return 2;
		}
	}
	if (/-256(color)?$/i.test(env.TERM)) return 2;
	if (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(env.TERM)) return 1;
	if ("COLORTERM" in env) return 1;
	return min;
}
function createSupportsColor(stream, options = {}) {
	return translateLevel(_supportsColor(stream, {
		streamIsTTY: stream && stream.isTTY,
		...options
	}));
}
const supportsColor = {
	stdout: createSupportsColor({ isTTY: tty.isatty(1) }),
	stderr: createSupportsColor({ isTTY: tty.isatty(2) })
};
var supports_color_default = supportsColor;

//#endregion
//#region ../node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/utilities.js
function stringReplaceAll(string, substring, replacer) {
	let index = string.indexOf(substring);
	if (index === -1) return string;
	const substringLength = substring.length;
	let endIndex = 0;
	let returnValue = "";
	do {
		returnValue += string.slice(endIndex, index) + substring + replacer;
		endIndex = index + substringLength;
		index = string.indexOf(substring, endIndex);
	} while (index !== -1);
	returnValue += string.slice(endIndex);
	return returnValue;
}
function stringEncaseCRLFWithFirstIndex(string, prefix, postfix, index) {
	let endIndex = 0;
	let returnValue = "";
	do {
		const gotCR = string[index - 1] === "\r";
		returnValue += string.slice(endIndex, gotCR ? index - 1 : index) + prefix + (gotCR ? "\r\n" : "\n") + postfix;
		endIndex = index + 1;
		index = string.indexOf("\n", endIndex);
	} while (index !== -1);
	returnValue += string.slice(endIndex);
	return returnValue;
}

//#endregion
//#region ../node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/index.js
const { stdout: stdoutColor, stderr: stderrColor } = supports_color_default;
const GENERATOR = Symbol("GENERATOR");
const STYLER = Symbol("STYLER");
const IS_EMPTY = Symbol("IS_EMPTY");
const levelMapping = [
	"ansi",
	"ansi",
	"ansi256",
	"ansi16m"
];
const styles = Object.create(null);
const applyOptions = (object, options = {}) => {
	if (options.level && !(Number.isInteger(options.level) && options.level >= 0 && options.level <= 3)) throw new Error("The `level` option should be an integer from 0 to 3");
	const colorLevel = stdoutColor ? stdoutColor.level : 0;
	object.level = options.level === void 0 ? colorLevel : options.level;
};
var Chalk = class {
	constructor(options) {
		return chalkFactory(options);
	}
};
const chalkFactory = (options) => {
	const chalk = (...strings) => strings.join(" ");
	applyOptions(chalk, options);
	Object.setPrototypeOf(chalk, createChalk.prototype);
	return chalk;
};
function createChalk(options) {
	return chalkFactory(options);
}
Object.setPrototypeOf(createChalk.prototype, Function.prototype);
for (const [styleName, style] of Object.entries(ansi_styles_default)) styles[styleName] = { get() {
	const builder = createBuilder(this, createStyler(style.open, style.close, this[STYLER]), this[IS_EMPTY]);
	Object.defineProperty(this, styleName, { value: builder });
	return builder;
} };
styles.visible = { get() {
	const builder = createBuilder(this, this[STYLER], true);
	Object.defineProperty(this, "visible", { value: builder });
	return builder;
} };
const getModelAnsi = (model, level, type, ...arguments_) => {
	if (model === "rgb") {
		if (level === "ansi16m") return ansi_styles_default[type].ansi16m(...arguments_);
		if (level === "ansi256") return ansi_styles_default[type].ansi256(ansi_styles_default.rgbToAnsi256(...arguments_));
		return ansi_styles_default[type].ansi(ansi_styles_default.rgbToAnsi(...arguments_));
	}
	if (model === "hex") return getModelAnsi("rgb", level, type, ...ansi_styles_default.hexToRgb(...arguments_));
	return ansi_styles_default[type][model](...arguments_);
};
for (const model of [
	"rgb",
	"hex",
	"ansi256"
]) {
	styles[model] = { get() {
		const { level } = this;
		return function(...arguments_) {
			const styler = createStyler(getModelAnsi(model, levelMapping[level], "color", ...arguments_), ansi_styles_default.color.close, this[STYLER]);
			return createBuilder(this, styler, this[IS_EMPTY]);
		};
	} };
	const bgModel = "bg" + model[0].toUpperCase() + model.slice(1);
	styles[bgModel] = { get() {
		const { level } = this;
		return function(...arguments_) {
			const styler = createStyler(getModelAnsi(model, levelMapping[level], "bgColor", ...arguments_), ansi_styles_default.bgColor.close, this[STYLER]);
			return createBuilder(this, styler, this[IS_EMPTY]);
		};
	} };
}
const proto = Object.defineProperties(() => {}, {
	...styles,
	level: {
		enumerable: true,
		get() {
			return this[GENERATOR].level;
		},
		set(level) {
			this[GENERATOR].level = level;
		}
	}
});
const createStyler = (open, close, parent) => {
	let openAll;
	let closeAll;
	if (parent === void 0) {
		openAll = open;
		closeAll = close;
	} else {
		openAll = parent.openAll + open;
		closeAll = close + parent.closeAll;
	}
	return {
		open,
		close,
		openAll,
		closeAll,
		parent
	};
};
const createBuilder = (self, _styler, _isEmpty) => {
	const builder = (...arguments_) => applyStyle(builder, arguments_.length === 1 ? "" + arguments_[0] : arguments_.join(" "));
	Object.setPrototypeOf(builder, proto);
	builder[GENERATOR] = self;
	builder[STYLER] = _styler;
	builder[IS_EMPTY] = _isEmpty;
	return builder;
};
const applyStyle = (self, string) => {
	if (self.level <= 0 || !string) return self[IS_EMPTY] ? "" : string;
	let styler = self[STYLER];
	if (styler === void 0) return string;
	const { openAll, closeAll } = styler;
	if (string.includes("\x1B")) while (styler !== void 0) {
		string = stringReplaceAll(string, styler.close, styler.open);
		styler = styler.parent;
	}
	const lfIndex = string.indexOf("\n");
	if (lfIndex !== -1) string = stringEncaseCRLFWithFirstIndex(string, closeAll, openAll, lfIndex);
	return openAll + string + closeAll;
};
Object.defineProperties(createChalk.prototype, styles);
const chalk = createChalk();
const chalkStderr = createChalk({ level: stderrColor ? stderrColor.level : 0 });
var source_default = chalk;

//#endregion
//#region ../node_modules/.pnpm/chalk-template@1.1.2/node_modules/chalk-template/index.js
const TEMPLATE_REGEX = /(?:\\(u(?:[a-f\d]{4}|{[a-f\d]{1,6}})|x[a-f\d]{2}|.))|(?:{(~)?(#?[\w:]+(?:\([^)]*\))?(?:\.#?[\w:]+(?:\([^)]*\))?)*)(?:[ \t]|(?=\r?\n)))|(})|((?:.|[\r\n\f])+?)/gi;
const STYLE_REGEX = /(?:^|\.)(?:(?:(\w+)(?:\(([^)]*)\))?)|(?:#(?=[:a-fA-F\d]{2,})([a-fA-F\d]{6})?(?::([a-fA-F\d]{6}))?))/g;
const STRING_REGEX = /^(['"])((?:\\.|(?!\1)[^\\])*)\1$/;
const ESCAPE_REGEX = /\\(u(?:[a-f\d]{4}|{[a-f\d]{1,6}})|x[a-f\d]{2}|.)|([^\\])/gi;
const ESCAPES = new Map([
	["n", "\n"],
	["r", "\r"],
	["t", "	"],
	["b", "\b"],
	["f", "\f"],
	["v", "\v"],
	["0", "\0"],
	["\\", "\\"],
	["e", "\x1B"],
	["a", "\x07"]
]);
function unescape(c) {
	const u = c[0] === "u";
	const bracket = c[1] === "{";
	if (u && !bracket && c.length === 5 || c[0] === "x" && c.length === 3) return String.fromCodePoint(Number.parseInt(c.slice(1), 16));
	if (u && bracket) return String.fromCodePoint(Number.parseInt(c.slice(2, -1), 16));
	return ESCAPES.get(c) || c;
}
function parseArguments(name, arguments_) {
	const results = [];
	const chunks = arguments_.trim().split(/\s*,\s*/g);
	let matches;
	for (const chunk of chunks) {
		const number = Number(chunk);
		if (!Number.isNaN(number)) results.push(number);
		else if (matches = chunk.match(STRING_REGEX)) results.push(matches[2].replace(ESCAPE_REGEX, (_, escape, character) => escape ? unescape(escape) : character));
		else throw new Error(`Invalid Chalk template style argument: ${chunk} (in style '${name}')`);
	}
	return results;
}
function parseHex(hex) {
	const n = Number.parseInt(hex, 16);
	return [
		n >> 16 & 255,
		n >> 8 & 255,
		n & 255
	];
}
function parseStyle(style) {
	STYLE_REGEX.lastIndex = 0;
	const results = [];
	let matches;
	while ((matches = STYLE_REGEX.exec(style)) !== null) {
		const name = matches[1];
		if (matches[2]) results.push([name, ...parseArguments(name, matches[2])]);
		else if (matches[3] || matches[4]) {
			if (matches[3]) results.push(["rgb", ...parseHex(matches[3])]);
			if (matches[4]) results.push(["bgRgb", ...parseHex(matches[4])]);
		} else results.push([name]);
	}
	return results;
}
function makeTemplate(chalk) {
	function buildStyle(styles) {
		const enabled = {};
		for (const layer of styles) for (const style of layer.styles) enabled[style[0]] = layer.inverse ? null : style.slice(1);
		let current = chalk;
		for (const [styleName, styles] of Object.entries(enabled)) {
			if (!Array.isArray(styles)) continue;
			if (!(styleName in current)) throw new Error(`Unknown Chalk style: ${styleName}`);
			current = styles.length > 0 ? current[styleName](...styles) : current[styleName];
		}
		return current;
	}
	function template(string) {
		const styles = [];
		const chunks = [];
		let chunk = [];
		string.replace(TEMPLATE_REGEX, (_, escapeCharacter, inverse, style, close, character) => {
			if (escapeCharacter) chunk.push(unescape(escapeCharacter));
			else if (style) {
				const string = chunk.join("");
				chunk = [];
				chunks.push(styles.length === 0 ? string : buildStyle(styles)(string));
				styles.push({
					inverse,
					styles: parseStyle(style)
				});
			} else if (close) {
				if (styles.length === 0) throw new Error("Found extraneous } in Chalk template literal");
				chunks.push(buildStyle(styles)(chunk.join("")));
				chunk = [];
				styles.pop();
			} else chunk.push(character);
		});
		chunks.push(chunk.join(""));
		if (styles.length > 0) throw new Error(`Chalk template literal is missing ${styles.length} closing bracket${styles.length === 1 ? "" : "s"} (\`}\`)`);
		return chunks.join("");
	}
	return template;
}
function makeChalkTemplate(template) {
	function chalkTemplate(firstString, ...arguments_) {
		if (!Array.isArray(firstString) || !Array.isArray(firstString.raw)) throw new TypeError("A tagged template literal must be provided");
		const parts = [firstString.raw[0]];
		for (let index = 1; index < firstString.raw.length; index++) parts.push(String(arguments_[index - 1]).replace(/[{}\\]/g, "\\$&"), String(firstString.raw[index]));
		return template(parts.join(""));
	}
	return chalkTemplate;
}
const template = makeTemplate(source_default);
var chalk_template_default = makeChalkTemplate(template);
const templateStderr = makeTemplate(chalkStderr);
const chalkTemplateStderr = makeChalkTemplate(templateStderr);

//#endregion
//#region ../node_modules/.pnpm/ansi-regex@6.2.2/node_modules/ansi-regex/index.js
function ansiRegex({ onlyFirst = false } = {}) {
	return new RegExp(`(?:\\u001B\\][\\s\\S]*?(?:\\u0007|\\u001B\\u005C|\\u009C))|[\\u001B\\u009B][[\\]()#;?]*(?:\\d{1,4}(?:[;:]\\d{0,4})*)?[\\dA-PR-TZcf-nq-uy=><~]`, onlyFirst ? void 0 : "g");
}

//#endregion
//#region ../node_modules/.pnpm/cspell-gitignore@9.6.4/node_modules/cspell-gitignore/dist/findRepoRoot.js
/**
* Find the git repository root directory.
* @param directory - directory to search up from.
* @returns resolves to `.git` root or undefined
*/
async function findRepoRoot(directory, vfs) {
	directory = toFileDirURL(directory);
	vfs = vfs || getDefaultVirtualFs().getFS(directory);
	const foundDir = await vfs.findUp(".git", directory, { type: "directory" });
	const foundFile = await vfs.findUp(".git", directory, { type: "file" });
	const found = foundDir || foundFile;
	if (!found) return void 0;
	return toFilePathOrHref(new URL(".", found));
}

//#endregion
//#region ../node_modules/.pnpm/cspell-gitignore@9.6.4/node_modules/cspell-gitignore/dist/utils.js
function isDefined(v) {
	return v !== void 0 && v !== null;
}
function isParentOf(parent, child) {
	parent = toFileDirURL(parent);
	return child.pathname.startsWith(parent.pathname);
}
function makeRelativeTo(child, parent) {
	const c = toFileURL(child);
	const rel = urlRelative(toFileDirURL(parent), c);
	if (rel.startsWith("../")) return void 0;
	return rel;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-gitignore@9.6.4/node_modules/cspell-gitignore/dist/GitIgnoreFile.js
/**
* Represents an instance of a .gitignore file.
*/
var GitIgnoreFile = class GitIgnoreFile {
	matcher;
	gitignore;
	constructor(matcher, gitignore) {
		this.matcher = matcher;
		this.gitignore = gitignore;
	}
	get root() {
		return this.matcher.root;
	}
	isIgnored(file) {
		return this.matcher.match(file.toString());
	}
	isIgnoredEx(file) {
		const m = this.matcher.matchEx(file.toString());
		const { matched } = m;
		const partial = m;
		const pattern = partial.pattern;
		const glob = pattern?.rawGlob ?? partial.glob;
		const root = partial.root;
		const line = pattern?.line;
		return {
			glob,
			matched,
			gitIgnoreFile: toFilePathOrHref(this.gitignore),
			root,
			line
		};
	}
	getGlobPatters() {
		return this.matcher.patterns;
	}
	getGlobs(relativeToDir) {
		return this.getGlobPatters().map((pat) => globToString(pat, relativeToDir)).filter(isDefined);
	}
	static parseGitignore(content, gitignoreFilename) {
		gitignoreFilename = toFileURL(gitignoreFilename);
		const options = { root: urlDirname(gitignoreFilename).href };
		return new GitIgnoreFile(new GlobMatcher(content.split(/\r?\n/g).map((glob, index) => ({
			glob: glob.replace(/^#.*/, ""),
			source: gitignoreFilename.toString(),
			line: index + 1
		})).filter((g) => !!g.glob), options), gitignoreFilename);
	}
	static async loadGitignore(gitignore, vfs) {
		gitignore = toFileURL(gitignore);
		const file = await vfs.readFile(gitignore, "utf8");
		return this.parseGitignore(file.getText(), gitignore);
	}
};
/**
* A collection of nested GitIgnoreFiles to be evaluated from top to bottom.
*/
var GitIgnoreHierarchy = class {
	gitIgnoreChain;
	constructor(gitIgnoreChain) {
		this.gitIgnoreChain = gitIgnoreChain;
		mustBeHierarchical(gitIgnoreChain);
	}
	isIgnored(file) {
		for (const git of this.gitIgnoreChain) if (git.isIgnored(file)) return true;
		return false;
	}
	/**
	* Check to see which `.gitignore` file ignored the given file.
	* @param file - fsPath to check.
	* @returns IsIgnoredExResult of the match or undefined if there was no match.
	*/
	isIgnoredEx(file) {
		for (const git of this.gitIgnoreChain) {
			const r = git.isIgnoredEx(file);
			if (r.matched) return r;
		}
	}
	getGlobPatters() {
		return this.gitIgnoreChain.flatMap((gf) => gf.getGlobPatters());
	}
	getGlobs(relativeTo) {
		return this.gitIgnoreChain.flatMap((gf) => gf.getGlobs(relativeTo));
	}
};
async function loadGitIgnore(dir, vfs) {
	dir = toFileDirURL(dir);
	if (!dir.pathname.startsWith("/")) return void 0;
	vfs ??= getDefaultVirtualFs().getFS(dir);
	const file = new URL(".gitignore", dir);
	try {
		return await GitIgnoreFile.loadGitignore(file, vfs);
	} catch {
		return;
	}
}
function mustBeHierarchical(chain) {
	let root = "";
	for (const file of chain) {
		if (!file.root.startsWith(root)) throw new Error("Hierarchy violation - files are not nested");
		root = file.root;
	}
}
function globToString(glob, relativeToDir) {
	if (glob.isGlobalPattern) return glob.glob;
	relativeToDir = toFileDirURL(relativeToDir);
	const root = toFileDirURL(glob.root);
	if (isParentOf(root, relativeToDir) && glob.glob.startsWith("**/")) return glob.glob;
	const base = makeRelativeTo(root, relativeToDir);
	if (base === void 0) return void 0;
	return (base ? base + "/" : "") + glob.glob;
}

//#endregion
//#region ../node_modules/.pnpm/cspell-gitignore@9.6.4/node_modules/cspell-gitignore/dist/GitIgnore.js
/**
* Class to cache and process `.gitignore` file queries.
*/
var GitIgnore = class {
	resolvedGitIgnoreHierarchies = /* @__PURE__ */ new Map();
	knownGitIgnoreHierarchies = /* @__PURE__ */ new Map();
	_roots;
	_sortedRoots;
	_vfs;
	/**
	* @param roots - (search roots) an optional array of root paths to prevent searching for `.gitignore` files above the root.
	*   If a file is under multiple roots, the closest root will apply. If a file is not under any root, then
	*   the search for `.gitignore` will go all the way to the system root of the file.
	*/
	constructor(roots = [], vfs) {
		this._vfs = vfs;
		this._sortedRoots = resolveAndSortRoots(roots);
		this._roots = new Set(this._sortedRoots);
	}
	findResolvedGitIgnoreHierarchy(directory) {
		return this.resolvedGitIgnoreHierarchies.get(toFileDirURL(directory).href);
	}
	isIgnoredQuick(file) {
		const uFile = toFileURL(file);
		return this.findResolvedGitIgnoreHierarchy(getDir(uFile))?.isIgnored(uFile);
	}
	async isIgnored(file) {
		const uFile = toFileURL(file);
		return (await this.findGitIgnoreHierarchy(getDir(uFile))).isIgnored(uFile);
	}
	async isIgnoredEx(file) {
		const uFile = toFileURL(file);
		return (await this.findGitIgnoreHierarchy(getDir(uFile))).isIgnoredEx(uFile);
	}
	async findGitIgnoreHierarchy(directory) {
		directory = toFileDirURL(directory).href;
		const known = this.knownGitIgnoreHierarchies.get(directory);
		if (known) return known;
		const find = this._findGitIgnoreHierarchy(directory);
		this.knownGitIgnoreHierarchies.set(directory, find);
		const found = await find;
		this.resolvedGitIgnoreHierarchies.set(directory, found);
		return find;
	}
	filterOutIgnored(files) {
		const iter = this.filterOutIgnoredAsync(files);
		return isAsyncIterable(files) ? iter : asyncIterableToArray(iter);
	}
	async *filterOutIgnoredAsync(files) {
		for await (const file of files) if (!(this.isIgnoredQuick(file) ?? await this.isIgnored(file))) yield file;
	}
	get roots() {
		return this._sortedRoots;
	}
	addRoots(roots) {
		const rootsToAdd = roots.map((r) => toFileDirURL(r).href).filter((r) => !this._roots.has(r));
		if (!rootsToAdd.length) return;
		rootsToAdd.forEach((r) => this._roots.add(r));
		this._sortedRoots = resolveAndSortRoots([...this._roots]);
		this.cleanCachedEntries();
	}
	peekGitIgnoreHierarchy(directory) {
		directory = toFileDirURL(directory).href;
		return this.knownGitIgnoreHierarchies.get(directory);
	}
	async getGlobs(directory) {
		return (await this.findGitIgnoreHierarchy(directory)).getGlobs(directory);
	}
	cleanCachedEntries() {
		this.knownGitIgnoreHierarchies.clear();
		this.resolvedGitIgnoreHierarchies.clear();
	}
	async _findGitIgnoreHierarchy(directory) {
		directory = toFileDirURL(directory);
		const root = this.determineRoot(directory);
		const parent = urlDirname(directory);
		const parentHierarchy = parent.href !== directory.href && isParentOf(root, parent) ? await this.findGitIgnoreHierarchy(parent) : void 0;
		const git = await loadGitIgnore(directory, this._vfs);
		if (!git) return parentHierarchy || new GitIgnoreHierarchy([]);
		return new GitIgnoreHierarchy(parentHierarchy ? [...parentHierarchy.gitIgnoreChain, git] : [git]);
	}
	determineRoot(directory) {
		const uDir = toFileDirURL(directory);
		const roots = this.roots;
		for (let i = roots.length - 1; i >= 0; --i) {
			const r = roots[i];
			if (uDir.href.startsWith(r)) return r;
		}
		return uDir.pathname.startsWith("/") ? new URL("/", uDir).href : uDir.href;
	}
};
/**
* Convert the roots into urls strings.
* @param roots
* @returns
*/
function resolveAndSortRoots(roots) {
	const sortedRoots = roots.map((a) => toFileDirURL(a).href);
	sortRoots(sortedRoots);
	Object.freeze(sortedRoots);
	return sortedRoots;
}
function getDir(file) {
	return urlDirname(toFileURL(file));
}
/**
* Sorts root paths based upon their length.
* @param roots - array to be sorted
*/
function sortRoots(roots) {
	roots.sort((a, b) => a.length - b.length || a.localeCompare(b));
	return roots;
}
function isAsyncIterable(i) {
	return typeof i[Symbol.asyncIterator] === "function";
}
async function asyncIterableToArray(iter) {
	const r = [];
	for await (const t of iter) r.push(t);
	return r;
}

//#endregion
//#region ../node_modules/.pnpm/fdir@6.5.0_picomatch@4.0.3/node_modules/fdir/dist/index.mjs
var __require = /* @__PURE__ */ createRequire$1(import.meta.url);
function cleanPath(path) {
	let normalized = normalize(path);
	if (normalized.length > 1 && normalized[normalized.length - 1] === sep$1) normalized = normalized.substring(0, normalized.length - 1);
	return normalized;
}
const SLASHES_REGEX = /[\\/]/g;
function convertSlashes(path, separator) {
	return path.replace(SLASHES_REGEX, separator);
}
const WINDOWS_ROOT_DIR_REGEX = /^[a-z]:[\\/]$/i;
function isRootDirectory(path) {
	return path === "/" || WINDOWS_ROOT_DIR_REGEX.test(path);
}
function normalizePath$2(path, options) {
	const { resolvePaths, normalizePath: normalizePath$1, pathSeparator } = options;
	const pathNeedsCleaning = process.platform === "win32" && path.includes("/") || path.startsWith(".");
	if (resolvePaths) path = resolve$1(path);
	if (normalizePath$1 || pathNeedsCleaning) path = cleanPath(path);
	if (path === ".") return "";
	return convertSlashes(path[path.length - 1] !== pathSeparator ? path + pathSeparator : path, pathSeparator);
}
function joinPathWithBasePath(filename, directoryPath) {
	return directoryPath + filename;
}
function joinPathWithRelativePath(root, options) {
	return function(filename, directoryPath) {
		if (directoryPath.startsWith(root)) return directoryPath.slice(root.length) + filename;
		else return convertSlashes(relative$1(root, directoryPath), options.pathSeparator) + options.pathSeparator + filename;
	};
}
function joinPath(filename) {
	return filename;
}
function joinDirectoryPath(filename, directoryPath, separator) {
	return directoryPath + filename + separator;
}
function build$7(root, options) {
	const { relativePaths, includeBasePath } = options;
	return relativePaths && root ? joinPathWithRelativePath(root, options) : includeBasePath ? joinPathWithBasePath : joinPath;
}
function pushDirectoryWithRelativePath(root) {
	return function(directoryPath, paths) {
		paths.push(directoryPath.substring(root.length) || ".");
	};
}
function pushDirectoryFilterWithRelativePath(root) {
	return function(directoryPath, paths, filters) {
		const relativePath = directoryPath.substring(root.length) || ".";
		if (filters.every((filter) => filter(relativePath, true))) paths.push(relativePath);
	};
}
const pushDirectory = (directoryPath, paths) => {
	paths.push(directoryPath || ".");
};
const pushDirectoryFilter = (directoryPath, paths, filters) => {
	const path = directoryPath || ".";
	if (filters.every((filter) => filter(path, true))) paths.push(path);
};
const empty$2 = () => {};
function build$6(root, options) {
	const { includeDirs, filters, relativePaths } = options;
	if (!includeDirs) return empty$2;
	if (relativePaths) return filters && filters.length ? pushDirectoryFilterWithRelativePath(root) : pushDirectoryWithRelativePath(root);
	return filters && filters.length ? pushDirectoryFilter : pushDirectory;
}
const pushFileFilterAndCount = (filename, _paths, counts, filters) => {
	if (filters.every((filter) => filter(filename, false))) counts.files++;
};
const pushFileFilter = (filename, paths, _counts, filters) => {
	if (filters.every((filter) => filter(filename, false))) paths.push(filename);
};
const pushFileCount = (_filename, _paths, counts, _filters) => {
	counts.files++;
};
const pushFile = (filename, paths) => {
	paths.push(filename);
};
const empty$1 = () => {};
function build$5(options) {
	const { excludeFiles, filters, onlyCounts } = options;
	if (excludeFiles) return empty$1;
	if (filters && filters.length) return onlyCounts ? pushFileFilterAndCount : pushFileFilter;
	else if (onlyCounts) return pushFileCount;
	else return pushFile;
}
const getArray = (paths) => {
	return paths;
};
const getArrayGroup = () => {
	return [""].slice(0, 0);
};
function build$4(options) {
	return options.group ? getArrayGroup : getArray;
}
const groupFiles = (groups, directory, files) => {
	groups.push({
		directory,
		files,
		dir: directory
	});
};
const empty = () => {};
function build$3(options) {
	return options.group ? groupFiles : empty;
}
const resolveSymlinksAsync = function(path, state, callback$1) {
	const { queue, fs, options: { suppressErrors } } = state;
	queue.enqueue();
	fs.realpath(path, (error, resolvedPath) => {
		if (error) return queue.dequeue(suppressErrors ? null : error, state);
		fs.stat(resolvedPath, (error$1, stat) => {
			if (error$1) return queue.dequeue(suppressErrors ? null : error$1, state);
			if (stat.isDirectory() && isRecursive(path, resolvedPath, state)) return queue.dequeue(null, state);
			callback$1(stat, resolvedPath);
			queue.dequeue(null, state);
		});
	});
};
const resolveSymlinks = function(path, state, callback$1) {
	const { queue, fs, options: { suppressErrors } } = state;
	queue.enqueue();
	try {
		const resolvedPath = fs.realpathSync(path);
		const stat = fs.statSync(resolvedPath);
		if (stat.isDirectory() && isRecursive(path, resolvedPath, state)) return;
		callback$1(stat, resolvedPath);
	} catch (e) {
		if (!suppressErrors) throw e;
	}
};
function build$2(options, isSynchronous) {
	if (!options.resolveSymlinks || options.excludeSymlinks) return null;
	return isSynchronous ? resolveSymlinks : resolveSymlinksAsync;
}
function isRecursive(path, resolved, state) {
	if (state.options.useRealPaths) return isRecursiveUsingRealPaths(resolved, state);
	let parent = dirname(path);
	let depth = 1;
	while (parent !== state.root && depth < 2) {
		const resolvedPath = state.symlinks.get(parent);
		if (!!resolvedPath && (resolvedPath === resolved || resolvedPath.startsWith(resolved) || resolved.startsWith(resolvedPath))) depth++;
		else parent = dirname(parent);
	}
	state.symlinks.set(path, resolved);
	return depth > 1;
}
function isRecursiveUsingRealPaths(resolved, state) {
	return state.visited.includes(resolved + state.options.pathSeparator);
}
const onlyCountsSync = (state) => {
	return state.counts;
};
const groupsSync = (state) => {
	return state.groups;
};
const defaultSync = (state) => {
	return state.paths;
};
const limitFilesSync = (state) => {
	return state.paths.slice(0, state.options.maxFiles);
};
const onlyCountsAsync = (state, error, callback$1) => {
	report(error, callback$1, state.counts, state.options.suppressErrors);
	return null;
};
const defaultAsync = (state, error, callback$1) => {
	report(error, callback$1, state.paths, state.options.suppressErrors);
	return null;
};
const limitFilesAsync = (state, error, callback$1) => {
	report(error, callback$1, state.paths.slice(0, state.options.maxFiles), state.options.suppressErrors);
	return null;
};
const groupsAsync = (state, error, callback$1) => {
	report(error, callback$1, state.groups, state.options.suppressErrors);
	return null;
};
function report(error, callback$1, output, suppressErrors) {
	if (error && !suppressErrors) callback$1(error, output);
	else callback$1(null, output);
}
function build$1(options, isSynchronous) {
	const { onlyCounts, group, maxFiles } = options;
	if (onlyCounts) return isSynchronous ? onlyCountsSync : onlyCountsAsync;
	else if (group) return isSynchronous ? groupsSync : groupsAsync;
	else if (maxFiles) return isSynchronous ? limitFilesSync : limitFilesAsync;
	else return isSynchronous ? defaultSync : defaultAsync;
}
const readdirOpts = { withFileTypes: true };
const walkAsync = (state, crawlPath, directoryPath, currentDepth, callback$1) => {
	state.queue.enqueue();
	if (currentDepth < 0) return state.queue.dequeue(null, state);
	const { fs } = state;
	state.visited.push(crawlPath);
	state.counts.directories++;
	fs.readdir(crawlPath || ".", readdirOpts, (error, entries = []) => {
		callback$1(entries, directoryPath, currentDepth);
		state.queue.dequeue(state.options.suppressErrors ? null : error, state);
	});
};
const walkSync = (state, crawlPath, directoryPath, currentDepth, callback$1) => {
	const { fs } = state;
	if (currentDepth < 0) return;
	state.visited.push(crawlPath);
	state.counts.directories++;
	let entries = [];
	try {
		entries = fs.readdirSync(crawlPath || ".", readdirOpts);
	} catch (e) {
		if (!state.options.suppressErrors) throw e;
	}
	callback$1(entries, directoryPath, currentDepth);
};
function build(isSynchronous) {
	return isSynchronous ? walkSync : walkAsync;
}
/**
* This is a custom stateless queue to track concurrent async fs calls.
* It increments a counter whenever a call is queued and decrements it
* as soon as it completes. When the counter hits 0, it calls onQueueEmpty.
*/
var Queue = class {
	count = 0;
	constructor(onQueueEmpty) {
		this.onQueueEmpty = onQueueEmpty;
	}
	enqueue() {
		this.count++;
		return this.count;
	}
	dequeue(error, output) {
		if (this.onQueueEmpty && (--this.count <= 0 || error)) {
			this.onQueueEmpty(error, output);
			if (error) {
				output.controller.abort();
				this.onQueueEmpty = void 0;
			}
		}
	}
};
var Counter = class {
	_files = 0;
	_directories = 0;
	set files(num) {
		this._files = num;
	}
	get files() {
		return this._files;
	}
	set directories(num) {
		this._directories = num;
	}
	get directories() {
		return this._directories;
	}
	/**
	* @deprecated use `directories` instead
	*/
	/* c8 ignore next 3 */
	get dirs() {
		return this._directories;
	}
};
/**
* AbortController is not supported on Node 14 so we use this until we can drop
* support for Node 14.
*/
var Aborter = class {
	aborted = false;
	abort() {
		this.aborted = true;
	}
};
var Walker = class {
	root;
	isSynchronous;
	state;
	joinPath;
	pushDirectory;
	pushFile;
	getArray;
	groupFiles;
	resolveSymlink;
	walkDirectory;
	callbackInvoker;
	constructor(root, options, callback$1) {
		this.isSynchronous = !callback$1;
		this.callbackInvoker = build$1(options, this.isSynchronous);
		this.root = normalizePath$2(root, options);
		this.state = {
			root: isRootDirectory(this.root) ? this.root : this.root.slice(0, -1),
			paths: [""].slice(0, 0),
			groups: [],
			counts: new Counter(),
			options,
			queue: new Queue((error, state) => this.callbackInvoker(state, error, callback$1)),
			symlinks: /* @__PURE__ */ new Map(),
			visited: [""].slice(0, 0),
			controller: new Aborter(),
			fs: options.fs || nativeFs$1
		};
		this.joinPath = build$7(this.root, options);
		this.pushDirectory = build$6(this.root, options);
		this.pushFile = build$5(options);
		this.getArray = build$4(options);
		this.groupFiles = build$3(options);
		this.resolveSymlink = build$2(options, this.isSynchronous);
		this.walkDirectory = build(this.isSynchronous);
	}
	start() {
		this.pushDirectory(this.root, this.state.paths, this.state.options.filters);
		this.walkDirectory(this.state, this.root, this.root, this.state.options.maxDepth, this.walk);
		return this.isSynchronous ? this.callbackInvoker(this.state, null) : null;
	}
	walk = (entries, directoryPath, depth) => {
		const { paths, options: { filters, resolveSymlinks: resolveSymlinks$1, excludeSymlinks, exclude, maxFiles, signal, useRealPaths, pathSeparator }, controller } = this.state;
		if (controller.aborted || signal && signal.aborted || maxFiles && paths.length > maxFiles) return;
		const files = this.getArray(this.state.paths);
		for (let i = 0; i < entries.length; ++i) {
			const entry = entries[i];
			if (entry.isFile() || entry.isSymbolicLink() && !resolveSymlinks$1 && !excludeSymlinks) {
				const filename = this.joinPath(entry.name, directoryPath);
				this.pushFile(filename, files, this.state.counts, filters);
			} else if (entry.isDirectory()) {
				let path = joinDirectoryPath(entry.name, directoryPath, this.state.options.pathSeparator);
				if (exclude && exclude(entry.name, path)) continue;
				this.pushDirectory(path, paths, filters);
				this.walkDirectory(this.state, path, path, depth - 1, this.walk);
			} else if (this.resolveSymlink && entry.isSymbolicLink()) {
				let path = joinPathWithBasePath(entry.name, directoryPath);
				this.resolveSymlink(path, this.state, (stat, resolvedPath) => {
					if (stat.isDirectory()) {
						resolvedPath = normalizePath$2(resolvedPath, this.state.options);
						if (exclude && exclude(entry.name, useRealPaths ? resolvedPath : path + pathSeparator)) return;
						this.walkDirectory(this.state, resolvedPath, useRealPaths ? resolvedPath : path + pathSeparator, depth - 1, this.walk);
					} else {
						resolvedPath = useRealPaths ? resolvedPath : path;
						const filename = basename(resolvedPath);
						const directoryPath$1 = normalizePath$2(dirname(resolvedPath), this.state.options);
						resolvedPath = this.joinPath(filename, directoryPath$1);
						this.pushFile(resolvedPath, files, this.state.counts, filters);
					}
				});
			}
		}
		this.groupFiles(this.state.groups, directoryPath, files);
	};
};
function promise(root, options) {
	return new Promise((resolve$1, reject) => {
		callback(root, options, (err, output) => {
			if (err) return reject(err);
			resolve$1(output);
		});
	});
}
function callback(root, options, callback$1) {
	new Walker(root, options, callback$1).start();
}
function sync(root, options) {
	return new Walker(root, options).start();
}
var APIBuilder = class {
	constructor(root, options) {
		this.root = root;
		this.options = options;
	}
	withPromise() {
		return promise(this.root, this.options);
	}
	withCallback(cb) {
		callback(this.root, this.options, cb);
	}
	sync() {
		return sync(this.root, this.options);
	}
};
let pm = null;
/* c8 ignore next 6 */
try {
	__require.resolve("picomatch");
	pm = __require("picomatch");
} catch {}
var Builder = class {
	globCache = {};
	options = {
		maxDepth: Infinity,
		suppressErrors: true,
		pathSeparator: sep$1,
		filters: []
	};
	globFunction;
	constructor(options) {
		this.options = {
			...this.options,
			...options
		};
		this.globFunction = this.options.globFunction;
	}
	group() {
		this.options.group = true;
		return this;
	}
	withPathSeparator(separator) {
		this.options.pathSeparator = separator;
		return this;
	}
	withBasePath() {
		this.options.includeBasePath = true;
		return this;
	}
	withRelativePaths() {
		this.options.relativePaths = true;
		return this;
	}
	withDirs() {
		this.options.includeDirs = true;
		return this;
	}
	withMaxDepth(depth) {
		this.options.maxDepth = depth;
		return this;
	}
	withMaxFiles(limit) {
		this.options.maxFiles = limit;
		return this;
	}
	withFullPaths() {
		this.options.resolvePaths = true;
		this.options.includeBasePath = true;
		return this;
	}
	withErrors() {
		this.options.suppressErrors = false;
		return this;
	}
	withSymlinks({ resolvePaths = true } = {}) {
		this.options.resolveSymlinks = true;
		this.options.useRealPaths = resolvePaths;
		return this.withFullPaths();
	}
	withAbortSignal(signal) {
		this.options.signal = signal;
		return this;
	}
	normalize() {
		this.options.normalizePath = true;
		return this;
	}
	filter(predicate) {
		this.options.filters.push(predicate);
		return this;
	}
	onlyDirs() {
		this.options.excludeFiles = true;
		this.options.includeDirs = true;
		return this;
	}
	exclude(predicate) {
		this.options.exclude = predicate;
		return this;
	}
	onlyCounts() {
		this.options.onlyCounts = true;
		return this;
	}
	crawl(root) {
		return new APIBuilder(root || ".", this.options);
	}
	withGlobFunction(fn) {
		this.globFunction = fn;
		return this;
	}
	/**
	* @deprecated Pass options using the constructor instead:
	* ```ts
	* new fdir(options).crawl("/path/to/root");
	* ```
	* This method will be removed in v7.0
	*/
	/* c8 ignore next 4 */
	crawlWithOptions(root, options) {
		this.options = {
			...this.options,
			...options
		};
		return new APIBuilder(root || ".", this.options);
	}
	glob(...patterns) {
		if (this.globFunction) return this.globWithOptions(patterns);
		return this.globWithOptions(patterns, ...[{ dot: true }]);
	}
	globWithOptions(patterns, ...options) {
		const globFn = this.globFunction || pm;
		/* c8 ignore next 5 */
		if (!globFn) throw new Error("Please specify a glob function to use glob matching.");
		var isMatch = this.globCache[patterns.join("\0")];
		if (!isMatch) {
			isMatch = globFn(patterns, ...options);
			this.globCache[patterns.join("\0")] = isMatch;
		}
		this.options.filters.push((path) => isMatch(path));
		return this;
	}
};

//#endregion
//#region ../node_modules/.pnpm/tinyglobby@0.2.15/node_modules/tinyglobby/dist/index.mjs
const isReadonlyArray = Array.isArray;
const isWin = process.platform === "win32";
const ONLY_PARENT_DIRECTORIES = /^(\/?\.\.)+$/;
function getPartialMatcher(patterns, options = {}) {
	const patternsCount = patterns.length;
	const patternsParts = Array(patternsCount);
	const matchers = Array(patternsCount);
	const globstarEnabled = !options.noglobstar;
	for (let i = 0; i < patternsCount; i++) {
		const parts = splitPattern(patterns[i]);
		patternsParts[i] = parts;
		const partsCount = parts.length;
		const partMatchers = Array(partsCount);
		for (let j = 0; j < partsCount; j++) partMatchers[j] = (0, import_picomatch.default)(parts[j], options);
		matchers[i] = partMatchers;
	}
	return (input) => {
		const inputParts = input.split("/");
		if (inputParts[0] === ".." && ONLY_PARENT_DIRECTORIES.test(input)) return true;
		for (let i = 0; i < patterns.length; i++) {
			const patternParts = patternsParts[i];
			const matcher = matchers[i];
			const inputPatternCount = inputParts.length;
			const minParts = Math.min(inputPatternCount, patternParts.length);
			let j = 0;
			while (j < minParts) {
				const part = patternParts[j];
				if (part.includes("/")) return true;
				if (!matcher[j](inputParts[j])) break;
				if (globstarEnabled && part === "**") return true;
				j++;
			}
			if (j === inputPatternCount) return true;
		}
		return false;
	};
}
/* node:coverage ignore next 2 */
const WIN32_ROOT_DIR = /^[A-Z]:\/$/i;
const isRoot = isWin ? (p) => WIN32_ROOT_DIR.test(p) : (p) => p === "/";
function buildFormat(cwd, root, absolute) {
	if (cwd === root || root.startsWith(`${cwd}/`)) {
		if (absolute) {
			const start = isRoot(cwd) ? cwd.length : cwd.length + 1;
			return (p, isDir) => p.slice(start, isDir ? -1 : void 0) || ".";
		}
		const prefix = root.slice(cwd.length + 1);
		if (prefix) return (p, isDir) => {
			if (p === ".") return prefix;
			const result = `${prefix}/${p}`;
			return isDir ? result.slice(0, -1) : result;
		};
		return (p, isDir) => isDir && p !== "." ? p.slice(0, -1) : p;
	}
	if (absolute) return (p) => posix$1.relative(cwd, p) || ".";
	return (p) => posix$1.relative(cwd, `${root}/${p}`) || ".";
}
function buildRelative(cwd, root) {
	if (root.startsWith(`${cwd}/`)) {
		const prefix = root.slice(cwd.length + 1);
		return (p) => `${prefix}/${p}`;
	}
	return (p) => {
		const result = posix$1.relative(cwd, `${root}/${p}`);
		if (p.endsWith("/") && result !== "") return `${result}/`;
		return result || ".";
	};
}
const splitPatternOptions = { parts: true };
function splitPattern(path$1) {
	var _result$parts;
	const result = import_picomatch.default.scan(path$1, splitPatternOptions);
	return ((_result$parts = result.parts) === null || _result$parts === void 0 ? void 0 : _result$parts.length) ? result.parts : [path$1];
}
const POSIX_UNESCAPED_GLOB_SYMBOLS = /(?<!\\)([()[\]{}*?|]|^!|[!+@](?=\()|\\(?![()[\]{}!*+?@|]))/g;
const WIN32_UNESCAPED_GLOB_SYMBOLS = /(?<!\\)([()[\]{}]|^!|[!+@](?=\())/g;
const escapePosixPath = (path$1) => path$1.replace(POSIX_UNESCAPED_GLOB_SYMBOLS, "\\$&");
const escapeWin32Path = (path$1) => path$1.replace(WIN32_UNESCAPED_GLOB_SYMBOLS, "\\$&");
/**
* Escapes a path's special characters depending on the platform.
* @see {@link https://superchupu.dev/tinyglobby/documentation#escapePath}
*/
/* node:coverage ignore next */
const escapePath = isWin ? escapeWin32Path : escapePosixPath;
/**
* Checks if a pattern has dynamic parts.
*
* Has a few minor differences with [`fast-glob`](https://github.com/mrmlnc/fast-glob) for better accuracy:
*
* - Doesn't necessarily return `false` on patterns that include `\`.
* - Returns `true` if the pattern includes parentheses, regardless of them representing one single pattern or not.
* - Returns `true` for unfinished glob extensions i.e. `(h`, `+(h`.
* - Returns `true` for unfinished brace expansions as long as they include `,` or `..`.
*
* @see {@link https://superchupu.dev/tinyglobby/documentation#isDynamicPattern}
*/
function isDynamicPattern(pattern, options) {
	if ((options === null || options === void 0 ? void 0 : options.caseSensitiveMatch) === false) return true;
	const scan = import_picomatch.default.scan(pattern);
	return scan.isGlob || scan.negated;
}
function log(...tasks) {
	console.log(`[tinyglobby ${(/* @__PURE__ */ new Date()).toLocaleTimeString("es")}]`, ...tasks);
}
const PARENT_DIRECTORY = /^(\/?\.\.)+/;
const ESCAPING_BACKSLASHES = /\\(?=[()[\]{}!*+?@|])/g;
const BACKSLASHES = /\\/g;
function normalizePattern(pattern, expandDirectories, cwd, props, isIgnore) {
	let result = pattern;
	if (pattern.endsWith("/")) result = pattern.slice(0, -1);
	if (!result.endsWith("*") && expandDirectories) result += "/**";
	const escapedCwd = escapePath(cwd);
	if (path$1.isAbsolute(result.replace(ESCAPING_BACKSLASHES, ""))) result = posix$1.relative(escapedCwd, result);
	else result = posix$1.normalize(result);
	const parentDirectoryMatch = PARENT_DIRECTORY.exec(result);
	const parts = splitPattern(result);
	if (parentDirectoryMatch === null || parentDirectoryMatch === void 0 ? void 0 : parentDirectoryMatch[0]) {
		const n = (parentDirectoryMatch[0].length + 1) / 3;
		let i = 0;
		const cwdParts = escapedCwd.split("/");
		while (i < n && parts[i + n] === cwdParts[cwdParts.length + i - n]) {
			result = result.slice(0, (n - i - 1) * 3) + result.slice((n - i) * 3 + parts[i + n].length + 1) || ".";
			i++;
		}
		const potentialRoot = posix$1.join(cwd, parentDirectoryMatch[0].slice(i * 3));
		if (!potentialRoot.startsWith(".") && props.root.length > potentialRoot.length) {
			props.root = potentialRoot;
			props.depthOffset = -n + i;
		}
	}
	if (!isIgnore && props.depthOffset >= 0) {
		var _props$commonPath;
		(_props$commonPath = props.commonPath) !== null && _props$commonPath !== void 0 || (props.commonPath = parts);
		const newCommonPath = [];
		const length = Math.min(props.commonPath.length, parts.length);
		for (let i = 0; i < length; i++) {
			const part = parts[i];
			if (part === "**" && !parts[i + 1]) {
				newCommonPath.pop();
				break;
			}
			if (part !== props.commonPath[i] || isDynamicPattern(part) || i === parts.length - 1) break;
			newCommonPath.push(part);
		}
		props.depthOffset = newCommonPath.length;
		props.commonPath = newCommonPath;
		props.root = newCommonPath.length > 0 ? posix$1.join(cwd, ...newCommonPath) : cwd;
	}
	return result;
}
function processPatterns({ patterns = ["**/*"], ignore = [], expandDirectories = true }, cwd, props) {
	if (typeof patterns === "string") patterns = [patterns];
	if (typeof ignore === "string") ignore = [ignore];
	const matchPatterns = [];
	const ignorePatterns = [];
	for (const pattern of ignore) {
		if (!pattern) continue;
		if (pattern[0] !== "!" || pattern[1] === "(") ignorePatterns.push(normalizePattern(pattern, expandDirectories, cwd, props, true));
	}
	for (const pattern of patterns) {
		if (!pattern) continue;
		if (pattern[0] !== "!" || pattern[1] === "(") matchPatterns.push(normalizePattern(pattern, expandDirectories, cwd, props, false));
		else if (pattern[1] !== "!" || pattern[2] === "(") ignorePatterns.push(normalizePattern(pattern.slice(1), expandDirectories, cwd, props, true));
	}
	return {
		match: matchPatterns,
		ignore: ignorePatterns
	};
}
function formatPaths(paths, relative) {
	for (let i = paths.length - 1; i >= 0; i--) {
		const path$1 = paths[i];
		paths[i] = relative(path$1);
	}
	return paths;
}
function normalizeCwd(cwd) {
	if (!cwd) return process.cwd().replace(BACKSLASHES, "/");
	if (cwd instanceof URL) return fileURLToPath$1(cwd).replace(BACKSLASHES, "/");
	return path$1.resolve(cwd).replace(BACKSLASHES, "/");
}
function getCrawler(patterns, inputOptions = {}) {
	const options = process.env.TINYGLOBBY_DEBUG ? {
		...inputOptions,
		debug: true
	} : inputOptions;
	const cwd = normalizeCwd(options.cwd);
	if (options.debug) log("globbing with:", {
		patterns,
		options,
		cwd
	});
	if (Array.isArray(patterns) && patterns.length === 0) return [{
		sync: () => [],
		withPromise: async () => []
	}, false];
	const props = {
		root: cwd,
		commonPath: null,
		depthOffset: 0
	};
	const processed = processPatterns({
		...options,
		patterns
	}, cwd, props);
	if (options.debug) log("internal processing patterns:", processed);
	const matchOptions = {
		dot: options.dot,
		nobrace: options.braceExpansion === false,
		nocase: options.caseSensitiveMatch === false,
		noextglob: options.extglob === false,
		noglobstar: options.globstar === false,
		posix: true
	};
	const matcher = (0, import_picomatch.default)(processed.match, {
		...matchOptions,
		ignore: processed.ignore
	});
	const ignore = (0, import_picomatch.default)(processed.ignore, matchOptions);
	const partialMatcher = getPartialMatcher(processed.match, matchOptions);
	const format = buildFormat(cwd, props.root, options.absolute);
	const formatExclude = options.absolute ? format : buildFormat(cwd, props.root, true);
	const fdirOptions = {
		filters: [options.debug ? (p, isDirectory) => {
			const path$1 = format(p, isDirectory);
			const matches = matcher(path$1);
			if (matches) log(`matched ${path$1}`);
			return matches;
		} : (p, isDirectory) => matcher(format(p, isDirectory))],
		exclude: options.debug ? (_, p) => {
			const relativePath = formatExclude(p, true);
			const skipped = relativePath !== "." && !partialMatcher(relativePath) || ignore(relativePath);
			if (skipped) log(`skipped ${p}`);
			else log(`crawling ${p}`);
			return skipped;
		} : (_, p) => {
			const relativePath = formatExclude(p, true);
			return relativePath !== "." && !partialMatcher(relativePath) || ignore(relativePath);
		},
		fs: options.fs ? {
			readdir: options.fs.readdir || nativeFs.readdir,
			readdirSync: options.fs.readdirSync || nativeFs.readdirSync,
			realpath: options.fs.realpath || nativeFs.realpath,
			realpathSync: options.fs.realpathSync || nativeFs.realpathSync,
			stat: options.fs.stat || nativeFs.stat,
			statSync: options.fs.statSync || nativeFs.statSync
		} : void 0,
		pathSeparator: "/",
		relativePaths: true,
		resolveSymlinks: true,
		signal: options.signal
	};
	if (options.deep !== void 0) fdirOptions.maxDepth = Math.round(options.deep - props.depthOffset);
	if (options.absolute) {
		fdirOptions.relativePaths = false;
		fdirOptions.resolvePaths = true;
		fdirOptions.includeBasePath = true;
	}
	if (options.followSymbolicLinks === false) {
		fdirOptions.resolveSymlinks = false;
		fdirOptions.excludeSymlinks = true;
	}
	if (options.onlyDirectories) {
		fdirOptions.excludeFiles = true;
		fdirOptions.includeDirs = true;
	} else if (options.onlyFiles === false) fdirOptions.includeDirs = true;
	props.root = props.root.replace(BACKSLASHES, "");
	const root = props.root;
	if (options.debug) log("internal properties:", props);
	const relative = cwd !== root && !options.absolute && buildRelative(cwd, props.root);
	return [new Builder(fdirOptions).crawl(root), relative];
}
async function glob(patternsOrOptions, options) {
	if (patternsOrOptions && (options === null || options === void 0 ? void 0 : options.patterns)) throw new Error("Cannot pass patterns as both an argument and an option");
	const isModern = isReadonlyArray(patternsOrOptions) || typeof patternsOrOptions === "string";
	const opts = isModern ? options : patternsOrOptions;
	const [crawler, relative] = getCrawler(isModern ? patternsOrOptions : patternsOrOptions.patterns, opts);
	if (!relative) return crawler.withPromise();
	return formatPaths(await crawler.withPromise(), relative);
}

//#endregion
//#region ../node_modules/.pnpm/flatted@3.3.3/node_modules/flatted/esm/index.js
const { parse: $parse, stringify: $stringify } = JSON;
const { keys } = Object;
const Primitive = String;
const primitive = "string";
const ignore = {};
const object = "object";
const noop = (_, value) => value;
const primitives = (value) => value instanceof Primitive ? Primitive(value) : value;
const Primitives = (_, value) => typeof value === primitive ? new Primitive(value) : value;
const revive = (input, parsed, output, $) => {
	const lazy = [];
	for (let ke = keys(output), { length } = ke, y = 0; y < length; y++) {
		const k = ke[y];
		const value = output[k];
		if (value instanceof Primitive) {
			const tmp = input[value];
			if (typeof tmp === object && !parsed.has(tmp)) {
				parsed.add(tmp);
				output[k] = ignore;
				lazy.push({
					k,
					a: [
						input,
						parsed,
						tmp,
						$
					]
				});
			} else output[k] = $.call(output, k, tmp);
		} else if (output[k] !== ignore) output[k] = $.call(output, k, value);
	}
	for (let { length } = lazy, i = 0; i < length; i++) {
		const { k, a } = lazy[i];
		output[k] = $.call(output, k, revive.apply(null, a));
	}
	return output;
};
const set = (known, input, value) => {
	const index = Primitive(input.push(value) - 1);
	known.set(value, index);
	return index;
};
/**
* Converts a specialized flatted string into a JS value.
* @param {string} text
* @param {(this: any, key: string, value: any) => any} [reviver]
* @returns {any}
*/
const parse = (text, reviver) => {
	const input = $parse(text, Primitives).map(primitives);
	const value = input[0];
	const $ = reviver || noop;
	const tmp = typeof value === object && value ? revive(input, /* @__PURE__ */ new Set(), value, $) : value;
	return $.call({ "": tmp }, "", tmp);
};
/**
* Converts a JS value into a specialized flatted string.
* @param {any} value
* @param {((this: any, key: string, value: any) => any) | (string | number)[] | null | undefined} [replacer]
* @param {string | number | undefined} [space]
* @returns {string}
*/
const stringify = (value, replacer, space) => {
	const $ = replacer && typeof replacer === object ? (k, v) => k === "" || -1 < replacer.indexOf(k) ? v : void 0 : replacer || noop;
	const known = /* @__PURE__ */ new Map();
	const input = [];
	const output = [];
	let i = +set(known, input, $.call({ "": value }, "", value));
	let firstRun = !i;
	while (i < input.length) {
		firstRun = true;
		output[i] = $stringify(input[i++], replace, space);
	}
	return "[" + output.join(",") + "]";
	function replace(key, value) {
		if (firstRun) {
			firstRun = !firstRun;
			return value;
		}
		const after = $.call(this, key, value);
		switch (typeof after) {
			case object: if (after === null) return after;
			case primitive: return known.get(after) || set(known, input, after);
		}
		return after;
	}
};

//#endregion
//#region ../node_modules/.pnpm/cspell@9.6.4/node_modules/cspell/dist/esm/application-DYABxs7R.js
var ImplChannel = class {
	constructor(stream) {
		this.stream = stream;
	}
	write = (msg) => this.stream.write(msg);
	writeLine = (msg) => this.write(msg + "\n");
	clearLine = (dir, callback) => this.stream.clearLine?.(dir, callback) ?? false;
	printLine = (...params) => this.writeLine(params.length && formatWithOptions({ colors: this.stream.hasColors?.() }, ...params) || "");
	getColorLevel = () => getColorLevel(this.stream);
};
var Console = class {
	stderrChannel;
	stdoutChannel;
	constructor(stdout = process.stdout, stderr = process.stderr) {
		this.stdout = stdout;
		this.stderr = stderr;
		this.stderrChannel = new ImplChannel(this.stderr);
		this.stdoutChannel = new ImplChannel(this.stdout);
	}
	log = (...p) => this.stdoutChannel.printLine(...p);
	error = (...p) => this.stderrChannel.printLine(...p);
	info = this.log;
	warn = this.error;
};
const console$2 = new Console();
function getColorLevel(stream) {
	switch (stream.getColorDepth?.() || 0) {
		case 1: return 1;
		case 4: return 2;
		case 24: return 3;
		default: return 0;
	}
}
var CheckFailed = class extends Error {
	constructor(message, exitCode = 1) {
		super(message);
		this.exitCode = exitCode;
	}
};
var ApplicationError = class extends Error {
	constructor(message, exitCode = 1, cause) {
		super(message);
		this.exitCode = exitCode;
		this.cause = cause;
	}
};
var IOError = class extends ApplicationError {
	constructor(message, cause) {
		super(message, void 0, cause);
		this.cause = cause;
	}
	get code() {
		return this.cause.code;
	}
	isNotFound() {
		return this.cause.code === "ENOENT";
	}
};
function toError$1(e) {
	if (isError(e)) return e;
	if (isErrorLike(e)) {
		const ex = new Error(e.message, { cause: e });
		if (e.code !== void 0) ex.code = e.code;
		return ex;
	}
	const message = format(e);
	return new Error(message);
}
function isError(e) {
	return e instanceof Error;
}
function isErrorLike(e) {
	if (e instanceof Error) return true;
	if (!e || typeof e !== "object") return false;
	return typeof e.message === "string";
}
function toApplicationError(e, message) {
	if (e instanceof ApplicationError && !message) return e;
	const err = toError$1(e);
	return new ApplicationError(message ?? err.message, void 0, err);
}
function getPerfMeasurements() {
	const measurements = performance.getEntriesByType("measure");
	const root = {
		depth: -1,
		totalTimeMs: 0,
		nestedTimeMs: 0,
		children: /* @__PURE__ */ new Map()
	};
	if (!measurements.length) return [];
	const stack = [];
	let depth = 0;
	for (let i = 0; i < measurements.length; i++) {
		const m = measurements[i];
		rollUpStack(m.startTime);
		const s = {
			m,
			p: addToParent(depth === 0 ? root : stack[depth - 1].p, m)
		};
		stack[depth++] = s;
	}
	sortChildren(root);
	return [...root.children.values()].flatMap((r) => [...flattenChildren(r)]);
	function contains(m, t) {
		const stop = m.startTime + m.duration;
		return t >= m.startTime && t < stop;
	}
	function rollUpStack(t) {
		for (; depth > 0 && !contains(stack[depth - 1].m, t); --depth);
	}
	function addToParent(p, m) {
		p.children ??= /* @__PURE__ */ new Map();
		p.nestedTimeMs += m.duration;
		return updateChild(p.children, m, p.depth + 1);
	}
	function updateChild(children, m, depth) {
		const p = children.get(m.name);
		if (p) {
			p.totalTimeMs += m.duration;
			p.count += 1;
			p.minTimeMs = Math.min(p.minTimeMs, m.duration);
			p.maxTimeMs = Math.max(p.maxTimeMs, m.duration);
			return p;
		}
		const n = {
			name: m.name,
			depth,
			totalTimeMs: m.duration,
			nestedTimeMs: 0,
			count: 1,
			minTimeMs: m.duration,
			maxTimeMs: m.duration
		};
		children.set(m.name, n);
		return n;
	}
	function* flattenChildren(m) {
		yield m;
		if (!m.children) return;
		for (const child of m.children.values()) yield* flattenChildren(child);
	}
	function sortChildren(m) {
		if (!m.children) return;
		m.children = new Map([...m.children.entries()].sort((a, b) => b[1].totalTimeMs - a[1].totalTimeMs));
		m.children.forEach(sortChildren);
	}
}
function isAnsiString(s) {
	return s.includes("\x1B") || s.includes("");
}
/**
*
* @param s - the string to measure - should NOT contains ANSI codes
* @param tabWidth -
* @returns
*/
function width(s, tabWidth = 1) {
	return s.replaceAll("", ".").replaceAll("	", " ".repeat(tabWidth)).replaceAll(/\p{M}/gu, "").replaceAll(/\p{L}/gu, ".").replaceAll(/[\u0000-\u001F\u0300-\u036F]/g, "").replaceAll(/[\uD800-\uDBFF][\uDC00-\uDFFF]/g, ".").length;
}
/**
* Measure the width of a string containing ANSI control characters.
* @param s - string to measure with width in characters.
* @returns the approximate number of screen characters.
*/
function ansiWidth(s) {
	return width(stripVTControlCharacters(s));
}
function fragmentString(str, splitOnRegex, sType) {
	const fragments = [];
	let lastIndex = 0;
	for (const match of str.matchAll(new RegExp(splitOnRegex))) {
		if (match.index > lastIndex) fragments.push({
			type: "text",
			text: str.slice(lastIndex, match.index)
		});
		fragments.push({
			type: sType,
			text: match[0]
		});
		lastIndex = match.index + match[0].length;
	}
	if (lastIndex < str.length) fragments.push({
		type: "text",
		text: str.slice(lastIndex)
	});
	return fragments;
}
const ansi = ansiRegex();
function parseAnsiStr(str) {
	return fragmentString(str, ansi, "ansi");
}
/**
* Prune the end of a string to fit within a specified width, adding an ellipsis if necessary.
* @param str - the text to prune - ANSI is supported
* @param maxWidth - the maximum width of the text
* @param pad - the string to use for padding, default is ''
* @returns the pruned text
*/
function pruneAnsiTextEnd(str, maxWidth, pad = "") {
	if (!maxWidth || maxWidth <= 0) return str;
	if (str.length <= maxWidth) return str;
	if (ansiWidth(str) <= maxWidth) return str;
	const padWidth = ansiWidth(pad);
	const fragments = parseAnsiStr(str);
	let remaining = maxWidth - padWidth;
	for (const frag of fragments) {
		if (frag.type !== "text") continue;
		if (remaining <= 0) {
			frag.text = "";
			continue;
		}
		const pruned = pruneTextEnd(frag.text, remaining, pad);
		if (pruned !== frag.text) {
			frag.text = pruned;
			remaining = 0;
			continue;
		}
		remaining -= width(frag.text);
	}
	return fragments.map((frag) => frag.text).join("");
}
/**
* Prune the end of a string to fit within a specified width, adding an ellipsis if necessary.
* @param str - the text to prune - ANSI is not supported
* @param maxWidth - the maximum width of the text
* @param pad - the string to use for padding, default is ''
* @returns the pruned text
*/
function pruneTextEnd(str, maxWidth, pad = "") {
	if (!maxWidth || maxWidth <= 0) return str;
	if (str.length <= maxWidth) return str;
	if (isAnsiString(str)) return pruneAnsiTextEnd(str, maxWidth, pad);
	const maxWidthWithPad = maxWidth - width(pad);
	const letters = [...str];
	let len = 0;
	for (let i = 0; i < letters.length; i++) {
		const c = letters[i];
		len += width(c);
		if (len > maxWidthWithPad) {
			let j = i + 1;
			while (j < letters.length && width(letters[j]) === 0) ++j;
			return j === letters.length ? str : letters.slice(0, i).join("") + pad;
		}
	}
	return str;
}
function pad(s, w) {
	const p = padWidth(s, w);
	if (!p) return s;
	return s.padEnd(p + s.length);
}
function padWidth(s, target) {
	const sWidth = ansiWidth(s);
	return Math.max(target - sWidth, 0);
}
function padLeft(s, w) {
	const p = padWidth(s, w);
	if (!p) return s;
	return s.padStart(p + s.length);
}
function tableToLines(table, deliminator) {
	const del = deliminator || table.deliminator || " | ";
	const columnWidths = [];
	const columnAlignments = table.columnAlignments || [];
	const maxColumnWidthsMap = table.maxColumnWidths || {};
	const tableIndent = table.indent ? typeof table.indent === "number" ? " ".repeat(table.indent) : table.indent : "";
	const { header, rows } = table;
	const simpleHeader = header.map((col) => Array.isArray(col) ? col[1] : col);
	const columnFieldNames = header.map((col) => Array.isArray(col) ? col[0] : col);
	const maxColumnWidths = columnFieldNames.map((field, idx) => maxColumnWidthsMap[field] ?? maxColumnWidthsMap[idx]);
	function getCell(row, col) {
		return getCellFromRow(rows[row], col);
	}
	function getCellFromRow(row, col) {
		if (!row) return void 0;
		if (Array.isArray(row)) return row[col];
		return row[columnFieldNames[col]];
	}
	function rowToCells(row) {
		if (Array.isArray(row)) return row;
		return columnFieldNames.map((fieldName) => row[fieldName]);
	}
	function getText(col, maxWidth) {
		return !col ? "" : typeof col === "string" ? pruneTextEnd(col, maxWidth) : col(maxWidth);
	}
	function getRCText(row, col, maxWidth) {
		return getText(getCell(row, col), maxWidth);
	}
	function recordHeaderWidths(header) {
		header.forEach((col, idx) => {
			columnWidths[idx] = Math.max(ansiWidth(col), columnWidths[idx] || 0);
		});
	}
	function recordColWidths() {
		for (let rowIndex = 0; rowIndex < rows.length; rowIndex++) for (let colIndex = 0; colIndex < columnFieldNames.length; colIndex++) columnWidths[colIndex] = Math.max(ansiWidth(getRCText(rowIndex, colIndex, void 0)), columnWidths[colIndex] || 0);
	}
	function justifyRow(c, i) {
		return columnAlignments[i] === "R" ? padLeft(c, columnWidths[i]) : pad(c, columnWidths[i]);
	}
	function toHeaderLine(header) {
		return tableIndent + decorateRowWith(header.map((c, i) => getText(c, columnWidths[i])), justifyRow, headerDecorator).join(del);
	}
	function toLine(row) {
		return tableIndent + decorateRowWith(rowToCells(row).map((c, i) => getText(c, columnWidths[i])), justifyRow).join(del);
	}
	function* process() {
		if (table.title) yield table.title;
		yield toHeaderLine(simpleHeader);
		yield* rows.map(toLine);
	}
	function sumColumnWidths() {
		return columnWidths.reduce((sum, width) => sum + width, 0);
	}
	function adjustColWidths() {
		for (let i = 0; i < columnWidths.length; i++) {
			const mw = maxColumnWidths[i];
			if (!mw) continue;
			columnWidths[i] = Math.min(columnWidths[i], mw);
		}
		if (!table.terminalWidth) return;
		const dWidth = (columnWidths.length - 1) * ansiWidth(del);
		const lineWidth = table.terminalWidth - dWidth;
		if (lineWidth <= columnWidths.length * 2) {
			const fixedWidth = Math.max(Math.min(...columnWidths), 5);
			for (let i = 0; i < columnWidths.length; i++) columnWidths[i] = fixedWidth;
			return;
		}
		if (columnWidths.length === 1) {
			columnWidths[0] = lineWidth;
			return;
		}
		function trimWidestColumn(neededToTrim) {
			let first = 0;
			let second = 0;
			for (let i = 0; i < columnWidths.length; i++) if (columnWidths[i] > columnWidths[first]) {
				second = first;
				first = i;
			} else if (columnWidths[i] > columnWidths[second]) second = i;
			const diff = Math.max(columnWidths[first] - columnWidths[second], 1);
			columnWidths[first] -= Math.min(diff, neededToTrim);
		}
		for (let sum = sumColumnWidths(); sum > lineWidth; sum = sumColumnWidths()) trimWidestColumn(sum - lineWidth);
	}
	recordHeaderWidths(simpleHeader);
	recordColWidths();
	adjustColWidths();
	return [...process()];
}
function headerDecorator(t) {
	return source_default.bold(source_default.underline(t));
}
function decorateRowWith(row, ...decorators) {
	return decorators.reduce((row, decorator) => row.map(decorator), row);
}
const uniqueFn = uniqueFilterFnGenerator;
function uniqueFilterFnGenerator(extractFn) {
	const values = /* @__PURE__ */ new Set();
	const extractor = extractFn || ((a) => a);
	return (v) => {
		const vv = extractor(v);
		const ret = !values.has(vv);
		values.add(vv);
		return ret;
	};
}
/**
* Removed all properties with a value of `undefined` from the object.
* @param src - the object to clean.
* @returns the same object with all properties with a value of `undefined` removed.
*/
function clean(src) {
	const r = src;
	for (const key of Object.keys(r)) if (r[key] === void 0) delete r[key];
	return r;
}
const templateIssue = `{green $filename}:{yellow $row:$col} - $message ({red $text}) $quickFix`;
const templateIssueNoFix = `{green $filename}:{yellow $row:$col} - $message ({red $text})`;
const templateIssueWithSuggestions = `{green $filename}:{yellow $row:$col} - $message ({red $text}) Suggestions: {yellow [$suggestions]}`;
const templateIssueWithContext = `{green $filename}:{yellow $row:$col} $padRowCol- $message ({red $text})$padContext -- {gray $contextLeft}{red {underline $text}}{gray $contextRight}`;
const templateIssueWithContextWithSuggestions = `{green $filename}:{yellow $row:$col} $padRowCol- $message ({red $text})$padContext -- {gray $contextLeft}{red {underline $text}}{gray $contextRight}\n\t Suggestions: {yellow [$suggestions]}`;
const templateIssueLegacy = `{green $filename}[$row, $col]: $message: {red $text}`;
const templateIssueWordsOnly = "$text";
assert(true);
/**
*
* @param template - The template to use for the issue.
* @param uniqueIssues - If true, only unique issues will be reported.
* @param reportedIssuesCollection - optional collection to store reported issues.
* @returns issueEmitter function
*/
function genIssueEmitter(stdIO, errIO, template, uniqueIssues, reportedIssuesCollection) {
	const uniqueFilter = uniqueIssues ? uniqueFilterFnGenerator((issue) => issue.text) : () => true;
	const defaultWidth = 10;
	let maxWidth = defaultWidth;
	let uri;
	return function issueEmitter(issue) {
		if (!uniqueFilter(issue)) return;
		if (uri !== issue.uri) {
			maxWidth = defaultWidth;
			uri = issue.uri;
		}
		maxWidth = Math.max(maxWidth * .999, issue.text.length, 10);
		const issueText = formatIssue(stdIO, template, issue, Math.ceil(maxWidth));
		reportedIssuesCollection?.push(formatIssue(errIO, template, issue, Math.ceil(maxWidth)));
		stdIO.writeLine(issueText);
	};
}
function nullEmitter() {}
function relativeUriFilename(uri, rootURL) {
	const url = toFileURL(uri);
	const rel = urlRelative(rootURL, url);
	if (rel.startsWith("..")) return toFilePathOrHref(url);
	return rel;
}
function reportProgress(io, p, cwdURL, options) {
	if (p.type === "ProgressFileComplete") return reportProgressFileComplete(io, p, cwdURL, options);
	if (p.type === "ProgressFileBegin") return reportProgressFileBegin(io, p, cwdURL);
}
function determineFilename(io, p, cwd) {
	const fc = "" + p.fileCount;
	return {
		idx: (" ".repeat(fc.length) + p.fileNum).slice(-fc.length) + "/" + fc,
		filename: io.chalk.gray(relativeUriFilename(p.filename, cwd))
	};
}
function reportProgressFileBegin(io, p, cwdURL) {
	const { idx, filename } = determineFilename(io, p, cwdURL);
	if (io.getColorLevel() > 0) {
		io.clearLine?.(0);
		io.write(`${idx} ${filename}\r`);
	}
}
function reportProgressFileComplete(io, p, cwd, options) {
	const { idx, filename } = determineFilename(io, p, cwd);
	const { verbose, debug } = options;
	const time = reportTime(io, p.elapsedTimeMs, !!p.cached);
	const skippedReason = p.skippedReason ? ` (${p.skippedReason})` : "";
	const skipped = p.processed === false ? ` skipped${skippedReason}` : "";
	const hasErrors = p.numErrors ? io.chalk.red` X` : "";
	const msg = `${idx} ${filename} ${time}${skipped}${hasErrors}${(verbose || debug || hasErrors || isSlow(p.elapsedTimeMs) || io.getColorLevel() < 1 ? "\n" : "") || "\r"}`;
	io.write(msg);
}
function reportTime(io, elapsedTimeMs, cached) {
	if (cached) return io.chalk.green("cached");
	if (elapsedTimeMs === void 0) return "-";
	const slow = isSlow(elapsedTimeMs);
	return (!slow ? io.chalk.white : slow === 1 ? io.chalk.yellow : io.chalk.redBright)(elapsedTimeMs.toFixed(2) + "ms");
}
function isSlow(elapsedTmeMs) {
	if (!elapsedTmeMs || elapsedTmeMs < 1e3) return 0;
	if (elapsedTmeMs < 2e3) return 1;
	return 2;
}
function getReporter(options, config) {
	const perfStats = {
		filesProcessed: 0,
		filesSkipped: 0,
		filesCached: 0,
		accumulatedTimeMs: 0,
		startTime: performance.now(),
		perf: Object.create(null)
	};
	const noColor = options.color === false;
	const forceColor = options.color === true;
	const uniqueIssues = config?.unique || false;
	const defaultIssueTemplate = options.wordsOnly ? templateIssueWordsOnly : options.legacy ? templateIssueLegacy : options.showContext ? options.showSuggestions ? templateIssueWithContextWithSuggestions : templateIssueWithContext : options.showSuggestions ? templateIssueWithSuggestions : options.showSuggestions === false ? templateIssueNoFix : templateIssue;
	const { fileGlobs, silent, summary, issues, progress: showProgress, verbose, debug } = options;
	const issueTemplate = config?.issueTemplate || defaultIssueTemplate;
	assertCheckTemplate(issueTemplate);
	const console$1 = config?.console || console$2;
	const colorLevel = noColor ? 0 : forceColor ? 2 : console$1.stdoutChannel.getColorLevel();
	const stdio = {
		...console$1.stdoutChannel,
		chalk: new Chalk({ level: colorLevel })
	};
	const stderr = {
		...console$1.stderrChannel,
		chalk: new Chalk({ level: colorLevel })
	};
	const consoleError = (msg) => stderr.writeLine(msg);
	function createInfoLog(wrap) {
		return (msg) => console$1.info(wrap(msg));
	}
	const emitters = {
		Debug: !silent && debug ? createInfoLog(stdio.chalk.cyan) : nullEmitter,
		Info: !silent && verbose ? createInfoLog(stdio.chalk.yellow) : nullEmitter,
		Warning: createInfoLog(stdio.chalk.yellow)
	};
	function infoEmitter(message, msgType) {
		emitters[msgType]?.(message);
	}
	const rootURL = toFileDirURL(options.root || process.cwd());
	function relativeIssue(fn) {
		const fnFilename = options.relative ? (uri) => relativeUriFilename(uri, rootURL) : (uri) => toFilePathOrHref(toFileURL(uri, rootURL));
		return (i) => {
			const fullFilename = i.uri ? toFilePathOrHref(toFileURL(i.uri, rootURL)) : "";
			const filename = i.uri ? fnFilename(i.uri) : "";
			fn({
				...i,
				filename,
				fullFilename
			});
		};
	}
	const issuesCollection = void 0;
	const errorCollection = [];
	function errorEmitter(message, error) {
		if (isSpellingDictionaryLoadError(error)) error = error.cause;
		const errorText = formatWithOptions({ colors: stderr.stream.hasColors?.() }, stderr.chalk.red(message), debug ? error : error.toString());
		errorCollection?.push(errorText);
		consoleError(errorText);
	}
	const resultEmitter = (result) => {
		if (!fileGlobs.length && !result.files) return;
		const { files, issues, cachedFiles, filesWithIssues, errors, skippedFiles } = result;
		const numFilesWithIssues = filesWithIssues.size;
		const chalk = stderr.chalk;
		if (stderr.getColorLevel() > 0) {
			stderr.write("\r");
			stderr.clearLine(0);
		}
		if (issuesCollection?.length || errorCollection?.length) consoleError("-------------------------------------------");
		if (issuesCollection?.length) {
			consoleError("Issues found:");
			issuesCollection.forEach((issue) => consoleError(issue));
		}
		const filesChecked = files - (skippedFiles || 0);
		const cachedFilesText = cachedFiles ? ` (${cachedFiles} from cache)` : "";
		const skippedFilesText = skippedFiles ? `, skipped: ${skippedFiles}` : "";
		const withErrorsText = errors ? ` with ${errors} error${errors === 1 ? "" : "s"}` : "";
		consoleError(`CSpell\u003A Files checked: ${filesChecked}${cachedFilesText}${skippedFilesText}, Issues found: ${issues} in ${numFilesWithIssues === 1 ? "1 file" : `${numFilesWithIssues} files`}${withErrorsText}.`);
		if (errorCollection?.length && issues > 5) {
			consoleError("-------------------------------------------");
			consoleError("Errors:");
			errorCollection.forEach((error) => consoleError(error));
		}
		if (options.showPerfSummary) {
			const elapsedTotal = performance.now() - perfStats.startTime;
			consoleError("-------------------------------------------");
			consoleError("Performance Summary:");
			consoleError(`  Files Processed : ${perfStats.filesProcessed.toString().padStart(11)}`);
			consoleError(`  Files Skipped   : ${perfStats.filesSkipped.toString().padStart(11)}`);
			consoleError(`  Files Cached    : ${perfStats.filesCached.toString().padStart(11)}`);
			consoleError(`  Processing Time : ${perfStats.accumulatedTimeMs.toFixed(2).padStart(9)}ms`);
			consoleError(`  Total Time      : ${elapsedTotal.toFixed(2).padStart(9)}ms`);
			const tableStats = {
				title: chalk.bold("Perf Stats:"),
				header: ["Name", "Time (ms)"],
				columnAlignments: ["L", "R"],
				indent: 2,
				rows: Object.entries(perfStats.perf).filter((p) => !!p[1]).map(([key, value]) => [key, value.toFixed(2)])
			};
			consoleError("");
			for (const line of tableToLines(tableStats)) consoleError(line);
			if (options.verboseLevel) verbosePerfReport();
		}
	};
	function verbosePerfReport() {
		const perfMeasurements = getPerfMeasurements();
		if (!perfMeasurements.length) return;
		const notable = extractNotableBySelfTimeInGroup(perfMeasurements);
		const chalk = stderr.chalk;
		const maxDepth = Math.max(...perfMeasurements.map((m) => m.depth));
		const depthIndicator = (d) => "".repeat(d) + " ".repeat(maxDepth - d);
		const rows = perfMeasurements.map((m) => {
			const cbd = (text) => colorByDepth(chalk, m.depth, text);
			const cNotable = (text) => notable.has(m) ? chalk.yellow(text) : text;
			return [
				chalk.dim("".repeat(m.depth)) + colorByDepthGrayscale(stderr.chalk, m.depth, m.name),
				cbd(m.totalTimeMs.toFixed(2) + chalk.dim(depthIndicator(m.depth))),
				cbd(cNotable((m.totalTimeMs - m.nestedTimeMs).toFixed(2))),
				cbd(m.count.toString()),
				cbd(m.minTimeMs.toFixed(2)),
				cbd(m.maxTimeMs.toFixed(2)),
				cbd((m.totalTimeMs / m.count).toFixed(2))
			];
		});
		const table = tableToLines({
			title: chalk.bold("Detailed Measurements:"),
			header: [
				"Name",
				"Total Time (ms)",
				"Self (ms)",
				"Count",
				"Min (ms)",
				"Max (ms)",
				"Avg (ms)"
			],
			rows,
			columnAlignments: [
				"L",
				"R",
				"R",
				"R",
				"R",
				"R",
				"R"
			],
			indent: 2
		});
		consoleError("\n-------------------------------------------\n");
		for (const line of table) consoleError(line);
	}
	function colorByDepth(chalk, depth, text) {
		const colors = [
			chalk.green,
			chalk.cyan,
			chalk.blue,
			chalk.magenta,
			chalk.red
		];
		const color = colors[depth % colors.length];
		if (depth / colors.length >= 1) return chalk.dim(color(text));
		return color(text);
	}
	function colorByDepthGrayscale(chalk, depth, text) {
		const grayLevel = Math.max(32, 255 - depth * 20);
		return chalk.rgb(grayLevel, grayLevel, grayLevel)(text);
	}
	function collectPerfStats(p) {
		if (p.cached) {
			perfStats.filesCached++;
			return;
		}
		perfStats.filesProcessed += p.processed ? 1 : 0;
		perfStats.filesSkipped += !p.processed ? 1 : 0;
		perfStats.accumulatedTimeMs += p.elapsedTimeMs || 0;
		if (!p.perf) return;
		for (const [key, value] of Object.entries(p.perf)) if (typeof value === "number") perfStats.perf[key] = (perfStats.perf[key] || 0) + value;
	}
	function progress(p) {
		if (!silent && showProgress) reportProgress(stderr, p, rootURL, options);
		if (p.type === "ProgressFileComplete") collectPerfStats(p);
	}
	return {
		issue: relativeIssue(silent || !issues ? nullEmitter : genIssueEmitter(stdio, stderr, issueTemplate, uniqueIssues, issuesCollection)),
		error: silent ? nullEmitter : errorEmitter,
		info: infoEmitter,
		debug: emitters.Debug,
		progress,
		result: !silent && summary ? resultEmitter : nullEmitter,
		features: void 0
	};
}
function extractNotableBySelfTimeInGroup(measurements) {
	const notable = /* @__PURE__ */ new Set();
	if (!measurements.length) return notable;
	let highest;
	let highestSelfTime = 0;
	for (const m of measurements) {
		if (m.depth === 0 || !highest) {
			if (highest) notable.add(highest);
			highest = m;
			highestSelfTime = m.totalTimeMs - m.nestedTimeMs;
			continue;
		}
		const selfTime = m.totalTimeMs - m.nestedTimeMs;
		if (selfTime > highestSelfTime) {
			highest = m;
			highestSelfTime = selfTime;
		}
	}
	if (highest) notable.add(highest);
	return notable;
}
function formatIssue(io, templateStr, issue, maxIssueTextWidth) {
	function clean(t) {
		return t.replace(/\s+/, " ");
	}
	const { uri = "", filename, row, col, text, context = issue.line, offset } = issue;
	const contextLeft = clean(context.text.slice(0, offset - context.offset));
	const contextRight = clean(context.text.slice(offset + text.length - context.offset));
	const contextFull = clean(context.text);
	const padContext = " ".repeat(Math.max(maxIssueTextWidth - text.length, 0));
	const rowText = row.toString();
	const colText = col.toString();
	const padRowCol = " ".repeat(Math.max(1, 8 - (rowText.length + colText.length)));
	const suggestions = formatSuggestions(io, issue);
	const msg = issue.message || (issue.isFlagged ? "Forbidden word" : "Unknown word");
	const messageColored = issue.isFlagged ? `{yellow ${msg}}` : msg;
	const substitutions = {
		$col: colText,
		$contextFull: contextFull,
		$contextLeft: contextLeft,
		$contextRight: contextRight,
		$filename: filename,
		$padContext: padContext,
		$padRowCol: padRowCol,
		$row: rowText,
		$suggestions: suggestions,
		$text: text,
		$uri: uri,
		$quickFix: formatQuickFix(io, issue),
		$message: msg,
		$messageColored: messageColored
	};
	const t = templateStr.replaceAll("$messageColored", messageColored);
	return substitute(makeTemplate(io.chalk)(t), substitutions).trimEnd();
}
function formatSuggestions(io, issue) {
	if (issue.suggestionsEx) return issue.suggestionsEx.map((sug) => sug.isPreferred ? io.chalk.italic(io.chalk.bold(sug.wordAdjustedToMatchCase || sug.word)) + "*" : sug.wordAdjustedToMatchCase || sug.word).join(", ");
	if (issue.suggestions) return issue.suggestions.join(", ");
	return "";
}
function formatQuickFix(io, issue) {
	if (!issue.suggestionsEx?.length) return "";
	const preferred = issue.suggestionsEx.filter((sug) => sug.isPreferred).map((sug) => sug.wordAdjustedToMatchCase || sug.word);
	if (!preferred.length) return "";
	return `fix: (${preferred.map((w) => io.chalk.italic(io.chalk.yellow(w))).join(", ")})`;
}
function substitute(text, substitutions) {
	const subs = [];
	for (const [match, replaceWith] of Object.entries(substitutions)) {
		const len = match.length;
		for (let i = text.indexOf(match); i >= 0; i = text.indexOf(match, i)) {
			const end = i + len;
			const reg = /\b/y;
			reg.lastIndex = end;
			if (reg.test(text)) subs.push([
				i,
				end,
				replaceWith
			]);
			i = end;
		}
	}
	subs.sort((a, b) => a[0] - b[0]);
	let i = 0;
	function sub(r) {
		const [a, b, t] = r;
		const prefix = text.slice(i, a);
		i = b;
		return prefix + t;
	}
	return subs.map(sub).join("") + text.slice(i);
}
function assertCheckTemplate(template) {
	const r = checkTemplate(template);
	if (r instanceof Error) throw r;
}
function checkTemplate(template) {
	const chalkTemplate = makeTemplate(new Chalk());
	const substitutions = {
		$col: "<col>",
		$contextFull: "<contextFull>",
		$contextLeft: "<contextLeft>",
		$contextRight: "<contextRight>",
		$filename: "<filename>",
		$padContext: "<padContext>",
		$padRowCol: "<padRowCol>",
		$row: "<row>",
		$suggestions: "<suggestions>",
		$text: "<text>",
		$uri: "<uri>",
		$quickFix: "<quickFix>",
		$message: "<message>",
		$messageColored: "<messageColored>"
	};
	try {
		const problems = [...substitute(chalkTemplate(template), substitutions).matchAll(/\$[a-z]+/gi)].map((m) => m[0]);
		if (problems.length) throw new Error(`Unresolved template variable${problems.length > 1 ? "s" : ""}: ${problems.map((v) => `'${v}'`).join(", ")}`);
		return true;
	} catch (e) {
		return new ApplicationError(e instanceof Error ? e.message : `${e}`);
	}
}
function getFeatureFlags() {
	return getSystemFeatureFlags();
}
const environmentKeys = {
	CSPELL_ENABLE_DICTIONARY_LOGGING: "CSPELL_ENABLE_DICTIONARY_LOGGING",
	CSPELL_ENABLE_DICTIONARY_LOG_FILE: "CSPELL_ENABLE_DICTIONARY_LOG_FILE",
	CSPELL_ENABLE_DICTIONARY_LOG_FIELDS: "CSPELL_ENABLE_DICTIONARY_LOG_FIELDS",
	CSPELL_GLOB_ROOT: "CSPELL_GLOB_ROOT",
	CSPELL_CONFIG_PATH: "CSPELL_CONFIG_PATH",
	CSPELL_DEFAULT_CONFIG_PATH: "CSPELL_DEFAULT_CONFIG_PATH"
};
function setEnvironmentVariable(key, value) {
	process.env[key] = value;
}
function getEnvironmentVariable(key) {
	return process.env[key];
}
function truthy(value) {
	switch (value?.toLowerCase().trim()) {
		case "t":
		case "true":
		case "on":
		case "yes":
		case "1": return true;
	}
	return false;
}
let _dirname;
try {
	if (typeof import.meta.url !== "string") throw new Error("assert");
	_dirname = fileURLToPath(new URL(".", import.meta.url));
} catch {
	_dirname = __dirname;
}
const pkgDir = _dirname;
const npmPackage = {
	name: "cspell",
	version: "9.6.4",
	engines: { node: ">=20.18" }
};
function filterFeatureIssues(features, issue, reportOptions) {
	if (issue.issueType === IssueType.directive) return features?.issueType && reportOptions?.validateDirectives || false;
	if (features?.unknownWords) return true;
	if (!reportOptions) return true;
	if (issue.isFlagged || !reportOptions.unknownWords || reportOptions.unknownWords === unknownWordsChoices.ReportAll) return true;
	if (issue.hasPreferredSuggestions && reportOptions.unknownWords !== unknownWordsChoices.ReportFlagged) return true;
	if (issue.hasSimpleSuggestions && reportOptions.unknownWords === unknownWordsChoices.ReportSimple) return true;
	return false;
}
function handleIssue(reporter, issue, reportOptions) {
	if (!reporter.issue) return;
	if (!filterFeatureIssues(reporter.features, issue, reportOptions)) return;
	if (!reporter.features?.contextGeneration && !issue.context) {
		issue = { ...issue };
		issue.context = issue.line;
	}
	return reporter.issue(issue, reportOptions);
}
/**
* Loads reporter modules configured in cspell config file
*/
async function loadReporters(reporters, defaultReporter, config) {
	async function loadReporter(reporterSettings) {
		if (reporterSettings === "default") return defaultReporter;
		if (!Array.isArray(reporterSettings)) reporterSettings = [reporterSettings];
		const [moduleName, settings] = reporterSettings;
		try {
			const { getReporter } = await dynamicImportFrom(moduleName, [process.cwd(), pkgDir]);
			return getReporter(settings, config);
		} catch (e) {
			throw new ApplicationError(`Failed to load reporter ${moduleName}: ${toError$1(e).message}`);
		}
	}
	reporters = !reporters || !reporters.length ? ["default"] : [...reporters];
	return (await Promise.all(reporters.map(loadReporter))).filter((v) => v !== void 0);
}
function finalizeReporter(reporter) {
	if (!reporter) return void 0;
	if (reporterIsFinalized(reporter)) return reporter;
	return {
		issue: (...params) => reporter.issue?.(...params),
		info: (...params) => reporter.info?.(...params),
		debug: (...params) => reporter.debug?.(...params),
		progress: (...params) => reporter.progress?.(...params),
		error: (...params) => reporter.error?.(...params),
		result: (...params) => reporter.result?.(...params),
		features: reporter.features
	};
}
function reporterIsFinalized(reporter) {
	return !!reporter && reporter.features && typeof reporter.issue === "function" && typeof reporter.info === "function" && typeof reporter.debug === "function" && typeof reporter.error === "function" && typeof reporter.progress === "function" && typeof reporter.result === "function" || false;
}
const reportIssueOptionsKeyMap = {
	unknownWords: "unknownWords",
	validateDirectives: "validateDirectives",
	showContext: "showContext"
};
function setValue(options, key, value) {
	if (value !== void 0) options[key] = value;
}
function extractReporterIssueOptions(settings) {
	const src = settings;
	const options = {};
	for (const key in reportIssueOptionsKeyMap) {
		const k = key;
		setValue(options, k, src[k]);
	}
	return options;
}
function mergeReportIssueOptions(a, b) {
	const options = extractReporterIssueOptions(a);
	if (!b) return options;
	for (const key in reportIssueOptionsKeyMap) {
		const k = key;
		setValue(options, k, b[k]);
	}
	return options;
}
var LintReporter = class {
	#reporters = [];
	#config;
	#finalized = false;
	constructor(defaultReporter, config) {
		this.defaultReporter = defaultReporter;
		this.#config = config;
		if (defaultReporter) this.#reporters.push(finalizeReporter(defaultReporter));
	}
	get config() {
		return this.#config;
	}
	set config(config) {
		assert(!this.#finalized, "Cannot change the configuration of a finalized reporter");
		this.#config = config;
	}
	issue(issue, reportOptions) {
		for (const reporter of this.#reporters) handleIssue(reporter, issue, reportOptions);
	}
	info(...params) {
		for (const reporter of this.#reporters) reporter.info(...params);
	}
	debug(...params) {
		for (const reporter of this.#reporters) reporter.debug(...params);
	}
	error(...params) {
		for (const reporter of this.#reporters) reporter.error(...params);
	}
	progress(...params) {
		for (const reporter of this.#reporters) reporter.progress(...params);
	}
	async result(result) {
		await Promise.all(this.#reporters.map((reporter) => reporter.result?.(result)));
	}
	get features() {
		return {
			unknownWords: true,
			issueType: true
		};
	}
	async loadReportersAndFinalize(reporters) {
		assert(!this.#finalized, "Cannot change the configuration of a finalized reporter");
		const loaded = await loadReporters(reporters, this.defaultReporter, this.config);
		this.#reporters = [...new Set(loaded)].map((reporter) => finalizeReporter(reporter));
	}
	emitProgressBegin(filename, fileNum, fileCount) {
		this.progress({
			type: "ProgressFileBegin",
			fileNum,
			fileCount,
			filename
		});
	}
	emitProgressComplete(filename, fileNum, fileCount, result) {
		const numIssues = result.issues.filter((issue) => filterFeatureIssues({}, issue, result.reportIssueOptions)).length;
		for (const reporter of this.#reporters) {
			const progress = clean({
				type: "ProgressFileComplete",
				fileNum,
				fileCount,
				filename,
				elapsedTimeMs: result.elapsedTimeMs,
				processed: result.processed,
				skippedReason: result.skippedReason,
				numErrors: numIssues || result.errors,
				cached: result.cached,
				perf: result.perf,
				issues: reporter.features && result.issues,
				reportIssueOptions: reporter.features && result.reportIssueOptions
			});
			reporter.progress(progress);
		}
		result.issues.forEach((issue) => this.issue(issue, result.reportIssueOptions));
		return numIssues;
	}
};
var ReportItemCollector = class {
	#collection;
	constructor(collection) {
		this.#collection = collection;
	}
	get #items() {
		if (!this.#collection.reportItems) this.#collection.reportItems = [];
		return this.#collection.reportItems;
	}
	get items() {
		return this.#collection.reportItems;
	}
	info(...params) {
		this.#items.push({
			type: "info",
			payload: params
		});
	}
	debug(...params) {
		this.#items.push({
			type: "debug",
			payload: params
		});
	}
	error(...params) {
		this.#items.push({
			type: "error",
			payload: params
		});
	}
};
function replayReportItems(reportItemsCollection, reporter) {
	const items = reportItemsCollection.reportItems;
	if (!items) return;
	for (const item of items) switch (item.type) {
		case "info":
			reporter.info(...item.payload);
			break;
		case "debug":
			reporter.debug(...item.payload);
			break;
		case "error":
			reporter.error(...item.payload);
			break;
	}
}
const asyncMap = operators.opMapAsync;
operators.opFilterAsync;
const asyncAwait = operators.opAwaitAsync;
const asyncFlatten = operators.opFlattenAsync;
const UTF8 = "utf8";
const STDIN = "stdin";
const STDINProtocol = "stdin:";
const STDINUrlPrefix = "stdin://";
const FileUrlPrefix = "file://";
const FileUrlAbsPrefix = "file:///";
const defaultExcludeGlobs = ["node_modules/**"];
/**
*
* @param pattern - glob patterns and NOT file paths. It can be a file path turned into a glob.
* @param options - search options.
*/
async function globP(pattern, options) {
	const cwd = options?.root || options?.cwd || process.cwd();
	const ignore = (typeof options?.ignore === "string" ? [options.ignore] : options?.ignore)?.filter((g) => !g.startsWith("../"));
	const onlyFiles = options?.nodir;
	const dot = options?.dot;
	const patterns = typeof pattern === "string" ? [pattern] : pattern;
	const useOptions = clean({
		cwd,
		onlyFiles,
		dot,
		ignore,
		absolute: true,
		followSymbolicLinks: false,
		expandDirectories: false
	});
	const compare = new Intl.Collator("en").compare;
	return (await glob$1(patterns, useOptions)).sort(compare).map((absFilename) => Path.relative(cwd, absFilename));
}
function calcGlobs(commandLineExclude) {
	const commandLineExcludes = {
		globs: [...new Set((commandLineExclude || []).flatMap((glob) => glob.split(/(?<!\\)\s+/g)).map((g) => g.replaceAll("\\ ", " ")))],
		source: "arguments"
	};
	const defaultExcludes = {
		globs: defaultExcludeGlobs,
		source: "default"
	};
	return commandLineExcludes.globs.length ? commandLineExcludes : defaultExcludes;
}
function extractPatterns(globs) {
	return globs.reduce((info, g) => {
		const source = g.source;
		const patterns = g.matcher.patternsNormalizedToRoot;
		return [...info, ...patterns.map((glob) => ({
			glob,
			source
		}))];
	}, []);
}
function calcExcludeGlobInfo(root, commandLineExclude) {
	commandLineExclude = typeof commandLineExclude === "string" ? [commandLineExclude] : commandLineExclude;
	const choice = calcGlobs(commandLineExclude);
	return [{
		matcher: new GlobMatcher(choice.globs, {
			root,
			dot: true
		}),
		source: choice.source
	}];
}
/**
* Build GlobMatcher from command line or config file globs.
* @param globs Glob patterns or file paths
* @param root - directory to use as the root
*/
function buildGlobMatcher(globs, root, isExclude) {
	return new GlobMatcher(globs.map((g) => {
		return {
			source: typeof g === "string" ? "command line" : void 0,
			...fileOrGlobToGlob(g, root)
		};
	}), {
		root,
		mode: isExclude ? "exclude" : "include"
	});
}
function extractGlobsFromMatcher(globMatcher) {
	return globMatcher.patternsNormalizedToRoot.map((g) => g.glob);
}
function normalizeGlobsToRoot(globs, root, isExclude) {
	return [globs.filter((g) => typeof g === "string" && isPossibleUrlRegExp.test(g)), extractGlobsFromMatcher(buildGlobMatcher(globs.filter((g) => typeof g !== "string" || !isPossibleUrlRegExp.test(g)), root, isExclude))].flat();
}
const isPossibleGlobRegExp = /[()*?[{}]/;
const isPossibleUrlRegExp = /^[\d_a-z-]{3,}:\/\//;
/**
* If a 'glob' is a path to a directory, then append `**` so that
* directory searches work.
* @param glob - a glob, file, or directory
* @param root - root to use.
* @returns `**` is appended directories.
*/
async function adjustPossibleDirectory(glob, root) {
	const g = typeof glob === "string" ? {
		glob,
		root
	} : {
		glob: glob.glob,
		root: glob.root ?? root
	};
	if (isPossibleGlobRegExp.test(g.glob)) return glob;
	if (isPossibleUrlRegExp.test(g.glob)) return glob;
	const dirPath = Path.resolve(g.root, g.glob);
	try {
		if ((await promises.stat(dirPath)).isDirectory()) {
			const useGlob = posix.join(posixPath(g.glob), "**");
			return typeof glob === "string" ? useGlob : {
				...glob,
				glob: useGlob
			};
		}
	} catch {
		return glob;
	}
	return glob;
}
function posixPath(p) {
	return Path.sep === "\\" ? p.replaceAll("\\", "/") : p;
}
async function normalizeFileOrGlobsToRoot(globs, root) {
	return normalizeGlobsToRoot(await Promise.all(globs.map((g) => adjustPossibleDirectory(g, root))), root, false);
}
function glob$1(patterns, options) {
	patterns = typeof patterns === "string" ? workaroundPicomatchBug(patterns) : patterns.map((g) => workaroundPicomatchBug(g));
	return glob(patterns, options);
}
function readStdin() {
	return readline.createInterface(process.stdin);
}
function isStdinUrl(url) {
	if (url instanceof URL) return url.protocol === STDINProtocol;
	return url.startsWith(STDINProtocol);
}
/**
* Normalize and resolve a stdin url.
* @param url - stdin url to resolve.
* @param cwd - file path to resolve relative paths against.
* @returns
*/
function resolveStdinUrl(url, cwd) {
	assert(url.startsWith(STDINProtocol), `Expected url to start with ${STDINProtocol}`);
	const path = decodeURIComponent(url).slice(6).replace(/^\/\//, "").replace(/^\/([a-z]:)/i, "$1");
	const fileUrl = toFileURL(path, cwd);
	return new URL(fileUrl.toString().replace(/^file:/, STDINProtocol) + (path ? "" : "/"));
}
function fileInfoToDocument(fileInfo, languageId, locale) {
	const { filename, text } = fileInfo;
	languageId = languageId || void 0;
	locale = locale || void 0;
	const uri = filenameToUrl(filename);
	if (uri.href.startsWith(STDINProtocol)) return clean({
		uri: uri.href,
		text,
		languageId,
		locale
	});
	return fileToDocument(uri.href, text, languageId, locale);
}
function filenameToUrl(filename, cwd = ".") {
	if (filename instanceof URL) return filename;
	const cwdURL = toFileDirURL(cwd);
	if (filename === STDIN) return new URL("stdin:///");
	if (isStdinUrl(filename)) return new URL(resolveStdinUrl(filename, cwd));
	return toFileURL(filename, cwdURL);
}
function filenameToUri(filename, cwd) {
	return toURL$2(filenameToUrl(filename, cwd));
}
function isBinaryFile$1(filename, cwd) {
	const uri = filenameToUri(filename, cwd);
	if (uri.protocol.startsWith("stdin")) return false;
	return isBinaryFile(uri);
}
function resolveFilenameToUrl(filename, cwd) {
	if (filename instanceof URL) return filename;
	if (filename === STDIN) return new URL(STDINUrlPrefix);
	if (filename.startsWith(FileUrlAbsPrefix)) return new URL(filename);
	const cwdUrl = toFileDirURL(cwd || process.cwd());
	if (filename.startsWith(FileUrlPrefix)) return new URL(filename.slice(7), cwdUrl);
	if (isStdinUrl(filename)) return resolveStdinUrl(filename, cwdUrl);
	return toFileURL(filename, cwdUrl);
}
function resolveFilename(filename, cwd) {
	return toFilePathOrHref(resolveFilenameToUrl(filename, cwd));
}
function readFileInfo(filename, encoding = UTF8, handleNotFound = false) {
	filename = resolveFilename(filename);
	return (filename.startsWith(STDINProtocol) ? streamConsumers.text(process.stdin) : readFileText(filename, encoding)).then((text) => ({
		text,
		filename
	}), (e) => {
		const error = toError$1(e);
		return handleNotFound && error.code === "EISDIR" ? Promise.resolve({
			text: "",
			filename,
			errorCode: error.code
		}) : handleNotFound && error.code === "ENOENT" ? Promise.resolve({
			text: "",
			filename,
			errorCode: error.code
		}) : Promise.reject(new IOError(`Error reading file: "${filename}"`, error));
	});
}
async function getFileSize(filename) {
	const s = await getStat(filename);
	if (!(s instanceof Error)) return s.size;
	throw s;
}
function readFile$1(filename, encoding = UTF8) {
	return readFileInfo(filename, encoding).then((info) => info.text);
}
/**
* Looks for matching glob patterns or stdin
* @param globPatterns patterns or stdin
*/
async function findFiles(globPatterns, options) {
	const stdin = [];
	const globPats = globPatterns.filter((filename) => !isStdin(filename) && !filename.startsWith(FileUrlPrefix) ? true : (stdin.push(filename), false));
	const globResults = globPats.length ? await globP(globPats, options) : [];
	const cwd = options.cwd || process.cwd();
	return [...stdin, ...globResults].map((filename) => resolveFilename(filename, cwd));
}
const resolveFilenames = asyncMap(resolveFilename);
/**
* Read
* @param listFiles - array of file paths to read that will contain a list of files. Paths contained in each
*   file will be resolved relative to the containing file.
* @returns - a list of files to be processed.
*/
function readFileListFiles(listFiles) {
	let useStdin = false;
	return pipeAsync(toAsyncIterable(pipeAsync(listFiles.filter((file) => {
		const isStdin = file === "stdin";
		useStdin = useStdin || isStdin;
		return !isStdin;
	}), asyncMap((file) => readFileListFile(file)), asyncAwait(), asyncFlatten()), useStdin ? readStdin() : []), resolveFilenames);
}
/**
* Read a `listFile` and return the containing file paths resolved relative to the `listFile`.
* @param listFiles - array of file paths to read that will contain a list of files. Paths contained in each
*   file will be resolved relative to the containing file.
* @returns - a list of files to be processed.
*/
async function readFileListFile(listFile) {
	try {
		const relTo = Path.resolve(Path.dirname(listFile));
		return (await readFile$1(listFile)).split("\n").map((a) => a.trim()).filter((a) => !!a).map((file) => Path.resolve(relTo, file));
	} catch (err) {
		throw toApplicationError(err, `Error reading file list from: "${listFile}"`);
	}
}
function isStdin(filename) {
	return filename === STDIN || isStdinUrl(filename);
}
async function isFile(filename) {
	if (isStdin(filename)) return true;
	try {
		return (await promises.stat(filename)).isFile();
	} catch {
		return false;
	}
}
async function isDir(filename) {
	try {
		return (await promises.stat(filename)).isDirectory();
	} catch {
		return false;
	}
}
function isNotDir(filename) {
	return isDir(filename).then((a) => !a);
}
function relativeToCwd(filename, cwd = process.cwd()) {
	const urlCwd = toFileDirURL(cwd);
	const url = toFileURL(filename, urlCwd);
	const rel = urlRelative(urlCwd, url);
	if (rel.startsWith("..")) return toFilePathOrHref(url);
	return rel;
}
var FlatCache = class {
	#cache;
	constructor(cacheFilename) {
		this.cacheFilename = cacheFilename;
		this.#cache = /* @__PURE__ */ new Map();
	}
	keys() {
		return this.#cache.keys();
	}
	set(key, value) {
		this.#cache.set(key, value);
		return this;
	}
	removeKey(key) {
		this.#cache.delete(key);
	}
	get(key) {
		return this.#cache.get(key);
	}
	async load(ifFound = true) {
		this.#cache.clear();
		try {
			const content = await fs$1.readFile(this.cacheFilename, "utf8");
			this.#cache = new Map(Object.entries(parse(content)));
		} catch (error) {
			if (!ifFound) throw error;
		}
		return this;
	}
	async save() {
		const dir = new URL(".", this.cacheFilename);
		await fs$1.mkdir(dir, { recursive: true });
		const content = stringify(Object.fromEntries(this.#cache.entries()));
		await fs$1.writeFile(this.cacheFilename, content, "utf8");
	}
	/**
	* Clear the cache and remove the cache file from disk.
	*/
	async destroy() {
		this.#cache.clear();
		try {
			await fs$1.unlink(this.cacheFilename);
		} catch {}
	}
};
/**
*
* @param cachefile - The location of the cache file.
* @returns
*/
function loadCacheFile(cachefile) {
	return new FlatCache(cachefile).load();
}
async function createFromFile$1(cacheFileUrl, useChecksum, currentWorkingDir) {
	const fec = new ImplFileEntryCache(await loadCacheFile(cacheFileUrl), useChecksum ?? false, currentWorkingDir);
	await fec.removeNotFoundFiles();
	return fec;
}
var ImplFileEntryCache = class {
	cache;
	useChecksum;
	#normalizedEntries = /* @__PURE__ */ new Map();
	/**
	* To enable relative paths as the key with current working directory
	*/
	currentWorkingDir;
	constructor(cache, useChecksum, currentWorkingDir) {
		this.cache = cache;
		this.useChecksum = useChecksum || false;
		this.currentWorkingDir = currentWorkingDir ? fileURLToPath(currentWorkingDir) : void 0;
	}
	async removeNotFoundFiles() {
		for (const fPath of this.cache.keys()) try {
			const filePath = this.resolveKeyToFile(fPath);
			await fs$1.stat(filePath);
		} catch (error) {
			if (isNodeError(error) && error.code === "ENOENT") this.cache.removeKey(fPath);
		}
	}
	/**
	* Given a buffer, calculate md5 hash of its content.
	* @param  buffer buffer to calculate hash on
	* @return content hash digest
	*/
	#getHash(buffer) {
		return crypto.createHash("md5").update(buffer).digest("hex");
	}
	async getFileDescriptor(file) {
		let fstat;
		try {
			fstat = await fs$1.stat(file);
		} catch (error) {
			this.#removeEntry(file);
			return {
				key: file,
				notFound: true,
				err: toError(error)
			};
		}
		if (this.useChecksum) return this.#getFileDescriptorUsingChecksum(file);
		return this.#getFileDescriptorUsingMtimeAndSize(file, fstat);
	}
	#getFileDescriptorUsingMtimeAndSize(file, fstat) {
		const key = this.#getFileKey(file);
		let meta = this.cache.get(key);
		const cacheExists = !!meta;
		const cSize = fstat.size;
		const cTime = fstat.mtime.getTime();
		let isDifferentDate;
		let isDifferentSize;
		if (meta) {
			isDifferentDate = cTime !== meta.mtime;
			isDifferentSize = cSize !== meta.size;
		} else meta = {
			size: cSize,
			mtime: cTime
		};
		const nEntry = {
			key,
			changed: !cacheExists || isDifferentDate || isDifferentSize,
			meta
		};
		this.#normalizedEntries.set(key, nEntry);
		return nEntry;
	}
	async #getFileDescriptorUsingChecksum(file) {
		const key = this.#getFileKey(file);
		let meta = this.cache.get(key);
		const cacheExists = !!meta;
		let contentBuffer;
		try {
			contentBuffer = await fs$1.readFile(file);
		} catch {
			contentBuffer = "";
		}
		let isDifferent = true;
		const hash = this.#getHash(contentBuffer);
		if (meta) isDifferent = hash !== meta.hash;
		else meta = { hash };
		const nEntry = {
			key,
			changed: !cacheExists || isDifferent,
			meta
		};
		this.#normalizedEntries.set(key, nEntry);
		return nEntry;
	}
	/**
	* Remove an entry from the file-entry-cache. Useful to force the file to still be considered
	* modified the next time the process is run
	*/
	#removeEntry(file) {
		const key = this.#getFileKey(file);
		this.#normalizedEntries.delete(key);
		this.cache.removeKey(key);
	}
	/**
	* Deletes the cache file from the disk and clears the memory cache
	*/
	async destroy() {
		this.#normalizedEntries.clear();
		await this.cache.destroy();
	}
	async #getMetaForFileUsingCheckSum(cacheEntry) {
		const filePath = this.resolveKeyToFile(cacheEntry.key);
		const contentBuffer = await fs$1.readFile(filePath);
		const hash = this.#getHash(contentBuffer);
		const meta = {
			...cacheEntry.meta,
			hash
		};
		delete meta.size;
		delete meta.mtime;
		return meta;
	}
	async #getMetaForFileUsingMtimeAndSize(cacheEntry) {
		const filePath = this.resolveKeyToFile(cacheEntry.key);
		const stat = await fs$1.stat(filePath);
		const meta = {
			...cacheEntry.meta,
			size: stat.size,
			mtime: stat.mtime.getTime()
		};
		delete meta.hash;
		return meta;
	}
	/**
	* Sync the files and persist them to the cache
	*/
	async reconcile() {
		await this.removeNotFoundFiles();
		for (const [entryKey, cacheEntry] of this.#normalizedEntries.entries()) try {
			const meta = this.useChecksum ? await this.#getMetaForFileUsingCheckSum(cacheEntry) : await this.#getMetaForFileUsingMtimeAndSize(cacheEntry);
			this.cache.set(entryKey, meta);
		} catch (error) {
			if (!isNodeError(error) || error.code !== "ENOENT") throw error;
		}
		await this.cache.save();
	}
	resolveKeyToFile(entryKey) {
		if (this.currentWorkingDir) return path.resolve(this.currentWorkingDir, entryKey);
		return entryKey;
	}
	#getFileKey(file) {
		if (this.currentWorkingDir && path.isAbsolute(file)) return normalizePath$1(path.relative(this.currentWorkingDir, file));
		return normalizePath$1(file);
	}
};
function isNodeError(error) {
	return typeof error === "object" && error !== null && "code" in error;
}
function toError(error) {
	if (error instanceof Error) return error;
	if (typeof error === "string") return new Error(error);
	return new Error("Unknown error", { cause: error });
}
function normalizePath$1(filePath) {
	if (path.sep === "/") return filePath;
	return filePath.split(path.sep).join("/");
}
function createFromFile(cacheFileUrl, useCheckSum, useRelative) {
	return createFromFile$1(cacheFileUrl, useCheckSum, useRelative ? new URL("./", cacheFileUrl) : void 0);
}
const compare = Intl.Collator().compare;
var ShallowObjectCollection = class {
	tree = {};
	get(v) {
		if (typeof v !== "object" || v === null) return v;
		const keys = Object.entries(v).filter((entry) => entry[1] !== void 0).sort((a, b) => compare(a[0], b[0]));
		let t = this.tree;
		for (const [key, obj] of keys) {
			if (!t.c) t.c = /* @__PURE__ */ new Map();
			const c0 = t.c.get(key);
			const cc = c0 || /* @__PURE__ */ new Map();
			if (!c0) t.c.set(key, cc);
			const c1 = cc.get(obj);
			const ccc = c1 || {};
			if (!c1) cc.set(obj, ccc);
			t = ccc;
		}
		if (t.v) return t.v;
		t.v = v;
		return v;
	}
};
const META_DATA_VERSION_SUFFIX = "-1-" + Object.keys({
	v: "v",
	r: "r",
	d: "d"
}).join("|");
/**
* Caches cspell results on disk
*/
var DiskCache = class {
	cacheDir;
	dependencyCache = /* @__PURE__ */ new Map();
	dependencyCacheTree = {};
	objectCollection = new ShallowObjectCollection();
	ocCacheFileResult = new ShallowObjectCollection();
	version;
	constructor(cacheFileLocation, useCheckSum, cspellVersion, useUniversalCache, fileEntryCache) {
		this.cacheFileLocation = cacheFileLocation;
		this.useCheckSum = useCheckSum;
		this.cspellVersion = cspellVersion;
		this.useUniversalCache = useUniversalCache;
		this.fileEntryCache = fileEntryCache;
		this.cacheDir = fileURLToPath(new URL("./", cacheFileLocation));
		this.version = calcVersion(cspellVersion);
	}
	async getCachedLintResults(filename) {
		filename = normalizePath(filename);
		const fileDescriptor = await this.fileEntryCache.getFileDescriptor(filename);
		const meta = fileDescriptor.meta;
		const data = meta?.data;
		const result = data?.r;
		const versionMatches = this.version === data?.v;
		if (fileDescriptor.notFound || fileDescriptor.changed || !meta || !result || !versionMatches || !await this.checkDependencies(data.d)) return;
		const dd = { ...data };
		if (dd.d) dd.d = setTreeEntry(this.dependencyCacheTree, dd.d);
		dd.r = dd.r && this.normalizeResult(dd.r);
		meta.data = this.objectCollection.get(dd);
		const hasErrors = !!result && (result.errors > 0 || result.configErrors > 0 || result.issues.length > 0);
		const cached = true;
		const shouldReadFile = hasErrors;
		return {
			...result,
			elapsedTimeMs: void 0,
			fileInfo: shouldReadFile ? await readFileInfo(filename) : { filename },
			cached
		};
	}
	async setCachedLintResults({ fileInfo, elapsedTimeMs: _, cached: __, ...result }, dependsUponFiles) {
		const fileDescriptor = await this.fileEntryCache.getFileDescriptor(fileInfo.filename);
		const meta = fileDescriptor.meta;
		if (fileDescriptor.notFound || !meta) return;
		meta.data = this.objectCollection.get({
			v: this.version,
			r: this.normalizeResult(result),
			d: await this.calcDependencyHashes(dependsUponFiles)
		});
	}
	async reconcile() {
		await this.fileEntryCache.reconcile();
	}
	async reset() {
		await this.fileEntryCache.destroy();
		this.dependencyCache.clear();
		this.dependencyCacheTree = {};
		this.objectCollection = new ShallowObjectCollection();
		this.ocCacheFileResult = new ShallowObjectCollection();
	}
	normalizeResult(result) {
		const { issues, processed, errors, configErrors, reportIssueOptions, ...rest } = result;
		if (!Object.keys(rest).length) return this.ocCacheFileResult.get(result);
		return this.ocCacheFileResult.get({
			issues,
			processed,
			errors,
			configErrors,
			reportIssueOptions
		});
	}
	async calcDependencyHashes(dependsUponFiles) {
		dependsUponFiles.sort();
		const c = getTreeEntry(this.dependencyCacheTree, dependsUponFiles);
		if (c?.d) return c.d;
		const dependencies = await Promise.all(dependsUponFiles.map((f) => this.getDependency(f)));
		return setTreeEntry(this.dependencyCacheTree, dependencies);
	}
	async checkDependency(dep) {
		const depFile = this.resolveFile(dep.f);
		const cDep = this.dependencyCache.get(depFile);
		if (cDep && compDep(dep, cDep)) return true;
		if (cDep) return false;
		const d = await this.getFileDep(depFile);
		if (compDep(dep, d)) {
			this.dependencyCache.set(depFile, dep);
			return true;
		}
		this.dependencyCache.set(depFile, d);
		return false;
	}
	async getDependency(file) {
		const dep = this.dependencyCache.get(file);
		if (dep) return dep;
		const d = await this.getFileDep(file);
		this.dependencyCache.set(file, d);
		return d;
	}
	async getFileDep(file) {
		if (isUrlLike(file)) {
			if (!file.startsWith("file://")) return getDependencyForUrl(file);
			file = toFilePathOrHref(file);
		}
		assert(isAbsolute(file), `Dependency must be absolute "${file}"`);
		const f = this.toRelFile(file);
		let h;
		try {
			const buffer = await fs$1.readFile(file);
			h = this.getHash(buffer);
		} catch {
			return { f };
		}
		return {
			f,
			h
		};
	}
	async checkDependencies(dependencies) {
		if (!dependencies) return false;
		for (const dep of dependencies) if (!await this.checkDependency(dep)) return false;
		return true;
	}
	getHash(buffer) {
		return crypto.createHash("md5").update(buffer).digest("hex");
	}
	resolveFile(file) {
		if (isUrlLike(file)) return file;
		return normalizePath(resolve(this.cacheDir, file));
	}
	toRelFile(file) {
		return normalizePath(this.useUniversalCache ? relative(this.cacheDir, file) : file);
	}
};
async function getDependencyForUrl(remoteUrl) {
	const url = new URL(remoteUrl);
	try {
		const response = await fetch(url, { method: "HEAD" });
		const h = response.headers.get("etag") || response.headers.get("last-modified") || response.headers.get("content-length") || "";
		return {
			f: url.href,
			h: h ? h.trim() : ""
		};
	} catch {
		return {
			f: url.href,
			h: ""
		};
	}
}
async function createDiskCache(cacheFileLocation, useCheckSum, cspellVersion, useUniversalCache) {
	return new DiskCache(cacheFileLocation, useCheckSum, cspellVersion, useUniversalCache, await createFromFile(cacheFileLocation, useCheckSum, useUniversalCache));
}
function getTreeEntry(tree, keys) {
	let r = tree;
	for (const k of keys) {
		r = r.c?.get(k);
		if (!r) return r;
	}
	return r;
}
function setTreeEntry(tree, deps, update = false) {
	let r = tree;
	for (const d of deps) {
		const k = d.f;
		if (!r.c) r.c = /* @__PURE__ */ new Map();
		const cn = r.c.get(k);
		const n = cn ?? {};
		if (!cn) r.c.set(k, n);
		r = n;
	}
	let d = r.d;
	if (!d || r.d && update) {
		r.d = deps;
		d = deps;
	}
	return d;
}
function compDep(a, b) {
	return a.f === b.f && a.h === b.h;
}
function calcVersion(version) {
	return version + META_DATA_VERSION_SUFFIX;
}
function normalizePath(filePath) {
	if (sep === "/") return filePath;
	return filePath.split(sep).join("/");
}
/**
* Dummy cache implementation that should be usd if caching option is disabled.
*/
var DummyCache = class {
	getCachedLintResults() {
		return Promise.resolve(void 0);
	}
	setCachedLintResults() {
		return Promise.resolve();
	}
	reconcile() {
		return Promise.resolve();
	}
	reset() {
		return Promise.resolve();
	}
};
const DEFAULT_CACHE_LOCATION = ".cspellcache";
const versionSuffix = "";
/**
* Creates CSpellLintResultCache (disk cache if caching is enabled in config or dummy otherwise)
*/
async function createCache(options) {
	const { useCache, cacheLocation, cacheStrategy, reset } = options;
	const location = toFileURL(cacheLocation);
	const useChecksum = cacheStrategy === "content";
	const version = normalizeVersion(options.version);
	const useUniversal = options.cacheFormat === "universal";
	const cache = useCache ? await createDiskCache(location, useChecksum, version, useUniversal) : new DummyCache();
	if (reset) await cache.reset();
	return cache;
}
async function calcCacheSettings(config, cacheOptions, root) {
	const cs = config.cache ?? {};
	const useCache = cacheOptions.cache ?? cs.useCache ?? false;
	const cacheLocation = await resolveCacheLocation(path.resolve(root, cacheOptions.cacheLocation ?? cs.cacheLocation ?? DEFAULT_CACHE_LOCATION));
	const cacheStrategy = cacheOptions.cacheStrategy ?? cs.cacheStrategy ?? "content";
	const cacheFormat = cacheOptions.cacheFormat ?? cs.cacheFormat ?? "universal";
	const optionals = {};
	if (cacheOptions.cacheReset) optionals.reset = true;
	return {
		...optionals,
		useCache,
		cacheLocation,
		cacheStrategy,
		version: cacheOptions.version,
		cacheFormat
	};
}
async function resolveCacheLocation(cacheLocation) {
	try {
		if ((await stat(cacheLocation)).isFile()) return cacheLocation;
		return path.join(cacheLocation, DEFAULT_CACHE_LOCATION);
	} catch (err) {
		if (isErrorLike(err) && err.code === "ENOENT") return cacheLocation;
		throw err;
	}
}
/**
* Normalizes the version and return only `major.minor + versionSuffix`
* @param version The cspell semantic version.
*/
function normalizeVersion(version) {
	const parts = version.split(".").slice(0, 2);
	assert(parts.length === 2);
	return parts.join(".") + versionSuffix;
}
async function readConfig(configFile, root, stopConfigSearchAt) {
	configFile ??= getEnvironmentVariable(environmentKeys.CSPELL_CONFIG_PATH);
	if (configFile) return configFileToConfigInfo(typeof configFile === "string" ? await readConfigHandleError(configFile) : configFile);
	const config = await searchForConfig(root, { stopSearchAt: stopConfigSearchAt });
	const defaultConfigFile = getEnvironmentVariable(environmentKeys.CSPELL_DEFAULT_CONFIG_PATH);
	if (!config && defaultConfigFile) {
		const cfgFile = await readConfigFile(defaultConfigFile).catch(() => void 0);
		if (cfgFile) return configFileToConfigInfo(cfgFile);
	}
	return {
		source: config?.__importRef?.filename || "None found",
		config: config || {}
	};
}
async function configFileToConfigInfo(cfgFile) {
	const config = await resolveConfigFileImports(cfgFile);
	return {
		source: toFilePathOrHref(cfgFile.url),
		config
	};
}
function readConfigFile(filename) {
	return readConfigFile$1(filename);
}
async function readConfigHandleError(filename) {
	try {
		return await readConfigFile(filename);
	} catch (e) {
		const settings = { __importRef: {
			filename: filename.toString(),
			error: e
		} };
		return {
			url: filenameToUrl(filename),
			settings
		};
	}
}
function getTimeMeasurer() {
	const timer = createPerfTimer("timer");
	return () => timer.elapsed;
}
/**
* Indent each line of a multi-line string.
* @param str - multi-line string to left pad
* @param padding - the padding to use for all lines except the first.
* @param firstLinePadding - optional padding of first line.
* @returns
*/
function indent(str, padding, firstLinePadding = "") {
	let pad = firstLinePadding;
	const lines = [];
	for (const line of str.split("\n")) {
		lines.push(pad + line);
		pad = padding;
	}
	return lines.join("\n");
}
/**
* Inject values into a template string while keeping indentation of multi-line values.
* @param template - template string
* @param values- values to inject
* @returns the injected string
*/
function keepIndent(template, ...values) {
	const strings = template;
	const adjValues = [];
	for (let i = 0; i < values.length; ++i) {
		const prevLines = strings[i].split("\n");
		const currLine = prevLines[prevLines.length - 1];
		const padLen = padLength(currLine);
		const padding = " ".repeat(padLen);
		adjValues.push(indent(`${values[i]}`, padding));
	}
	return String.raw({ raw: strings }, ...adjValues);
}
/**
* Calculate the padding at the start of the string.
* @param s - string to evaluate
* @returns number of padding characters
*/
function padLength(s) {
	return s.length - s.trimStart().length;
}
function unindent(templateOrString, ...values) {
	return unindentString(typeof templateOrString === "string" ? templateOrString : keepIndent(templateOrString, ...values));
}
function unindentString(str) {
	const lines = str.split("\n");
	let curPad = str.length;
	for (const line of lines) {
		if (!line.trim()) continue;
		curPad = Math.min(curPad, padLength(line));
	}
	return lines.map((line) => line.slice(curPad)).join("\n");
}
const wrapSep = /\s+|(?<=,)|\.(?=\w)/g;
function wordWrapAnsiText(str, maxWidth, indent = "", sep = wrapSep) {
	if (!maxWidth || maxWidth <= 0) return str;
	if (str.length <= maxWidth) return str;
	if (str.includes("\n")) return str.split("\n").map((line) => wordWrapAnsiText(line, maxWidth, indent)).join("\n");
	const fragments = fragmentString(str, sep, "sep");
	const lines = [];
	let line = "";
	for (const text of joinFragments(fragments)) {
		const lineWidth = ansiWidth(line);
		const textWidth = ansiWidth(text);
		if (line && lineWidth + textWidth > maxWidth) {
			if (line) lines.push(line);
			line = indent + text.trimStart();
			continue;
		}
		line += text;
	}
	if (line) lines.push(line);
	return lines.join("\n");
}
function* joinFragments(fragments) {
	let last;
	for (const frag of fragments) {
		if (frag.type === "sep") {
			if (last) yield last.text;
			last = frag;
			continue;
		}
		yield last ? last.text + frag.text : frag.text;
		last = void 0;
	}
	if (last) yield last.text;
}
async function writeFileOrStream(filename, data) {
	switch (filename) {
		case "stdout":
			await writeStream(process.stdout, data);
			return;
		case "stderr":
			await writeStream(process.stderr, data);
			return;
		case "null": return;
	}
	return fs$1.writeFile(filename, data);
}
function writeStream(stream, data) {
	return new Promise((resolve, reject) => {
		stream.write(data, (err) => {
			if (err) reject(err);
			else resolve();
		});
	});
}
function prefCharIndex(text, offset, count = 1) {
	if (offset - count < 0) return 0;
	for (; count > 0 && offset > 0; count--) {
		let code = text.charCodeAt(--offset) || 0;
		if (code === 65039) code = text.charCodeAt(--offset) || 0;
		offset -= (code & 64512) === 56320 ? 1 : 0;
	}
	return offset < 0 ? 0 : offset;
}
function nextCharIndex(text, offset, count = 1) {
	if (offset + count >= text.length) return text.length;
	for (; count > 0 && offset < text.length; count--) {
		const code = text.charCodeAt(offset++) || 0;
		offset += (code & 64512) === 55296 ? 1 : 0;
		if (text.charCodeAt(offset) === 65039) offset++;
	}
	return offset > text.length ? text.length : offset;
}
function lineContext(lineText, start, end, contextRange) {
	let left = prefCharIndex(lineText, start, contextRange);
	let right = nextCharIndex(lineText, end, contextRange);
	const isLetter = /^\p{L}$/u;
	const isMark = /^\p{M}$/u;
	for (let n = contextRange / 2; n > 0 && left > 0; n--, left--) {
		const c = lineText[left - 1];
		if (isMark.test(c)) {
			if (!isLetter.test(lineText[left - 2])) break;
			left--;
			continue;
		}
		if (!isLetter.test(lineText[left - 1])) break;
	}
	for (let n = contextRange / 2; n > 0 && right < lineText.length; n--, right++) {
		if (!isLetter.test(lineText[right])) break;
		if (isMark.test(lineText[right + 1])) right++;
	}
	left = left < 0 ? 0 : left;
	const t0 = lineText.slice(left, right);
	const tLeft = t0.trimStart();
	left = Math.min(left + t0.length - tLeft.length, start);
	return {
		text: tLeft.trimEnd(),
		offset: left
	};
}
function extractContext(tdo, contextRange) {
	const { line, offset, text } = tdo;
	const start = offset - line.offset;
	const context = lineContext(line.text, start, start + text.length, contextRange);
	context.offset += line.offset;
	return context;
}
var LinterError = class extends Error {
	constructor(message) {
		super(message);
	}
	toString() {
		return this.message;
	}
};
async function processFile(file, cache, prefetch, processFileOptions) {
	if (prefetch?.fileResult) return prefetch.fileResult;
	const { filename } = file;
	const { cfg, configInfo, userSettings } = processFileOptions;
	const getElapsedTimeMs = getTimeMeasurer();
	const reportIssueOptions = prefetch?.reportIssueOptions;
	const cachedResult = await cache.getCachedLintResults(filename);
	if (cachedResult) return {
		...cachedResult,
		elapsedTimeMs: getElapsedTimeMs(),
		reportIssueOptions: {
			...cachedResult.reportIssueOptions,
			...reportIssueOptions
		}
	};
	const result = {
		fileInfo: { filename },
		issues: [],
		processed: false,
		errors: 0,
		configErrors: 0,
		elapsedTimeMs: 0,
		reportIssueOptions,
		reportItems: void 0
	};
	const reporter = new ReportItemCollector(result);
	const fileInfo = prefetch?.fileInfo || await readFileInfo(filename, void 0, true);
	if (fileInfo.errorCode) {
		if (fileInfo.errorCode !== "EISDIR" && cfg.options.mustFindFiles) {
			const err = new LinterError(`File not found: "${filename}"`);
			reporter.error("Linter:", err);
			result.errors += 1;
		}
		return result;
	}
	const doc = fileInfoToDocument(fileInfo, cfg.options.languageId, cfg.locale);
	const { text } = fileInfo;
	result.fileInfo = fileInfo;
	let spellResult = {};
	try {
		const { showSuggestions: generateSuggestions, validateDirectives, skipValidation } = cfg.options;
		const r = await spellCheckDocument(doc, clean({
			generateSuggestions,
			numSuggestions: configInfo.config.numSuggestions ?? 5,
			validateDirectives,
			skipValidation
		}), userSettings);
		spellResult = r;
		result.processed = r.checked;
		result.perf = r.perf ? { ...r.perf } : void 0;
		result.issues = calculateTextDocumentOffsets(doc.uri, text, r.issues).map(mapIssue);
	} catch (e) {
		reporter.error(`Failed to process "${filename}"`, toError$1(e));
		result.errors += 1;
	}
	result.elapsedTimeMs = getElapsedTimeMs();
	const config = spellResult.settingsUsed ?? {};
	result.reportIssueOptions = mergeReportIssueOptions(spellResult.settingsUsed || configInfo.config, reportIssueOptions);
	result.configErrors += reportSpellingResultConfigErrors(reporter, spellResult, processFileOptions);
	reportCheckResult(result, doc, spellResult, config, processFileOptions);
	const dep = calcDependencies(config);
	await cache.setCachedLintResults(result, dep.files);
	return result;
	function mapIssue({ doc: _, ...tdo }) {
		const context = cfg.showContext ? extractContext(tdo, cfg.showContext) : void 0;
		return clean({
			...tdo,
			context
		});
	}
}
function reportCheckResult(result, _doc, spellResult, config, processFileOptions) {
	const { configInfo, verboseLevel, useColor, cfg, chalk } = processFileOptions;
	const elapsed = result.elapsedTimeMs || 0;
	const dictionaries = config.dictionaries || [];
	const reporter = new ReportItemCollector(result);
	if (verboseLevel > 1) {
		const dictsUsed = [...dictionaries].sort().map((name) => chalk.green(name)).join(", ");
		const msg = unindent`
                    File type: ${config.languageId}, Language: ${config.language}, Issues: ${result.issues.length} ${elapsed.toFixed(2)}ms
                    Config file Used: ${relativeToCwd(spellResult.localConfigFilepath || configInfo.source, cfg.root)}
                    Dictionaries Used:
                      ${wordWrapAnsiText(dictsUsed, 70)}`;
		reporter.info(indent(msg, "  "), MessageTypes.Info);
	}
	if (cfg.options.debug) {
		const { enabled, language, languageId, dictionaries } = config;
		const msg = unindent`\
                Debug Config: ${formatWithOptions({
			depth: 2,
			colors: useColor
		}, {
			languageId,
			enabled,
			language,
			dictionaries
		})}`;
		reporter.debug(msg);
	}
}
function calcDependencies(config) {
	const { configFiles, dictionaryFiles } = extractDependencies(config);
	return { files: [...configFiles, ...dictionaryFiles] };
}
function reportConfigurationErrors(reporter, config, processFileOptions) {
	return reportImportErrors(reporter, extractImportErrors(config), processFileOptions);
}
function reportImportErrors(reporter, errors, processFileOptions) {
	const { configErrors } = processFileOptions;
	let count = 0;
	errors.forEach((ref) => {
		const key = ref.error.toString();
		if (configErrors.has(key)) return;
		configErrors.add(key);
		count += 1;
		reporter.error("Configuration", ref.error);
	});
	return count;
}
function reportSpellingResultConfigErrors(reporter, spellResult, processFileOptions) {
	const { configErrors } = processFileOptions;
	let count = reportImportErrors(reporter, spellResult.configErrors || [], processFileOptions);
	const dictionaryErrors = [...spellResult.dictionaryErrors || []];
	for (const [dictName, dictErrors] of dictionaryErrors) {
		const msg = `Dictionary Error with (${dictName})`;
		dictErrors.forEach((error) => {
			const key = msg + error.toString();
			if (configErrors.has(key)) return;
			configErrors.add(key);
			count += 1;
			reporter.error(msg, error);
		});
	}
	return count;
}
function countConfigErrors(reporter, configInfo, processFileOptions) {
	return reportConfigurationErrors(reporter, configInfo.config, processFileOptions);
}
function* prefetchIterable(iterable, size) {
	assert(size >= 0);
	const buffer = [];
	for (const value of iterable) {
		buffer.push(value);
		if (buffer.length >= size - 1) {
			const value = buffer[0];
			buffer.shift();
			yield value;
		}
	}
	yield* buffer;
}
const regexUnitNumber = /^((?:\d+(?:\.\d*)?)|(?:\.\d+))([a-z]*)$/i;
const unitSizes = {
	"": 1,
	b: 1,
	k: 1024,
	kb: 1024,
	m: 1 << 20,
	mb: 1 << 20,
	g: 1 << 30,
	gb: 1 << 30
};
function parseUnitSize(size) {
	const match = size.match(regexUnitNumber);
	const digits = match?.[1] || "";
	const units = (match?.[2] || "").toLowerCase();
	if (!match) return {
		size,
		digits,
		units,
		error: "Invalid size."
	};
	if (!units || units in unitSizes) return {
		size,
		digits,
		units
	};
	return {
		size,
		digits,
		units,
		error: `Unknown units. Valid units are: ${Object.keys(unitSizes).filter(Boolean).join(", ").toUpperCase()}.`
	};
}
function sizeToNumber(size) {
	const p = parseUnitSize(size);
	if (p.error) return NaN;
	return Number.parseFloat(p.digits) * (unitSizes[p.units] || 1);
}
const BATCH_FETCH_SIZE = 12;
const BATCH_PROCESS_SIZE = 1;
function prefetch(fileToProcess, cfg) {
	const { filename } = fileToProcess;
	if (isBinaryFile$1(filename, cfg.root)) return {
		...fileToProcess,
		result: Promise.resolve({
			skip: true,
			skipReason: "Binary file."
		})
	};
	const reportIssueOptions = extractReporterIssueOptions(cfg.config);
	async function fetch() {
		const getElapsedTimeMs = getTimeMeasurer();
		const cachedResult = await cfg.cache.getCachedLintResults(filename);
		if (cachedResult) return { fileResult: {
			...cachedResult,
			elapsedTimeMs: getElapsedTimeMs()
		} };
		const uri = filenameToUri(filename, cfg.root).href;
		const checkResult = await shouldCheckDocument({ uri }, {}, cfg.config);
		if (!checkResult.shouldCheck) return {
			skip: true,
			skipReason: checkResult.reason || "Ignored by configuration."
		};
		const maxFileSize = processMaxFileSize(cfg.maxFileSize ?? checkResult.settings.maxFileSize);
		if (maxFileSize) {
			if (await getFileSize(filename) > maxFileSize) return {
				skip: true,
				skipReason: `File exceeded max file size of ${maxFileSize.toLocaleString()}`
			};
		}
		return {
			fileInfo: await readFileInfo(filename, void 0, true),
			reportIssueOptions
		};
	}
	const result = fetch().catch((e) => toApplicationError(e));
	return {
		...fileToProcess,
		result
	};
}
async function processFiles(files, options) {
	const status = runResult();
	const cache = await createCache(options.cacheSettings);
	const failFast = options.cfg.options.failFast ?? options.configInfo.config.failFast ?? false;
	const reporter = options.lintReporter;
	const prefetchConfig = {
		root: options.cfg.root,
		maxFileSize: options.cfg.maxFileSize,
		config: options.configInfo.config,
		cache
	};
	const processFileOptionsGeneral = {
		chalk: options.chalk,
		configInfo: options.configInfo,
		cfg: options.cfg,
		verboseLevel: options.verboseLevel,
		useColor: options.useColor,
		configErrors: options.configErrors,
		userSettings: options.configInfo.config
	};
	function* prefetchFiles(files) {
		yield* prefetchIterable(pipeSync$1(files, opMapSync$1((file) => prefetch(file, prefetchConfig))), BATCH_FETCH_SIZE);
	}
	async function* prefetchFilesAsync(files) {
		for await (const file of files) yield prefetch(file, prefetchConfig);
	}
	const emptyResult = {
		fileInfo: { filename: "" },
		issues: [],
		processed: false,
		errors: 0,
		configErrors: 0,
		elapsedTimeMs: 1,
		reportIssueOptions: void 0,
		reportItems: void 0
	};
	async function processPrefetchFileResult(pf) {
		const { filename, sequence, sequenceSize, result: pFetchResult } = pf;
		const getElapsedTimeMs = getTimeMeasurer();
		const fetchResult = await pFetchResult;
		if (fetchResult instanceof Error) throw fetchResult;
		const fileNum = sequence + 1;
		reporter.emitProgressBegin(filename, fileNum, pf.sequenceSize ?? sequence);
		if (fetchResult?.skip) return {
			filename,
			sequence,
			sequenceSize,
			result: {
				...emptyResult,
				fileInfo: { filename },
				elapsedTimeMs: getElapsedTimeMs(),
				skippedReason: fetchResult.skipReason
			}
		};
		return {
			filename,
			sequence,
			sequenceSize,
			result: await processFile(pf, cache, fetchResult, processFileOptionsGeneral)
		};
	}
	async function* loadAndProcessFiles() {
		if (isAsyncIterable$1(files)) {
			for await (const pf of prefetchFilesAsync(files)) yield processPrefetchFileResult(pf);
			return;
		}
		if (BATCH_PROCESS_SIZE <= 1) {
			for (const pf of prefetchFiles(files)) {
				await pf.result;
				yield processPrefetchFileResult(pf);
			}
			return;
		}
		yield* pipeSync$1(prefetchIterable(pipeSync$1(prefetchFiles(files), opMapSync$1(async (pf) => processPrefetchFileResult(pf))), BATCH_PROCESS_SIZE));
	}
	for await (const processed of loadAndProcessFiles()) {
		const { filename, sequence, sequenceSize, result } = processed;
		replayReportItems(result, reporter);
		status.files += 1;
		status.cachedFiles = (status.cachedFiles || 0) + (result.cached ? 1 : 0);
		status.skippedFiles = (status.skippedFiles || 0) + (result.processed ? 0 : 1);
		const fileNum = sequence + 1;
		const numIssues = reporter.emitProgressComplete(filename, fileNum, sequenceSize ?? fileNum, result);
		if (numIssues || result.errors) {
			status.filesWithIssues.add(relativeToCwd(filename, options.cfg.root));
			status.issues += numIssues;
			status.errors += result.errors;
			if (failFast) return status;
		}
		status.errors += result.configErrors;
	}
	await cache.reconcile();
	return status;
}
function processMaxFileSize(value) {
	if (!value) return void 0;
	if (typeof value === "number") return value;
	const num = sizeToNumber(value);
	if (Number.isNaN(num)) throw new ApplicationError(`Invalid max file size: "${value}"`);
	return num;
}
function runResult(init = {}) {
	const { files = 0, filesWithIssues = /* @__PURE__ */ new Set(), issues = 0, errors = 0, cachedFiles = 0 } = init;
	return {
		files,
		filesWithIssues,
		issues,
		errors,
		cachedFiles
	};
}
function _usingCtx() {
	var r = "function" == typeof SuppressedError ? SuppressedError : function(r, e) {
		var n = Error();
		return n.name = "SuppressedError", n.error = r, n.suppressed = e, n;
	}, e = {}, n = [];
	function using(r, e) {
		if (null != e) {
			if (Object(e) !== e) throw new TypeError("using declarations can only be used with objects, functions, null, or undefined.");
			if (r) var o = e[Symbol.asyncDispose || Symbol["for"]("Symbol.asyncDispose")];
			if (void 0 === o && (o = e[Symbol.dispose || Symbol["for"]("Symbol.dispose")], r)) var t = o;
			if ("function" != typeof o) throw new TypeError("Object is not disposable.");
			t && (o = function o() {
				try {
					t.call(e);
				} catch (r) {
					return Promise.reject(r);
				}
			}), n.push({
				v: e,
				d: o,
				a: r
			});
		} else r && n.push({
			d: e,
			a: r
		});
		return e;
	}
	return {
		e,
		u: using.bind(null, !1),
		a: using.bind(null, !0),
		d: function d() {
			var o, t = this.e, s = 0;
			function next() {
				for (; o = n.pop();) try {
					if (!o.a && 1 === s) return s = 0, n.push(o), Promise.resolve().then(next);
					if (o.d) {
						var r = o.d.call(o.v);
						if (o.a) return s |= 2, Promise.resolve(r).then(next, err);
					} else s |= 1;
				} catch (r) {
					return err(r);
				}
				if (1 === s) return t !== e ? Promise.reject(t) : Promise.resolve();
				if (t !== e) throw t;
			}
			function err(n) {
				return t = t !== e ? new r(n, t) : n, next();
			}
			return next();
		}
	};
}
const version = npmPackage.version;
const { opFilterAsync } = operators;
async function runLint(cfg) {
	const reporter = new LintReporter(cfg.reporter, cfg.options);
	const configErrors = /* @__PURE__ */ new Set();
	const verboseLevel = calcVerboseLevel(cfg.options);
	const useColor = cfg.options.color ?? true;
	if (verboseLevel >= 1 && cfg.options.showPerfSummary) enablePerformanceMeasurements();
	const timer = getTimeMeasurer();
	const logDictRequests = truthy(getEnvironmentVariable("CSPELL_ENABLE_DICTIONARY_LOGGING"));
	if (logDictRequests) dictionaryCacheEnableLogging(true);
	const lintResult = await run();
	if (logDictRequests) await writeDictionaryLog();
	await reporter.result(lintResult);
	const elapsed = timer();
	if (getFeatureFlags().getFlag("timer") || verboseLevel >= 1 || cfg.options.showPerfSummary) console$2.error(`Elapsed Time: ${elapsed.toFixed(2)}ms`);
	return lintResult;
	async function run() {
		try {
			var _usingCtx$1 = _usingCtx();
			_usingCtx$1.u(measurePerf("runLint"));
			if (cfg.options.root) setEnvironmentVariable(ENV_CSPELL_GLOB_ROOT, cfg.root);
			const configInfo = await readConfig(cfg.configFile, cfg.root, cfg.options.stopConfigSearchAt);
			const processFileOptions = getProcessFileOptions(configInfo);
			if (cfg.options.defaultConfiguration !== void 0) configInfo.config.loadDefaultConfiguration = cfg.options.defaultConfiguration;
			configInfo.config = mergeSettings(configInfo.config, cfg.cspellSettingsFromCliOptions);
			const reporterConfig = clean({
				maxNumberOfProblems: configInfo.config.maxNumberOfProblems,
				maxDuplicateProblems: configInfo.config.maxDuplicateProblems,
				minWordLength: configInfo.config.minWordLength,
				...cfg.options,
				console: console$2
			});
			const reporters = cfg.options.reporter ?? configInfo.config.reporters;
			reporter.config = reporterConfig;
			await reporter.loadReportersAndFinalize(reporters);
			setLogger(getLoggerFromReporter(reporter, useColor));
			const globInfo = await determineGlobs(configInfo, cfg);
			const { fileGlobs, excludeGlobs } = globInfo;
			const hasFileLists = !!cfg.fileLists.length;
			if (!fileGlobs.length && !hasFileLists && !cfg.files?.length) return runResult();
			header(fileGlobs, excludeGlobs);
			checkGlobs(fileGlobs, reporter);
			if (verboseLevel > 1) reporter.info(`Config Files Found:\n    ${relativeToCwd(configInfo.source)}\n`, MessageTypes.Info);
			const configErrorCount = countConfigErrors(reporter, configInfo, processFileOptions);
			if (configErrorCount && cfg.options.exitCode !== false && !cfg.options.continueOnError) return runResult({ errors: configErrorCount });
			const { root } = cfg;
			try {
				const cacheSettings = await calcCacheSettings(configInfo.config, {
					...cfg.options,
					version
				}, root);
				const result = await processFiles(await determineFilesToCheck(configInfo, cfg, reporter, globInfo), {
					chalk: source_default,
					configInfo,
					cfg,
					verboseLevel,
					useColor,
					configErrors,
					userSettings: configInfo.config,
					lintReporter: reporter,
					cacheSettings
				});
				if (configErrorCount && cfg.options.exitCode !== false) result.errors ||= configErrorCount;
				return result;
			} catch (e) {
				const err = toApplicationError(e);
				reporter.error("Linter", err);
				return runResult({ errors: 1 });
			}
		} catch (_) {
			_usingCtx$1.e = _;
		} finally {
			_usingCtx$1.d();
		}
	}
	function header(files, cliExcludes) {
		if (verboseLevel < 2) return;
		const formattedFiles = files.length > 100 ? [...files.slice(0, 100), "..."] : files;
		reporter.info(unindent`
                cspell;
                Date: ${(/* @__PURE__ */ new Date()).toUTCString()}
                Options:
                    verbose:   ${yesNo(!!cfg.options.verbose)}
                    config:    ${cfg.configFile || "default"}
                    exclude:   ${wordWrapAnsiText(cliExcludes.join(", "), 60, "  ")}
                    files:     ${formattedFiles}
                    wordsOnly: ${yesNo(!!cfg.options.wordsOnly)}
                    unique:    ${yesNo(!!cfg.options.unique)}
                `, MessageTypes.Info);
	}
	function getProcessFileOptions(configInfo) {
		return {
			chalk: source_default,
			configInfo,
			cfg,
			verboseLevel,
			useColor,
			configErrors,
			userSettings: configInfo.config
		};
	}
}
function checkGlobs(globs, reporter) {
	globs.filter((g) => g.startsWith("'") || g.endsWith("'")).map((glob) => source_default.yellow(glob)).forEach((glob) => reporter.error("Linter", new CheckFailed(`Glob starting or ending with ' (single quote) is not likely to match any files: ${glob}.`)));
}
async function determineGlobs(configInfo, cfg) {
	const useGitignore = cfg.options.gitignore ?? configInfo.config.useGitignore ?? false;
	const gitignoreRoots = cfg.options.gitignoreRoot ?? configInfo.config.gitignoreRoot;
	const gitIgnore = useGitignore ? await generateGitIgnore(gitignoreRoots) : void 0;
	const cliGlobs = cfg.fileGlobs;
	const allGlobs = cliGlobs.length && cliGlobs || cfg.options.filterFiles !== false && configInfo.config.files || [];
	const combinedGlobs = await normalizeFileOrGlobsToRoot(allGlobs, cfg.root);
	const normalizedExcludes = normalizeGlobsToRoot(extractPatterns(cfg.excludes).map((p) => p.glob), cfg.root, true);
	return {
		allGlobs,
		gitIgnore,
		fileGlobs: combinedGlobs.filter((g) => !g.startsWith("!")),
		excludeGlobs: [...combinedGlobs.filter((g) => g.startsWith("!")).map((g) => g.slice(1)), ...normalizedExcludes],
		normalizedExcludes
	};
}
async function* filesToProcessAsync(filenames) {
	let sequence = 0;
	for await (const filename of filenames) yield {
		filename,
		sequence: sequence++
	};
}
function filesToProcess(files) {
	const filenames = [...files];
	const sequenceSize = filenames.length;
	return filenames.map((filename, sequence) => ({
		filename,
		sequence,
		sequenceSize
	}));
}
async function determineFilesToCheck(configInfo, cfg, reporter, globInfo) {
	async function _determineFilesToCheck() {
		const { fileLists } = cfg;
		const hasFileLists = !!fileLists.length;
		const { allGlobs, gitIgnore, fileGlobs, excludeGlobs, normalizedExcludes } = globInfo;
		const { root } = cfg;
		const globsToExcludeRaw = [...configInfo.config.ignorePaths || [], ...excludeGlobs];
		const globsToExclude = globsToExcludeRaw.filter((g) => !globPattern(g).startsWith("!"));
		if (globsToExclude.length !== globsToExcludeRaw.length) {
			const msg = `Negative glob exclusions are not supported: ${globsToExcludeRaw.map((g) => globPattern(g)).filter((g) => g.startsWith("!")).join(", ")}`;
			reporter.info(msg, MessageTypes.Warning);
		}
		const globMatcher = buildGlobMatcher(globsToExclude, root, true);
		const globOptions = {
			root,
			cwd: root,
			ignore: [...extractGlobsFromMatcher(globMatcher), ...normalizedExcludes],
			nodir: true
		};
		const enableGlobDot = cfg.enableGlobDot ?? configInfo.config.enableGlobDot;
		if (enableGlobDot !== void 0) globOptions.dot = enableGlobDot;
		const opFilterExcludedFiles = opFilter(filterOutExcludedFilesFn(globMatcher));
		const includeFilter = createIncludeFileFilterFn(allGlobs, root, enableGlobDot);
		const rawCliFiles = cfg.files?.map((file) => resolveFilename(file, root)).filter(includeFilter);
		const cliFiles = cfg.options.mustFindFiles ? rawCliFiles : rawCliFiles && pipeAsync(rawCliFiles, opFilterAsync(isFile));
		const foundFiles = hasFileLists ? concatAsyncIterables(cliFiles, await useFileLists(fileLists, includeFilter)) : cliFiles || await findFiles(fileGlobs, globOptions);
		const filtered = gitIgnore ? await gitIgnore.filterOutIgnored(foundFiles) : foundFiles;
		return isAsyncIterable$1(filtered) ? pipeAsync(filtered, opFilterExcludedFiles, filesToProcessAsync) : filesToProcess(pipeSync$1(filtered, opFilterExcludedFiles));
	}
	function isExcluded(filename, globMatcherExclude) {
		if (isBinaryFile(toFileURL(filename))) return true;
		const { root } = cfg;
		const absFilename = Path.resolve(root, filename);
		const r = globMatcherExclude.matchEx(absFilename);
		if (r.matched) {
			const { glob, source } = extractGlobSource(r.pattern);
			if (calcVerboseLevel(cfg.options) > 1) reporter.info(`Excluded File: ${Path.relative(root, absFilename)}; Excluded by ${glob} from ${source}`, MessageTypes.Info);
		}
		return r.matched;
	}
	function filterOutExcludedFilesFn(globMatcherExclude) {
		const excludeInfo = globMatcherExclude.patterns.map(extractGlobSource).map(({ glob, source }) => `Glob: ${glob} from ${source}`).filter(uniqueFn());
		if (calcVerboseLevel(cfg.options) > 1) reporter.info(`Exclusion Globs: \n    ${excludeInfo.join("\n    ")}\n`, MessageTypes.Info);
		return (filename) => !isExcluded(filename, globMatcherExclude);
	}
	return _determineFilesToCheck();
}
function extractGlobSource(g) {
	const { glob, rawGlob, source } = g;
	return {
		glob: rawGlob || glob,
		source
	};
}
function yesNo(value) {
	return value ? "Yes" : "No";
}
function getLoggerFromReporter(reporter, useColor) {
	const inspectOptions = { colors: useColor };
	const log = (...params) => {
		const msg = formatWithOptions(inspectOptions, ...params);
		reporter.info(msg, "Info");
	};
	const error = (...params) => {
		const msg = formatWithOptions(inspectOptions, ...params);
		reporter.error(msg, {
			message: "",
			name: "error",
			toString: () => ""
		});
	};
	const warn = (...params) => {
		const msg = formatWithOptions(inspectOptions, ...params);
		reporter.info(msg, "Warning");
	};
	return {
		log,
		warn,
		error
	};
}
async function generateGitIgnore(roots) {
	const root = (typeof roots === "string" ? [roots].filter((r) => !!r) : roots) || [];
	if (!root?.length) {
		const cwd = process.cwd();
		const repo = await findRepoRoot(cwd) || cwd;
		root.push(repo);
	}
	return new GitIgnore(root?.map((p) => Path.resolve(p)));
}
async function useFileLists(fileListFiles, filterFiles) {
	return pipeAsync(readFileListFiles(fileListFiles), opFilter(filterFiles), opFilterAsync(isNotDir));
}
function createIncludeFileFilterFn(includeGlobPatterns, root, dot) {
	if (!includeGlobPatterns?.length) return () => true;
	const patterns = includeGlobPatterns.map((g) => g === "." ? "/**" : g);
	const options = {
		root,
		mode: "include"
	};
	if (dot !== void 0) options.dot = dot;
	const globMatcher = new GlobMatcher(patterns, options);
	return (file) => globMatcher.match(file);
}
async function* concatAsyncIterables(...iterables) {
	for (const iter of iterables) {
		if (!iter) continue;
		yield* iter;
	}
}
async function writeDictionaryLog() {
	const fields = (getEnvironmentVariable("CSPELL_ENABLE_DICTIONARY_LOG_FIELDS") || "time, word, value").split(",").map((f) => f.trim());
	const data = fields.join(", ") + "\n" + dictionaryCacheGetLog().filter((d) => d.method === "has").map((d) => fields.map((f) => f in d ? `${d[f]}` : "").join(", ")).join("\n") + "\n";
	await writeFileOrStream(getEnvironmentVariable("CSPELL_ENABLE_DICTIONARY_LOG_FILE") || "cspell-dictionary-log.csv", data);
}
function globPattern(g) {
	return typeof g === "string" ? g : g.glob;
}
function calcVerboseLevel(options) {
	return options.verboseLevel ?? (options.verbose ? 1 : 0);
}
const defaultContextRange = 20;
var LintRequest = class {
	locale;
	configFile;
	excludes;
	root;
	showContext;
	enableGlobDot;
	fileLists;
	files;
	cspellSettingsFromCliOptions;
	maxFileSize;
	constructor(fileGlobs, options, reporter) {
		this.fileGlobs = fileGlobs;
		this.options = options;
		this.reporter = reporter;
		this.root = Path.resolve(options.root || process.cwd());
		this.configFile = options.config;
		this.excludes = calcExcludeGlobInfo(this.root, options.exclude);
		this.locale = options.locale ?? options.local ?? "";
		this.enableGlobDot = options.dot;
		this.showContext = Math.max(options.showContext === true ? defaultContextRange : options.showContext ? options.showContext : 0, 0);
		this.fileLists = (options.fileList ?? options.fileLists) || [];
		this.files = mergeFiles(options.file, options.files);
		const noConfigSearch = options.configSearch === false ? true : options.configSearch === true ? false : void 0;
		const languageSettings = [{
			languageId: "*",
			locale: "*",
			dictionaries: [...(options.disableDictionary ?? []).map((d) => `!${d}`), ...(options.dictionary ?? []).map((d) => `!!${d}`)]
		}];
		this.cspellSettingsFromCliOptions = {
			...noConfigSearch !== void 0 ? { noConfigSearch } : {},
			...extractUnknownWordsConfig(options),
			languageSettings
		};
		this.maxFileSize = options.maxFileSize ? sizeToNumber(options.maxFileSize) : void 0;
	}
};
function mergeFiles(a, b) {
	const files = merge(a, b);
	if (!files) return void 0;
	return [...new Set(files.flatMap((a) => a.split("\n").map((a) => a.trim())).filter((a) => !!a))];
}
function merge(a, b) {
	if (!a) return b;
	if (!b) return a;
	return [...a, ...b];
}
function extractUnknownWordsConfig(options) {
	const config = {};
	if (!options.report) return config;
	switch (options.report) {
		case "all":
			config.unknownWords = unknownWordsChoices.ReportAll;
			break;
		case "simple":
			config.unknownWords = unknownWordsChoices.ReportSimple;
			break;
		case "typos":
			config.unknownWords = unknownWordsChoices.ReportCommonTypos;
			break;
		case "flagged":
			config.unknownWords = unknownWordsChoices.ReportFlagged;
			break;
	}
	return config;
}
function fixLegacy(opts) {
	const { local, ...rest } = opts;
	if (local && !rest.locale) rest.locale = local;
	return rest;
}
var SimpleRepl = class {
	beforeEach;
	completer;
	_history;
	rl;
	constructor(prompt = "> ") {
		this.prompt = prompt;
		this._history = [];
		this.rl = readline.createInterface({
			input: process.stdin,
			output: process.stdout,
			prompt,
			history: this._history,
			historySize: 100,
			completer: (line) => this._completer(line)
		});
		this.rl.on("history", (h) => (this._history = h, void 0));
	}
	question(query) {
		return new Promise((resolve) => {
			this.rl.question(query, resolve);
		});
	}
	_completer(line) {
		if (this.completer) return this.completer(line);
		return [this._history.filter((h) => h.startsWith(line)), line];
	}
	get history() {
		return this._history;
	}
	[Symbol.asyncIterator]() {
		const next = () => {
			if (this.beforeEach) this.beforeEach();
			return this.question(this.prompt).then((value) => ({ value })).catch(() => ({
				done: true,
				value: void 0
			}));
		};
		return { next };
	}
};
function lint$1(fileGlobs, options, reporter) {
	options = fixLegacy(options);
	const unknownWordsConfig = extractUnknownWordsConfig(options);
	const useOptions = {
		...options,
		...unknownWordsConfig
	};
	const reporterOptions = {
		...useOptions,
		console: console$2
	};
	return runLint(new LintRequest(fileGlobs, useOptions, finalizeReporter(reporter) ?? getReporter({
		...useOptions,
		fileGlobs
	}, reporterOptions)));
}

//#endregion
//#region src/spell.ts
/**
* Spell check files.
* @param globs - files or glob patterns to check
* @param root - the root directory to scan
* @param reporter - reporter to use.
*/
async function lint(globs, lintOptions, reporter) {
	const { root, config, checkDotFiles, files, showSuggestions, report } = lintOptions;
	const options = {
		root,
		config,
		files,
		mustFindFiles: !files,
		showSuggestions,
		report
	};
	if (checkDotFiles) options.dot = true;
	else if (checkDotFiles === false) options.dot = false;
	await lint$1(globs, options, reporter);
}

//#endregion
//#region src/checkSpelling.ts
async function checkSpellingForContext(params, context) {
	const files = await gatherGitCommitFilesFromContext(context);
	return await checkSpelling(params, await gatherFileGlobsFromContext(context), files);
}
async function gatherGitCommitFilesFromContext(context) {
	if (context.useEventFiles) {
		const eventFiles = await gatherFiles(context);
		if (!eventFiles) return void 0;
		const root = await gitRoot();
		return [...eventFiles].map((f) => path.resolve(root, f));
	}
}
async function gatherFileGlobsFromContext(context) {
	if (context.useCSpellFiles) return;
	return [...new Set(context.globs.split("\n").map((a) => a.trim()).filter((a) => !!a))];
}
/**
* Gather the set of files to be spell checked.
* @param context Context
*/
async function gatherFiles(context) {
	const logger = getDefaultLogger();
	const eventName = context.githubContext.eventName;
	try {
		switch (eventName) {
			case "push": return new Set(await gitListFilesForPush(context.githubContext.payload));
			case "pull_request": return new Set(await gitListFilesForPullRequest(context.githubContext.payload));
			default:
				logger.warning(`Unsupported event: ${eventName}. Using files from latest commit.`);
				return new Set(await gitListFiles("HEAD"));
		}
	} catch (e) {
		logger.error(toError$5(e));
	}
}
async function checkSpelling(params, globs, files) {
	const options = {
		root: params.root || process.cwd(),
		config: params.config || void 0,
		checkDotFiles: checkDotMap[params.check_dot_files],
		files,
		showSuggestions: params.suggestions === "true",
		report: params.report
	};
	const reporterOptions = {
		verbose: params.verbose === "true",
		treatFlaggedWordsAsErrors: params.treat_flagged_words_as_errors === "true",
		summary: params.summary === "true"
	};
	const collector = new CSpellReporterForGithubAction(params.inline, reporterOptions);
	await lint(globs || [], options, collector.reporter);
	return collector.result;
}

//#endregion
//#region src/utils.ts
function tf(value) {
	let v = value;
	const mapValues = {
		true: "true",
		t: "true",
		false: "false",
		f: "false",
		"0": "false",
		"1": "true"
	};
	v = typeof v === "boolean" || typeof v === "number" ? v ? "true" : "false" : v;
	v = v?.toString();
	v = v?.toLowerCase();
	v = mapValues[v || ""] || value;
	return v;
}

//#endregion
//#region src/getActionParams.ts
function getActionParams() {
	return applyDefaults({
		files: getInput("files"),
		incremental_files_only: tf(getInput("incremental_files_only")),
		config: getInput("config"),
		root: getInput("root"),
		inline: getInput("inline").toLowerCase(),
		treat_flagged_words_as_errors: tf(getInput("treat_flagged_words_as_errors")),
		strict: tf(getInput("strict")),
		verbose: tf(getInput("verbose")),
		check_dot_files: tf(getInput("check_dot_files")),
		use_cspell_files: tf(getInput("use_cspell_files")),
		suggestions: tf(getInput("suggestions")),
		report: getInput("report").toLowerCase(),
		summary: tf(getInput("summary") || "false")
	});
}

//#endregion
//#region src/action.ts
const core = {
	debug: debug$1,
	error,
	info,
	warning
};
const defaultGlob = "**";
const supportedIncrementalEvents = new Set(["push", "pull_request"]);
function friendlyEventName(eventName) {
	switch (eventName) {
		case "push": return "Push";
		case "pull_request": return "Pull Request";
		default: return `'${eventName}'`;
	}
}
function isSupportedEvent(eventName) {
	return supportedIncrementalEvents.has(eventName);
}
/**
* Run the action based upon the githubContext.
* @param githubContext
* @param octokit
* @returns a promise that resolves to `true` if no issues were found.
*/
async function action(githubContext) {
	const params = getActionParams();
	validateActionParams(params, core.error);
	const eventName = githubContext.eventName;
	if (params.incremental_files_only === "true" && !isSupportedEvent(eventName)) {
		params.files = params.files || defaultGlob;
		core.warning("Unable to determine which files have changed, checking files: " + params.files);
		params.incremental_files_only = "false";
	}
	params.files = params.files || (params.incremental_files_only !== "true" ? defaultGlob : "");
	const dot = !!checkDotMap[params.check_dot_files];
	const context = {
		githubContext,
		globs: params.files,
		useEventFiles: params.incremental_files_only === "true",
		useCSpellFiles: params.use_cspell_files === "true",
		dot
	};
	core.info(friendlyEventName(eventName));
	const result = await checkSpellingForContext(params, context);
	if (!result.files && !context.useEventFiles) core.error("No files found to check.");
	const message = `Files checked: ${result.files}, Issues found: ${result.issues} in ${result.filesWithIssues.size} files.`;
	core.info(message);
	outputResult(result);
	const fnS = (n) => n === 1 ? "" : "s";
	if (params.strict === "true" && result.issues) {
		const filesWithIssues = result.filesWithIssues.size;
		setFailed(`${result.issues} spelling issue${fnS(result.issues)} found in ${filesWithIssues} of the ${result.files} file${fnS(result.files)} checked.`);
	}
	if (result.errors) setFailed("Errors encountered.");
	return !(result.issues + result.errors);
}
function outputResult(runResult) {
	const result = normalizeResult(runResult);
	setOutput("success", result.success);
	setOutput("errors", result.errors);
	setOutput("number_of_files_checked", result.number_of_files_checked);
	setOutput("number_of_issues", result.number_of_issues);
	setOutput("number_of_files_with_issues", result.files_with_issues.length);
	setOutput("files_with_issues", result.files_with_issues);
	setOutput("number_of_files_skipped", result.number_of_files_skipped);
	setOutput("number_of_files_cached", result.number_of_files_cached);
	setOutput("result", result);
}
function normalizeResult(result) {
	const { issues: number_of_issues, files, filesWithIssues, skippedFiles = 0, cachedFiles = 0 } = result;
	return {
		success: !number_of_issues && !result.errors,
		errors: result.errors,
		number_of_issues,
		number_of_files_checked: files - skippedFiles,
		number_of_files_skipped: skippedFiles,
		number_of_files_cached: cachedFiles,
		files_with_issues: normalizeFiles(filesWithIssues).slice(0, 1e3)
	};
}
function normalizeFiles(files) {
	const cwd = process.cwd();
	return [...files].map((file) => path.relative(cwd, file));
}

//#endregion
//#region src/actions/github/context.ts
var Context = class {
	/**
	* Webhook payload object that triggered the workflow
	*/
	payload;
	eventName;
	sha;
	ref;
	workflow;
	action;
	actor;
	job;
	runAttempt;
	runNumber;
	runId;
	apiUrl;
	serverUrl;
	graphqlUrl;
	/**
	* Hydrate the context from the environment
	*/
	constructor() {
		this.payload = {};
		if (process.env.GITHUB_EVENT_PATH) if (existsSync(process.env.GITHUB_EVENT_PATH)) this.payload = JSON.parse(readFileSync(process.env.GITHUB_EVENT_PATH, { encoding: "utf8" }));
		else {
			const path = process.env.GITHUB_EVENT_PATH;
			process.stdout.write(`GITHUB_EVENT_PATH ${path} does not exist${EOL}`);
		}
		this.eventName = process.env.GITHUB_EVENT_NAME;
		this.sha = process.env.GITHUB_SHA;
		this.ref = process.env.GITHUB_REF;
		this.workflow = process.env.GITHUB_WORKFLOW;
		this.action = process.env.GITHUB_ACTION;
		this.actor = process.env.GITHUB_ACTOR;
		this.job = process.env.GITHUB_JOB;
		this.runAttempt = parseInt(process.env.GITHUB_RUN_ATTEMPT, 10);
		this.runNumber = parseInt(process.env.GITHUB_RUN_NUMBER, 10);
		this.runId = parseInt(process.env.GITHUB_RUN_ID, 10);
		this.apiUrl = process.env.GITHUB_API_URL ?? `https://api.github.com`;
		this.serverUrl = process.env.GITHUB_SERVER_URL ?? `https://github.com`;
		this.graphqlUrl = process.env.GITHUB_GRAPHQL_URL ?? `https://api.github.com/graphql`;
	}
	get issue() {
		const payload = this.payload;
		return {
			...this.repo,
			number: (payload.issue || payload.pull_request || payload).number
		};
	}
	get repo() {
		if (process.env.GITHUB_REPOSITORY) {
			const [owner, repo] = process.env.GITHUB_REPOSITORY.split("/");
			return {
				owner,
				repo
			};
		}
		if (this.payload.repository) return {
			owner: this.payload.repository.owner.login,
			repo: this.payload.repository.name
		};
		throw new Error("context.repo requires a GITHUB_REPOSITORY environment variable like 'owner/repo'");
	}
};

//#endregion
//#region src/main.ts
async function run() {
	try {
		info("cspell-action");
		await action(new Context());
		info("Done.");
		return;
	} catch (error) {
		console.error(error);
		const err = toError$5(error);
		setFailed(err.message);
		return err;
	}
}

//#endregion
//#region src/main_root.ts
run();

//#endregion
export {  };